<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[POSIX信号量]]></title>
    <url>%2F2019%2F04%2F22%2FPOSIX%E4%BF%A1%E5%8F%B7%E9%87%8F%2F</url>
    <content type="text"><![CDATA[POSIX信号量的操作POSIX信号量有两种：有名信号量和无名信号量，无名信号量也被称作基于内存的信号量。有名信号量通过IPC名字进行进程间的同步，而无名信号量如果不是放在进程间的共享内存区中，是不能用来进行进程间同步的，只能用来进行线程同步。POSIX三种操作创建信号量创建的过程还要求初始化信号量的值。根据信号量取值（代表可用资源的数目）的不同，POSIX信号量还可以分为：二值信号量：信号量的值只有0和1，这和互斥量很类型，若资源被锁住，信号量的值为0，若资源可用，则信号量的值为1；计数信号量：信号量的值在0到一个大于1的限制值（POSIX指出系统的最大限制值至少要为32767）。该计数表示可用的资源的个数。等待信号量(wait)/P操作该操作会检查信号量的值，如果其值小于或等于0，那就阻塞，直到该值变成大于0，然后等待进程将信号量的值减1，进程获得共享资源的访问权限。为原子操作。挂出一个信号量(post)/V操作该操作将信号量的值加1，如果有进程阻塞着等待该信号量，那么其中一个进程将被唤醒。POSIX信号量函数接口有名信号量的创建和删除创建1234567#include &lt;semaphore.h&gt; sem_t *sem_open(const char *name, int oflag);sem_t *sem_open(const char *name, int oflag, mode_t mode, unsigned int value); //成功返回信号量指针，失败返回SEM_FAILED信号量通过name参数即信号量的名字来进行标识oflag参数可以为：0，O_CREAT，O_EXCL，0表示打开一个已存在的信号量，如果为O_CREAT，表示如果信号量不存在就创建一个信号量，如果存在则打开被返回。此时mode和value需要指定。如果为O_CREAT | O_EXCL，表示如果信号量已存在会返回错误。mode参数用于创建信号量时，表示信号量的权限位，和open函数一样包括：S_IRUSR，S_IWUSR，S_IRGRP，S_IWGRP，S_IROTH，S_IWOTH。value表示创建信号量时，信号量的初始值。删除12345#include &lt;semaphore.h&gt; int sem_close(sem_t *sem);int sem_unlink(const char *name); //成功返回0，失败返回-1sem_close互斥量和信号量的差别互斥量必须由给它上锁的线程解锁。而信号量不需要由等待它的线程进行挂出，可以在其他进程进行挂出操作。互斥量要么被锁住，要么是解开状态，只有这两种状态。而信号量的值可以支持多个进程成功进行wait操作。信号量的挂出操作总是被记住，因为信号量有一个计数值，挂出操作总会将该计数值加1，然而当向条件变量发送一个信号时，如果没有线程等待在条件变量，那么该信号会丢失。]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>Linux编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下的信号量机制与编程]]></title>
    <url>%2F2019%2F04%2F22%2FLinux%E4%B8%8B%E7%9A%84%E4%BF%A1%E5%8F%B7%E9%87%8F%E6%9C%BA%E5%88%B6%E4%B8%8E%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[信号量当我们在多用户系统，多进程系统，或是两者混合的系统中使用线程操作编写程序时，我们经常会发现我们有段临界代码，在此处我们需要保证一个进程（或是一个线程的执行）需要排他的访问一个资源。为了解决这个问题，引用了信号量机制，我们可以使用互斥或信号量来控制一个多线程程序对于临界区的访问。信号量是一个特殊的变量，他是一个整数，并且只有两个操 作可以使得其值增加：等待(wait)与信号(signal)。用于等待(wait)的P(信号量变量)用于信号(signal)的V(信号量变量)二值信号量二值信号量使是只有0和1两个值的变量假如有一个信号量为mutex，有如下两个操作P(mutex)/wait(mutex) 若mutex大于0,mutex减为0;若mutex等于0,则挂起该进程V(mutex)/signal(mutex) 若有进程被挂起等待mutex则释放mutex使被挂起的进程执行,若没有,则mutex加到1mutex取值只能为1/0也叫互斥信号量,可以用其管理临界区资源的控制权Linux中的信号量工具信号量函数信号量函数定义:1234#include &lt;sys/sem.h&gt;/*有可能还需要包含sys/types.h与sys/ipc.h文件*/int semctl(int sem_id, int sem_num, int command, ...);int semget(key_t key, int num_sems, int sem_flags);int semop(int sem_id, struct sembuf *sem_ops, size_t num_sem_ops);这些函数用于操作信号量值数组semget函数semget的作用： 创建一个新信号量 或者 取得一个已有的信号量1int semget(key_t key, int num_sems, int sem_flags);key是整数值(唯一非零),可以任意指定一个正整数,semget可以根据key,新创建一个信号量,返回改信号量的标识,不相关的进程可以通过它访问这个创建的信号量,代表程序可能会使用某个资源.如果在两个进程中使用相同的key则key将负责两个进程的协调工作.PS:​ 同一个key值返回的信号量标识相同​ 不同的key值会创建不同的信号量,且信号量之间没有任何关系num_sems表示需要的信号量数目,一般为1sem_flags是一组标志,与fopen函数的 “w” “b” “r”类似,最低的9位二进制数字代表了这个信号量的权限信息.如IPC_CREATE | 0666,这些标记可以与 IPC_CREAT进行或操作来创建新的信号量,同时又可以用于取一个已有的信号量,使用IPC_CREAT | IPC_EXCL 来确保新建信号量，如果信号量已经有了会返回错误。PS:​ IPC_CREAT 如果共享内存不存在，则创建一个共享内存，否则打开操作。​ IPC_EXCL 只有在共享内存不存在的时候，新的共享内存才建立，否则就产生错误。semget函数成功返回一个相应信号量标识符(非0),失败返回-1.semop函数semop函数用于对信号量进行操作。1int semop(int sem_id, struct sembuf *sem_opa, size_t num_sem_ops);sem_id,表示对哪一个信号量进行操作,由semget函数返回sembuf *sem_ops123456789struct sembuf &#123;short sem_num; //要处理的信号量的下标,即指定对哪个信号灯进行操作(0,1,2...)若为二值信号量则为0short sem_op; //要执行的操作,1表示加一,-1表示减一short sem_flg; //操作标志,通常设置为SEM_UNDO。这会使得操作系统跟踪当前进程对信号量所 //做的改变，而且如果进程终止而没有释放这个信号量， 如果信号量为这个进 //程所占有，这个标记可以使得操作系统自动释放这个信号量。&#125;size_t num_sem_ops表示操作次数一般为1semctl函数semctl用于直接控制信号量的信息，例如初始化一个值或删除信号量。1int semctl(int sem_id, int sem_num, int command, ...);sem_id,表示对哪一个信号量进行操作,由semget函数返回sem_num,要处理的信号量的下标,即指定对哪个信号灯进行操作(0,1,2…)若为二值信号量则为0command,表示要执行的动作SETVAL：用于初始化信号量为一个已知的值。所需要的值作为联合semun.val成员来传递。在信号量第一次使用之前需要设置信号量。IPC_RMID：当信号量不再需要时用于删除一个信号量标识。union semun123456789union semun&#123;int val;struct semid_ds *buf;unsigned short *array;&#125;;这个声明一般包含在sem.h里面，也有可能没有，没有的话需要自己声明。根据command的不同，返回值也不同。对于 SETVAL和IPC_RMID 成功返回0 失败返回-1信号量的使用创建信号量1234int sem_id;sem_id = semget((key_t)1234, 2, 0666 | IPC_CREAT);if (sem_id == -1) fprintf(stderr, "Failed to create semapore\n");设置信号量初值12345678910int set_semvalue(int sem_id, int index, int value)//index为信号量中的第几个信号灯&#123; union semun sem_union; sem_union.val = value; if (semctl(sem_id, index, SETVAL, sem_union) == -1) return 0; else return 1;&#125;删除信号量12345void del_semvalue(int sem_id)&#123; if (semctl(sem_id, 0, IPC_RMID) == -1) fprintf(stderr, "Failed to delete semapore\n");&#125;P操作P操作是通过调用semop函数实现的。123456789101112131415int P(int sem_id, int index)&#123; struct sembuf sem_b; sem_b.sem_num = index; sem_b.sem_op = -1; sem_b.sem_flg = SEM_UNDO; if (semop(sem_id, &amp;sem_b, 1) == -1) &#123; fprintf(stderr, "semapore_p failed\n"); return 0; &#125; return 1;&#125;V操作123456789101112131415int V(int sem_id, int index)&#123; struct sembuf sem_b; sem_b.sem_num = index; sem_b.sem_op = 1; sem_b.sem_flg = SEM_UNDO; if (semop(sem_id, &amp;sem_b, 1) == -1) &#123; fprintf(stderr, "semapore_v failed\n"); return 0; &#125; return 1;&#125;]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>Linux编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python爬虫框架Scrapy(二)]]></title>
    <url>%2F2019%2F04%2F08%2Fpython%E7%88%AC%E8%99%AB%E6%A1%86%E6%9E%B6Scrapy-%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[爬虫编写item读取数据12345678910tr_list = response.xpath("//table[@class='tablelist']/tr")[1:-1] for tr in tr_list: item = &#123;&#125; item['title'] = tr.xpath("./td[1]/a/text()").extract_first() item['position'] = tr.xpath("./td[2]/text()").extract_first() item['number'] = tr.xpath("./td[3]/text()").extract_first() item['place'] = tr.xpath("./td[4]/text()").extract_first() item['publish_date'] = tr.xpath("./td[5]/text()").extract_first() logging.warning(item) yield item构造Request对象实现翻页12345678#下一页URL地址 next_url = response.xpath("//a[@id='next']/@href").extract_first() if next_url != "javascript:;": next_url = "http://hr.tencent.com/" + next_url yield scrapy.Request( next_url, callback=self.parse )1scrapy.Request(url[,callback,method='GET',headers,body,cookies,meta,dont_filter=False])构造Request对象实现详情页爬取12def parse_detail(self,response): ...]]></content>
      <categories>
        <category>python爬虫</category>
      </categories>
      <tags>
        <tag>scrapy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python爬虫框架Scrapy(一)]]></title>
    <url>%2F2019%2F04%2F07%2Fpython%E7%88%AC%E8%99%AB%E6%A1%86%E6%9E%B6Scrapy-%E4%B8%80%2F</url>
    <content type="text"><![CDATA[Scrapy框架简介-Spider MiddlewaresSpider只对response进行过滤处理，不对数据进行处理初始化创建项目1scrapy startproject myspider生成爬虫123scrapy genspider response response.cn#@response 爬虫名称#@response.cn 爬虫域名范围在生成的response.py文件中包含以下代码12345678910111213# -*- coding: utf-8 -*-import scrapyclass PixviSpider(scrapy.Spider): name = 'pixvi' #爬虫名 allowed_domains = ['pixiv.net'] #爬虫范围，需要爬取的url地址你必须在这个域名下 start_urls = ['http://www.pixiv.net/'] #初始响应网站，需要有内容爬取的内容 def parse(self, response):#parse函数名称不能修改 #处理start_ urls对应的响应 item = response.xpath() #返回的是一个含有selector对象的列表 yield item#生成器可以遍历不占用太多空间运行爬虫在项目文件夹下运行1scrapy crawl responsepipline生成的item数据会传入pipline中，在使用pipline之前要先在settings.py中去掉可以创建多个pipline：​ 1.可能有多个爬虫​ 2.可能爬取的数据需要不同的处理（如写入不同的数据库）123class Test1Pipeline(object): def process_item(self, item, spider):#实现存储方法，函数名同样不能改变 return item如有多个pipline，每个pipline都要return item以传入下一个管道，不能缺少return123#ITEM_PIPELINES = &#123;# 'test1.pipelines.Test1Pipeline': 300,#&#125;的注释。300表示举例pipline的远近，越小越先执行若有多个爬虫，则可以​ 1.在item中加入item[&#39;come_from&#39;] = &#39;spider1&#39;​ if item[&#39;come_from&#39;] == &#39;spider1&#39;:​ …​ 2.在pipline.py中直接用​ if spider.name == &#39;spider1&#39;:​ …logging模块logging模块是输出日志的模块可以在settings.py中加入LOG_LEVEL = &#39;WARNING&#39;来使程序输出warning及以上级别的日志logging模块可以代替print输出数据并知晓数据来自哪一个文件1234import logginglogger = logging.getlogger(__name__)logger.warning(item)运行结果12345672019-04-08 17:30:19 [test1.spiders.pixvi] WARNING: &#123;'come_from': 'pixvi'&#125;2019-04-08 17:30:19 [test1.pipelines] WARNING: ----------2019-04-08 17:30:19 [test1.spiders.pixvi] WARNING: &#123;'come_from': 'pixvi'&#125;2019-04-08 17:30:19 [test1.pipelines] WARNING: ----------2019-04-08 17:30:19 [test1.spiders.pixvi] WARNING: &#123;'come_from': 'pixvi'&#125;2019-04-08 17:30:19 [test1.pipelines] WARNING: ----------...即可以打印输出内容的时间，文件来源，等级，内容在settings.py中加入LOG_FILE = ./XXX.log即可把日志内容保存在文件中]]></content>
      <categories>
        <category>python爬虫</category>
      </categories>
      <tags>
        <tag>scrapy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django学习笔记（三）]]></title>
    <url>%2F2019%2F03%2F12%2FDjango%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89%2F</url>
    <content type="text"><![CDATA[初试API1$python manage.py shell创建一个管理员账号1$python manage.py createsuperuser]]></content>
      <categories>
        <category>Web学习</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django学习笔记（二）]]></title>
    <url>%2F2019%2F03%2F12%2FDjango%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Django基本命令创建project1$django-admin startproject myproject进入myproject目录使用开发服务器1$ python manage.py runserver会报错1You&apos;re accessing the development server over HTTPS, but it only supports HTTP.django 默认的runserver使用的是http协议，如果需要https协议，需要以下3个库123django-extensions django-werkzeug-debugger-runserver pyOpenSSL安装12345pip install django-extensionspip install django-werkzeug-debugger-runserverpip install pyOpenSSL配置django的settings.py文件在INSTALLED_APPS下添加123'werkzeug_debugger_runserver','django_extensions',在终端以https的方式运行1$python manage.py runserver_plus --cert server.crt创建APP1$ python manage.py startapp learn创建数据库表或更改数据库表或字段1234# 1. 创建更改的文件python manage.py makemigrations# 2. 将生成的py文件应用到数据库python manage.py migrate清空数据库1$python manage.py flush创建超级管理员123456$python manage.py createsuperuser# 按照提示输入用户名和对应的密码就好了邮箱可以留空，用户名和密码必填# 修改 用户密码可以用：$python manage.py changepassword usernameDjango项目环境终端1$python manage.py shell数据库命令行1$python manage.py dbshellDjango 会自动进入在settings.py中设置的数据库，如果是 MySQL 或 postgreSQL,会要求输入数据库用户密码。在这个终端可以执行数据库的SQL语句。如果对SQL比较熟悉，可能喜欢这种方式。视图在/views.py中输入代码12345from django.http import HttpResponsedef index(request): return HttpResponse("Hello, world. You're at the learn index.")如果想看见效果，我们需要将一个 URL 映射到它为了创建 URLconf，请在 learn目录里新建一个 urls.py 文件。在urls.py中输入代码1234567891011121314151617181920212223242526from django.urls import pathfrom . import viewsurlpatterns = [ path('', views.index, name='index'),]'''path函数有四个参数两个必须参数：route 和 view，两个可选参数：kwargs 和 name。@route:route 是一个匹配 URL 的准则（类似正则表达式）。当 Django 响应一个请求时，它会从 urlpatterns 的第一项开始，按顺序依次匹配列表中的项，直到找到匹配的项。这些准则不会匹配 GET 和 POST 参数或域名。例如，URLconf 在处理请求 https://www.example.com/myapp/ 时，它会尝试匹配 myapp/ 。处理请求 https://www.example.com/myapp/?page=3 时，也只会尝试匹配 myapp/。@view:当 Django 找到了一个匹配的准则，就会调用这个特定的视图函数，并传入一个 HttpRequest 对象作为第一个参数，被“捕获”的参数以关键字参数的形式传入。稍后，我们会给出一个例子。@kwargs:任意个关键字参数可以作为一个字典传递给目标视图函数。@name:为你的 URL 取名能使你在 Django 的任意地方唯一地引用它，尤其是在模板中。这个有用的特性允许你只改一个文件就能全局地修改某个 URL 模式。'''下一步是要在根 URLconf 文件中指定我们创建的 learn.urls 模块。在 vx/urls.py 文件的 urlpatterns 列表里插入一个 include()， 如下：1234567from django.contrib import adminfrom django.urls import include, pathurlpatterns = [ path('learn/', include('learn.urls')), path('admin/', admin.site.urls),]函数 include()允许引用其它 URLconfs。每当 Django 遇到 :func：~django.urls.include时，它会截断与此项匹配的 URL 的部分，并将剩余的字符串发送到 URLconf 以供进一步处理。我们设计 include()的理念是使其可以即插即用。因为应用有它自己的URLconf( vx/urls.py )，他们能够被放在&quot;/vx/&quot; ， &quot;/fun_vx/&quot; ，&quot;/content/vx/&quot;，或者其他任何路径下，这个应用都能够正常工作。当包括其它 URL 模式时你应该总是使用 include() ， admin.site.urls 是唯一例外。运行1$python manage.py runserver_plus --cert server.crt访问.../learn即可看见简单的文字视图数据库配置vx/settings.py是Django项目设置的python模块。通常，这个配置文件使用 SQLite 作为默认数据库。如果你不熟悉数据库，或者只是想尝试下 Django，这是最简单的选择。Python 内置 SQLite，所以你无需安装额外东西来使用它。当你开始一个真正的项目时，你可能更倾向使用一个更具扩展性的数据库，例如 PostgreSQL，避免中途切换数据库这个令人头疼的问题。如果你想使用其他数据库，你需要安装合适的 database bindings ，然后改变设置文件中 DATABASES &#39;default&#39; 项目中的一些键值：ENGINE – 可选值有 &#39;django.db.backends.sqlite3&#39;，&#39;django.db.backends.postgresql&#39;，&#39;django.db.backends.mysql&#39;，或 &#39;django.db.backends.oracle&#39;。其它 可用后端。NAME - 数据库的名称。如果使用的是 SQLite，数据库将是你电脑上的一个文件，在这种情况下， NAME 应该是此文件的绝对路径，包括文件名。默认值 os.path.join(BASE_DIR, &#39;db.sqlite3&#39;) 将会把数据库文件储存在项目的根目录。在编辑/settings之前，将TIME_ZONE设置为自己所在时区通常， INSTALLED_APPS 默认包括了以下 Django 的自带应用：django.contrib.admin – 管理员站点， 你很快就会使用它。django.contrib.auth – 认证授权系统。django.contrib.contenttypes – 内容类型框架。django.contrib.sessions – 会话框架。django.contrib.messages – 消息框架。django.contrib.staticfiles – 管理静态文件的框架。这些应用被默认启用是为了给常规项目提供方便。默认开启的某些应用需要至少一个数据表，所以，在使用他们之前需要在数据库中创建一些表。1$python manage.py migrate创造模型在 Django 里写一个数据库驱动的 Web 应用的第一步是定义模型 - 也就是数据库结构设计和附加的其它元数据。在learn/models.py中创建python类激活模型创建模型的代码给了 Django 很多信息，通过这些信息，Django 可以：为这个应用创建数据库 schema（生成 CREATE TABLE 语句）。创建可以与 Question 和 Choice 对象进行交互的 Python 数据库 API。但是首先得把 learn 应用安装到我们的项目里。为了在我们的工程中包含这个应用，我们需要在配置类 INSTALLED_APPS 中添加设置。因为 learnConfig 类写在文件 learn/apps.py 中，所以它的点式路径是 &#39;learn.apps.learnConfig&#39;。在文件 mysite/settings.py中 INSTALLED_APPS 子项添加点式路径。运行命令进行模型迁移1$python manage.py makemigrations learn运行migrate命令在数据库里创建新定义的模型的数据表1$python manage.py migrate迁移是非常强大的功能，它能让你在开发过程中持续的改变数据库结构而不需要重新删除和创建表 - 它专注于使数据库平滑升级而不会丢失数据。我们会在后面的教程中更加深入的学习这部分内容，现在，你只需要记住，改变模型需要这三步：编辑 models.py 文件，改变模型。运行 python manage.py makemigrations 为模型的改变生成迁移文件。运行 python manage.py migrate 来应用数据库迁移。]]></content>
      <categories>
        <category>Web学习</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django学习笔记（一）]]></title>
    <url>%2F2019%2F03%2F12%2FDjango%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Django文件urls.py网址入口，关联到对应的views.py中的一个函数（或者generic类），访问网址就对应一个函数。views,py处理用户发出的请求，从urls.py中对应过来, 通过渲染templates中的网页可以将显示内容，比如登陆后的用户名，用户请求的数据，输出到网页。models.py与数据库操作相关，存入或读取数据时用到这个，当然用不到数据库的时候 你可以不使用。forms.py表单，用户在浏览器上输入数据提交，对数据的验证工作以及输入框的生成等工作，当然你也可以不使用。templates 文件夹views.py 中的函数渲染templates中的Html模板，得到动态内容的网页，当然可以用缓存来提高速度。admin.py后台，可以用很少量的代码就拥有一个强大的后台。settings.pyDjango 的设置，配置文件，比如 DEBUG 的开关，静态文件的位置等。Django安装DjangoWindows下在Anaconda Prompt中用pip install Django安装虚拟环境依赖安装（搭建多个开发环境）Windows下Anaconda Prompt中用pip install virtualenv virtualenvwrapper-win安装虚拟环境使用方法mkvirtualenv zqxt：创建运行环境zqxtworkon zqxt: 工作在 zqxt 环境 或 从其它环境切换到 zqxt 环境deactivate: 退出终端环境rmvirtualenv ENV：删除运行环境ENVmkproject mic：创建mic项目和运行环境micmktmpenv：创建临时运行环境lsvirtualenv: 列出可用的运行环境lssitepackages: 列出当前环境安装了的包创建的环境是独立的，互不干扰，无需sudo权限即可使用 pip 来进行包的管理。]]></content>
      <categories>
        <category>Web学习</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用numpy实现简单的三层BP神经网络]]></title>
    <url>%2F2018%2F10%2F13%2F%E7%94%A8numpy%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E7%9A%84%E4%B8%89%E5%B1%82bp%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[用numpy实现简单的三层BP神经网络最近在看吴恩达老师的机器学习视频，讲到神经网络时有些模糊，于是决定自己用代码实现一下最基本的神经网络。 关于BP算法一文弄懂神经网络中的反向传播法代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374import numpy as npclass NeuralNetwork(object): def __init__(self,input_nodes,hidden_nodes,output_nodes,learning_rate): #设定输入层，隐藏层，输出层的节点个数 self.input_nodes = input_nodes+1 # +1 设置偏执神经元来进行修正 self.hidden_nodes = hidden_nodes self.output_nodes = output_nodes #初始化权值和学习速率 self.weight_input_to_hidden = np.random.normal(0.0,self.hidden_nodes**-0.5,(self.hidden_nodes,self.input_nodes)) self.weight_hidden_to_output = np.random.normal(0.0,self.output_nodes**-0.5,(self.output_nodes,self.hidden_nodes)) self.lr = learning_rate #激励函数 def Sigmoid(self,x): return 1.0 / (1.0 + np.exp(-x)) def train(self,input_list,target_list): inputs = np.array(input_list,ndmin=2).T targets = np.array(target_list,ndmin=2).T #前向传播 hidden_inputs = np.dot(self.weight_input_to_hidden,inputs) hidden_outputs= self.Sigmoid(hidden_inputs) final_inputs = np.dot(self.weight_hidden_to_output,hidden_outputs) final_outputs = self.Sigmoid(final_inputs) #反向传播 outputs_errors = (final_outputs - targets) * final_outputs * (1 - final_outputs) hidden_errors = np.dot(self.weight_hidden_to_output.T,outputs_errors) #梯度下降 self.weight_input_to_hidden -= np.dot((hidden_errors * hidden_outputs * (1 - hidden_outputs)),inputs.T) * self.lr self.weight_hidden_to_output -= np.dot(outputs_errors,hidden_outputs.T) *self.lr print("误差:") print(1/2 * np.square((final_outputs-targets))) #测试函数 def run(self,inputs_list): inputs = np.array(inputs_list,ndmin=2).T hidden_inputs = np.dot(self.weight_input_to_hidden,inputs) hidden_outputs = self.Sigmoid(hidden_inputs) final_inputs = np.dot(self.weight_hidden_to_output,hidden_outputs) final_outputs = self.Sigmoid(final_inputs) return final_outputs #测试用神经网络实现异或功能def main(): cases = [[0,0,0.1], [0,1,0.1], [1,0,0.1], [1,1,0.1]] labels = [[0],[1],[1],[0]] #迭代10000次 limit = 10000 nn = NeuralNetwork(2,4,1,0.5) for i in range(limit): for i in range(4): nn.train(cases[i],labels[i]) a = nn.run([1,1,0.1]) print(a)if __name__ == '__main__': main()只在输入层加入了偏执神经元，在第二层并没有添加，在第二层添加对拟合效果的提升并不是很大(主要是实现会更复杂一些(逃]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于Github+Hexo+NexT的配置]]></title>
    <url>%2F2018%2F09%2F30%2F%E5%85%B3%E4%BA%8EGithub-Hexo-NexT%E7%9A%84%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[]]></content>
  </entry>
</search>

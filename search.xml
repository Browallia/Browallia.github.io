<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>CS231n-note-3</title>
    <url>/2019/10/21/CS231n-note-3/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<h1 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h1><h2 id="卷积核-w"><a href="#卷积核-w" class="headerlink" title="卷积核($w$)"></a>卷积核($w$)</h2><p>通常遍历输入向量的所有通道，Input为32 X 32 X 3。</p>
<p><img src="/2019/10/21/CS231n-note-3/1.png" style="zoom:50%;"></p>
<p>卷积核在输入的向量上滑动，至于图像的一个局部区域发生关联，进行点积运算$w^Tx+b    $     $w为filter$</p>
<p><strong>卷积核滑动</strong></p>
<p>在图像空间滑动，计算出每个位置的点积(滑动的方式可以改变)</p>
<h3 id="激活映射"><a href="#激活映射" class="headerlink" title="激活映射"></a>激活映射</h3><blockquote>
<p><strong>PS</strong></p>
<p><strong>7X7X3</strong> input(spatially)</p>
<p>assume <strong>3X3X3</strong> filter</p>
<p>可以得到一个<strong>5X5X<font color="red">1</font></strong>的output</p>
</blockquote>
<p><font color="red"><strong>有多少个卷积核则Output的深度为多少</strong></font>。</p>
<p><strong>步长(stride)</strong></p>
<p>控制滑动的步长可以得到不同的output。</p>
<p>如果stride=3则无法fitinput的纬度，则不采用。</p>
<p><strong>Output size：</strong></p>
<p>$(N-F) / stride + 1$</p>
<p>可以增加像素(PS：补0)来改变输出的维度,<strong>保持输出维度和输入维度相同</strong>。</p>
<h3 id="Pooling-layer"><a href="#Pooling-layer" class="headerlink" title="Pooling layer"></a>Pooling layer</h3><p> 将生成的表示更加小以及更易于控制，是参数更少。</p>
<p><img src="/2019/10/21/CS231n-note-3/2.png" style="zoom:67%;"></p>
<p>进行降采样(downsampling)，只在平面上进行降采样，不在深度上降采样。</p>
<h4 id="最大池化法-max-pooling"><a href="#最大池化法-max-pooling" class="headerlink" title="最大池化法(max pooling)"></a>最大池化法(max pooling)</h4><p>池化层中也有一个卷积核(卷积核和步长使扫描区域不重合)，在滑动过程中不进行点积计算而是只取最大值。</p>
<p>最大值可以反映在这个区域内神经元受激程度，所以最大池化法比均值池化法用的更多。</p>
<p><img src="/2019/10/21/CS231n-note-3/3.png" alt></p>
<p><strong>一般在池化层不进行0像素填补</strong></p>
<p>Common settings</p>
<p>F = 2, S = 2</p>
<p>F = 3, S = 3</p>
<p><strong>一般的卷积神经网络结构</strong></p>
<p>CONV + RELU + POOL + FC</p>
<h2 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h2><p>见note-2</p>
<h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><p>一般对于图像，做零均值化的预处理(均值指所有输入图像的均值)</p>
<p> <strong>均值减法（<em>Mean subtraction</em>）</strong>是预处理最常用的形式。它对数据中每个独立<em>特征</em>减去平均值，从几何上可以理解为在每个维度上都将数据云的中心都迁移到原点。在numpy中，该操作可以通过代码<strong>X -= np.mean(X, axis=0)</strong>实现。而对于图像，更常用的是对所有像素都减去一个值，可以用<strong>X -= np.mean(X)</strong>实现，也可以在3个颜色通道上分别操作。</p>
<h4 id="权重初始化"><a href="#权重初始化" class="headerlink" title="权重初始化"></a>权重初始化</h4><p>权重初始化太小会造成网络崩溃，权重太大网络饱和，导致梯度消失。</p>
<h5 id="Xavier初始化"><a href="#Xavier初始化" class="headerlink" title="Xavier初始化"></a>Xavier初始化</h5><p><code>w = np.random.randn(fan_in, fan_out) / np.sqrt(fan_in)</code></p>
<p>如果使用ReLU激活函数，会造成一半左右的神经元消失</p>
<p>在权重初始化的时候<code>w = np.random.randn(fan_in, fan_out) / np.sqrt(fan_in / 2)</code></p>
<h2 id="批量归一化-Bathch-Normalization"><a href="#批量归一化-Bathch-Normalization" class="headerlink" title="批量归一化(Bathch Normalization)"></a>批量归一化(Bathch Normalization)</h2><p><strong>起因</strong>：在高斯范围内激活，将数据变为单位高斯数据</p>
<p> 批量归一化可以理解为在网络的每一层之前都做预处理，只是这种操作以另一种方式与网络集成在了一起 </p>
<p><strong>归一化公式</strong></p>
<script type="math/tex; mode=display">
\hat x^{(k)} = \frac{x^{(k)}-E[x^{(k)}]}{\sqrt{Var[x^{(k)}]}}</script><p>$k$代表输入的每个维度，分别对每一个维度独立计算经验均值和方差。</p>
<p><strong>运用</strong>：通常在全连接层或者卷积层之后、非线性层(激活函数层)之前加入BN。</p>
<p><strong>作用</strong>： 批量归一化使我们可以使用更高的学习率，而对初始化则不必那么小心 。</p>
<p>在完成归一化操作之后，还(需要)进行额外的缩放操作</p>
<script type="math/tex; mode=display">
y^{(k)}=\gamma^{(k)}\hat x^{(k)}  + \beta^{(k)}</script><p>可以学习$\gamma$和$\beta$以调整网络的饱和程度，若将其学习为均值和方差则可以完成于原数据的恒等映射。</p>
<p><strong>总结</strong></p>
<p><img src="/2019/10/21/CS231n-note-3/4.png" style="zoom: 67%;"></p>
<ul>
<li>改进了整个网络的梯度流</li>
<li>有了更高的鲁棒性，允许使用更广范围的学习率和不同的初始化下进行学习</li>
<li>可以看作一种正则化方法</li>
</ul>
<h2 id="Babysitting-the-Learning-Process"><a href="#Babysitting-the-Learning-Process" class="headerlink" title="Babysitting the Learning Process"></a>Babysitting the Learning Process</h2><p><strong>step1:</strong>数据预处理</p>
<p><strong>step2：</strong>网络构造</p>
<p><strong>step3：</strong>检验网络是否合理</p>
<p><strong>step3：</strong>进行训练</p>
<h1 id="神经网络优化"><a href="#神经网络优化" class="headerlink" title="神经网络优化"></a>神经网络优化</h1><h2 id="Fancier-Optimization"><a href="#Fancier-Optimization" class="headerlink" title="Fancier Optimization"></a>Fancier Optimization</h2><h3 id="SGD"><a href="#SGD" class="headerlink" title="SGD"></a>SGD</h3><p><strong>SGD的问题</strong></p>
<ul>
<li>只对一个方向的敏感度高，会在不敏感的方向反复增减。</li>
<li>会找到局部极小值或者鞍点(梯度为零)，在高维参数空间中，局部最小值不常见，常见的是鞍点。</li>
<li>随机性，因为SGD使用的是minibatch(=1)，会产生噪声，如果在梯度下降时加入噪声会花费很长的时间</li>
</ul>
<p><strong>解决：</strong></p>
<p><strong>SGD+Momentum</strong></p>
<p><img src="/2019/10/21/CS231n-note-3/5.png" style="zoom: 33%;"></p>
<ul>
<li><p>在局部最优点或者鞍点时，梯度为0，但依旧会有一个速度，能够越过这个点继续进行梯度下降。</p>
</li>
<li><p>加入动量之后，噪声会被抵消，下降曲线更平滑。</p>
</li>
</ul>
<p><strong>Nesterov Momentum</strong></p>
<p><img src="/2019/10/21/CS231n-note-3/6.png" style="zoom:33%;"></p>
<h3 id="AdaGrad-amp-RMSProp"><a href="#AdaGrad-amp-RMSProp" class="headerlink" title="AdaGrad&amp;RMSProp"></a>AdaGrad&amp;RMSProp</h3><p><img src="/2019/10/21/CS231n-note-3/7.png" style="zoom:50%;"></p>
<p><strong>AdaGrad</strong>对于凸函数来说效果比较好，在接近极值点时会减小步长。</p>
<h3 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h3><p>结合momentum&amp;AdaGrad&amp;RMSProp，加入第一动量和第二动量。</p>
<p><img src="/2019/10/21/CS231n-note-3/8.png" style="zoom:50%;"></p>
<p>有可能first_moment以及second_moment趋于0，人为造成第一步步长很大。</p>
<p><strong>改进：</strong></p>
<p><img src="/2019/10/21/CS231n-note-3/9.png" style="zoom:50%;"></p>
<p><code>beta1=0.9,beta2=0.999,lr=1e-3or5e-4 is a great initialization point for many models.</code></p>
<h3 id="关于Learning-Rate"><a href="#关于Learning-Rate" class="headerlink" title="关于Learning Rate"></a>关于Learning Rate</h3><p>Learning rate decacy over time</p>
<ul>
<li>指数衰减</li>
</ul>
<script type="math/tex; mode=display">
\alpha = \alpha_0e^{-kt}</script><ul>
<li>1/t衰减</li>
</ul>
<script type="math/tex; mode=display">
\alpha = \alpha_0/(1+kt)</script><p><strong>ps：</strong>SGDlr衰减很常见，但是Adam优化lr衰减很少用</p>
<h3 id="Second-Order-Optimization-TODO"><a href="#Second-Order-Optimization-TODO" class="headerlink" title="Second-Order Optimization(TODO)"></a>Second-Order Optimization(TODO)</h3><p><img src="/2019/10/21/CS231n-note-3/10.png" style="zoom:50%;"></p>
<p>牛顿法-拟牛顿法</p>
<h2 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h2><h3 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h3><p>在正向传播时随机将一层中的节点置零()然后继续传播。</p>
<p><code>hyperparameter=0.5 is common</code></p>
<p> 一般在全连接层使用Dropout,在卷积层中，可能是将某一通道全部置零。</p>
<ul>
<li>避免了特征之间的联系/组合</li>
<li>可以看作model集成</li>
</ul>
<p>在<strong>predict</strong>函数中不进行随机失活，但是对于两个隐层的输出都要乘以$p$，调整其数值范围。 最后输出的期望值为原输出*hyperparameter。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">p = <span class="number">0.5</span> <span class="comment"># 激活神经元的概率. p值更高 = 随机失活更弱</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_step</span>(<span class="params">X</span>):</span></span><br><span class="line">  <span class="string">&quot;&quot;&quot; X中是输入数据 &quot;&quot;&quot;</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment"># 3层neural network的前向传播</span></span><br><span class="line">  H1 = np.maximum(<span class="number">0</span>, np.dot(W1, X) + b1)</span><br><span class="line">  U1 = np.random.rand(*H1.shape) &lt; p <span class="comment"># 第一个随机失活遮罩</span></span><br><span class="line">  H1 *= U1 <span class="comment"># drop!</span></span><br><span class="line">  H2 = np.maximum(<span class="number">0</span>, np.dot(W2, H1) + b2)</span><br><span class="line">  U2 = np.random.rand(*H2.shape) &lt; p <span class="comment"># 第二个随机失活遮罩</span></span><br><span class="line">  H2 *= U2 <span class="comment"># drop!</span></span><br><span class="line">  out = np.dot(W3, H2) + b3</span><br><span class="line">  </span><br><span class="line">  <span class="comment"># 反向传播:计算梯度... (略)</span></span><br><span class="line">  <span class="comment"># 进行参数更新... (略)</span></span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">X</span>):</span></span><br><span class="line">  <span class="comment"># 前向传播时模型集成</span></span><br><span class="line">  H1 = np.maximum(<span class="number">0</span>, np.dot(W1, X) + b1) * p <span class="comment"># 注意：激活数据要乘以p</span></span><br><span class="line">  H2 = np.maximum(<span class="number">0</span>, np.dot(W2, H1) + b2) * p <span class="comment"># 注意：激活数据要乘以p</span></span><br><span class="line">  out = np.dot(W3, H2) + b3</span><br></pre></td></tr></table></figure>
<p><strong>Inverted dropout</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot; </span></span><br><span class="line"><span class="string">反向随机失活: 推荐实现方式.</span></span><br><span class="line"><span class="string">在训练的时候drop和调整数值范围，测试时不做任何事.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">p = <span class="number">0.5</span> <span class="comment"># 激活神经元的概率. p值更高 = 随机失活更弱</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_step</span>(<span class="params">X</span>):</span></span><br><span class="line">  <span class="comment"># 3层neural network的前向传播</span></span><br><span class="line">  H1 = np.maximum(<span class="number">0</span>, np.dot(W1, X) + b1)</span><br><span class="line">  U1 = (np.random.rand(*H1.shape) &lt; p) / p <span class="comment"># 第一个随机失活遮罩. 注意/p!</span></span><br><span class="line">  H1 *= U1 <span class="comment"># drop!</span></span><br><span class="line">  H2 = np.maximum(<span class="number">0</span>, np.dot(W2, H1) + b2)</span><br><span class="line">  U2 = (np.random.rand(*H2.shape) &lt; p) / p <span class="comment"># 第二个随机失活遮罩. 注意/p!</span></span><br><span class="line">  H2 *= U2 <span class="comment"># drop!</span></span><br><span class="line">  out = np.dot(W3, H2) + b3</span><br><span class="line">  <span class="comment"># 反向传播:计算梯度... (略)</span></span><br><span class="line">  <span class="comment"># 进行参数更新... (略)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">X</span>):</span></span><br><span class="line">  <span class="comment"># 前向传播时模型集成</span></span><br><span class="line">  H1 = np.maximum(<span class="number">0</span>, np.dot(W1, X) + b1) <span class="comment"># 不用数值范围调整了</span></span><br><span class="line">  H2 = np.maximum(<span class="number">0</span>, np.dot(W2, H1) + b2)</span><br><span class="line">  out = np.dot(W3, H2) + b3</span><br></pre></td></tr></table></figure>
<p>运用dropout可能会用更长的时间进行训练，但是在收敛之后，模型的鲁棒性会更好。</p>
<h3 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h3><h3 id="Data-Augmentation"><a href="#Data-Augmentation" class="headerlink" title="Data Augmentation"></a>Data Augmentation</h3><ul>
<li>transform image</li>
<li>crops and scales</li>
<li>Color Jitter(色彩抖动) </li>
</ul>
<h3 id="DropConnect"><a href="#DropConnect" class="headerlink" title="DropConnect"></a>DropConnect</h3><p>随即将权重的一些值置零。</p>
<h3 id="Fractional-Max-Poolong-TODO"><a href="#Fractional-Max-Poolong-TODO" class="headerlink" title="Fractional Max Poolong(TODO)"></a>Fractional Max Poolong(TODO)</h3><p>在最大池化层进行部分随机池化。</p>
<h3 id="Stochastic-Depth-随即深度"><a href="#Stochastic-Depth-随即深度" class="headerlink" title="Stochastic Depth(随即深度)"></a>Stochastic Depth(随即深度)</h3><p>在训练中，随机丢弃一些层，只用部分层。</p>
<h2 id="迁移学习"><a href="#迁移学习" class="headerlink" title="迁移学习"></a>迁移学习</h2><p>不需要超大的样本集</p>
<p><img src="/2019/10/21/CS231n-note-3/11.png" style="zoom:80%;"></p>
<p>预训练模型</p>
<ul>
<li><a href="https://github.com/pytorch/vision">PyTorch</a></li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
        <tag>卷积神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>CS231n note-1</title>
    <url>/2019/07/25/CS231n-note-1/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<h1 id="图像分类"><a href="#图像分类" class="headerlink" title="图像分类"></a>图像分类</h1><p><strong>目标</strong>：所谓图像分类问题，就是已有固定的分类标签集合，然后对于输入的图像，从分类标签集合中找出一个分类标签，最后把分类标签分配给该输入图像。虽然看起来挺简单的，但这可是计算机视觉领域的核心问题之一，并且有着各种各样的实际应用。在后面的课程中，我们可以看到计算机视觉领域中很多看似不同的问题（比如物体检测和分割），都可以被归结为图像分类问题。</p>
<p><img src="https://pic2.zhimg.com/baab9e4b97aceb77ec70abeda6be022d_r.jpg" alt="preview"></p>
<p><strong>图像分类流程</strong>。在课程视频中已经学习过，<strong>图像分类</strong>就是输入一个元素为像素值的数组，然后给它分配一个分类标签。完整流程如下：</p>
<ul>
<li><strong>输入</strong>：输入是包含N个图像的集合，每个图像的标签是K种分类标签中的一种。这个集合称为<em>训练集。</em></li>
<li><strong>学习</strong>：这一步的任务是使用训练集来学习每个类到底长什么样。一般该步骤叫做<em>训练分类器</em>或者<em>学习一个模型</em>。</li>
<li><strong>评价</strong>：让分类器来预测它未曾见过的图像的分类标签，并以此来评价分类器的质量。我们会把分类器预测的标签和图像真正的分类标签对比。毫无疑问，分类器预测的分类标签和图像真正的分类标签如果一致，那就是好事，这样的情况越多越好。</li>
</ul>
<h2 id="K-nearest算法（KNN）"><a href="#K-nearest算法（KNN）" class="headerlink" title="K-nearest算法（KNN）"></a>K-nearest算法（KNN）</h2><p>需要样本尽量高密度占据样本空间</p>
<p><strong>曼哈顿距离（L1）</strong></p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cdisplaystyle+d_1%28I_1%2CI_2%29%3D%5Csum_p%7CI%5Ep_1-I%5Ep_2%7C" alt="[公式]"></p>
<p>适合样本空间向量属性已知的情况，虽坐标轴变化值不同</p>
<p><strong>欧式距离（L2）</strong></p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cdisplaystyle+d_2%28I_1%2CI_2%29%3D%5Csqrt%7B+%5Csum_p%28I%5Ep_1-I%5Ep_2%29%5E2%7D" alt="[公式]"></p>
<p>适合样本向量为一般的通用向量</p>
<h3 id="超参数选择"><a href="#超参数选择" class="headerlink" title="超参数选择"></a><strong>超参数选择</strong></h3><p>选取超参数的正确方法是：将原始训练集分为训练集和<strong>验证集</strong>，我们在验证集上尝试不同的超参数，最后保留表现最好那个。如果训练数据量不够，使用<strong>交叉验证</strong>方法，它能帮助我们在选取最优超参数的时候减少噪声。</p>
<h3 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a><strong>交叉验证</strong></h3><p>有时候，训练集数量较小（因此验证集的数量更小），可以将训练集平均分成5份，其中4份用来训练，1份用来验证。然后我们循环着取其中4份来训练，其中1份来验证，最后取所有5次验证结果的平均值作为算法验证结果。</p>
<h1 id="线性分类"><a href="#线性分类" class="headerlink" title="线性分类"></a>线性分类</h1><p><img src="https://www.zhihu.com/equation?tex=%5Cdisplaystyle+f%28x_i%2CW%2Cb%29%3DWx_i%2Bb" alt="[å¬å¼]"></p>
<p><img src="https://pic2.zhimg.com/80/3c69a5c87a43bfb07e2b59bfcbd2f149_hd.jpg" alt="img"></p>
<h2 id="图像数据预处理"><a href="#图像数据预处理" class="headerlink" title="图像数据预处理"></a><strong>图像数据预处理</strong></h2><p>对输入的特征作归一化(normalization),对每个特征减去平均值去中心化，然后将数值分布区间变为[-1,1]，称为零均值中心化。</p>
<h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><h3 id="多类支持向量机损失-Multiclass-Support-Vector-Machine-Loss"><a href="#多类支持向量机损失-Multiclass-Support-Vector-Machine-Loss" class="headerlink" title="多类支持向量机损失 Multiclass Support Vector Machine Loss"></a>多类支持向量机损失 Multiclass Support Vector Machine Loss</h3><p>针对第j个类别的得分就是第j个元素：<img src="https://www.zhihu.com/equation?tex=s_j%3Df%28x_i%2CW%29_j" alt="[公式]">。针对第i个数据的多类SVM的损失函数定义如下：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cdisplaystyle+L_i%3D%5Csum_%7Bj%5Cnot%3Dy_i%7Dmax%280%2Cs_j-s_%7By_i%7D%2B%5CDelta%29" alt="[å¬å¼]"></p>
<p>在线性分类模型中，我们面对的是线性评分函数（<img src="https://www.zhihu.com/equation?tex=f%28x_i%2CW%29%3DWx_i" alt="[公式]">），可以将损失函数的公式稍微改写一下：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cdisplaystyle+L_i%3D%5Csum_%7Bj%5Cnot%3Dy_i%7Dmax%280%2Cw%5ET_jx_i-w%5ET_%7By_i%7Dx_i%2B%5CDelta%29" alt="[å¬å¼]"></p>
<p>其中$w_j$是权重$W$的第j行，被变形为列向量。然而，一旦开始考虑更复杂的评分函数$f$公式，这样做就不是必须的了。</p>
<p><img src="/2019/07/25/CS231n-note-1/1.png" alt></p>
<p>$max(0,-)$称为折叶损失函数，但也会有平方折叶损失SVM，如何选择这两种可以通过交叉验证来进行选择。</p>
<p><strong>损失函数的正则化(Regularization)</strong></p>
<p>为了防止过拟合，需要对损失函数进行正则化操作。不是为了拟合数据而是为了减轻模型的复杂度。</p>
<p>正则项</p>
<p>$\lambda R(W)$</p>
<p>超参数$\lambda$用来平衡Data loss项和Regularization</p>
<p><strong>常见的正则化</strong></p>
<p>批量归一化，随机深度</p>
<p><img src="/2019/07/25/CS231n-note-1/2.png" style="zoom:50%;"></p>
<p>L1 更倾向于稀疏解</p>
<p>L2 更倾向于鲁棒性更强的解（鲁棒性：鲁棒性是指异常样本对于算法的整体性能影响不大）</p>
<h3 id="多项式逻辑斯蒂克损失-softmax-loss"><a href="#多项式逻辑斯蒂克损失-softmax-loss" class="headerlink" title="多项式逻辑斯蒂克损失(softmax loss)"></a>多项式逻辑斯蒂克损失(softmax loss)</h3><p> 在Softmax分类器中，函数映射<img src="https://www.zhihu.com/equation?tex=f%28x_i%3BW%29%3DWx_i" alt="[公式]">保持不变，但将这些评分值视为每个分类的未归一化的对数概率，并且将折叶损失（hinge loss）替换为<strong>交叉熵损失</strong>（<strong>cross-entropy loss）</strong>。公式如下： </p>
<p> <img src="https://www.zhihu.com/equation?tex=%5Cdisplaystyle+Li%3D-log%28%5Cfrac%7Be%5E%7Bf_%7By_i%7D%7D%7D%7B%5Csum_je%5E%7Bf_j%7D%7D%29" alt="[公式]"> 或者 <img src="https://www.zhihu.com/equation?tex=L_i%3D-f_%7By_i%7D%2Blog%28%5Csum_je%5E%7Bf_j%7D%29" alt="[公式]"> </p>
<p> 在上式中，使用$f_j$来表示分类评分向量$f$中的第j个元素。和之前一样，整个数据集的损失值是数据集中所有样本数据的损失值$L_i$的均值与正则化损失$R(W)$之和。其中函数$f_j(z)=\frac{e^zj}{\sum_ke^zk}$被称作<strong>softmax 函数</strong>：其输入值是一个向量，向量中元素为任意实数的评分值（$z$中的)，函数对</p>
<p>其进行压缩，输出一个向量，其中每个元</p>
<p>素值在0到1之间，且所有元素之和为1。 </p>
<h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><h3 id="梯度"><a href="#梯度" class="headerlink" title="梯度"></a>梯度</h3><p>​    在权重空间中找到一个方向，沿着该方向能降低损失函数的损失值。其实不需要随机寻找方向，因为可以直接计算出最好的方向，这就是从数学上计算出最陡峭的方向。这个方向就是损失函数的<strong>梯度（gradient）</strong> </p>
<h3 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a><strong>梯度下降</strong></h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 普通的梯度下降</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">  weights_grad = evaluate_gradient(loss_fun, data, weights)</span><br><span class="line">  weights += - step_size * weights_grad <span class="comment"># 进行梯度更新</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 普通的小批量数据梯度下降</span></span><br><span class="line"><span class="comment">#可以减少运算成本</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">  data_batch = sample_training_data(data, <span class="number">256</span>) <span class="comment"># 256个数据</span></span><br><span class="line">  weights_grad = evaluate_gradient(loss_fun, data_batch, weights)</span><br><span class="line">  weights += - step_size * weights_grad <span class="comment"># 参数更新</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>CS231n-note-2</title>
    <url>/2019/10/15/CS231n-note-2/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<h1 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h1><h2 id="计算图"><a href="#计算图" class="headerlink" title="计算图"></a>计算图</h2><p> <img src="https://pic1.zhimg.com/80/0799b3d6e5e92245ee937db3c26d1b80_hd.png" alt="img" style="zoom: 80%;"> </p>
<p>根据链式法则进行反向传播，算出每个结点的梯度。</p>
<ul>
<li>max门：一个是1 一个是0</li>
<li>乘法门：梯度互换</li>
</ul>
<p>梯度会在分支节点处累加</p>
<p><strong>sigmod函数</strong></p>
<script type="math/tex; mode=display">
\sigma(x) = \frac{1}{1+e^{-x}}</script><p><strong>梯度</strong>为</p>
<script type="math/tex; mode=display">
\frac{d\sigma(x)}{dx}=(1-\sigma(x))\sigma(x)</script><h2 id="雅可比矩阵"><a href="#雅可比矩阵" class="headerlink" title="雅可比矩阵"></a>雅可比矩阵</h2><p> 在向量分析中，<strong>雅可比矩阵</strong>是函数的一阶偏导数以一定方式排列成的矩阵，其行列式称为<strong>雅可比行列式</strong>。 </p>
<p>假设<strong><em>F: Rn→Rm</em></strong>是一个从欧式n维空间转换到欧式m维空间的函数。这个函数<strong><em>F\</em></strong>由m个实函数组成: <strong><em>y1(x1,…,xn), …, ym(x1,…,xn)</em></strong>。这些函数的偏导数(如果存在)可以组成一个m行n列的矩阵, 这就是所谓的雅可比矩阵：</p>
<p><img src="https://gitee.com/browallia/tuchuang/raw/master/img/20201124211815.png" alt></p>
<p>由球坐标系 到直角坐标系的转化由F函数给出 ：</p>
<p><img src="https://gitee.com/browallia/tuchuang/raw/master/img/20201124211732.png" alt></p>
<p>此坐标变换的雅可比矩阵是</p>
<p><img src="https://gitee.com/browallia/tuchuang/raw/master/img/20201124211832.png" alt></p>
<hr>
<p>在实际的运用中，不用计算$4096*4096$的雅可比矩阵（如果输入向量为4096维）。</p>
<p>一般的雅可比矩阵为对角矩阵，只用算出每一个维度的梯度。</p>
<p><img src="/2019/10/15/CS231n-note-2/1.png" alt></p>
<p> <strong>矩阵函数的梯度矩阵是其Jacobian矩阵的转置【Transposition】</strong></p>
<h1 id="构造神经网络"><a href="#构造神经网络" class="headerlink" title="构造神经网络"></a>构造神经网络</h1><p> <img src="https://pic2.zhimg.com/80/d0cbce2f2654b8e70fe201fec2982c7d_hd.png" alt="img"></p>
<p> 一个神经元前向传播的实例代码如下  </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Neuron</span>(<span class="params">object</span>):</span></span><br><span class="line">  <span class="comment"># ... </span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">inputs</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot; 假设输入和权重是1-D的numpy数组，偏差是一个数字 &quot;&quot;&quot;</span></span><br><span class="line">    cell_body_sum = np.sum(inputs * self.weights) + self.bias</span><br><span class="line">    firing_rate = <span class="number">1.0</span> / (<span class="number">1.0</span> + math.exp(-cell_body_sum)) <span class="comment"># sigmoid激活函数</span></span><br><span class="line">    <span class="keyword">return</span> firing_rate</span><br></pre></td></tr></table></figure>
<h2 id="常用激活函数"><a href="#常用激活函数" class="headerlink" title="常用激活函数"></a>常用激活函数</h2><p> 每个激活函数（或非线性函数）的输入都是一个数字，然后对其进行某种固定的数学操作。 </p>
<h3 id="Sigmod"><a href="#Sigmod" class="headerlink" title="Sigmod"></a>Sigmod</h3><p> <img src="/2019/10/15/CS231n-note-2/3.png" alt="img"> </p>
<p> 左边是Sigmoid非线性函数，将实数压缩到[0,1]之间。右边是tanh函数，将实数压缩到[-1,1]。 </p>
<script type="math/tex; mode=display">
\sigma(x) = \frac{1}{1+e^{-x}}</script><p>它输入实数值并将其“挤压”到0到1范围内。更具体地说，很大的负数变成0，很大的正数变成1。在历史上，sigmoid函数非常常用，这是因为它对于神经元的激活频率有良好的解释：从完全不激活（0）到在求和后的最大频率处的完全饱和（<strong>saturated</strong>）的激活（1）。然而现在sigmoid函数已经不太受欢迎，实际很少使用了，这是因为它有两个主要缺点：</p>
<ul>
<li><em>Sigmoid函数饱和使梯度消失</em>。sigmoid神经元有一个不好的特性，就是当神经元的激活在接近0或1处时会饱和：在这些区域，梯度几乎为0。回忆一下，在反向传播的时候，这个（局部）梯度将会与整个损失函数关于该门单元输出的梯度相乘。因此，如果局部梯度非常小，那么相乘的结果也会接近零，这会有效地“杀死”梯度，几乎就有没有信号通过神经元传到权重再到数据了。还有，为了防止饱和，必须对于权重矩阵初始化特别留意。比如，如果初始化权重过大，那么大多数神经元将会饱和，导致网络就几乎不学习了。</li>
<li><em>Sigmoid函数的输出不是零中心的</em>。这个性质并不是我们想要的，因为在神经网络后面层中的神经元得到的数据将不是零中心的。这一情况将影响梯度下降的运作，因为如果输入神经元的数据总是正数（比如在$f=w^T+b$中每个元素都$x&gt;0$），那么关于$w$的梯度在反向传播的过程中，将会要么全部是正数，要么全部是负数（具体依整个表达式$f$而定)。这将会导致梯度下降权重更新时出现z字型的下降。然而，可以看到整个批量的数据的梯度被加起来后，对于权重的最终更新将会有不同的正负，这样就从一定程度上减轻了这个问题。因此，该问题相对于上面的神经元饱和问题来说只是个小麻烦，没有那么严重。</li>
</ul>
<p><img src="/2019/10/15/CS231n-note-2/4.PNG" style="zoom:50%;"></p>
<h3 id="Tanh"><a href="#Tanh" class="headerlink" title="Tanh"></a>Tanh</h3><script type="math/tex; mode=display">
tanh(x)=2\sigma(2x)-1</script><p> tanh非线性函数图像如上图右边所示。它将实数值压缩到[-1,1]之间。和sigmoid神经元一样，它也存在饱和问题，但是和sigmoid神经元不同的是，它的输出是零中心的。因此，在实际操作中，<em>tanh非线性函数比sigmoid非线性函数更受欢迎</em>。tanh神经元是一个简单放大的sigmoid神经元 </p>
<h3 id="ReLU"><a href="#ReLU" class="headerlink" title="ReLU"></a>ReLU</h3><p> <img src="/2019/10/15/CS231n-note-2/7.png" alt></p>
<p> 左边是ReLU（校正线性单元：Rectified Linear Unit）激活函数，当 $x=0$ 时函数值为0。当$x&gt;0$时函数的斜率为1。 </p>
<script type="math/tex; mode=display">
f(x) = max(0,x)</script><ul>
<li><p>优点：相较于sigmoid和tanh函数，ReLU对于随机梯度下降的收敛有巨大的加速作用（ <a href="https://link.zhihu.com/?target=http%3A//www.cs.toronto.edu/~fritz/absps/imagenet.pdf">Krizhevsky </a>等的论文指出有6倍之多）。据称这是由它的线性，非饱和的公式导致的。(右图)</p>
</li>
<li><p>优点：sigmoid和tanh神经元含有指数运算等耗费计算资源的操作，而ReLU可以简单地通过对一个矩阵进行阈值计算得到。</p>
</li>
<li><p>缺点：在训练的时候，ReLU单元比较脆弱并且可能“死掉”。举例来说，当一个很大的梯度流过ReLU的神经元的时候，可能会导致梯度更新到一种特别的状态，在这种状态下神经元将无法被其他任何数据点再次激活。如果这种情况发生，那么从此所以流过这个神经元的梯度将都变成0。也就是说，这个ReLU单元在训练中将不可逆转的死亡，因为这导致了数据多样化的丢失。例如，如果学习率设置得太高，可能会发现网络中40%的神经元都会死掉（在整个训练集中这些神经元都不会被激活）。通过合理设置学习率，这种情况的发生概率会降低。</p>
<p><img src="/2019/10/15/CS231n-note-2/5.png" style="zoom: 33%;"></p>
</li>
</ul>
<h3 id="Leaky-ReLU"><a href="#Leaky-ReLU" class="headerlink" title="Leaky ReLU"></a>Leaky ReLU</h3><p><img src="/2019/10/15/CS231n-note-2/8.png" alt></p>
<script type="math/tex; mode=display">
f(x) = max(0.01x,x)</script><p> Leaky ReLU是为解决“ReLU死亡”问题的尝试。ReLU中当x&lt;0时，函数值为0。而Leaky ReLU则是给出一个很小的负数梯度值，比如0.01。</p>
<h4 id="Parametric-Rectifier-PReLU"><a href="#Parametric-Rectifier-PReLU" class="headerlink" title="Parametric Rectifier(PReLU)"></a>Parametric Rectifier(PReLU)</h4><script type="math/tex; mode=display">
f(x)=max(\alpha x,x)</script><p>$\alpha$可以作为反向传播训练的参数。</p>
<h3 id="ELU"><a href="#ELU" class="headerlink" title="ELU"></a>ELU</h3><script type="math/tex; mode=display">
\left\{
\begin{aligned}
x  & &  x\geq0\\
\alpha(e^x -1)  & &  x<0
\end{aligned}
\right.</script><p><img src="/2019/10/15/CS231n-note-2/2.png" style="zoom:67%;"></p>
<p>会获得均值接近0的输出。</p>
<h3 id="Maxout"><a href="#Maxout" class="headerlink" title="Maxout"></a>Maxout</h3><script type="math/tex; mode=display">
max(w_1^Tx+b_1,w_2^T+b_2)</script><p> ReLU和Leaky ReLU都是这个公式的特殊情况 。 这样Maxout神经元就拥有ReLU单元的所有优点（线性操作和不饱和），而没有它的缺点（死亡的ReLU单元）。然而和ReLU对比，它每个神经元的参数数量增加了一倍，这就导致整体参数的数量激增。 </p>
<h3 id="Summury"><a href="#Summury" class="headerlink" title="Summury"></a>Summury</h3><p><img src="/2019/10/15/CS231n-note-2/6.png" alt></p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>CS231n-note-4</title>
    <url>/2019/10/28/CS231n-note-4/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<h1 id="深度学习软件"><a href="#深度学习软件" class="headerlink" title="深度学习软件"></a>深度学习软件</h1><h2 id="PyTorch-TODO"><a href="#PyTorch-TODO" class="headerlink" title="PyTorch(TODO)"></a>PyTorch(TODO)</h2><h3 id="组成-三层"><a href="#组成-三层" class="headerlink" title="组成(三层)"></a>组成(三层)</h3><h4 id="Tensor"><a href="#Tensor" class="headerlink" title="Tensor"></a>Tensor</h4><p>运行在GPU上的命令式数组(Imperative ndarray)</p>
<h4 id="Variable"><a href="#Variable" class="headerlink" title="Variable"></a>Variable</h4><p>计算图中的节点，存储数据和梯度</p>
<h4 id="Module"><a href="#Module" class="headerlink" title="Module"></a>Module</h4><p>一个神经网络的层</p>
<h1 id="CNN架构"><a href="#CNN架构" class="headerlink" title="CNN架构"></a>CNN架构</h1><p><strong>AlexNet</strong>：8layers</p>
<p><strong>ZFNet</strong>：在AlexNet基础上调整了超参数</p>
<p><strong>VGG</strong>：16/19layers(全部采用3X3的卷积核——更有利于加深神经网络的深度)</p>
<p><strong>GoogleNet</strong>:</p>
<p>22layers，高效的“Inception”层，无全连接层</p>
<p>Inception层是设计好的一个局部网络拓朴，对输入的层进行并行操作，然后将每个滤波器的输出进行深度上的串联，通过0填充保持输出尺寸一致。</p>
<p><img src="/2019/10/28/CS231n-note-4/1.png" alt="1572427047546" style="zoom: 50%;"></p>
<p>利用1X1卷积核进行深度的压缩对模型进行改进。 </p>
<p><img src="/2019/10/28/CS231n-note-4/2.png" alt="1572427217649" style="zoom:50%;"></p>
<p><strong>ResNet</strong>: 152layers</p>
<p><img src="/2019/10/28/CS231n-note-4/3.png" alt="1572428187168" style="zoom:50%;"></p>
<p>ResNet的整体结构</p>
<p><img src="/2019/10/28/CS231n-note-4/4.png" style="zoom:50%;"></p>
<h1 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h1><p><img src="/2019/10/28/CS231n-note-4/5.png" alt="1572832029309" style="zoom:67%;"></p>
<p><strong>Vanilla RNN</strong></p>
<script type="math/tex; mode=display">
h_t = f_w(h_{t-1},x_t)\\
h_t = tanh(W_{hh}h_{t-1}+W_{xh}x_t)\\
y_t = W_{hy}h_t</script><p>Loss是每一个时步下的loss之和</p>
<p>W的梯度是每个节点的W梯度值和  </p>
<p><strong>Vanilla RNN梯度流</strong></p>
<p><img src="/2019/10/28/CS231n-note-4/7.png" alt="1572869122126" style="zoom:50%;"></p>
<p>在计算h0梯度时会发生梯度爆炸或者梯度消失   </p>
<p>当梯度爆炸，L2范式大于一个阙值时可以进行剪枝。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">grad_norm = np.sum(grad * grad)</span><br><span class="line"><span class="keyword">if</span> grad_norm &gt; threshold</span><br><span class="line">	grad *= (threshold / grad_norm)</span><br></pre></td></tr></table></figure>
<p>当梯度消失时可以采用更深的RNN网络，比如LSTM。</p>
<p><strong>LSTM(长短期记忆网络)</strong></p>
<p><img src="/2019/10/28/CS231n-note-4/blog\source\_posts\CS231n-note-4\8.png" alt="1572870827165" style="zoom: 50%;"></p>
<p> ht为隐藏状态，ct为单元状态，保留在lstm内部不会暴露到外面。</p>
<p>LSTM状态变化图</p>
<p><img src="/2019/10/28/CS231n-note-4/9.png" alt="1572882658486" style="zoom:50%;"></p>
<p>利用加法和乘法门可以很好的解决梯度消失和梯度爆炸问题。</p>
<p><strong>图像标注</strong></p>
<p><img src="/2019/10/28/CS231n-note-4/6.png" alt></p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>CS231n-note-5</title>
    <url>/2019/11/05/CS231n-note-5/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<h1 id="图像识别和分割"><a href="#图像识别和分割" class="headerlink" title="图像识别和分割"></a>图像识别和分割</h1><h2 id="分割"><a href="#分割" class="headerlink" title="分割"></a>分割</h2><h3 id="语义分割"><a href="#语义分割" class="headerlink" title="语义分割"></a>语义分割</h3><p>只将像素进行分割并贴上对应的分类标签。</p>
<h4 id="Idea-1"><a href="#Idea-1" class="headerlink" title="Idea-1"></a><strong>Idea-1</strong></h4><p>sliding windows，利用滑动窗口来对个像素进行分类，计算量太大</p>
<h4 id="idea-2"><a href="#idea-2" class="headerlink" title="idea-2"></a><strong>idea-2</strong></h4><p>全连接卷积神经网络，可以生成一个CxHxW的张量，对每个像素进行评分，数据集获取昂贵且困难。并且模型训练代价很高。</p>
<h4 id="idea-3"><a href="#idea-3" class="headerlink" title="idea-3"></a><strong>idea-3</strong></h4><p>不采用全连接(同尺寸)卷积神经网络，而是采用downsampling和upsampling，在中间层可以用池化或者跨卷积来降低清晰度，但是可以让网络建立的很深。</p>
<h5 id="upsampling"><a href="#upsampling" class="headerlink" title="upsampling"></a>upsampling</h5><h6 id="去池化-Unpooling"><a href="#去池化-Unpooling" class="headerlink" title="去池化(Unpooling)"></a>去池化(Unpooling)</h6><p><img src="/2019/11/05/CS231n-note-5/1.png" alt="1572945307155" style="zoom:50%;"></p>
<h6 id="Max-Unpooling"><a href="#Max-Unpooling" class="headerlink" title="Max Unpooling"></a>Max Unpooling</h6><p><img src="/2019/11/05/CS231n-note-5/2.png" alt="1572945525749" style="zoom:50%;"></p>
<p>将池化层和去池化层相对应，其最大元素的相应位置将会被记录。</p>
<h6 id="转置卷积"><a href="#转置卷积" class="headerlink" title="转置卷积"></a>转置卷积</h6><p>正常卷积和跨卷积(可以进行downsampling)并且可以学习参数进行下采样</p>
<p>转置卷积</p>
<p>在进行转置卷积时，将每个元素(标量)乘以过滤器(卷积核)，然后将加权后的卷积核叠加于新的输出。</p>
<p><img src="/2019/11/05/CS231n-note-5/3.png" alt="1572946348192" style="zoom:50%;"></p>
<p>sample：</p>
<p><img src="/2019/11/05/CS231n-note-5/4.png" alt="1572946547455" style="zoom:50%;"></p>
<p>卷积矩阵化</p>
<p><img src="/2019/11/05/CS231n-note-5/5.png" alt="1572955265649" style="zoom:50%;"></p>
<p>$4<em>4input &lt;—&gt; 4</em>4output$</p>
<p><img src="/2019/11/05/CS231n-note-5/6.png" alt="1572955416177" style="zoom:50%;"></p>
<p>$4<em>4input &lt;—&gt;2</em>2output$</p>
<h2 id="分类和定位"><a href="#分类和定位" class="headerlink" title="分类和定位"></a>分类和定位</h2><p><img src="/2019/11/05/CS231n-note-5/7.png" alt="1572956657061" style="zoom:50%;"></p>
<p>定位一般使用回归损失函数。</p>
<h2 id="识别"><a href="#识别" class="headerlink" title="识别"></a>识别</h2><p>固定几类对象，再输入图片之后将识别图中对象框起来并预测该对象的从属类别。</p>
<p>输入图片的包含对象数量是不确定的。</p>
<h3 id="候选区域方法-Region-Proposals"><a href="#候选区域方法-Region-Proposals" class="headerlink" title="候选区域方法(Region Proposals)"></a><strong>候选区域方法(Region Proposals)</strong></h3><p>将输入的图像划分为若干(很多)区域，在应用卷积神经网络对其进行分类。</p>
<p>R-CNN    效率低</p>
<p>Fast R-CNN 不用事先确定候选区而是通过一个卷积神经网络生成特征映射，在特征映射上通过固定函数像素划分确定候选区</p>
<p>Faster R-CNN在确定备选区时自己进行区域选择网络的训练</p>
<h3 id="Detection-without-Proposals"><a href="#Detection-without-Proposals" class="headerlink" title="Detection without Proposals"></a><strong>Detection without Proposals</strong></h3><h4 id="YOLO-You-Only-Look-Once-SSD-Single-Shot-Detection"><a href="#YOLO-You-Only-Look-Once-SSD-Single-Shot-Detection" class="headerlink" title="YOLO(You Only Look Once)/SSD(Single Shot Detection)"></a>YOLO(You Only Look Once)/SSD(Single Shot Detection)</h4><p>利用回归，将输入图片划分为网格。 然后预测每个基本的方框的类别权重以及距离对象的信息。</p>
<p><img src="/2019/11/05/CS231n-note-5/8.png" alt="1572970026182" style="zoom:50%;"></p>
<h3 id="目标分割"><a href="#目标分割" class="headerlink" title="目标分割"></a>目标分割</h3><p><img src="/2019/11/05/CS231n-note-5/9.png" alt="1572972443690" style="zoom:50%;"></p>
<p> 两个分支，一个分支进行分类，一个分支进行类似语义分割确定对象的区域。  </p>
<h3 id="DeepDream-amp-Feature-Inversion"><a href="#DeepDream-amp-Feature-Inversion" class="headerlink" title="DeepDream&amp;Feature Inversion"></a>DeepDream&amp;Feature Inversion</h3><p>DeepDream：放大存在的特征</p>
<p>Feature Inversion：特征反演</p>
<h3 id="纹理拼接-amp-风格迁移"><a href="#纹理拼接-amp-风格迁移" class="headerlink" title="纹理拼接&amp;风格迁移"></a>纹理拼接&amp;风格迁移</h3><p>Gram Matrix</p>
<p><img src="/2019/11/05/CS231n-note-5/10.png" alt="1573008687755" style="zoom:50%;"></p>
<p><img src="/2019/11/05/CS231n-note-5/11.png" alt="1573008897926" style="zoom:50%;"></p>
<p>传统风格迁移会消耗大量的资源</p>
<p><strong>Fast Style Transfer</strong></p>
<h1 id="可视化和理解卷积神经网络"><a href="#可视化和理解卷积神经网络" class="headerlink" title="可视化和理解卷积神经网络"></a>可视化和理解卷积神经网络</h1>]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>DETR-note</title>
    <url>/2020/06/03/DETR-note/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<h1 id="Transformer和Attention"><a href="#Transformer和Attention" class="headerlink" title="Transformer和Attention"></a>Transformer和Attention</h1><h3 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h3><p>Transformer本质上是一个Encoder-Decoder的结构</p>
<p><img src="/2020/06/03/DETR-note/1.png" style="zoom: 67%;"></p>
<p>在paper中，encoder和decoder都由6个block组成，编码器的输出作为解码器的输入。</p>
<p>encoders每个block都是独立的单元，不会share weights。每个block又由以下的两部分组成(self-attention和FFN)</p>
<p><img src="/2020/06/03/DETR-note/2.png" style="zoom:67%;"></p>
<p>在decoder部分每个block也和encoder相似，只是在两层之间加了一个attention层(类似于seq2seq的attention机制，可以让decoder更加关注input相关的部分)。</p>
<h4 id="编码器"><a href="#编码器" class="headerlink" title="编码器"></a>编码器</h4><p><img src="/2020/06/03/DETR-note/3.png" style="zoom:67%;"></p>
<p>编码器接受单词的词嵌入列表作为输入(列表中每个向量为512-d)。单词在通过self-attention层时会依赖单词之间的关系，但是在通过Feed Forward时没有这些依赖关系，可以并行进行。</p>
<h5 id="self-attention"><a href="#self-attention" class="headerlink" title="self-attention"></a>self-attention</h5><p>类似于RNN中的隐藏层，self-attention的作用是将其他单词的信息融入到正在处理的单词中。</p>
<p>PS： ”<code>The animal didn&#39;t cross the street because it was too tired</code>” 在处理it时会将前文the animal等信息加到it中。</p>
<p><strong>三个向量</strong></p>
<p>self-attention的<strong>第一步</strong>就是从输入的词嵌入向量列表生成三个向量(64-d)</p>
<p><img src="/2020/06/03/DETR-note/4.png" style="zoom:67%;"></p>
<hr>
<p><strong>query vector</strong>：与其他单词的key vector相乘计算得分<br><strong>key vector</strong>：与其他单词query vector相乘代表对其他单词在语义上的影响<br><strong>value vector</strong>：</p>
<p> <strong>第二步</strong>是对输入的单词进行得分计算，得分决定了这个词在句子中有多重视其他部分。</p>
<p>得分的计算是由其他单词的key vector和该单词的query vector进行点积计算。</p>
<p><strong>第三步</strong>是对每个得分除以$\sqrt{d_k}$然后进行softmax可以得出每个位置的单词对该位置的贡献。</p>
<p><strong>第四步</strong>是将每个单词的value vector与求出来的softmax权重相乘，可以关注语义上联系很强的单词。</p>
<p><strong>第五步</strong>是将所有带权重的value vector进行求和，当作self-attention的输出。</p>
<p><img src="/2020/06/03/DETR-note/5.png" style="zoom:50%;"></p>
<p>在实际的运算中是以矩阵来进行运算的。</p>
<p><img src="/2020/06/03/DETR-note/6.png" style="zoom:50%;"></p>
<h5 id="multi-head机制"><a href="#multi-head机制" class="headerlink" title="multi-head机制"></a>multi-head机制</h5><ol>
<li>多头注意力扩展了模型专注于不同位置的能力</li>
<li>可以将每个词嵌入投射到不同的子空间</li>
</ol>
<p>n个注意力头会产生n个z输出，通过$W^0$与拼接好的输出进行相乘得到最后融合多个注意力头的Z</p>
<p><img src="/2020/06/03/DETR-note/7.png" style="zoom:50%;"></p>
<p>self-attention的总体计算过程</p>
<p><img src="/2020/06/03/DETR-note/8.png" style="zoom:67%;"></p>
<h5 id="Position-Encoding"><a href="#Position-Encoding" class="headerlink" title="Position Encoding"></a>Position Encoding</h5><p>在词嵌入中，将每个单词的位置编码(向量)加入到嵌入向量中，描述单词的输入顺序。</p>
<p><img src="/2020/06/03/DETR-note/9.png" style="zoom:67%;"><img src="/2020/06/03/DETR-note/10.png" alt></p>
<p>(Positional Embedding左半部分通过正弦函数求出，右半部分通过余弦函数求出)</p>
<h5 id="Residuals"><a href="#Residuals" class="headerlink" title="Residuals"></a>Residuals</h5><p><img src="/2020/06/03/DETR-note/10.png" style="zoom:67%;"></p>
<h4 id="解码器"><a href="#解码器" class="headerlink" title="解码器"></a>解码器</h4><p> <img src="https://jalammar.github.io/images/t/transformer_decoding_2.gif" alt="img"> </p>
<p>编码器通过处理输入序列开启工作。顶端编码器的输出之后会变转化为一个包含向量K（键向量）和V（值向量）的注意力向量集 。这些向量将被每个解码器用于自身的“编码-解码注意力层”，而这些层可以帮助解码器关注输入序列哪些位置合适 。</p>
<p> 这个“编码-解码注意力层”工作方式基本就像多头自注意力层一样，只不过它是通过在它下面的层来创造查询矩阵，并且从编码器的输出中取得键/值矩阵。 </p>
<p><strong>整体结构</strong></p>
<p><img src="/2020/06/03/DETR-note/11.png" style="zoom:80%;"></p>
<h2 id="DETR"><a href="#DETR" class="headerlink" title="DETR"></a>DETR</h2><h3 id="二分图匹配损失函数-bipartite-matiching-loss"><a href="#二分图匹配损失函数-bipartite-matiching-loss" class="headerlink" title="二分图匹配损失函数(bipartite matiching loss)"></a>二分图匹配损失函数(bipartite matiching loss)</h3><p>图片经过CNN提取特征输入Transformer模型，输出N个固定prediction box(class, bbox)格式。GT的bbox也以(class,bbox)的形式存在，并且补齐N个$(\emptyset,*)$ bbox。</p>
<p>通过最佳匹配算法(匈牙利算法)来确定GT的最佳匹配框，然后可以计算损失函数。</p>
<p>将输出的bbox与GT的bbox对应起来，寻找一个最佳的对应关系，使得loss最小。(这样做的好处是可以将多个输出相同object的框选择一个最优的输出bbox与GT标注框对应，迫使模型学习输出更多不同object的bbox，并且匈牙利算法会对预测的object数大于GT的object数进行惩罚)</p>
<h3 id="DETR结构"><a href="#DETR结构" class="headerlink" title="DETR结构"></a>DETR结构</h3><p><img src="/2020/06/03/DETR-note/12.png" alt></p>
<ol>
<li><p>将图像经过CNN提取的特征与object的位置positional encoding结合送入transformer encoder中。</p>
<p>(由于transformer只接受序列化输入，所以将(C,H,W) flatten 得到(C, HXW)的序列化特征)</p>
</li>
<li><p>将encoder的输出特征传入decoder(相当于一个特征映射的过程，encoder能够学习更多的其他位置的特征)，decoder的输入是object queries，object queries首先是n个随机变量，经过decoder融合encoder输出的图像信息得出n个合适的bbox输出（n个object queries可以当作n个不同的人从n个不同的角度对图像进行观测，<strong>注意</strong>图像不同的地方，<strong>是需要学习的</strong>）</p>
</li>
</ol>
<p><strong>具体结构</strong></p>
<p><img src="/2020/06/03/DETR-note/13.png" style="zoom:80%;"></p>
<h3 id="实现代码"><a href="#实现代码" class="headerlink" title="实现代码"></a>实现代码</h3><p><strong>pytorch</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torchvision.models <span class="keyword">import</span> resnet50</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DETR</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_classes, hidden_dim, nheads,</span></span></span><br><span class="line"><span class="function"><span class="params">num_encoder_layers, num_decoder_layers</span>):</span></span><br><span class="line">	super().__init__()</span><br><span class="line"><span class="comment"># We take only convolutional layers from ResNet-50 model</span></span><br><span class="line">	self.backbone = nn.Sequential(*list(resnet50(pretrained=<span class="literal">True</span>).children())[:<span class="number">-2</span>])</span><br><span class="line">	self.conv = nn.Conv2d(<span class="number">2048</span>, hidden_dim, <span class="number">1</span>)</span><br><span class="line">    self.transformer = nn.Transformer(hidden_dim, nheads,</span><br><span class="line">	num_encoder_layers, num_decoder_layers)</span><br><span class="line">	self.linear_class = nn.Linear(hidden_dim, num_classes + <span class="number">1</span>)</span><br><span class="line">	self.linear_bbox = nn.Linear(hidden_dim, <span class="number">4</span>)</span><br><span class="line">	self.query_pos = nn.Parameter(torch.rand(<span class="number">100</span>, hidden_dim))</span><br><span class="line">	self.row_embed = nn.Parameter(torch.rand(<span class="number">50</span>, hidden_dim // <span class="number">2</span>))</span><br><span class="line">	self.col_embed = nn.Parameter(torch.rand(<span class="number">50</span>, hidden_dim // <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, inputs</span>):</span></span><br><span class="line">		x = self.backbone(inputs)</span><br><span class="line">		h = self.conv(x)</span><br><span class="line">		H, W = h.shape[<span class="number">-2</span>:]</span><br><span class="line">		pos = torch.cat([</span><br><span class="line">		self.col_embed[:W].unsqueeze(<span class="number">0</span>).repeat(H, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">		self.row_embed[:H].unsqueeze(<span class="number">1</span>).repeat(<span class="number">1</span>, W, <span class="number">1</span>),</span><br><span class="line">			], dim=<span class="number">-1</span>).flatten(<span class="number">0</span>, <span class="number">1</span>).unsqueeze(<span class="number">1</span>)</span><br><span class="line">		h = self.transformer(pos + h.flatten(<span class="number">2</span>).permute(<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>),</span><br><span class="line">		self.query_pos.unsqueeze(<span class="number">1</span>))</span><br><span class="line">		<span class="keyword">return</span> self.linear_class(h), self.linear_bbox(h).sigmoid()</span><br><span class="line"></span><br><span class="line">detr = DETR(num_classes=<span class="number">91</span>, hidden_dim=<span class="number">256</span>, nheads=<span class="number">8</span>, num_encoder_layers=<span class="number">6</span>, num_decoder_layers=<span class="number">6</span>)</span><br><span class="line">detr.eval()</span><br><span class="line">inputs = torch.randn(<span class="number">1</span>, <span class="number">3</span>, <span class="number">800</span>, <span class="number">1200</span>)</span><br><span class="line">logits, bboxes = detr(inputs)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>Django学习笔记（三）</title>
    <url>/2019/03/12/Django%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<h1 id="初试API"><a href="#初试API" class="headerlink" title="初试API"></a>初试API</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$python manage.py shell</span><br></pre></td></tr></table></figure>
<h1 id="创建一个管理员账号"><a href="#创建一个管理员账号" class="headerlink" title="创建一个管理员账号"></a>创建一个管理员账号</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$python manage.py createsuperuser</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Web学习</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title>FCN note</title>
    <url>/2020/04/13/FCN-note/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<h1 id="FCN：Semantic-Segmentation"><a href="#FCN：Semantic-Segmentation" class="headerlink" title="FCN：Semantic Segmentation"></a>FCN：Semantic Segmentation</h1><p>图像的语义分割，简言之就是对一张图片上的所有像素点进行分类</p>
<h4 id="1-FCN介绍"><a href="#1-FCN介绍" class="headerlink" title="1 FCN介绍"></a>1 FCN介绍</h4><p>​    与传统的CNN解决的分类与检测问题不同，语义分割是一个空间密集型的预测任务，是<strong>像素级别</strong>的，需要对图像上所有的像素进行分类。 由于CNN在进行convolution和pooling过程中丢失了图像细节，即feature map size逐渐变小，所以不能很好地指出物体的具体轮廓、指出每个像素具体属于哪个物体，无法做到精确的分割。 </p>
<p>​    FCN是针对语义分割训练的的一个端到端的网络, 是处理语义分割问题的基本框架，后续算法其实都是在这个框架中改进而来。 </p>
<h5 id="1-1-卷积化"><a href="#1-1-卷积化" class="headerlink" title="1.1 卷积化"></a>1.1 卷积化</h5><p>​    在一般的分类任务中在conv层之后一般会有全连接层,将二维的图像特征压缩为一维,可以训练输出一个标量,成为分类标签。这样做会失去部分的空间信息，不适用于分割的操作。</p>
<p>​    语义分割输出为分割图，信息是二维的，所以在进行网络构建的时候抛弃了全连接层而是采用了卷积层，叫做卷积化。</p>
<p><img src="/2020/04/13/FCN-note/1.png" alt></p>
<h5 id="1-2-上采样-Upsampling"><a href="#1-2-上采样-Upsampling" class="headerlink" title="1.2 上采样(Upsampling)"></a>1.2 上采样(Upsampling)</h5><p>上采样与下采样相反，我们需要得到原图像的分割图就需要将缩小的特征恢复到原来的size。</p>
<p>上采样一般有两种方式：</p>
<ul>
<li>Resize 即图片缩放</li>
<li>Deconvolution（反卷积） 也叫做Transposed Convolution（转置卷积）</li>
</ul>
<p>常用的方式就是反卷积</p>
<p>反卷积通俗的来讲就是将普通的卷积操作反过来做。</p>
<p>PS：</p>
<p>输入为2X2矩阵，kernel_size = 3, pad = 0, stride = 1,进行反卷积操作会变成4X4的矩阵</p>
<p><img src="/2020/04/13/FCN-note/1.gif" style="zoom:50%;"></p>
<p>反卷积公式如下</p>
<p>$output = (input-1)<em>stride + outputpadding-2</em>padding+kernel_size$</p>
<p>upsampling的意义在于小尺寸的高纬度feature map恢复成原来图像的大小，再做像素预测，获取每个像素的分类信息。</p>
<p>为了更好地将图像还原成原来的尺寸，在FCN中还加入了crop层，</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#caffe中的crop层定义</span></span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">&quot;score_pool4c&quot;</span></span><br><span class="line">  type: <span class="string">&quot;Crop&quot;</span></span><br><span class="line">  bottom: <span class="string">&quot;score_pool4&quot;</span>  <span class="comment"># 需要裁切的blob</span></span><br><span class="line">  bottom: <span class="string">&quot;upscore2&quot;</span>     <span class="comment"># 用于指示裁切尺寸的blob，和输出blob一样大</span></span><br><span class="line">  top: <span class="string">&quot;score_pool4c&quot;</span>    <span class="comment"># 输出blob</span></span><br><span class="line">  crop_param &#123;</span><br><span class="line">    axis: <span class="number">2</span></span><br><span class="line">    offset: <span class="number">5</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>相当于在图像的W，H纬度进行剪裁。用python的语法表示为</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">score_pool4c = score_pool4[:, :, <span class="number">5</span>:<span class="number">5</span>+crop_h, <span class="number">5</span>:<span class="number">5</span>+crop_w]</span><br></pre></td></tr></table></figure>
<h5 id="1-3-跳跃结构-Skip-Architecture"><a href="#1-3-跳跃结构-Skip-Architecture" class="headerlink" title="1.3 跳跃结构(Skip Architecture)"></a>1.3 跳跃结构(Skip Architecture)</h5><p>​    如果只用最后一层池化结果进行上采样的话得到的结果通常十分粗糙，所以FCN采用了将不同池化层的结果进行上采样最后叠加的结构来增加精确度。</p>
<p><img src="/2020/04/13/FCN-note/2.png" style="zoom:80%;"></p>
<p> 效果：FCN-32s &lt; FCN-16s &lt; FCN-8s，即<strong>使用多层feature融合有利于提高分割准确性</strong>。 </p>
<p><img src="/2020/04/13/FCN-note/3.png" style="zoom:80%;"></p>
<h4 id="2-代码实现"><a href="#2-代码实现" class="headerlink" title="2 代码实现"></a>2 代码实现</h4><p><strong>FCN model代码</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FCN8s</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_classes, pretrained=True, caffe=False</span>):</span></span><br><span class="line">        super(FCN8s, self).__init__()</span><br><span class="line">        vgg = models.vgg16()</span><br><span class="line">        <span class="keyword">if</span> pretrained:</span><br><span class="line">            <span class="keyword">if</span> caffe:</span><br><span class="line">                <span class="comment"># load the pretrained vgg16 used by the paper&#x27;s author</span></span><br><span class="line">                vgg.load_state_dict(torch.load(vgg16_caffe_path))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                vgg.load_state_dict(torch.load(vgg16_path))</span><br><span class="line">        features, classifier = list(vgg.features.children()), list(vgg.classifier.children())</span><br><span class="line"></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        100 padding for 2 reasons:</span></span><br><span class="line"><span class="string">            1) support very small input size</span></span><br><span class="line"><span class="string">            2) allow cropping in order to match size of different layers&#x27; feature maps</span></span><br><span class="line"><span class="string">        Note that the cropped part corresponds to a part of the 100 padding</span></span><br><span class="line"><span class="string">        Spatial information of different layers&#x27; feature maps cannot be align exactly because of cropping, which is bad</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        features[<span class="number">0</span>].padding = (<span class="number">100</span>, <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> f <span class="keyword">in</span> features:</span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;MaxPool&#x27;</span> <span class="keyword">in</span> f.__class__.__name__:</span><br><span class="line">                f.ceil_mode = <span class="literal">True</span></span><br><span class="line">            <span class="keyword">elif</span> <span class="string">&#x27;ReLU&#x27;</span> <span class="keyword">in</span> f.__class__.__name__:</span><br><span class="line">                f.inplace = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">        self.features3 = nn.Sequential(*features[: <span class="number">17</span>])</span><br><span class="line">        self.features4 = nn.Sequential(*features[<span class="number">17</span>: <span class="number">24</span>])</span><br><span class="line">        self.features5 = nn.Sequential(*features[<span class="number">24</span>:])</span><br><span class="line"></span><br><span class="line">        self.score_pool3 = nn.Conv2d(<span class="number">256</span>, num_classes, kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.score_pool4 = nn.Conv2d(<span class="number">512</span>, num_classes, kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.score_pool3.weight.data.zero_()</span><br><span class="line">        self.score_pool3.bias.data.zero_()</span><br><span class="line">        self.score_pool4.weight.data.zero_()</span><br><span class="line">        self.score_pool4.bias.data.zero_()</span><br><span class="line"></span><br><span class="line">        fc6 = nn.Conv2d(<span class="number">512</span>, <span class="number">4096</span>, kernel_size=<span class="number">7</span>)</span><br><span class="line">        fc6.weight.data.copy_(classifier[<span class="number">0</span>].weight.data.view(<span class="number">4096</span>, <span class="number">512</span>, <span class="number">7</span>, <span class="number">7</span>))</span><br><span class="line">        fc6.bias.data.copy_(classifier[<span class="number">0</span>].bias.data)</span><br><span class="line">        fc7 = nn.Conv2d(<span class="number">4096</span>, <span class="number">4096</span>, kernel_size=<span class="number">1</span>)</span><br><span class="line">        fc7.weight.data.copy_(classifier[<span class="number">3</span>].weight.data.view(<span class="number">4096</span>, <span class="number">4096</span>, <span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        fc7.bias.data.copy_(classifier[<span class="number">3</span>].bias.data)</span><br><span class="line">        score_fr = nn.Conv2d(<span class="number">4096</span>, num_classes, kernel_size=<span class="number">1</span>)</span><br><span class="line">        score_fr.weight.data.zero_()</span><br><span class="line">        score_fr.bias.data.zero_()</span><br><span class="line">        self.score_fr = nn.Sequential(</span><br><span class="line">            fc6, nn.ReLU(inplace=<span class="literal">True</span>), nn.Dropout(), fc7, nn.ReLU(inplace=<span class="literal">True</span>), nn.Dropout(), score_fr</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.upscore2 = nn.ConvTranspose2d(num_classes, num_classes, kernel_size=<span class="number">4</span>, stride=<span class="number">2</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.upscore_pool4 = nn.ConvTranspose2d(num_classes, num_classes, kernel_size=<span class="number">4</span>, stride=<span class="number">2</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.upscore8 = nn.ConvTranspose2d(num_classes, num_classes, kernel_size=<span class="number">16</span>, stride=<span class="number">8</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.upscore2.weight.data.copy_(get_upsampling_weight(num_classes, num_classes, <span class="number">4</span>))</span><br><span class="line">        self.upscore_pool4.weight.data.copy_(get_upsampling_weight(num_classes, num_classes, <span class="number">4</span>))</span><br><span class="line">        self.upscore8.weight.data.copy_(get_upsampling_weight(num_classes, num_classes, <span class="number">16</span>))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x_size = x.size()</span><br><span class="line">        pool3 = self.features3(x)</span><br><span class="line">        pool4 = self.features4(pool3)</span><br><span class="line">        pool5 = self.features5(pool4)</span><br><span class="line"></span><br><span class="line">        score_fr = self.score_fr(pool5)</span><br><span class="line">        upscore2 = self.upscore2(score_fr)</span><br><span class="line"></span><br><span class="line">        score_pool4 = self.score_pool4(<span class="number">0.01</span> * pool4)</span><br><span class="line">        upscore_pool4 = self.upscore_pool4(score_pool4[:, :, <span class="number">5</span>: (<span class="number">5</span> + upscore2.size()[<span class="number">2</span>]), <span class="number">5</span>: (<span class="number">5</span> + upscore2.size()[<span class="number">3</span>])]</span><br><span class="line">                                           + upscore2)</span><br><span class="line"></span><br><span class="line">        score_pool3 = self.score_pool3(<span class="number">0.0001</span> * pool3)</span><br><span class="line">        upscore8 = self.upscore8(score_pool3[:, :, <span class="number">9</span>: (<span class="number">9</span> + upscore_pool4.size()[<span class="number">2</span>]), <span class="number">9</span>: (<span class="number">9</span> + upscore_pool4.size()[<span class="number">3</span>])]</span><br><span class="line">                                 + upscore_pool4)</span><br><span class="line">        <span class="keyword">return</span> upscore8[:, :, <span class="number">31</span>: (<span class="number">31</span> + x_size[<span class="number">2</span>]), <span class="number">31</span>: (<span class="number">31</span> + x_size[<span class="number">3</span>])].contiguous()</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>语义分割</tag>
      </tags>
  </entry>
  <entry>
    <title>Django学习笔记（二）</title>
    <url>/2019/03/12/Django%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<h2 id="Django基本命令"><a href="#Django基本命令" class="headerlink" title="Django基本命令"></a>Django基本命令</h2><h3 id="创建project"><a href="#创建project" class="headerlink" title="创建project"></a>创建project</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$django-admin startproject myproject</span><br></pre></td></tr></table></figure>
<p>进入myproject目录</p>
<h3 id="使用开发服务器"><a href="#使用开发服务器" class="headerlink" title="使用开发服务器"></a>使用开发服务器</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$ python manage.py runserver</span><br></pre></td></tr></table></figure>
<p>会报错</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">You&#39;re accessing the development server over HTTPS, but it only supports HTTP.</span><br></pre></td></tr></table></figure>
<p>django 默认的runserver使用的是http协议，如果需要https协议，需要以下3个库</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">django-extensions </span><br><span class="line">django-werkzeug-debugger-runserver </span><br><span class="line">pyOpenSSL</span><br></pre></td></tr></table></figure>
<p>安装</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pip install django-extensions</span><br><span class="line"></span><br><span class="line">pip install django-werkzeug-debugger-runserver</span><br><span class="line"></span><br><span class="line">pip install pyOpenSSL</span><br></pre></td></tr></table></figure>
<p>配置django的settings.py文件</p>
<p>在INSTALLED_APPS下添加</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;werkzeug_debugger_runserver&#x27;</span>,</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;django_extensions&#x27;</span>,</span><br></pre></td></tr></table></figure>
<p>在终端以https的方式运行</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$python manage.py runserver_plus --cert server.crt</span><br></pre></td></tr></table></figure>
<h3 id="创建APP"><a href="#创建APP" class="headerlink" title="创建APP"></a>创建APP</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$ python manage.py startapp learn</span><br></pre></td></tr></table></figure>
<h3 id="创建数据库表或更改数据库表或字段"><a href="#创建数据库表或更改数据库表或字段" class="headerlink" title="创建数据库表或更改数据库表或字段"></a>创建数据库表或更改数据库表或字段</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 1. 创建更改的文件</span></span><br><span class="line">python manage.py makemigrations</span><br><span class="line"><span class="comment"># 2. 将生成的py文件应用到数据库</span></span><br><span class="line">python manage.py migrate</span><br></pre></td></tr></table></figure>
<h3 id="清空数据库"><a href="#清空数据库" class="headerlink" title="清空数据库"></a>清空数据库</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$python manage.py flush</span><br></pre></td></tr></table></figure>
<h3 id="创建超级管理员"><a href="#创建超级管理员" class="headerlink" title="创建超级管理员"></a>创建超级管理员</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$python manage.py createsuperuser</span><br><span class="line"></span><br><span class="line"><span class="comment"># 按照提示输入用户名和对应的密码就好了邮箱可以留空，用户名和密码必填</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改 用户密码可以用：</span></span><br><span class="line">$python manage.py changepassword username</span><br></pre></td></tr></table></figure>
<h3 id="Django项目环境终端"><a href="#Django项目环境终端" class="headerlink" title="Django项目环境终端"></a>Django项目环境终端</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$python manage.py shell</span><br></pre></td></tr></table></figure>
<h3 id="数据库命令行"><a href="#数据库命令行" class="headerlink" title="数据库命令行"></a>数据库命令行</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$python manage.py dbshell</span><br></pre></td></tr></table></figure>
<p>Django 会自动进入在settings.py中设置的数据库，如果是 MySQL 或 postgreSQL,会要求输入数据库用户密码。</p>
<p>在这个终端可以执行数据库的SQL语句。如果对SQL比较熟悉，可能喜欢这种方式。</p>
<h2 id="视图"><a href="#视图" class="headerlink" title="视图"></a>视图</h2><p>在/views.py中输入代码</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> django.http <span class="keyword">import</span> HttpResponse</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">index</span>(<span class="params">request</span>):</span></span><br><span class="line">    <span class="keyword">return</span> HttpResponse(<span class="string">&quot;Hello, world. You&#x27;re at the learn index.&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>如果想看见效果，我们需要将一个 URL 映射到它</p>
<p>为了创建 URLconf，请在 learn目录里新建一个 <code>urls.py</code> 文件。</p>
<p>在urls.py中输入代码</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> django.urls <span class="keyword">import</span> path</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> . <span class="keyword">import</span> views</span><br><span class="line"></span><br><span class="line">urlpatterns = [</span><br><span class="line">    path(<span class="string">&#x27;&#x27;</span>, views.index, name=<span class="string">&#x27;index&#x27;</span>),</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">path函数有四个参数</span></span><br><span class="line"><span class="string">两个必须参数：route 和 view，两个可选参数：kwargs 和 name。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@route:</span></span><br><span class="line"><span class="string">route 是一个匹配 URL 的准则（类似正则表达式）。当 Django 响应一个请求时，它会从 urlpatterns 的第一项开始，按顺序依次匹配列表中的项，直到找到匹配的项。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">这些准则不会匹配 GET 和 POST 参数或域名。例如，URLconf 在处理请求 https://www.example.com/myapp/ 时，它会尝试匹配 myapp/ 。处理请求 https://www.example.com/myapp/?page=3 时，也只会尝试匹配 myapp/。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@view:</span></span><br><span class="line"><span class="string">当 Django 找到了一个匹配的准则，就会调用这个特定的视图函数，并传入一个 HttpRequest 对象作为第一个参数，被“捕获”的参数以关键字参数的形式传入。稍后，我们会给出一个例子。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@kwargs:</span></span><br><span class="line"><span class="string">任意个关键字参数可以作为一个字典传递给目标视图函数。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@name:</span></span><br><span class="line"><span class="string">为你的 URL 取名能使你在 Django 的任意地方唯一地引用它，尤其是在模板中。这个有用的特性允许你只改一个文件就能全局地修改某个 URL 模式。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>下一步是要在根 URLconf 文件中指定我们创建的 <code>learn.urls</code> 模块。在 <code>vx/urls.py</code> 文件的 <code>urlpatterns</code> 列表里插入一个 <code>include()</code>， 如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> django.contrib <span class="keyword">import</span> admin</span><br><span class="line"><span class="keyword">from</span> django.urls <span class="keyword">import</span> include, path</span><br><span class="line"></span><br><span class="line">urlpatterns = [</span><br><span class="line">    path(<span class="string">&#x27;learn/&#x27;</span>, include(<span class="string">&#x27;learn.urls&#x27;</span>)),</span><br><span class="line">    path(<span class="string">&#x27;admin/&#x27;</span>, admin.site.urls),</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>函数 <code>include()</code>允许引用其它 URLconfs。每当 Django 遇到 <code>:func：~django.urls.include</code>时，它会截断与此项匹配的 URL 的部分，并将剩余的字符串发送到 URLconf 以供进一步处理。</p>
<p>我们设计 <code>include()</code>的理念是使其可以即插即用。因为应用有它自己的URLconf( <code>vx/urls.py</code> )，他们能够被放在<code>&quot;/vx/&quot; ， &quot;/fun_vx/&quot; ，&quot;/content/vx/&quot;</code>，或者其他任何路径下，这个应用都能够正常工作。</p>
<p>当包括其它 URL 模式时你应该总是使用 <code>include()</code> ， <code>admin.site.urls</code> 是唯一例外。</p>
<p>运行</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$python manage.py runserver_plus --cert server.crt</span><br></pre></td></tr></table></figure>
<p>访问<code>.../learn</code>即可看见简单的文字视图</p>
<h2 id="数据库配置"><a href="#数据库配置" class="headerlink" title="数据库配置"></a>数据库配置</h2><p><code>vx/settings.py</code>是Django项目设置的python模块。</p>
<p>通常，这个配置文件使用 SQLite 作为默认数据库。如果你不熟悉数据库，或者只是想尝试下 Django，这是最简单的选择。Python 内置 SQLite，所以你无需安装额外东西来使用它。当你开始一个真正的项目时，你可能更倾向使用一个更具扩展性的数据库，例如 PostgreSQL，避免中途切换数据库这个令人头疼的问题。</p>
<p>如果你想使用其他数据库，你需要安装合适的 <a href="https://docs.djangoproject.com/zh-hans/2.1/topics/install/#database-installation">database bindings</a> ，然后改变设置文件中 <a href="https://docs.djangoproject.com/zh-hans/2.1/ref/settings/#std:setting-DATABASES"><code>DATABASES</code></a> <code>&#39;default&#39;</code> 项目中的一些键值：</p>
<ul>
<li><a href="https://docs.djangoproject.com/zh-hans/2.1/ref/settings/#std:setting-DATABASE-ENGINE"><code>ENGINE</code></a> — 可选值有 <code>&#39;django.db.backends.sqlite3&#39;</code>，<code>&#39;django.db.backends.postgresql&#39;</code>，<code>&#39;django.db.backends.mysql&#39;</code>，或 <code>&#39;django.db.backends.oracle&#39;</code>。其它 <a href="https://docs.djangoproject.com/zh-hans/2.1/ref/databases/#third-party-notes">可用后端</a>。</li>
<li><a href="https://docs.djangoproject.com/zh-hans/2.1/ref/settings/#std:setting-NAME"><code>NAME</code></a> - 数据库的名称。如果使用的是 SQLite，数据库将是你电脑上的一个文件，在这种情况下， <a href="https://docs.djangoproject.com/zh-hans/2.1/ref/settings/#std:setting-NAME"><code>NAME</code></a> 应该是此文件的绝对路径，包括文件名。默认值 <code>os.path.join(BASE_DIR, &#39;db.sqlite3&#39;)</code> 将会把数据库文件储存在项目的根目录。</li>
</ul>
<p>在编辑/settings之前，将TIME_ZONE设置为自己所在时区</p>
<p>通常， <a href="https://docs.djangoproject.com/zh-hans/2.1/ref/settings/#std:setting-INSTALLED_APPS"><code>INSTALLED_APPS</code></a> 默认包括了以下 Django 的自带应用：</p>
<ul>
<li><a href="https://docs.djangoproject.com/zh-hans/2.1/ref/contrib/admin/#module-django.contrib.admin"><code>django.contrib.admin</code></a> — 管理员站点， 你很快就会使用它。</li>
<li><a href="https://docs.djangoproject.com/zh-hans/2.1/topics/auth/#module-django.contrib.auth"><code>django.contrib.auth</code></a> — 认证授权系统。</li>
<li><a href="https://docs.djangoproject.com/zh-hans/2.1/ref/contrib/contenttypes/#module-django.contrib.contenttypes"><code>django.contrib.contenttypes</code></a> — 内容类型框架。</li>
<li><a href="https://docs.djangoproject.com/zh-hans/2.1/topics/http/sessions/#module-django.contrib.sessions"><code>django.contrib.sessions</code></a> — 会话框架。</li>
<li><a href="https://docs.djangoproject.com/zh-hans/2.1/ref/contrib/messages/#module-django.contrib.messages"><code>django.contrib.messages</code></a> — 消息框架。</li>
<li><a href="https://docs.djangoproject.com/zh-hans/2.1/ref/contrib/staticfiles/#module-django.contrib.staticfiles"><code>django.contrib.staticfiles</code></a> — 管理静态文件的框架。</li>
</ul>
<p>这些应用被默认启用是为了给常规项目提供方便。</p>
<p>默认开启的某些应用需要至少一个数据表，所以，在使用他们之前需要在数据库中创建一些表。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$python manage.py migrate</span><br></pre></td></tr></table></figure>
<h2 id="创造模型"><a href="#创造模型" class="headerlink" title="创造模型"></a>创造模型</h2><p>在 Django 里写一个数据库驱动的 Web 应用的第一步是定义模型 - 也就是数据库结构设计和附加的其它元数据。</p>
<p>在learn/models.py中创建python类</p>
<h2 id="激活模型"><a href="#激活模型" class="headerlink" title="激活模型"></a>激活模型</h2><p>创建模型的代码给了 Django 很多信息，通过这些信息，Django 可以：</p>
<ul>
<li>为这个应用创建数据库 schema（生成 <code>CREATE TABLE</code> 语句）。</li>
<li>创建可以与 <code>Question</code> 和 <code>Choice</code> 对象进行交互的 Python 数据库 API。</li>
</ul>
<p>但是首先得把 <code>learn</code> 应用安装到我们的项目里。</p>
<p>为了在我们的工程中包含这个应用，我们需要在配置类 <a href="https://docs.djangoproject.com/zh-hans/2.1/ref/settings/#std:setting-INSTALLED_APPS"><code>INSTALLED_APPS</code></a> 中添加设置。因为 <code>learnConfig</code> 类写在文件 <code>learn/apps.py</code> 中，所以它的点式路径是 <code>&#39;learn.apps.learnConfig&#39;</code>。在文件 <code>mysite/settings.py</code>中 <a href="https://docs.djangoproject.com/zh-hans/2.1/ref/settings/#std:setting-INSTALLED_APPS"><code>INSTALLED_APPS</code></a> 子项添加点式路径。</p>
<p>运行命令进行模型迁移</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$python manage.py  makemigrations learn</span><br></pre></td></tr></table></figure>
<p>运行<code>migrate</code>命令在数据库里创建新定义的模型的数据表</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$python manage.py migrate</span><br></pre></td></tr></table></figure>
<p>迁移是非常强大的功能，它能让你在开发过程中持续的改变数据库结构而不需要重新删除和创建表 - 它专注于使数据库平滑升级而不会丢失数据。我们会在后面的教程中更加深入的学习这部分内容，现在，你只需要记住，改变模型需要这三步：</p>
<ul>
<li>编辑 <code>models.py</code> 文件，改变模型。</li>
<li>运行 <a href="https://docs.djangoproject.com/zh-hans/2.1/ref/django-admin/#django-admin-makemigrations"><code>python manage.py makemigrations</code></a> 为模型的改变生成迁移文件。</li>
<li>运行 <a href="https://docs.djangoproject.com/zh-hans/2.1/ref/django-admin/#django-admin-migrate"><code>python manage.py migrate</code></a> 来应用数据库迁移。</li>
</ul>
]]></content>
      <categories>
        <category>Web学习</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title>Django学习笔记（一）</title>
    <url>/2019/03/12/Django%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<h2 id="Django文件"><a href="#Django文件" class="headerlink" title="Django文件"></a>Django文件</h2><h3 id="urls-py"><a href="#urls-py" class="headerlink" title="urls.py"></a>urls.py</h3><p>网址入口，关联到对应的views.py中的一个函数（或者generic类），访问网址就对应一个函数。</p>
<h3 id="views-py"><a href="#views-py" class="headerlink" title="views,py"></a>views,py</h3><p>处理用户发出的请求，从urls.py中对应过来, 通过渲染templates中的网页可以将显示内容，比如登陆后的用户名，用户请求的数据，输出到网页。</p>
<h3 id="models-py"><a href="#models-py" class="headerlink" title="models.py"></a>models.py</h3><p>与数据库操作相关，存入或读取数据时用到这个，当然用不到数据库的时候 你可以不使用。</p>
<h3 id="forms-py"><a href="#forms-py" class="headerlink" title="forms.py"></a>forms.py</h3><p>表单，用户在浏览器上输入数据提交，对数据的验证工作以及输入框的生成等工作，当然你也可以不使用。</p>
<p><strong>templates 文件夹</strong></p>
<p>views.py 中的函数渲染templates中的Html模板，得到动态内容的网页，当然可以用缓存来提高速度。</p>
<h3 id="admin-py"><a href="#admin-py" class="headerlink" title="admin.py"></a>admin.py</h3><p>后台，可以用很少量的代码就拥有一个强大的后台。</p>
<h3 id="settings-py"><a href="#settings-py" class="headerlink" title="settings.py"></a>settings.py</h3><p>Django 的设置，配置文件，比如 DEBUG 的开关，静态文件的位置等。</p>
<h2 id="Django安装"><a href="#Django安装" class="headerlink" title="Django安装"></a>Django安装</h2><h3 id="Django"><a href="#Django" class="headerlink" title="Django"></a>Django</h3><p>Windows下在Anaconda Prompt中用pip install Django安装</p>
<h3 id="虚拟环境依赖安装（搭建多个开发环境）"><a href="#虚拟环境依赖安装（搭建多个开发环境）" class="headerlink" title="虚拟环境依赖安装（搭建多个开发环境）"></a>虚拟环境依赖安装（搭建多个开发环境）</h3><p>Windows下Anaconda Prompt中用</p>
<p>pip install virtualenv virtualenvwrapper-win</p>
<p>安装</p>
<h4 id="虚拟环境使用方法"><a href="#虚拟环境使用方法" class="headerlink" title="虚拟环境使用方法"></a>虚拟环境使用方法</h4><p><strong>mkvirtualenv</strong> zqxt：创建运行环境zqxt</p>
<p><strong>workon</strong> zqxt: 工作在 zqxt 环境 或 从其它环境切换到 zqxt 环境</p>
<p><strong>deactivate</strong>: 退出终端环境</p>
<p><strong>rmvirtualenv</strong> ENV：删除运行环境ENV</p>
<p><strong>mkproject</strong> mic：创建mic项目和运行环境mic</p>
<p><strong>mktmpenv</strong>：创建临时运行环境</p>
<p><strong>lsvirtualenv</strong>: 列出可用的运行环境</p>
<p><strong>lssitepackages</strong>: 列出当前环境安装了的包</p>
<p>创建的环境是独立的，互不干扰，无需sudo权限即可使用 pip 来进行包的管理。</p>
]]></content>
      <categories>
        <category>Web学习</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title>Faster_RCNN 笔记</title>
    <url>/2020/04/11/Faster-RCNN-%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<p>Faster RCNN是在2016提出的用于目标检测的网络结构，并且与之前的网络不同，已经将特征提取(feature extraction)，proposal提取，bounding box regression，classification都整合在了一个网络之中。由于RCNN的准确度很大一部分依赖于proposal区域的选择，所以候选区确定尤为重要。Faster RCNN中的RPN是一个最为突出也是最重要的部分。</p>
<h3 id="Faster-RCNN的基本结构"><a href="#Faster-RCNN的基本结构" class="headerlink" title="Faster_RCNN的基本结构"></a>Faster_RCNN的基本结构</h3><p><img src="/2020/04/11/Faster-RCNN-%E7%AC%94%E8%AE%B0/1.png" style="zoom:67%;"></p>
<p><strong>1.Conv layers</strong></p>
<p>Faster RCNN首先使用了基础的Conv layer(conv+relu+pooling)提取输入图像的feature maps。提取出来的feature maps共享用于后续的RPN层以及全连接层。</p>
<p><strong><font color="red">2.RPN(Region Proposal Networks)</font></strong></p>
<p>RPN是Faster RCNN中最重要的部分，用于生成region proposals。RPN中引入了一个重要的概念anchor，通过每个位置的anchor(共有k个选框生成)，输出2k个score评估选框是否为目标，4k个score确定选框的位置。 <strong>正是anchor的引入实现了通过单一尺度图像特征映射并使用单一滤波器解决多尺度问题。</strong>softmax判断anchors属于positive或者negative，再利用bounding box regression修正anchors获得精确的proposals。 </p>
<p><strong>3.Roi Pooling</strong></p>
<p>该层收集输入的feature maps和proposals，综合这些信息后提取proposal feature maps，送入后续全连接层判定目标类别。</p>
<p><strong>4.Classification</strong></p>
<p>利用proposal feature maps计算proposal的类别，同时再次bounding box regression获得检测框最终的精确位置。 </p>
<h3 id="Faster-RCNN结构分析"><a href="#Faster-RCNN结构分析" class="headerlink" title="Faster RCNN结构分析"></a>Faster RCNN结构分析</h3><p><img src="/2020/04/11/Faster-RCNN-%E7%AC%94%E8%AE%B0/2.png" style="zoom:80%;"></p>
<p>​    上图是基于VGG16的Faster RCNN网络结构，输入任意尺寸的image，缩放至固定大小MXN，然后经过Conv layers提取feature maps先送入RPN网络中，通过3X3的卷积生成positive anchors以及对应的bounding box regression偏移量，输出proposals进入Roi poooling层通过proposal feature map进行classification。</p>
<h4 id="1-Conv-layers"><a href="#1-Conv-layers" class="headerlink" title="1 Conv layers"></a>1 Conv layers</h4><p>卷积层一共包括常规的三种层(conv,relu,pooling)</p>
<p><strong>conv层</strong></p>
<p>kernel_size = 3, pad = 1, stride = 1</p>
<p><strong>pooling层</strong></p>
<p>kernel_size = 3, pad = 1, stride = 1</p>
<p>在经过conv层之后，输入输出矩阵尺度不变。</p>
<p>最后变成M/16，N/16的feature map</p>
<h4 id="2-Region-Proposal-Networks-RPN"><a href="#2-Region-Proposal-Networks-RPN" class="headerlink" title="2 Region Proposal Networks(RPN)"></a>2 Region Proposal Networks(RPN)</h4><p>​     经典的检测方法生成检测框都非常耗时，如OpenCV adaboost使用滑动窗口+图像金字塔生成检测框；或如R-CNN使用SS(Selective Search)方法生成检测框。而Faster RCNN则抛弃了传统的滑动窗口和SS方法，直接使用RPN生成检测框，这也是Faster R-CNN的巨大优势，能极大提升检测框的生成速度。 </p>
<h5 id="2-1-anchors"><a href="#2-1-anchors" class="headerlink" title="2.1 anchors"></a>2.1 anchors</h5><pre><code> 遍历Conv layers计算获得的feature maps，为每一个点都配备这9种anchors作为初始的检测框。 之后可以通过bbox regression修正检测的位置。
</code></pre><p><img src="/2020/04/11/Faster-RCNN-%E7%AC%94%E8%AE%B0/3.png" alt></p>
<p>​    </p>
<p>​    在原文中最后的conv5层输出了256个特征图，即每个点对应256-dimensions。在最后conv5层之后进入RPN层利用3X3的卷积输出，维度也是256-d，在conv5输出的feature map上每个点对应k个anchor(默认k = 9)。每个anchor需要判断是都为positive anchor，每个点有256-d转化为cls = 2k scores，每个anchor又有4个偏移量确定位置(x, y, w, h)，reg = 4k scores。在进行训练时会随机选取1:1数量的positive anchor和negative anchor进行训练。</p>
<h5 id="2-2-每个anchor的输出"><a href="#2-2-每个anchor的输出" class="headerlink" title="2.2 每个anchor的输出"></a>2.2 每个anchor的输出</h5><p>在mmdetection的源代码rpn_head.py中对anchor的卷积描述为</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.rpn_cls = nn.Conv2d(self.feat_channels,</span><br><span class="line">                         self.num_anchors * self.cls_out_channels, <span class="number">1</span>)</span><br><span class="line">self.rpn_reg = nn.Conv2d(self.feat_channels, self.num_anchors * <span class="number">4</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>cls做了1X1的卷积输出为2k，代表该anchor是否为positive。</p>
<p>reg做了1X1的卷积输出为4k，代表该anchor对应region proposal的位置。</p>
<p> <strong>RPN最终就是在原图尺度上，设置了密密麻麻的候选Anchor。然后用cnn去判断哪些Anchor是里面有目标的positive anchor，哪些是没目标的negative anchor。所以，仅仅是个二分类而已！</strong> </p>
<h5 id="2-3-bbox-regression原理"><a href="#2-3-bbox-regression原理" class="headerlink" title="2.3 bbox regression原理"></a>2.3 bbox regression原理</h5><p>如图所示绿色框为飞机的Ground Truth(GT)，红色为提取的positive anchors，即便红色的框被分类器识别为飞机，但是由于红色的框定位不准，这张图相当于没有正确的检测出飞机。所以我们希望采用一种方法对红色的框进行微调，使得positive anchors和GT更加接近。</p>
<p><img src="/2020/04/11/Faster-RCNN-%E7%AC%94%E8%AE%B0/4.png" alt></p>
<p>bbox regression的目标是寻找一种关系使输入的anchor A经过映射得到跟真实窗口G更接近的回归窗口G’。（TODO）</p>
<p>对应于Faster RCNN原文，positive anchor与ground truth之间的平移量 <img src="https://www.zhihu.com/equation?tex=%28t_x%2C+t_y%29" alt="[公式]"> 与尺度因子 <img src="https://www.zhihu.com/equation?tex=%28t_w%2C+t_h%29" alt="[公式]"> 如下：</p>
<p><img src="https://www.zhihu.com/equation?tex=t_x%3D%28x-x_a%29%2Fw_a%5C+%5C+%5C+%5C++t_y%3D%28y-y_a%29%2Fh_a%5C%5C" alt="[公式]"></p>
<p><img src="https://www.zhihu.com/equation?tex=t_w%3D%5Clog%28w%2Fw_a%29%5C+%5C+%5C+%5C+t_h%3D%5Clog%28h%2Fh_a%29%5C%5C" alt="[公式]"></p>
<p>对于训练bouding box regression网络回归分支，输入是cnn feature Φ，监督信号是Anchor与GT的差距 <img src="https://www.zhihu.com/equation?tex=%28t_x%2C+t_y%2C+t_w%2C+t_h%29" alt="[公式]">，即训练目标是：输入 Φ的情况下使网络输出与监督信号尽可能接近。那么当bouding box regression工作时，再输入Φ时，回归网络分支的输出就是每个Anchor的平移量和变换尺度 <img src="https://www.zhihu.com/equation?tex=%28t_x%2C+t_y%2C+t_w%2C+t_h%29" alt="[公式]">，显然即可用来修正Anchor位置了。</p>
<p><strong>对proposals进行bounding box regression</strong></p>
<p><img src="/2020/04/11/Faster-RCNN-%E7%AC%94%E8%AE%B0/6.png" alt></p>
<p>经卷积输出后的图像为(W,H,36)，相当于feature map每个店都有9个anchors，每个anchors有四个用于回归的变换量。</p>
<h5 id="2-4-Proposal-layer"><a href="#2-4-Proposal-layer" class="headerlink" title="2.4 Proposal layer"></a>2.4 Proposal layer</h5><p><img src="/2020/04/11/Faster-RCNN-%E7%AC%94%E8%AE%B0/5.png" alt></p>
<p>Propsal layer负责综合所有的$[d_x(A), d_y(A),d_w(A),d_h(A)]$变换量和positive anchors，计算出精准的proposal，送入后续的RoIl Pooling Layer。</p>
<p> Proposal Layer有3个输入：positive vs negative anchors分类器结果rpn_cls_prob_reshape，对应的bbox reg的 $[d_x(A), d_y(A),d_w(A),d_h(A)]$变换量rpn_bbox_pred，以及im_info；另外还有参数feature_stride=16。<br>首先解释im_info。对于一副任意大小PxQ图像，传入Faster RCNN前首先reshape到固定MxN，im_info=[M, N, scale_factor]则保存了此次缩放的所有信息。然后经过Conv Layers，经过4次pooling变为WxH=(M/16)x(N/16)大小，其中feature_stride=16则保存了该信息，用于计算anchor偏移量。 </p>
<ol>
<li>对<strong>所有</strong> anchors 做bbox regression回归（learning offset）</li>
<li>对 <strong>foreground</strong> (iou&gt;0.7) softmax scores由大到小排序anchors，提取 6000/12000(test/train) anchors(<strong>已经在上一步进行好了 coord reg</strong>)</li>
<li>限定超出图像边界的 foreground anchors 为图像边界（防止后续roi pooling时proposal超出图像边界）</li>
<li>剔除非常小的foreground anchors <strong>(__C.TRAIN.RPN_MIN_SIZE = 16)</strong></li>
<li>进行 NMS(threshold=0.7)</li>
<li><p>提取 NMS 后的前300/2000(test/train) 个 fg anchor 结果作为proposal输出</p>
<p>RPN网络结构总结起来就是：<br><strong>生成anchors -&gt; softmax分类器提取positvie anchors -&gt; bbox reg回归positive anchors -&gt; Proposal Layer生成proposals</strong> </p>
</li>
</ol>
<h4 id="3-RoI-Pooling"><a href="#3-RoI-Pooling" class="headerlink" title="3 RoI Pooling"></a>3 RoI Pooling</h4><p>RoI Pooling负责收集proposal并计算出proposal feature maps，送入后面的classification网络。</p>
<p>RoI Pooling层有两个输入：</p>
<p>1.原始的feature maps</p>
<p>2.RPN输出的proposal boxes</p>
<p>与传统网络不同，传入的图像尺寸必须是固定值，就需要进行crop或者wrap，但效果都不好，破坏了图像原始的信息，这正是需要引入RoIl Pooling的理由。</p>
<h5 id="3-1-RoI-Pooling原理"><a href="#3-1-RoI-Pooling原理" class="headerlink" title="3.1 RoI Pooling原理"></a>3.1 RoI Pooling原理</h5><p>TODO</p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>FPN-note</title>
    <url>/2020/05/06/FPN-note/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<h1 id="FPN-Feature-Pyramid-Networks-for-Object-Detection"><a href="#FPN-Feature-Pyramid-Networks-for-Object-Detection" class="headerlink" title="FPN(Feature Pyramid Networks for Object Detection)"></a>FPN(Feature Pyramid Networks for Object Detection)</h1><p>FPN解决的主要问题是检测算法在处理多尺度变化问题时的不足以及对小物体检测不友好的问题。传统的方法是构造图像特征金字塔，但是计算量很大，FPN通过独特的构造避免了计算量过高的问题，并且有良好的多尺度处理性能。</p>
<p><img src="/2020/05/06/FPN-note/1.png" alt></p>
<p>图a为传统的多尺度特征提取方法，计算量极大。</p>
<p>图b为单一特征的检测系统，有很大的局限性。</p>
<p>图c为网络多层次结构提取特征，但是存在底层语义较弱的问题。</p>
<p>图d为FPN金字塔特征提取，能够让各个不同尺度的特征都拥有较强的语义信息。</p>
<h2 id="FPN算法"><a href="#FPN算法" class="headerlink" title="FPN算法"></a>FPN算法</h2><p> FPN包含两个部分：第一部分是自底向上的过程，第二部分是自顶向下和侧向连接的融合过程。 </p>
<h3 id="自底向上过程"><a href="#自底向上过程" class="headerlink" title="自底向上过程"></a>自底向上过程</h3><p> 自底向上的过程和普通的CNN没有区别。现代的CNN网络一般都是按照特征图大小划分为不同的stage，每个stage之间特征图的尺度比例相差为2。在FPN中，每个stage对应了一个特征金字塔的级别（level），并且每个stage的最后一层特征被选为对应FPN中相应级别的特征。以ResNet为例，选取conv2、conv3、conv4、conv5层的最后一个残差block层特征作为FPN的特征，记为{C2、C3、C4、C5}。这几个特征层相对于原图的步长分别为4、8、16、32。 </p>
<h3 id="自顶向下过程"><a href="#自顶向下过程" class="headerlink" title="自顶向下过程"></a>自顶向下过程</h3><p>自顶向下的过程通过上采样（up-sampling）的方式将顶层的小特征图（例如20）放大到上一个stage的特征图一样的大小（例如40）。这样的好处是既利用了顶层较强的语义特征（利于分类），又利用了底层的高分辨率信息（利于定位）。上采样的方法可以用最近邻差值实现。为了将高层语义特征和底层的精确定位能力结合，作者提出类似于残差网络的侧向连接结构。侧向连接将上一层经过上采样后和当前层分辨率一致的特征，通过相加的方法进行融合。（这里为了修正通道数量，将当前层先经过1x1卷积操作。）如图所示。</p>
<p><img src="/2020/05/06/FPN-note/2.png" style="zoom:80%;"></p>
<p>具体的，C5层先经过1x1卷积，得到M5特征。M5通过上采样，再加上C4经过1x1卷积后的特征，得到M4。这个过程再做两次，分别得到M3和M2。M层特征再经过3x3卷积，得到最终的P2、P3、P4、P5层特征。另外，和传统的图像金字塔方式一样，所有M层的通道数都设计成一样的，本文都用d=256。细节图如下所示（以ResNet为例）： </p>
<p><img src="/2020/05/06/FPN-note/3.png" style="zoom:67%;"></p>
<p> FPN本身不是检测算法，只是一个特征提取器。它需要和其他检测算法结合才能使用。 RetinaNet就是一个运用了FPN的网络。</p>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>以Resnet为Backbone</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PyramidFeatures</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, C3_size, C4_size, C5_size, feature_size=<span class="number">256</span></span>):</span></span><br><span class="line">        super(PyramidFeatures, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># upsample C5 to get P5 from the FPN paper</span></span><br><span class="line">        self.P5_1 = nn.Conv2d(C5_size, feature_size, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>)</span><br><span class="line">        self.P5_upsampled = nn.Upsample(scale_factor=<span class="number">2</span>, mode=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">        self.P5_2 = nn.Conv2d(feature_size, feature_size, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># add P5 elementwise to C4</span></span><br><span class="line">        self.P4_1 = nn.Conv2d(C4_size, feature_size, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>)</span><br><span class="line">        self.P4_upsampled = nn.Upsample(scale_factor=<span class="number">2</span>, mode=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">        self.P4_2 = nn.Conv2d(feature_size, feature_size, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># add P4 elementwise to C3</span></span><br><span class="line">        self.P3_1 = nn.Conv2d(C3_size, feature_size, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>)</span><br><span class="line">        self.P3_2 = nn.Conv2d(feature_size, feature_size, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># &quot;P6 is obtained via a 3x3 stride-2 conv on C5&quot;</span></span><br><span class="line">        self.P6 = nn.Conv2d(C5_size, feature_size, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># &quot;P7 is computed by applying ReLU followed by a 3x3 stride-2 conv on P6&quot;</span></span><br><span class="line">        self.P7_1 = nn.ReLU()</span><br><span class="line">        self.P7_2 = nn.Conv2d(feature_size, feature_size, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, inputs</span>):</span></span><br><span class="line">        C3, C4, C5 = inputs</span><br><span class="line"></span><br><span class="line">        P5_x = self.P5_1(C5)</span><br><span class="line">        P5_upsampled_x = self.P5_upsampled(P5_x)</span><br><span class="line">        P5_x = self.P5_2(P5_x)</span><br><span class="line"></span><br><span class="line">        P4_x = self.P4_1(C4)</span><br><span class="line">        P4_x = P5_upsampled_x + P4_x</span><br><span class="line">        P4_upsampled_x = self.P4_upsampled(P4_x)</span><br><span class="line">        P4_x = self.P4_2(P4_x)</span><br><span class="line"></span><br><span class="line">        P3_x = self.P3_1(C3)</span><br><span class="line">        P3_x = P3_x + P4_upsampled_x</span><br><span class="line">        P3_x = self.P3_2(P3_x)</span><br><span class="line"></span><br><span class="line">        P6_x = self.P6(C5)</span><br><span class="line"></span><br><span class="line">        P7_x = self.P7_1(P6_x)</span><br><span class="line">        P7_x = self.P7_2(P7_x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> [P3_x, P4_x, P5_x, P6_x, P7_x]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux下的信号量机制与编程</title>
    <url>/2019/04/22/Linux%E4%B8%8B%E7%9A%84%E4%BF%A1%E5%8F%B7%E9%87%8F%E6%9C%BA%E5%88%B6%E4%B8%8E%E7%BC%96%E7%A8%8B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<h1 id="信号量"><a href="#信号量" class="headerlink" title="信号量"></a>信号量</h1><p>当我们在多用户系统，多进程系统，或是两者混合的系统中使用线程操作编写程序时，我们经常会发现我们有段临界代码，在此处我们需要保证一个进程（或是一个线程的执行）需要排他的访问一个资源。</p>
<p>为了解决这个问题，引用了信号量机制，我们可以使用互斥或信号量来控制一个多线程程序对于临界区的访问。</p>
<p>信号量是一个特殊的变量，他是一个整数，并且只有两个操 作可以使得其值增加：等待(wait)与信号(signal)。</p>
<p><strong>用于等待(wait)的P(信号量变量)</strong><br><strong>用于信号(signal)的V(信号量变量)</strong></p>
<h2 id="二值信号量"><a href="#二值信号量" class="headerlink" title="二值信号量"></a>二值信号量</h2><p>二值信号量使是只有0和1两个值的变量</p>
<p>假如有一个信号量为mutex，有如下两个操作</p>
<ul>
<li>P(mutex)/wait(mutex)    若mutex大于0,mutex减为0;若mutex等于0,则挂起该进程</li>
<li>V(mutex)/signal(mutex)     若有进程被挂起等待mutex则释放mutex使被挂起的进程执行,若没有,则mutex加到1</li>
</ul>
<font color="red">**mutex取值只能为1/0**</font>

<p>也叫互斥信号量,可以用其管理临界区资源的控制权</p>
<h1 id="Linux中的信号量工具"><a href="#Linux中的信号量工具" class="headerlink" title="Linux中的信号量工具"></a>Linux中的信号量工具</h1><h2 id="信号量函数"><a href="#信号量函数" class="headerlink" title="信号量函数"></a>信号量函数</h2><p>信号量函数定义:</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/sem.h&gt;/*有可能还需要包含sys/types.h与sys/ipc.h文件*/</span></span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">semctl</span><span class="params">(<span class="keyword">int</span> sem_id, <span class="keyword">int</span> sem_num, <span class="keyword">int</span> command, ...)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">semget</span><span class="params">(<span class="keyword">key_t</span> key, <span class="keyword">int</span> num_sems, <span class="keyword">int</span> sem_flags)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">semop</span><span class="params">(<span class="keyword">int</span> sem_id, struct sembuf *sem_ops, <span class="keyword">size_t</span> num_sem_ops)</span></span>;</span><br></pre></td></tr></table></figure>
<p>这些函数用于操作信号量值数组</p>
<h3 id="semget函数"><a href="#semget函数" class="headerlink" title="semget函数"></a>semget函数</h3><p><strong>semget的作用： 创建一个新信号量 或者 取得一个已有的信号量</strong></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">semget</span><span class="params">(<span class="keyword">key_t</span> key, <span class="keyword">int</span> num_sems, <span class="keyword">int</span> sem_flags)</span></span>;</span><br></pre></td></tr></table></figure>
<ul>
<li><p><strong>key</strong>是整数值(唯一非零),可以任意指定一个正整数,semget可以根据key,<strong>新创建一个信号量</strong>,返回改信号量的标识,不相关的进程可以通过它访问这个创建的信号量,代表程序可能会使用某个资源.如果在两个进程中使用相同的key则key将负责两个进程的协调工作.</p>
<p><strong>PS:</strong></p>
<p>​    同一个key值返回的信号量标识相同</p>
<p>​    不同的key值会创建不同的信号量,且信号量之间没有任何关系</p>
</li>
<li><p><strong>num_sems</strong>表示需要的信号量数目,一般为1</p>
</li>
<li><p><strong>sem_flags</strong>是一组标志,与fopen函数的 “w” “b” “r”类似,最低的9位二进制数字代表了这个信号量的权限信息.如IPC_CREATE | 0666,这些标记可以与 IPC_CREAT进行或操作来创建新的信号量,同时又可以用于取一个已有的信号量,使用IPC_CREAT | IPC_EXCL 来确保新建信号量，如果信号量已经有了会返回错误。</p>
<p><strong>PS:</strong></p>
<p>​    IPC_CREAT   如果共享内存不存在，则创建一个共享内存，否则打开操作。</p>
<p>​    IPC_EXCL     只有在共享内存不存在的时候，新的共享内存才建立，否则就产生错误。</p>
</li>
</ul>
<p>semget函数成功返回一个相应信号量标识符(非0),失败返回-1.</p>
<h3 id="semop函数"><a href="#semop函数" class="headerlink" title="semop函数"></a>semop函数</h3><p><strong>semop函数用于对信号量进行操作。</strong></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">semop</span><span class="params">(<span class="keyword">int</span> sem_id, struct sembuf *sem_opa, <span class="keyword">size_t</span> num_sem_ops)</span></span>;</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>sem_id</strong>,表示对哪一个信号量进行操作,由semget函数返回</li>
<li><strong>sembuf *sem_ops</strong></li>
</ul>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">sembuf</span> &#123;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">short</span> sem_num;  <span class="comment">//要处理的信号量的下标,即指定对哪个信号灯进行操作(0,1,2...)若为二值信号量则为0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">short</span> sem_op;     <span class="comment">//要执行的操作,1表示加一,-1表示减一</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">short</span> sem_flg;     <span class="comment">//操作标志,通常设置为SEM_UNDO。这会使得操作系统跟踪当前进程对信号量所					  //做的改变，而且如果进程终止而没有释放这个信号量， 如果信号量为这个进					 //程所占有，这个标记可以使得操作系统自动释放这个信号量。</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>size_t num_sem_ops</strong>表示操作次数一般为1</li>
</ul>
<h3 id="semctl函数"><a href="#semctl函数" class="headerlink" title="semctl函数"></a>semctl函数</h3><p><strong>semctl用于直接控制信号量的信息，例如初始化一个值或删除信号量。</strong></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">semctl</span><span class="params">(<span class="keyword">int</span> sem_id, <span class="keyword">int</span> sem_num, <span class="keyword">int</span> command, ...)</span></span>;</span><br></pre></td></tr></table></figure>
<ul>
<li><p><strong>sem_id</strong>,表示对哪一个信号量进行操作,由semget函数返回</p>
</li>
<li><p><strong>sem_num</strong>,要处理的信号量的下标,即指定对哪个信号灯进行操作(0,1,2…)若为二值信号量则为0</p>
</li>
<li><p><strong>command</strong>,表示要执行的动作</p>
<ul>
<li>SETVAL：用于初始化信号量为一个已知的值。所需要的值作为联合semun.val成员来传递。在信号量第一次使用之前需要设置信号量。</li>
<li>IPC_RMID：当信号量不再需要时用于删除一个信号量标识。</li>
</ul>
</li>
<li><p><strong>union semun</strong> </p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">union</span> semun&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> val;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">semid_ds</span> *<span class="title">buf</span>;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">short</span> *<span class="built_in">array</span>;</span><br><span class="line"></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>这个声明一般包含在sem.h里面，也有可能没有，没有的话需要自己声明。</p>
</li>
</ul>
<p>根据command的不同，返回值也不同。对于 SETVAL和IPC_RMID 成功返回0 失败返回-1</p>
<h2 id="信号量的使用"><a href="#信号量的使用" class="headerlink" title="信号量的使用"></a>信号量的使用</h2><h3 id="创建信号量"><a href="#创建信号量" class="headerlink" title="创建信号量"></a>创建信号量</h3><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> sem_id;</span><br><span class="line">sem_id = semget((<span class="keyword">key_t</span>)<span class="number">1234</span>, <span class="number">2</span>, <span class="number">0666</span> | IPC_CREAT);</span><br><span class="line"><span class="keyword">if</span> (sem_id == <span class="number">-1</span>)</span><br><span class="line">    <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">&quot;Failed to create semapore\n&quot;</span>);</span><br></pre></td></tr></table></figure>
<h3 id="设置信号量初值"><a href="#设置信号量初值" class="headerlink" title="设置信号量初值"></a>设置信号量初值</h3><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">set_semvalue</span><span class="params">(<span class="keyword">int</span> sem_id, <span class="keyword">int</span> index, <span class="keyword">int</span> value)</span><span class="comment">//index为信号量中的第几个信号灯</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">		<span class="keyword">union</span> semun sem_union;</span><br><span class="line">		sem_union.val = value;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">if</span> (semctl(sem_id, index, SETVAL, sem_union) == <span class="number">-1</span>) </span><br><span class="line">			<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="删除信号量"><a href="#删除信号量" class="headerlink" title="删除信号量"></a>删除信号量</h3><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">del_semvalue</span><span class="params">(<span class="keyword">int</span> sem_id)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="keyword">if</span> (semctl(sem_id, <span class="number">0</span>, IPC_RMID) == <span class="number">-1</span>)</span><br><span class="line">		<span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">&quot;Failed to delete semapore\n&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="P操作"><a href="#P操作" class="headerlink" title="P操作"></a>P操作</h3><p>P操作是通过调用<strong>semop</strong>函数实现的。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">P</span><span class="params">(<span class="keyword">int</span> sem_id, <span class="keyword">int</span> index)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">sembuf</span> <span class="title">sem_b</span>;</span></span><br><span class="line"></span><br><span class="line">	sem_b.sem_num = index;</span><br><span class="line">	sem_b.sem_op = <span class="number">-1</span>;</span><br><span class="line">	sem_b.sem_flg = SEM_UNDO;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> (semop(sem_id, &amp;sem_b, <span class="number">1</span>) == <span class="number">-1</span>)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">&quot;semapore_p failed\n&quot;</span>);</span><br><span class="line">		<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="V操作"><a href="#V操作" class="headerlink" title="V操作"></a>V操作</h3><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">V</span><span class="params">(<span class="keyword">int</span> sem_id, <span class="keyword">int</span> index)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">		<span class="class"><span class="keyword">struct</span> <span class="title">sembuf</span> <span class="title">sem_b</span>;</span></span><br><span class="line"></span><br><span class="line">		sem_b.sem_num = index;</span><br><span class="line">		sem_b.sem_op = <span class="number">1</span>;</span><br><span class="line">		sem_b.sem_flg = SEM_UNDO;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">if</span> (semop(sem_id, &amp;sem_b, <span class="number">1</span>) == <span class="number">-1</span>)</span><br><span class="line">		&#123;</span><br><span class="line">				<span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">&quot;semapore_v failed\n&quot;</span>);</span><br><span class="line">				<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>Linux编程</tag>
      </tags>
  </entry>
  <entry>
    <title>OCR手写识别_NoTe1</title>
    <url>/2019/11/07/OCR%E6%89%8B%E5%86%99%E8%AF%86%E5%88%AB-NoTe1/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>OCR手写识别</tag>
      </tags>
  </entry>
  <entry>
    <title>PolarMask-note</title>
    <url>/2020/05/28/PolarMask-note/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<h1 id="PolorMask：one-stage实例分割新思路"><a href="#PolorMask：one-stage实例分割新思路" class="headerlink" title="PolorMask：one-stage实例分割新思路"></a>PolorMask：one-stage实例分割新思路</h1><h2 id="前置知识"><a href="#前置知识" class="headerlink" title="前置知识"></a>前置知识</h2><h3 id="FCOS"><a href="#FCOS" class="headerlink" title="FCOS"></a>FCOS</h3><p>​    FCOS是一个基于全卷积的one-stage检测网络，类似于语义分割针对每个像素进行预测。FCOS是anchor free，proposal free的检测器，可以减少大量的内存计算以及内存占用，并且不需要调优设计anchor和proposal的超参数。事实上这个anchor free方法还是有anchor的只不过不再是box形式，而是用点作为anchor，既减少了anchor数量又取消了超参。此外文章还提出了一个思路：<strong>将检测问题可以统一到其他FCN_solvable问题，可以简单的重用其他任务的idea。</strong></p>
<p>​    网络结构图如下：</p>
<p><img src="/2020/05/28/PolarMask-note/1.png" style="zoom:80%;"></p>
<p>​    可以从图中看出网络结构中也运用了FPN的结构但是没有使用backbone的所有卷积层，但考虑了多尺度的问题直接加入了P5的下采样P6/P7。最后的损失函数也分为三个分支，classification、regression(不同于boxes，回归的4D向量为[l, r, t, b]代表每个像素点向四周的延伸)、centerness。</p>
<p>​    文章还解决了重叠区域问题，引入了参数$m_i$为特征层$i$的最大距离，如果一个像素点(x, y)满足$max(l^<em>,t^</em>,r^<em>,b^</em>)&gt;m_i \or max(l^<em>,t^</em>,r^<em>,b^</em>)&lt;m_{i-1}$ 那么在该特征层将其视为负样本，不进行回归。</p>
<p>​    此外，作者还运用了Center-ness($\sqrt{\frac{min(l^<em>,r^</em>)}{max(l^<em>, r^</em>)}\times\frac{min(t^<em>, b^</em>)}{max(t^<em>,b^</em>)}}$)对离物体中心较远质量差的预测边框进行了抑制。通过BCE Loss来进行训练。可以在预测时降低远离物体中心边框的得分。</p>
<h3 id="PolorMask解决的问题"><a href="#PolorMask解决的问题" class="headerlink" title="PolorMask解决的问题"></a>PolorMask解决的问题</h3><p>将实例分割问题转化为基于<strong>实例中心分类(instance center classification)</strong>和<strong>密集距离回归(dense distance regression)</strong>的极坐标轮廓建模问题。提供了一种新的建模方式，让实例分割建模变得简单且高效。</p>
<h3 id="PolorMask细节"><a href="#PolorMask细节" class="headerlink" title="PolorMask细节"></a>PolorMask细节</h3><h4 id="Polor-Representation"><a href="#Polor-Representation" class="headerlink" title="Polor Representation"></a>Polor Representation</h4><p>文章提出了一种新的mask表示，极坐标轮廓表示。这种表示方法有三个优势：</p>
<ol>
<li>极坐标的原点可以看作物体的中心</li>
<li>轮廓上的点由距离和角度确定</li>
<li>角度是确定的，所以将点连接到轮廓十分方便。(这是笛卡尔坐标系不存在的优势)</li>
</ol>
<h4 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h4><p><img src="/2020/05/28/PolarMask-note/2.png" style="zoom:80%;"></p>
<p><em>ps：k = nr_class of dataset, n = the number of raws</em></p>
<p>在网络结构上，PolorMask与FCOS十分相似，只是在head部分将bbox分支换成了mask分支。在网络结构复杂度上与FCOS相似。</p>
<h4 id="Polar-Segmentation建模"><a href="#Polar-Segmentation建模" class="headerlink" title="Polar Segmentation建模"></a><strong>Polar Segmentation建模</strong></h4><p>经过网络可以得到中心点的位置和n(n=36 is best in our setting)根射线的距离，根据角度和长度计算出轮廓上的这些点的坐标，从0°开始连接这些点，最后把联通区域内的区域当做实例分割的结果。 </p>
<h4 id="center-sample-中心采样"><a href="#center-sample-中心采样" class="headerlink" title="center sample(中心采样)"></a>center sample(中心采样)</h4><p>采取了在实例质心周围1.5个步幅内的像素点为正采样，否则为负采样，这样做的好处是避免了正负样本的过于不平衡以及有更多的候选点作为真正的中心。</p>
<h4 id="Polar-IoU-Loss-amp-Polar-Centerness"><a href="#Polar-IoU-Loss-amp-Polar-Centerness" class="headerlink" title="Polar IoU Loss &amp; Polar Centerness"></a>Polar IoU Loss &amp; Polar Centerness</h4><p><strong>Polar IoU Loss</strong></p>
<p><img src="/2020/05/28/PolarMask-note/4.png" style="zoom:80%;"></p>
<p>采用从0-2Π的积分形式来进行IoU计算</p>
<script type="math/tex; mode=display">IoU = \frac{\int_0^{2\pi}1/2min(d_i,\tilde{d_i})^2d\theta}{\int_0^{2\pi}1/2max(d_i,\tilde{d_i})^2d\theta}=\lim_{N\rightarrow\infty}\frac{\sum_{i=1}^N1/2d_{min}^2\Delta \theta_i}{\sum_{i=1}^N1/2d_{max}^2\Delta \theta_i}->Polar IoU=\frac{\sum_{i=1}^Ndmin}{\sum_{i=1}^Ndmax}->PolarIoULoss=log\frac{\sum_{i=1}^Ndmin}{\sum_{i=1}^Ndmax}</script><p>Polar IoU Loss采用的是BCE LOSS，在不用调权重的情况下，相比Smooth L1 Loss提了2.6个点</p>
<p><strong>Polar Centerness</strong></p>
<p>Polar Centerness是基于FCOS的Center ness的变化，也是为了定义高质量的正样本抑制低质量的正样本。</p>
<p>$Polar \ Centerness=\sqrt\frac{min(\{d_1,d_2,…,d_n\})}{max(\{d_1,d_2,…,d_n\})}$如下图所示，右边的mask更加符合要求。</p>
<p><img src="/2020/05/28/PolarMask-note/3.png" style="zoom:80%;"></p>
<h3 id="实验部分"><a href="#实验部分" class="headerlink" title="实验部分"></a>实验部分</h3><ul>
<li>关于实例中心的选择：实验表明使用质心(mass-center)比检测框中心(box-center)有更好的效果(可能是质心相比检测框中心更普遍在实例中？)</li>
<li>关于polar segmentation的建模上限问题：作者在这实验证明了IoU能够达到90左右，逐像素法也会因下采样等操作而达不到100%。</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th style="text-align:center">Number of rays</th>
<th style="text-align:center">Loss</th>
<th style="text-align:center">centerness</th>
<th style="text-align:center">box brunch</th>
<th>backbone</th>
<th>scale</th>
</tr>
</thead>
<tbody>
<tr>
<td>influence</td>
<td style="text-align:center">实验表明当数量增加时性能会提升但到72时接近饱和</td>
<td style="text-align:center">Polar IoU Loss 表现明显优于Smooth L1 Loss</td>
<td style="text-align:center">Polar centerness在大实例/高精度表现更好</td>
<td style="text-align:center">polar mask无需边界框</td>
<td>更好的特征提取网络会提高性能</td>
<td>较大的图像尺寸会以较低的推理速度产生较高的精度</td>
</tr>
<tr>
<td>best</td>
<td style="text-align:center">36</td>
<td style="text-align:center">-</td>
<td style="text-align:center">-</td>
<td style="text-align:center">-</td>
<td>ResNeXt-101</td>
<td>-</td>
</tr>
</tbody>
</table>
</div>
<h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a><strong>优点</strong></h4><ol>
<li>不需要检测框，与FCOS一样是简洁高效的结构，包括在loss部分都不需要过多的超参数调节，在推理速度实验上也略优于two-stage model和其他one-stage model</li>
<li>将目标检测和实例分割统一到了一个模型，为之后anchor free模型的研究与改进提供了一个思路</li>
</ol>
<h4 id="不足"><a href="#不足" class="headerlink" title="不足"></a><strong>不足</strong></h4><ol>
<li>在精度方面与sota模型还是有差距</li>
<li>center采样的过程在论文中没有详细描述这样采样的原因是什么</li>
<li>在数据处理会更加复杂，会处理实例质心相关的问题</li>
</ol>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>实例分割</tag>
      </tags>
  </entry>
  <entry>
    <title>POSIX信号量</title>
    <url>/2019/04/22/POSIX%E4%BF%A1%E5%8F%B7%E9%87%8F/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<h1 id="POSIX信号量的操作"><a href="#POSIX信号量的操作" class="headerlink" title="POSIX信号量的操作"></a>POSIX信号量的操作</h1><p>POSIX信号量有两种：<strong>有名信号量</strong>和<strong>无名信号量</strong>，无名信号量也被称作基于内存的信号量。有名信号量通过IPC名字进行进程间的同步，而无名信号量如果不是放在进程间的共享内存区中，是不能用来进行进程间同步的，只能用来进行线程同步。</p>
<h2 id="POSIX三种操作"><a href="#POSIX三种操作" class="headerlink" title="POSIX三种操作"></a>POSIX三种操作</h2><h3 id="创建信号量"><a href="#创建信号量" class="headerlink" title="创建信号量"></a>创建信号量</h3><p>创建的过程还要求初始化信号量的值。</p>
<p>根据信号量取值（代表可用资源的数目）的不同，POSIX信号量还可以分为：</p>
<ul>
<li><p>二值信号量：信号量的值只有0和1，这和互斥量很类型，若资源被锁住，信号量的值为0，若资源可用，则信号量的值为1；</p>
</li>
<li><p>计数信号量：信号量的值在0到一个大于1的限制值（POSIX指出系统的最大限制值至少要为32767）。该计数表示可用的资源的个数。</p>
</li>
</ul>
<h3 id="等待信号量-wait-P操作"><a href="#等待信号量-wait-P操作" class="headerlink" title="等待信号量(wait)/P操作"></a>等待信号量(wait)/P操作</h3><p>该操作会检查信号量的值，如果其值小于或等于0，那就阻塞，直到该值变成大于0，然后等待进程将信号量的值减1，进程获得共享资源的访问权限。为原子操作。</p>
<h3 id="挂出一个信号量-post-V操作"><a href="#挂出一个信号量-post-V操作" class="headerlink" title="挂出一个信号量(post)/V操作"></a>挂出一个信号量(post)/V操作</h3><p>该操作将信号量的值加1，如果有进程阻塞着等待该信号量，那么其中一个进程将被唤醒。</p>
<h2 id="POSIX信号量函数接口"><a href="#POSIX信号量函数接口" class="headerlink" title="POSIX信号量函数接口"></a>POSIX信号量函数接口</h2><h3 id="有名信号量的创建和删除"><a href="#有名信号量的创建和删除" class="headerlink" title="有名信号量的创建和删除"></a>有名信号量的创建和删除</h3><p><strong>创建</strong></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;semaphore.h&gt;</span></span></span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">sem_t</span> *<span class="title">sem_open</span><span class="params">(<span class="keyword">const</span> <span class="keyword">char</span> *name, <span class="keyword">int</span> oflag)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">sem_t</span> *<span class="title">sem_open</span><span class="params">(<span class="keyword">const</span> <span class="keyword">char</span> *name, <span class="keyword">int</span> oflag,</span></span></span><br><span class="line"><span class="function"><span class="params">                  <span class="keyword">mode_t</span> mode, <span class="keyword">unsigned</span> <span class="keyword">int</span> value)</span></span>;</span><br><span class="line">                              <span class="comment">//成功返回信号量指针，失败返回SEM_FAILED</span></span><br></pre></td></tr></table></figure>
<ul>
<li>信号量通过name参数即信号量的名字来进行标识</li>
<li><strong>oflag</strong>参数可以为：0，O_CREAT，O_EXCL，<strong>0</strong>表示打开一个已存在的信号量，如果为<strong>O_CREAT</strong>，表示如果信号量不存在就创建一个信号量，如果存在则打开被返回。此时mode和value需要指定。如果为<strong>O_CREAT | O_EXCL</strong>，表示如果信号量已存在会返回错误。</li>
<li><strong>mode</strong>参数用于创建信号量时，表示信号量的权限位，和open函数一样包括：S_IRUSR，S_IWUSR，S_IRGRP，S_IWGRP，S_IROTH，S_IWOTH。</li>
<li><strong>value</strong>表示创建信号量时，信号量的初始值。</li>
</ul>
<p><strong>删除</strong></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;semaphore.h&gt;</span></span></span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">sem_close</span><span class="params">(<span class="keyword">sem_t</span> *sem)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">sem_unlink</span><span class="params">(<span class="keyword">const</span> <span class="keyword">char</span> *name)</span></span>;</span><br><span class="line">                              <span class="comment">//成功返回0，失败返回-1</span></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>sem_close</strong></li>
<li></li>
</ul>
<h1 id="互斥量和信号量的差别"><a href="#互斥量和信号量的差别" class="headerlink" title="互斥量和信号量的差别"></a>互斥量和信号量的差别</h1><ul>
<li>互斥量必须由给它上锁的线程解锁。而信号量不需要由等待它的线程进行挂出，可以在其他进程进行挂出操作。</li>
<li><p>互斥量要么被锁住，要么是解开状态，只有这两种状态。而信号量的值可以支持多个进程成功进行wait操作。</p>
</li>
<li><p>信号量的挂出操作总是被记住，因为信号量有一个计数值，挂出操作总会将该计数值加1，然而当向条件变量发送一个信号时，如果没有线程等待在条件变量，那么该信号会丢失。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>Linux编程</tag>
      </tags>
  </entry>
  <entry>
    <title>PSPNet-note</title>
    <url>/2020/04/15/PSPNet-note/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<h3 id="Pyramid-Scene-Parseing-Network-Note"><a href="#Pyramid-Scene-Parseing-Network-Note" class="headerlink" title="Pyramid Scene Parseing Network  Note"></a>Pyramid Scene Parseing Network  Note</h3><p>​    PSPNet 采用金字塔池化模块搭建的场景分析网络 ， <strong>基于语义分割的场景解析，其目的是赋予图像中每个像素一个类别标签</strong>。 </p>
<h4 id="1-PSPNet介绍"><a href="#1-PSPNet介绍" class="headerlink" title="1 PSPNet介绍"></a>1 PSPNet介绍</h4><p>由于传统的FCN存在缺陷：</p>
<p><img src="/2020/04/15/PSPNet-note/1.png" alt></p>
<ol>
<li>不匹配上下文关系， <strong>FCN将水中的“boat”预测为“car”</strong> 。</li>
<li>类别混淆，将摩天大楼一部分识别成了其他。</li>
<li><p>不显著的类别难以预测，可能会忽略小的东西。</p>
<p>基于对FCN的透彻分析，作者提出了能够获取全局场景的深度网络PSPNet，可以融合局部特征和全局特征，有较好的效果。</p>
</li>
</ol>
<h5 id="1-1-Pyramid-Pooling-Module（金字塔池化模块）"><a href="#1-1-Pyramid-Pooling-Module（金字塔池化模块）" class="headerlink" title="1.1  Pyramid Pooling Module（金字塔池化模块）"></a>1.1  <strong>Pyramid Pooling Module</strong>（金字塔池化模块）</h5><p>​     金字塔池化模块Pyramid Pooling Module由一组不同尺度的池化块组成 </p>
<p><img src="/2020/04/15/PSPNet-note/2.png" alt></p>
<p>​    该模块融合了4种不同金字塔尺度的特征，第一行红色是最粗糙的特征–全局池化生成单个bin输出，后面三行是不同尺度的池化特征。为了保证全局特征的权重，如果金字塔共有N个级别，则在每个级别后使用1X1的卷积将对于级别通道降为原本的1/N。再通过双线性插值获得未池化前的大小，最终concat到一起。<br>​    在POOL过程中，论文一共采用了$1X1,2X2,3X3,6X6$ 4个等级的池化尺寸(即<strong>输出尺寸</strong>)进行池化。</p>
<h5 id="1-2-基于ResNet的预训练辅助损失函数"><a href="#1-2-基于ResNet的预训练辅助损失函数" class="headerlink" title="1.2 基于ResNet的预训练辅助损失函数"></a>1.2 基于ResNet的预训练辅助损失函数</h5><p><img src="/2020/04/15/PSPNet-note/3.png" alt></p>
<pre><code> 在ResNet101的基础上做了改进，除了使用后面的softmax分类做loss，额外的在第四阶段添加了一个辅助的loss， 叫做**auxiliary loss**， 两个loss一起传播，使用不同的权重，共同优化参数。后续的实验证明这样做有利于快速收敛。 
</code></pre><h4 id="2-代码实现"><a href="#2-代码实现" class="headerlink" title="2 代码实现"></a>2 代码实现</h4><p>金字塔池化以及PSPNet网络架构</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">_PyramidPoolingModule</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_dim, reduction_dim, setting</span>):</span></span><br><span class="line">        super(_PyramidPoolingModule, self).__init__()</span><br><span class="line">        self.features = []</span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> setting:</span><br><span class="line">            self.features.append(nn.Sequential(</span><br><span class="line">                nn.AdaptiveAvgPool2d(s),</span><br><span class="line">                nn.Conv2d(in_dim, reduction_dim, kernel_size=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">                nn.BatchNorm2d(reduction_dim, momentum=<span class="number">.95</span>),</span><br><span class="line">                nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">            ))</span><br><span class="line">        self.features = nn.ModuleList(self.features)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x_size = x.size()</span><br><span class="line">        out = [x]</span><br><span class="line">        <span class="keyword">for</span> f <span class="keyword">in</span> self.features:</span><br><span class="line">            out.append(F.upsample(f(x), x_size[<span class="number">2</span>:], mode=<span class="string">&#x27;bilinear&#x27;</span>))</span><br><span class="line">        out = torch.cat(out, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PSPNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_classes, pretrained=True, use_aux=True</span>):</span></span><br><span class="line">        super(PSPNet, self).__init__()</span><br><span class="line">        self.use_aux = use_aux</span><br><span class="line">        resnet = models.resnet101()</span><br><span class="line">        <span class="keyword">if</span> pretrained:</span><br><span class="line">            resnet.load_state_dict(torch.load(res101_path))</span><br><span class="line">        self.layer0 = nn.Sequential(resnet.conv1, resnet.bn1, resnet.relu, resnet.maxpool)</span><br><span class="line">        self.layer1, self.layer2, self.layer3, self.layer4 = resnet.layer1, resnet.layer2, resnet.layer3, resnet.layer4</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> n, m <span class="keyword">in</span> self.layer3.named_modules():</span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;conv2&#x27;</span> <span class="keyword">in</span> n:</span><br><span class="line">                m.dilation, m.padding, m.stride = (<span class="number">2</span>, <span class="number">2</span>), (<span class="number">2</span>, <span class="number">2</span>), (<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">            <span class="keyword">elif</span> <span class="string">&#x27;downsample.0&#x27;</span> <span class="keyword">in</span> n:</span><br><span class="line">                m.stride = (<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">for</span> n, m <span class="keyword">in</span> self.layer4.named_modules():</span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;conv2&#x27;</span> <span class="keyword">in</span> n:</span><br><span class="line">                m.dilation, m.padding, m.stride = (<span class="number">4</span>, <span class="number">4</span>), (<span class="number">4</span>, <span class="number">4</span>), (<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">            <span class="keyword">elif</span> <span class="string">&#x27;downsample.0&#x27;</span> <span class="keyword">in</span> n:</span><br><span class="line">                m.stride = (<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        self.ppm = _PyramidPoolingModule(<span class="number">2048</span>, <span class="number">512</span>, (<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">6</span>))</span><br><span class="line">        self.final = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">4096</span>, <span class="number">512</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">512</span>, momentum=<span class="number">.95</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Dropout(<span class="number">0.1</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">512</span>, num_classes, kernel_size=<span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> use_aux:</span><br><span class="line">            self.aux_logits = nn.Conv2d(<span class="number">1024</span>, num_classes, kernel_size=<span class="number">1</span>)</span><br><span class="line">            initialize_weights(self.aux_logits)</span><br><span class="line"></span><br><span class="line">        initialize_weights(self.ppm, self.final)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x_size = x.size()</span><br><span class="line">        x = self.layer0(x)</span><br><span class="line">        x = self.layer1(x)</span><br><span class="line">        x = self.layer2(x)</span><br><span class="line">        x = self.layer3(x)</span><br><span class="line">        <span class="keyword">if</span> self.training <span class="keyword">and</span> self.use_aux:</span><br><span class="line">            aux = self.aux_logits(x)</span><br><span class="line">        x = self.layer4(x)</span><br><span class="line">        x = self.ppm(x)</span><br><span class="line">        x = self.final(x)</span><br><span class="line">        <span class="keyword">if</span> self.training <span class="keyword">and</span> self.use_aux:</span><br><span class="line">            <span class="keyword">return</span> F.upsample(x, x_size[<span class="number">2</span>:], mode=<span class="string">&#x27;bilinear&#x27;</span>), F.upsample(aux, x_size[<span class="number">2</span>:], mode=<span class="string">&#x27;bilinear&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> F.upsample(x, x_size[<span class="number">2</span>:], mode=<span class="string">&#x27;bilinear&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>语义分割</tag>
      </tags>
  </entry>
  <entry>
    <title>用numpy实现简单的三层BP神经网络</title>
    <url>/2018/10/13/%E7%94%A8numpy%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E7%9A%84%E4%B8%89%E5%B1%82bp%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<pre><code>最近在看吴恩达老师的机器学习视频，讲到神经网络时有些模糊，于是决定自己用代码实现一下最基本的神经网络。
</code></pre><h2 id="关于BP算法"><a href="#关于BP算法" class="headerlink" title="关于BP算法"></a>关于BP算法</h2><p><a href="https://www.cnblogs.com/charlotte77/p/5629865.html">一文弄懂神经网络中的反向传播法</a></p>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p><img src="https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1539375900277&amp;di=d82dc6982d05663fcb6076f511a8a510&amp;imgtype=0&amp;src=http%3A%2F%2Fwww.alonely.com.cn%2Fd%2Ffile%2FXML%2F2016-08-28%2Fgvovpkjgawn.png" alt="三层神经网络"><br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NeuralNetwork</span>(<span class="params">object</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,input_nodes,hidden_nodes,output_nodes,learning_rate</span>):</span></span><br><span class="line">        <span class="comment">#设定输入层，隐藏层，输出层的节点个数</span></span><br><span class="line">        self.input_nodes = input_nodes+<span class="number">1</span></span><br><span class="line">        <span class="comment"># +1 设置偏执神经元来进行修正</span></span><br><span class="line">        self.hidden_nodes = hidden_nodes</span><br><span class="line">        self.output_nodes = output_nodes</span><br><span class="line"></span><br><span class="line">        <span class="comment">#初始化权值和学习速率</span></span><br><span class="line">        self.weight_input_to_hidden = np.random.normal(<span class="number">0.0</span>,self.hidden_nodes**<span class="number">-0.5</span>,(self.hidden_nodes,self.input_nodes))</span><br><span class="line">        self.weight_hidden_to_output = np.random.normal(<span class="number">0.0</span>,self.output_nodes**<span class="number">-0.5</span>,(self.output_nodes,self.hidden_nodes))</span><br><span class="line"></span><br><span class="line">        self.lr = learning_rate</span><br><span class="line"></span><br><span class="line">    <span class="comment">#激励函数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">Sigmoid</span>(<span class="params">self,x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">1.0</span> / (<span class="number">1.0</span> + np.exp(-x))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">self,input_list,target_list</span>):</span></span><br><span class="line">        inputs = np.array(input_list,ndmin=<span class="number">2</span>).T</span><br><span class="line">        targets = np.array(target_list,ndmin=<span class="number">2</span>).T</span><br><span class="line"></span><br><span class="line">        <span class="comment">#前向传播</span></span><br><span class="line">        hidden_inputs = np.dot(self.weight_input_to_hidden,inputs)</span><br><span class="line">        hidden_outputs= self.Sigmoid(hidden_inputs)</span><br><span class="line"></span><br><span class="line">        final_inputs = np.dot(self.weight_hidden_to_output,hidden_outputs)</span><br><span class="line">        final_outputs = self.Sigmoid(final_inputs)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#反向传播</span></span><br><span class="line">        outputs_errors = (final_outputs - targets) * final_outputs * (<span class="number">1</span> - final_outputs)</span><br><span class="line">        hidden_errors = np.dot(self.weight_hidden_to_output.T,outputs_errors)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#梯度下降</span></span><br><span class="line">        self.weight_input_to_hidden -= np.dot((hidden_errors * hidden_outputs * (<span class="number">1</span> - hidden_outputs)),inputs.T) * self.lr</span><br><span class="line">        self.weight_hidden_to_output -= np.dot(outputs_errors,hidden_outputs.T) *self.lr</span><br><span class="line"></span><br><span class="line">        print(<span class="string">&quot;误差:&quot;</span>)</span><br><span class="line">        print(<span class="number">1</span>/<span class="number">2</span> * np.square((final_outputs-targets)))</span><br><span class="line">    <span class="comment">#测试函数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span>(<span class="params">self,inputs_list</span>):</span></span><br><span class="line">        inputs = np.array(inputs_list,ndmin=<span class="number">2</span>).T</span><br><span class="line"></span><br><span class="line">        hidden_inputs = np.dot(self.weight_input_to_hidden,inputs)</span><br><span class="line">        hidden_outputs = self.Sigmoid(hidden_inputs)</span><br><span class="line"></span><br><span class="line">        final_inputs = np.dot(self.weight_hidden_to_output,hidden_outputs)</span><br><span class="line">        final_outputs = self.Sigmoid(final_inputs)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> final_outputs</span><br><span class="line"></span><br><span class="line">	<span class="comment">#测试用神经网络实现异或功能</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    cases = [[<span class="number">0</span>,<span class="number">0</span>,<span class="number">0.1</span>],</span><br><span class="line">             [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0.1</span>],</span><br><span class="line">             [<span class="number">1</span>,<span class="number">0</span>,<span class="number">0.1</span>],</span><br><span class="line">             [<span class="number">1</span>,<span class="number">1</span>,<span class="number">0.1</span>]]</span><br><span class="line"></span><br><span class="line">    labels = [[<span class="number">0</span>],[<span class="number">1</span>],[<span class="number">1</span>],[<span class="number">0</span>]]</span><br><span class="line">    <span class="comment">#迭代10000次</span></span><br><span class="line">    limit = <span class="number">10000</span>               </span><br><span class="line">    nn = NeuralNetwork(<span class="number">2</span>,<span class="number">4</span>,<span class="number">1</span>,<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(limit):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">4</span>):</span><br><span class="line">            nn.train(cases[i],labels[i])</span><br><span class="line"></span><br><span class="line">    a = nn.run([<span class="number">1</span>,<span class="number">1</span>,<span class="number">0.1</span>])</span><br><span class="line">    print(a)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure></p>
<p>只在输入层加入了偏执神经元，在第二层并没有添加，在第二层添加对拟合效果的提升并不是很大(主要是实现会更复杂一些(逃</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Retinanet&amp;focal-loss</title>
    <url>/2020/05/12/Retinanet-focal-loss/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<p>RetinaNet只是原来FPN网络与FCN网络的组合应用，因此在目标网络检测框架上它并无特别亮眼创新。文章中最大的创新来自于Focal loss的提出及在单阶段目标检测网络RetinaNet（实质为Resnet + FPN + FCN）的成功应用。Focal loss是一种改进了的交叉熵(cross-entropy, CE)loss，它通过在原有的CE loss上乘了个使易检测目标对模型训练贡献削弱的指数式，从而使得Focal loss成功地解决了在目标检测时，正负样本区域极不平衡而目标检测loss易被大批量负样本所左右的问题。此问题是单阶段目标检测框架（如SSD/Yolo系列）与双阶段目标检测框架（如Faster-RCNN/R-FCN等）accuracy gap的最大原因。</p>
<h1 id="Focal-Loss"><a href="#Focal-Loss" class="headerlink" title="Focal Loss"></a>Focal Loss</h1><p>Focal Loss主要解决的是类别不平衡问题，常规的单阶段目标检测网络像SSD一般在模型训练时会先大密度地在模型终端的系列feature maps上生成出10,000甚至100,0000个目标候选区域。然后再分别对这些候选区域进行分类与位置回归识别。而在这些生成的数万个候选区域中，绝大多数都是不包含待检测目标的图片背景，这样就造成了机器学习中经典的训练样本正负不平衡的问题。它往往会造成最终算出的training loss为占绝对多数但包含信息量却很少的负样本所支配，少样正样本提供的关键信息却不能在一般所用的training loss中发挥正常作用，从而无法得出一个能对模型训练提供正确指导的loss。</p>
<h2 id="Focal-Loss定义"><a href="#Focal-Loss定义" class="headerlink" title="Focal Loss定义"></a>Focal Loss定义</h2><p>$FL(p_t)=-\alpha_t(1-p_t)^rlog(p_t)$</p>
<p>下图为focal loss与常规CE loss的对比。从中，我们易看出focal loss所加的指数式系数可对正负样本对loss的贡献自动调节。当某样本类别比较明确些，它对整体loss的贡献就比较少；而若某样本类别不易区分，则对整体loss的贡献就相对偏大。这样得到的loss最终将集中精力去诱导模型去努力分辨那些难分的目标类别，于是就有效提升了整体的目标检测准度。不过在此focus loss计算当中，我们引入了一个新的hyper parameter即γ。一般来说新参数的引入，往往会伴随着模型使用难度的增加。在本文中，作者有试者对其进行调节，线性搜索后得出将γ设为2时，模型检测效果最好。</p>
<p><img src="/2020/05/12/Retinanet-focal-loss/1.png" style="zoom:80%;"></p>
<p>在最终所用的focal loss上，作者还引入了α系数，它能够使得focal loss对不同类别更加平衡。实验表明它会比原始的focal loss效果更好。</p>
<p>Focal loss还很大程度上避免了正负样本不平衡带来的模型初始化问题。</p>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="Retinanet"><a href="#Retinanet" class="headerlink" title="Retinanet"></a>Retinanet</h1><p> RetinaNet本质上是Resnet + FPN + 两个FCN子网络。 </p>
<h2 id="RetinaNet检测框架"><a href="#RetinaNet检测框架" class="headerlink" title="RetinaNet检测框架"></a>RetinaNet检测框架</h2><p><img src="/2020/05/12/Retinanet-focal-loss/2.png" style="zoom:80%;"></p>
<p>一般主干网络可选用任一有效的特征提取网络如vgg16或resnet系列，此处作者分别尝试了resnet-50与resnet-101。而FPN则是对resnet-50里面自动形成的多尺度特征进行了强化利用，从而得到了表达力更强、包含多尺度目标区域信息的feature maps集合。最后在FPN所吐出的feature maps集合上，分别使用了两个FCN子网络（它们有着相同的网络结构却各自独立，并不share参数）用来完成目标框类别分类与位置回归任务。</p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>python爬虫框架Scrapy(一)</title>
    <url>/2019/04/07/python%E7%88%AC%E8%99%AB%E6%A1%86%E6%9E%B6Scrapy-%E4%B8%80/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<h1 id="Scrapy框架简介"><a href="#Scrapy框架简介" class="headerlink" title="Scrapy框架简介"></a>Scrapy框架简介</h1><p><img src="/2019/04/07/python%E7%88%AC%E8%99%AB%E6%A1%86%E6%9E%B6Scrapy-%E4%B8%80/1.jpg" alt></p>
<p><img src="/2019/04/07/python%E7%88%AC%E8%99%AB%E6%A1%86%E6%9E%B6Scrapy-%E4%B8%80/2.jpg" alt></p>
<p>-Spider MiddlewaresSpider只对response进行过滤处理，不对数据进行处理</p>
<h1 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h1><h2 id="创建项目"><a href="#创建项目" class="headerlink" title="创建项目"></a>创建项目</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">scrapy startproject myspider </span><br></pre></td></tr></table></figure>
<h2 id="生成爬虫"><a href="#生成爬虫" class="headerlink" title="生成爬虫"></a>生成爬虫</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">scrapy genspider response response.cn</span><br><span class="line"><span class="comment">#@response 爬虫名称</span></span><br><span class="line"><span class="comment">#@response.cn 爬虫域名范围</span></span><br></pre></td></tr></table></figure>
<p>在生成的response.py文件中包含以下代码</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PixviSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;pixvi&#x27;</span>  <span class="comment">#爬虫名</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;pixiv.net&#x27;</span>] <span class="comment">#爬虫范围，需要爬取的url地址你必须在这个域名下</span></span><br><span class="line">    start_urls = [<span class="string">&#x27;http://www.pixiv.net/&#x27;</span>] <span class="comment">#初始响应网站，需要有内容爬取的内容</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span><span class="comment">#parse函数名称不能修改</span></span><br><span class="line">        <span class="comment">#处理start_ urls对应的响应</span></span><br><span class="line">        item = response.xpath() <span class="comment">#返回的是一个含有selector对象的列表</span></span><br><span class="line">        <span class="keyword">yield</span> item<span class="comment">#生成器可以遍历不占用太多空间</span></span><br></pre></td></tr></table></figure>
<h2 id="运行爬虫"><a href="#运行爬虫" class="headerlink" title="运行爬虫"></a>运行爬虫</h2><p>在项目文件夹下运行</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">scrapy crawl response</span><br></pre></td></tr></table></figure>
<h3 id="pipline"><a href="#pipline" class="headerlink" title="pipline"></a>pipline</h3><p>生成的item数据会传入pipline中，在使用pipline之前要先在settings.py中去掉</p>
<p>可以创建多个pipline：</p>
<p>​    1.可能有多个爬虫</p>
<p>​    2.可能爬取的数据需要不同的处理（如写入不同的数据库）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Test1Pipeline</span>(<span class="params">object</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span>(<span class="params">self, item, spider</span>):</span><span class="comment">#实现存储方法，函数名同样不能改变</span></span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure>
<p>如有多个pipline，每个pipline都要return item以传入下一个管道，不能缺少return</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#ITEM_PIPELINES = &#123;</span></span><br><span class="line"><span class="comment">#    &#x27;test1.pipelines.Test1Pipeline&#x27;: 300,</span></span><br><span class="line"><span class="comment">#&#125;</span></span><br></pre></td></tr></table></figure>
<p>的注释。</p>
<p>300表示举例pipline的远近，越小越先执行</p>
<p>若有多个爬虫，则可以</p>
<p>​    1.在item中加入<code>item[&#39;come_from&#39;] = &#39;spider1&#39;</code></p>
<p>​    <code>if item[&#39;come_from&#39;] == &#39;spider1&#39;:</code></p>
<p>​        …</p>
<p>​    2.在pipline.py中直接用</p>
<p>​    <code>if spider.name == &#39;spider1&#39;:</code></p>
<p>​        …</p>
<h3 id="logging模块"><a href="#logging模块" class="headerlink" title="logging模块"></a>logging模块</h3><p>logging模块是输出日志的模块</p>
<p>可以在settings.py中加入<code>LOG_LEVEL = &#39;WARNING&#39;</code>来使程序输出warning及以上级别的日志</p>
<p>logging模块可以代替print输出数据并知晓数据来自哪一个文件</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"></span><br><span class="line">logger = logging.getlogger(__name__)</span><br><span class="line">logger.warning(item)</span><br></pre></td></tr></table></figure>
<p>运行结果</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="number">2019</span><span class="number">-04</span><span class="number">-08</span> <span class="number">17</span>:<span class="number">30</span>:<span class="number">19</span> [test1.spiders.pixvi] WARNING: &#123;<span class="string">&#x27;come_from&#x27;</span>: <span class="string">&#x27;pixvi&#x27;</span>&#125;</span><br><span class="line"><span class="number">2019</span><span class="number">-04</span><span class="number">-08</span> <span class="number">17</span>:<span class="number">30</span>:<span class="number">19</span> [test1.pipelines] WARNING: ----------</span><br><span class="line"><span class="number">2019</span><span class="number">-04</span><span class="number">-08</span> <span class="number">17</span>:<span class="number">30</span>:<span class="number">19</span> [test1.spiders.pixvi] WARNING: &#123;<span class="string">&#x27;come_from&#x27;</span>: <span class="string">&#x27;pixvi&#x27;</span>&#125;</span><br><span class="line"><span class="number">2019</span><span class="number">-04</span><span class="number">-08</span> <span class="number">17</span>:<span class="number">30</span>:<span class="number">19</span> [test1.pipelines] WARNING: ----------</span><br><span class="line"><span class="number">2019</span><span class="number">-04</span><span class="number">-08</span> <span class="number">17</span>:<span class="number">30</span>:<span class="number">19</span> [test1.spiders.pixvi] WARNING: &#123;<span class="string">&#x27;come_from&#x27;</span>: <span class="string">&#x27;pixvi&#x27;</span>&#125;</span><br><span class="line"><span class="number">2019</span><span class="number">-04</span><span class="number">-08</span> <span class="number">17</span>:<span class="number">30</span>:<span class="number">19</span> [test1.pipelines] WARNING: ----------</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>即可以打印输出内容的时间，文件来源，等级，内容</p>
<p>在settings.py中加入<code>LOG_FILE = ./XXX.log</code>即可把日志内容保存在文件中</p>
]]></content>
      <categories>
        <category>python爬虫</category>
      </categories>
      <tags>
        <tag>scrapy</tag>
      </tags>
  </entry>
  <entry>
    <title>python爬虫框架Scrapy(二)</title>
    <url>/2019/04/08/python%E7%88%AC%E8%99%AB%E6%A1%86%E6%9E%B6Scrapy-%E4%BA%8C/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<h1 id="爬虫编写"><a href="#爬虫编写" class="headerlink" title="爬虫编写"></a>爬虫编写</h1><ol>
<li><p>item读取数据</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tr_list = response.xpath(<span class="string">&quot;//table[@class=&#x27;tablelist&#x27;]/tr&quot;</span>)[<span class="number">1</span>:<span class="number">-1</span>]</span><br><span class="line">       <span class="keyword">for</span> tr <span class="keyword">in</span> tr_list:</span><br><span class="line">           item = &#123;&#125;</span><br><span class="line">           item[<span class="string">&#x27;title&#x27;</span>] = tr.xpath(<span class="string">&quot;./td[1]/a/text()&quot;</span>).extract_first()</span><br><span class="line">           item[<span class="string">&#x27;position&#x27;</span>] = tr.xpath(<span class="string">&quot;./td[2]/text()&quot;</span>).extract_first()</span><br><span class="line">           item[<span class="string">&#x27;number&#x27;</span>] = tr.xpath(<span class="string">&quot;./td[3]/text()&quot;</span>).extract_first()</span><br><span class="line">           item[<span class="string">&#x27;place&#x27;</span>] = tr.xpath(<span class="string">&quot;./td[4]/text()&quot;</span>).extract_first()</span><br><span class="line">           item[<span class="string">&#x27;publish_date&#x27;</span>] = tr.xpath(<span class="string">&quot;./td[5]/text()&quot;</span>).extract_first()</span><br><span class="line">           logging.warning(item)</span><br><span class="line">           <span class="keyword">yield</span> item</span><br></pre></td></tr></table></figure>
</li>
<li><p>构造Request对象实现翻页</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#下一页URL地址</span></span><br><span class="line">      next_url = response.xpath(<span class="string">&quot;//a[@id=&#x27;next&#x27;]/@href&quot;</span>).extract_first()</span><br><span class="line">      <span class="keyword">if</span> next_url != <span class="string">&quot;javascript:;&quot;</span>:</span><br><span class="line">          next_url = <span class="string">&quot;http://hr.tencent.com/&quot;</span> + next_url</span><br><span class="line">      <span class="keyword">yield</span> scrapy.Request(</span><br><span class="line">          next_url,</span><br><span class="line">          callback=self.parse</span><br><span class="line">      )</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">scrapy.Request(url[,callback,method=<span class="string">&#x27;GET&#x27;</span>,headers,body,cookies,meta,dont_filter=<span class="literal">False</span>])</span><br></pre></td></tr></table></figure>
<p><img src="/2019/04/08/python%E7%88%AC%E8%99%AB%E6%A1%86%E6%9E%B6Scrapy-%E4%BA%8C/1.png" alt></p>
</li>
<li><p>构造Request对象实现详情页爬取</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def parse_detail(self,response):</span><br><span class="line">	...</span><br></pre></td></tr></table></figure>
</li>
</ol>
]]></content>
      <categories>
        <category>python爬虫</category>
      </categories>
      <tags>
        <tag>scrapy</tag>
      </tags>
  </entry>
  <entry>
    <title>C++期末复习</title>
    <url>/2019/12/26/C++%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<h4 id="第一章-引论"><a href="#第一章-引论" class="headerlink" title="第一章 引论"></a>第一章 引论</h4><ul>
<li>面向对象的核心概念：<ul>
<li><strong>数据封装</strong>：对内保护信息加强联系，对外提供访问接口。</li>
<li><strong>继承</strong>：整体和部分的关系，一般和特殊的关系。基类和派生类。</li>
<li><strong>多态性</strong>：一个符号有多种含义。表现为函数重载（普通函数重载，运算符重载）</li>
<li><strong>泛型编程</strong>：主要依托模板（Template）</li>
</ul>
</li>
</ul>
<h4 id="第二章-数据类型"><a href="#第二章-数据类型" class="headerlink" title="第二章 数据类型"></a>第二章 数据类型</h4><ul>
<li><strong>指针</strong></li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span>作用于指针</span><br><span class="line">三种形式：</span><br><span class="line"><span class="number">1</span>)<span class="keyword">const</span> <span class="keyword">int</span> *p;</span><br><span class="line">p是变量，但指向了常量；</span><br><span class="line"><span class="number">2</span>)<span class="keyword">int</span> * <span class="keyword">const</span> p;</span><br><span class="line">p是常量，但指向了变量；</span><br><span class="line"><span class="number">3</span>)<span class="keyword">const</span> <span class="keyword">int</span> * <span class="keyword">const</span> p;</span><br><span class="line">常量指针指向了常量</span><br></pre></td></tr></table></figure>
<ul>
<li><p><strong>引用&amp;</strong></p>
<ul>
<li><p>引用就是对象的<strong>别名</strong></p>
</li>
<li><p><strong>独立引用必须初始化</strong></p>
</li>
<li><p><strong>参数引用-&gt;实参和形参相同</strong></p>
</li>
<li><p>非常量引用不能指向常量</p>
</li>
<li><p><strong>引用作为返回类型</strong>（避免内存复制，直接返回对象）</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> &amp;<span class="title">f</span><span class="params">(<span class="keyword">int</span> &amp;i)</span></span>&#123;<span class="keyword">return</span> i;&#125;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">返回一个左值对象(左值 != 左值引用)</span></span><br><span class="line"><span class="comment">可以出现在=左边</span></span><br><span class="line"><span class="comment">++f() (√)	b = f() (√)</span></span><br><span class="line"><span class="comment">f(a)返回a这个对象	f(2) (X)</span></span><br><span class="line"><span class="comment">int* g();</span></span><br><span class="line"><span class="comment">*g() = (√)</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>
<p><strong>运算符</strong> </p>
</li>
<li><p>new delete    new[]    delete[]</p>
</li>
<li><p>sizeof()</p>
</li>
</ul>
</li>
<li><p>数组</p>
<ul>
<li><p>指向数组的指针：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> <span class="built_in">array</span>[<span class="number">10</span>];</span><br><span class="line"><span class="keyword">int</span> (*pa)[<span class="number">10</span>];</span><br><span class="line">pa = &amp;<span class="built_in">array</span>; <span class="comment">//请注意&amp;的存在</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>指针数组：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> <span class="built_in">array</span>[<span class="number">10</span>];</span><br><span class="line"><span class="keyword">int</span> *pa[<span class="number">10</span>]; <span class="comment">//指针数组的每一个元素都是指针</span></span><br><span class="line">pb[<span class="number">0</span>] = &amp;<span class="built_in">array</span>[<span class="number">0</span>];</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<h4 id="第三章-异常处理"><a href="#第三章-异常处理" class="headerlink" title="第三章 异常处理"></a>第三章 异常处理</h4><ul>
<li>异常抛出</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">viod <span class="title">f</span><span class="params">()</span> <span class="keyword">try</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="keyword">if</span>()	<span class="keyword">throw</span> <span class="string">&quot;error&quot;</span>;<span class="comment">//std::out_of_range(&quot;index out of range&quot;);</span></span><br><span class="line">&#125;<span class="keyword">catch</span>(<span class="keyword">const</span> <span class="keyword">char</span> * e)&#123;<span class="comment">//const std::out_of_range &amp;e</span></span><br><span class="line">	<span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; e &lt;&lt; <span class="built_in">endl</span>;<span class="comment">//e.what();</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="第四章-函数"><a href="#第四章-函数" class="headerlink" title="第四章 函数"></a>第四章 函数</h4><ul>
<li><strong>函数的类型</strong></li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> (<span class="keyword">int</span>) f; <span class="comment">//error</span></span><br><span class="line"><span class="function"><span class="keyword">typedef</span> <span class="title">int</span> <span class="params">(<span class="keyword">int</span>)</span> F</span>; <span class="comment">//error</span></span><br><span class="line"><span class="function"><span class="keyword">typedef</span> <span class="keyword">int</span> <span class="title">FF</span><span class="params">(<span class="keyword">int</span>)</span></span>; <span class="comment">//OK</span></span><br></pre></td></tr></table></figure>
<ul>
<li><p><strong>函数的参数</strong></p>
<ul>
<li><p>传值 传指针 传引用</p>
</li>
<li><p>const作用于参数</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">func</span><span class="params">(<span class="keyword">const</span> <span class="keyword">int</span> *pi)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="keyword">int</span> a = *pi;	<span class="comment">//正确</span></span><br><span class="line">	*pi = <span class="number">0</span>;	<span class="comment">//错误，因为pi指向的单元被视为常量</span></span><br><span class="line">	pi = &amp;a;	<span class="comment">//正确，因为pi不是常量指针</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>缺省参数</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//所有取缺省值的参数都必须出现在不取缺省值的参数的右边。亦即，一旦开始定义取缺省值的参数，就不可以再说明非缺省的参数</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">f1</span><span class="params">(<span class="keyword">int</span> x = <span class="number">10</span>, <span class="keyword">int</span> y)</span></span>;    	<span class="comment">//error</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">f2</span><span class="params">(<span class="keyword">int</span> x, <span class="keyword">int</span> y = <span class="number">0</span>)</span></span>; 	   	<span class="comment">//ok</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">f3</span><span class="params">(<span class="keyword">int</span> x = <span class="number">10</span>, <span class="keyword">int</span> y = <span class="number">0</span>)</span></span>; <span class="comment">//ok</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p><strong>函数返回值</strong></p>
<ul>
<li>返回值类型<ul>
<li>函数返回一个值类型，实际上是将返回的值放到一个临时对象中。调用者可以拷贝临时对象的值以供以后使用。函数Strlen()返回一个整数值，这个值被存储在一个临时变量（对象）中。临时对象是<strong>匿名</strong>的，并且被当做<strong>常量</strong>，因此<strong>不能作为左值</strong>使用。</li>
</ul>
</li>
<li>返回指针<ul>
<li>函数返回指针，实际上也是返回一个值，只不过这个值是某个单元的地址。</li>
<li>该指针指向的对象必须还是<strong>有效</strong>的  </li>
<li>函数内部分配了内存要在适当的时候利用返回的指针释放掉内存。</li>
</ul>
</li>
<li>返回引用<ul>
<li>实际上返回的是一个对象，是个左值，只不过是匿名的。  </li>
<li>与返回指针一样，函数返回的引用单元也必须在被调函数返回后一直<strong>有效</strong>。</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>函数重载</strong>（唯一依据是<strong>参数列表</strong>）</p>
</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">f(<span class="keyword">int</span> i = <span class="number">0</span>)/f()	<span class="comment">//不算</span></span><br><span class="line">f(<span class="keyword">int</span> *)/f(<span class="keyword">int</span> [])/f(<span class="keyword">int</span> [<span class="number">5</span>])<span class="comment">//不算</span></span><br><span class="line">f(<span class="keyword">int</span>)/f(<span class="keyword">const</span> <span class="keyword">int</span>)<span class="comment">//不算</span></span><br><span class="line">f(<span class="keyword">int</span> ())/f(<span class="keyword">int</span>(*)())<span class="comment">//不算</span></span><br><span class="line">f(<span class="keyword">int</span> i)/f(<span class="keyword">int</span>&amp; i)	<span class="comment">//算</span></span><br><span class="line">	<span class="keyword">int</span> a;</span><br><span class="line">	f(a);	<span class="comment">//可以存在但编译会出问题</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="第五章-类和对象（全部重点）"><a href="#第五章-类和对象（全部重点）" class="headerlink" title="第五章 类和对象（全部重点）"></a>第五章 类和对象（全部重点）</h4><ul>
<li>类的定义</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">className</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">	属性列表;</span><br><span class="line">	行为列表;</span><br><span class="line">&#125;;  <span class="comment">//注意这个分号的存在。很多的编译错误源于这个分号的缺漏</span></span><br></pre></td></tr></table></figure>
<ul>
<li>类和对象</li>
</ul>
<p>与其它类型一样，类只是一种形式化的规格说明。要使用类提供的功能，必须使用类的<strong>实例</strong>（类的静态成员(5.3.3)例外）。类的实例称为“对象”。一个类可以定义多个对象。定义对象的过程称为“实例化(instantiation)”，而一个对象也称为类的“实例(instance)”。</p>
<p><strong>关系</strong></p>
<p>•类代表了一组对象的<strong>共同性</strong>；对象被赋予了<strong>具体的性质</strong>。</p>
<p>•类在概念上是一种<strong>抽象机制</strong>，它抽象了一类对象的存储和操作特性；对象是类的一个实现，占据了物理存储器。</p>
<p>•在系统实现中，类是一种<strong>共享机制</strong>，它提供了一类对象共享其类的操作实现。这些操作通过类的实例（对象）来完成。</p>
<p>•类是一种<strong>封装机制</strong>，它将一组数据和对该组数据的操作封装在一起；对象是这种封转机制的具体实现。</p>
<p>•类是对象的<strong>模型</strong>，对象承袭了类中的数据和方法(操作)。只是各实例对象的数据初始化状态和各个数据成员的值不同。</p>
<ul>
<li><p><strong>访问控制</strong></p>
<ul>
<li>如果没有访问控制修饰符默认为private</li>
<li>private</li>
<li>protected</li>
<li>public</li>
</ul>
</li>
<li><p><strong>类的成员</strong></p>
<ul>
<li><p>在一般情况下，一个类不能包含该类类型的对象作为成员  </p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Zoo</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">	Zoo *p;  <span class="comment">//ok</span></span><br><span class="line">	Zoo &amp;r; <span class="comment">//ok 这个引用成员必须被初始化。</span></span><br><span class="line">	<span class="comment">//Zoo o; //错误，类定义依赖于自身。</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
</li>
<li><p>静态成员</p>
<ul>
<li><p>静态成员变量是所有类对象共享的，需要在类定义外额外分配存储</p>
</li>
<li><p>静态数据成员属于类，而不属于对象。访问方式</p>
<p>类名::静态共有数据成员 </p>
</li>
<li><p>一般使用静态成员函数来访问静态数据成员。</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="第六章-深入类和对象"><a href="#第六章-深入类和对象" class="headerlink" title="第六章 深入类和对象"></a>第六章 深入类和对象</h4><ul>
<li><p><strong>构造函数</strong></p>
<ul>
<li><p>构造函数的调用是<strong>自动进行</strong>的。这甚至不是一种程序员的可选项，而是编译器实施的一种强制性机制。每当创建类的一个新对象时，编译器将在创建的地方自动生成调用构造函数的代码，用以完成对象的初始化工作。在必要的时候，需要给出构造函数的参数。</p>
<p>类的构造函数的作用是：</p>
<p>–(1) 分配一个对象的数据成员的存储空间；（该功能由系统自动完成。）</p>
<p>–(2) 执行构造函数（体），一般是初始化一个对象的部分或全体数据成员。</p>
</li>
<li><p><strong>复制构造函数</strong></p>
<ul>
<li><p>进行两个类对象之间的复制</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> 类名</span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	类名(<span class="keyword">const</span> 类名&amp;[, other parameters]); <span class="comment">//copy constructor</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
</li>
<li><p>何处会调用复制构造函数</p>
<p>显式定义复制对象时，如下例所示：</p>
<p>–array a1;</p>
<p>–array a2(a1); //调用a2的复制构造函数</p>
<p>–array a3 = a2; //这不是对象间的赋值，而是复制（初始化）！</p>
<p>实参和形参结合时。如例中t和a结合时，将会调用形参t的复制构造函数来复制实参对象r；</p>
<p>函数返回值对象（非指针和引用）时。如例中f()返回一个临时对象，这个临时对象就是用其复制构造函数从return的返回表达式t中复制而来。这个临时对象是匿名的，并且被视为常量对象。</p>
</li>
<li><p>如果一个类没有显示定义复制构造函数，c++编译器会为该类合成一个隐式的缺省复制构造函数。</p>
</li>
<li><p>浅复制与深复制</p>
<ul>
<li>浅复制共享同一内存空间，析构出错。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>析构函数</strong></p>
<ul>
<li><p>析构函数的作用是：</p>
<p>1.执行析构函数（一般没有具体的工作）；</p>
<p>2.释放对象的存储空间。（该功能由系统自动完成。）</p>
<p>3.释放对象占用的资源。这项工作要有程序员设定。</p>
</li>
</ul>
</li>
<li><p><strong>对象和指针</strong></p>
<ul>
<li><strong>this指针</strong></li>
</ul>
</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//this指针只能出现在类的非静态成员函数中，并且常用于需要自引用的地方。</span></span><br><span class="line"><span class="function"><span class="built_in">array</span>&amp; <span class="title">array::me</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>​         <strong>指向类对象的指针</strong></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">f</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="built_in">array</span> a;</span><br><span class="line">	<span class="built_in">array</span> *pa = &amp;a; <span class="comment">//指针指向一个编译器对象</span></span><br><span class="line">	pa-&gt;traverse(print);</span><br><span class="line">	<span class="comment">//delete pa; //error，不能用这种方式来释放编译器对象</span></span><br><span class="line">	pa-&gt;~<span class="built_in">array</span>(); <span class="comment">//但可以显式调用这个对象的析构函数：</span></span><br><span class="line"> </span><br><span class="line">	pa = <span class="keyword">new</span> <span class="built_in">array</span>(); </span><br><span class="line">	pa-&gt;traverse(print);</span><br><span class="line">	<span class="keyword">delete</span> pa; <span class="comment">//OK             </span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​        <strong>指向类成员的指针</strong></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//类型名 类名::*指针; </span></span><br><span class="line"><span class="comment">//类型名 (类名::*指针)(参数表);</span></span><br><span class="line">ptr = &amp;X::b;</span><br><span class="line">fptr = &amp;X::f;</span><br><span class="line"><span class="comment">//要用.*或者-&gt;*调用</span></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>友元关系</strong>（提高效率、非必须）<strong>友元能够访问一个类的所有成员</strong><ul>
<li>友元关系不具备传递性</li>
<li>不具有对称性</li>
</ul>
</li>
<li><p>友元类定义在类中表示该友元类能访问本类的所有成员。</p>
</li>
<li><p>对象作为函数的参数/返回值  （复制构造函数的重要性）</p>
</li>
<li>常成员函数<ul>
<li>只读取属性而不修改它们。</li>
</ul>
</li>
<li>包围类的成员对嵌套类是不可见的。嵌套类的作用域对包围类来说也是封闭的。<ul>
<li>可以定义友元类来解决问题。</li>
</ul>
</li>
</ul>
<h4 id="第七章-运算符重载"><a href="#第七章-运算符重载" class="headerlink" title="第七章 运算符重载"></a>第七章 运算符重载</h4><ul>
<li>运算符重载的原型</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">返回值类型 <span class="keyword">operator</span> @ (参数列表);</span><br></pre></td></tr></table></figure>
<ul>
<li><p>双目运算符</p>
<ul>
<li>类似于+=，运算的结果可以作为左值使用</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">complex</span>&amp; <span class="keyword">operator</span> += (<span class="keyword">const</span> <span class="built_in">complex</span>&amp; rhs)</span><br><span class="line">&#123;</span><br><span class="line">	real += rhs.real;</span><br><span class="line">	imag += rhs.imag;</span><br><span class="line">	<span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><p>类似于+，运算符作为友元重载</p>
<p>参与运算的两个操作数都不变，运算结果是个新产生的值。</p>
</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">friend</span> Comlex <span class="keyword">operator</span> + (<span class="keyword">const</span> <span class="built_in">complex</span>&amp; lhs, <span class="keyword">const</span> comlex&amp; rhs)</span><br><span class="line">&#123;	</span><br><span class="line">	<span class="comment">//返回临时对象</span></span><br><span class="line">	<span class="keyword">return</span>	<span class="built_in">complex</span>(lhs.real + rhs.real, lhs.imag + rhs.imag);</span><br><span class="line">	<span class="comment">//调用构造函数</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>运算符重载形式</p>
<ul>
<li><p><img src="/2019/12/26/C++%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/Users\58341\AppData\Roaming\Typora\typora-user-images\1577638560890.png" alt="1577638560890" style="zoom:80%;"></p>
</li>
<li><p>对于重载的单目运算符</p>
<ul>
<li><p>作为成员重载时，函数没有参数，运算作用在lhs上；函数返回lhs的左值引用；</p>
</li>
<li><p>作为友元重载是，函数有一个参数（并且是左值引用），运算作用在参数对象上；函数返回参数对象的左值引用。当然，这是不推荐的重载方式。</p>
<p>这条规则关于参数个数有例外，就是当@是后缀++/—时。</p>
</li>
</ul>
</li>
<li><p>对于作为成员重载的双目运算符</p>
<ul>
<li>函数有一个参数，这个参数就是rhs，并且是常量；</li>
<li>产生的结果保存到lhs中；</li>
<li>函数的返回值是lhs的左值引用。</li>
</ul>
</li>
<li><p>对于作为友元重载的双目运算符</p>
<ul>
<li>有两个参数（即左右操作数），并且都是常量，且这两个参数中至少有一个是将该运算符函数作为友元对待的类的对象。；</li>
<li>函数产生一个新值，即返回值是一个对象（非引用非指针）。这会引起复制构造函数的调用，因此，最好为类提供一个复制构造函数。</li>
</ul>
</li>
<li><p>对于关系和逻辑运算符，它们应该产生一个bool类型的结果。如果使用的编译器不支持bool类型，那么应该返回一个替代的整型值：1表示真，0表示假。</p>
</li>
<li><p>如果作为成员重载的运算只是读取对象的属性而不会改变它们，那么建议将该函数设为常成员。</p>
</li>
</ul>
</li>
<li><p>常用运算符的重载(<strong>掌握</strong>运算符重载（算数、赋值）,特殊<a href></a>&gt;&gt;*不要求实现，要求阅读，lambda不考)</p>
<ul>
<li><p>赋值运算符的重载</p>
<p><strong>赋值运算符与复制构造函数不同</strong>，编译器会为类隐式重载一个赋值运算符。在多数情况下，隐式重载的赋值运算符函数工作得很好。但在某些特殊场合，例如需要深复制的场合，赋值操作可能会出现问题。所以，在这种情况下，显式地为类提供重载的赋值运算符是非常明智的选择。</p>
<p>赋值运算符是一个典型的双目运算符，它的左操作数是个左值，右操作数却是左右值不限。因此，赋值运算符函数最好（其实是只能）作为类的成员重载，其唯一的参数最好是右值对象的常量引用，而其返回值应该是左值对象的引用。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">complex</span>&amp; <span class="keyword">operator</span> = (<span class="keyword">const</span> <span class="built_in">complex</span>&amp; c)</span><br><span class="line">&#123;</span><br><span class="line">	real = c.real;</span><br><span class="line">	imag = c.imag;</span><br><span class="line">	<span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>算数运算符的重载</p>
<ul>
<li><p>单目运算符</p>
<p>产生临时变量，返回值为对象值</p>
<p>产生左值，返回值为操作数的引用</p>
</li>
<li><p>双目运算符</p>
<p>除了赋值（含复合赋值）运算符外，几乎所有的双目运算符都应该作为类的友元进行重载</p>
</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">friend</span> type <span class="keyword">operator</span> @ (<span class="keyword">const</span> &amp;, <span class="keyword">const</span> &amp;);</span><br></pre></td></tr></table></figure>
</li>
<li><p>重载++和—运算符</p>
<ul>
<li>前缀++应该以类的成员函数形式重载，其返回值是操作数对象本身的引用；</li>
<li>后缀++应该以类的成员函数形式重载，其返回值是操作数自加前的一个副本，是一个值结果。</li>
<li><strong>c++规定后缀++重载需要有一个整形占位参数</strong></li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">complex</span>&amp; <span class="keyword">operator</span>++()</span><br><span class="line">&#123;</span><br><span class="line">	++real;</span><br><span class="line">	++imag;</span><br><span class="line">	<span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">&#125;<span class="comment">//前缀++</span></span><br><span class="line"><span class="built_in">complex</span> <span class="keyword">operator</span>++(<span class="keyword">int</span>)</span><br><span class="line">&#123;</span><br><span class="line">	<span class="function"><span class="built_in">complex</span> <span class="title">temp</span><span class="params">(<span class="keyword">this</span>-&gt;real, <span class="keyword">this</span>-&gt;imag)</span></span>;</span><br><span class="line">	++real;++imag;</span><br><span class="line">	<span class="keyword">return</span> temp;</span><br><span class="line">&#125;<span class="comment">//后缀++</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>关系运算符重载</p>
</li>
<li><p>输入输出运算符重载</p>
</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">friend</span> ostream&amp; <span class="keyword">operator</span>&lt;&lt;(ostream&amp; os, <span class="keyword">const</span> <span class="built_in">complex</span> &amp;c);</span><br><span class="line">firend istream&amp; <span class="keyword">operator</span>&gt;&gt;(istream&amp; is, <span class="built_in">complex</span> &amp;c);</span><br></pre></td></tr></table></figure>
<ul>
<li>装箱和拆箱P177-P180</li>
<li>重载[] * ()</li>
</ul>
</li>
</ul>
<h4 id="第八章-继承和派生（全部重点）"><a href="#第八章-继承和派生（全部重点）" class="headerlink" title="第八章 继承和派生（全部重点）"></a>第八章 继承和派生（全部重点）</h4><ul>
<li><p><strong>继承：后代对祖先特征的全盘接受是继承的过程。</strong></p>
<ul>
<li><p><strong>基类和派生类：派生类（子类）继承基类（父类）</strong></p>
</li>
<li><p>继承关系确立</p>
<ul>
<li>继承基类的除（构造函数、析构函数、基类重载的赋值运算符）外的所有成员</li>
<li>改造基类成员，可以通过访问控制调用或直接<strong>使用同名成员覆盖基类成员</strong>。</li>
<li>增加新的成员。</li>
</ul>
</li>
<li><p>继承中的类等级</p>
<ul>
<li>直接基类、间接基类。<code>祖先类名::祖先类成员</code></li>
</ul>
</li>
<li><p>访问控制</p>
</li>
<li><p><img src="/2019/12/26/C++%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/Users\58341\AppData\Roaming\Typora\typora-user-images\1577778210569.png" alt="1577778210569" style="zoom:80%;"></p>
</li>
<li><p>基类的protected成员</p>
<p>​     基类的某些私有成员必须对派生类是可见的，或者可访问的，而在派生类外却又是不可见的，即是受保护的。  </p>
</li>
<li><p>访问声明</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">tiger</span> :</span> <span class="keyword">private</span> felid</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	<span class="keyword">using</span> felid::prey;<span class="comment">//恢复成员的原有访问属性</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li><p>基类静态成员的派生</p>
<p>所有后代和基类共享唯一的静态成员</p>
<p>用<code>基类名::静态成员名</code>进行访问</p>
</li>
</ul>
</li>
<li><p>基类和派生类的关系</p>
<ul>
<li><p>派生类对象初始化必须调用基类的构造函数。</p>
</li>
<li><p><strong>派生类对象和基类对象的相互转换</strong></p>
<ul>
<li><p>派生类直接赋值给基类合法</p>
<ul>
<li><code>基类 = 派生类</code></li>
</ul>
</li>
<li><p>派生类直接赋给基类的引用、指针</p>
<ul>
<li><p><code>基类&amp; = 派生类</code>    不会引起对象转化</p>
</li>
<li><p><code>基类* = &amp;派生类</code></p>
</li>
<li><p><strong>如果要反过来则需要强制转换</strong></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">felid &amp;fr = <span class="keyword">dynamic_cast</span>&lt;felid&amp;&gt;(c)<span class="comment">//强制转换基类为派生类</span></span><br><span class="line">q = <span class="keyword">dynamic_cast</span>&lt;felid *&gt;(&amp;c);</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>复制兼容性原则</strong></p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">子类对象可以直接赋值给父类对象</span><br><span class="line">父类指针可以直接指向子类对象</span><br><span class="line">父类引用可以直接引用子类对象</span><br></pre></td></tr></table></figure>
</li>
<li><p>派生类中重新定义基类的成员</p>
<ul>
<li><p>派生类中重新定义基类的数据成员（首先查找本类作用域中的数据成员）</p>
</li>
<li><p>派生类中重载基类的成员函数  </p>
<p>函数重载规则：</p>
<p>​    在相同的作用域中（例如同一个类中），重载的函数原型必须不同；</p>
<p>​    在不同的作用域中（例如不同的类中），重载的函数原型可以相同。</p>
<p>无论如何，派生类的函数名将屏蔽基类中重名的函数，即使它们的原型不一致。</p>
</li>
<li><p>```c++<br>class A {f();}<br>class B : A {f();}//可以原型相同(作用域不同)<br>//如果A中virtual f() 则B中为覆盖</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">      - 派生类继承基类重载的运算符函数  </span><br><span class="line"></span><br><span class="line">#### 第九章 虚函数和多态性</span><br><span class="line"></span><br><span class="line">- **多态性**：一个接口，多种实现</span><br><span class="line"></span><br><span class="line">  - 静态多态性：在编译时完成，普通的函数重载。</span><br><span class="line">  - 动态多态性：依赖**虚函数**来实现。虽然编译器仍然认为调用的是基类的成员，但由于派生类的成员覆盖了基类的同名成员，因此可以得到正确的结果。</span><br><span class="line"></span><br><span class="line">- **虚函数virtual关键字：**</span><br><span class="line"></span><br><span class="line">  - 关键字virtual明确地告诉编译器：该类派生类中的同名成员函数将**覆盖**基类已定义的函数。</span><br><span class="line"></span><br><span class="line">  - 包含虚函数的类被称为多态类。</span><br><span class="line"></span><br><span class="line">  - **特点：**</span><br><span class="line"></span><br><span class="line">    - ①虚特性必须赋予给类的**成员函数**；</span><br><span class="line"></span><br><span class="line">      ②虚函数不能是全局函数，也不能是类的静态成员函数；</span><br><span class="line"></span><br><span class="line">      ③不能将友元说明为虚函数，但虚函数可以是另一个类的友元；</span><br><span class="line"></span><br><span class="line">      ④**虚特性能够被继承**。如果派生类原型一致地重载了基类的某个虚函数，那么即使在派生类中没有将这个函数显式说明成是虚的，它也会被编译器认为是虚函数。</span><br><span class="line"></span><br><span class="line">  - 派生类覆盖之后，祖先的虚成员仍然存在。</span><br><span class="line"></span><br><span class="line">  - 一旦基类中的函数被声明为虚函数，后代中原型相同的函数都是虚的。</span><br><span class="line"></span><br><span class="line">  - 虚析构函数：</span><br><span class="line"></span><br><span class="line">    若析构函数不声明为虚函数，子类析构会出错。</span><br><span class="line"></span><br><span class="line">    - 通过强制类型转换将指针p转换为派生类指针，具体做法如下：</span><br><span class="line">    - delete (felid *)(p);</span><br><span class="line">    - 将felid类的析构函数说明成是虚的：</span><br><span class="line">    - virtual ~felid() &#123; … &#125;</span><br><span class="line"></span><br><span class="line">  - override和final描述符</span><br><span class="line"></span><br><span class="line">    - override表示覆盖基类中原型相同的成员</span><br><span class="line">    - final表示最终版本，派生类不能覆盖</span><br><span class="line"></span><br><span class="line">  - **&lt;font color&#x3D;red&gt;实现多态性的条件&lt;&#x2F;font&gt;**（要求阅读和编写）——程序阅读写结果&#x2F;程序补充</span><br><span class="line"></span><br><span class="line">    - 父类虚函数</span><br><span class="line">    - 子类覆盖</span><br><span class="line">    - 必须要父类指针、引用访问多态（虚）函数</span><br><span class="line"></span><br><span class="line">- **纯虚函数**</span><br><span class="line"></span><br><span class="line">  - 纯虚函数是一个在基类中说明的虚函数，它在该基类中没有定义，要求任何派生类都必须定义自己的版本。</span><br><span class="line"></span><br><span class="line">  &#96;&#96;&#96;c++</span><br><span class="line">  class felid</span><br><span class="line">  &#123;</span><br><span class="line">  public:</span><br><span class="line">  	virtual string what() &#x3D; 0;</span><br><span class="line">  &#125;;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
</li>
<li><p>包含纯虚函数的类是抽象类，<strong>不能直接对抽象类进行实例化</strong>。</p>
</li>
<li><p>在抽象类的派生类中，如果纯虚函数的最终覆盖函数仍是一个纯虚函数（即仍未提供一个函数体），那么该派生类仍是一个抽象类。</p>
</li>
<li><p>抽象类不能作为参数类型、返回类型，但指针、引用可</p>
</li>
</ul>
</li>
</ul>
<h4 id="第十章-模板和泛型编程"><a href="#第十章-模板和泛型编程" class="headerlink" title="第十章 模板和泛型编程"></a>第十章 模板和泛型编程</h4><ul>
<li><p><strong>模板</strong>（泛型编程）</p>
<ul>
<li><p>不依赖任何具体类型来编写通用代码。是某种形式上的<strong>静态多态</strong>。</p>
</li>
<li><p><strong>模板函数</strong></p>
<ul>
<li>函数模板需要实例化之后才能使用</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt; <span class="keyword">typename</span> T, </span><br><span class="line">                    [<span class="keyword">const</span>类 常量表达式, …] &gt;</span><br><span class="line">返回值类型 函数名(参数列表)</span><br><span class="line">&#123; </span><br><span class="line">	<span class="comment">//函数体</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">PS:</span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">Greater</span><span class="params">(<span class="keyword">const</span> T&amp; a, <span class="keyword">const</span> T&amp; b)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="keyword">return</span> a &gt; b;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, <span class="keyword">const</span> <span class="keyword">int</span> min&gt;</span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">Greater</span><span class="params">(<span class="keyword">const</span> T&amp; a, <span class="keyword">const</span> T&amp; b)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="keyword">return</span> a &gt; b &amp;&amp; b &gt; min;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//模板的非类型参数的类型不能是浮点型、类类型或void类型。它一般是整数类型、枚举类型。非类型参数如果不是引用，那么它不是左值，不能改变其值，也不能获取其地址。</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>模板特化</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">char</span> * cstring;</span><br><span class="line"><span class="keyword">template</span> &lt;&gt;<span class="comment">//特化的模板没有模板参数</span></span><br><span class="line"><span class="keyword">bool</span> Greater&lt;cstring&gt;(<span class="keyword">const</span> cstring&amp; s1, <span class="keyword">const</span> cstring&amp; s2)</span><br><span class="line">&#123;</span><br><span class="line">    out &lt;&lt; <span class="string">&quot;C-style string comparasion: &quot;</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">strcmp</span>(s1, s2) &gt; <span class="number">0</span> ? <span class="literal">true</span> : <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//特化后的模板仍然是模板</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>类模板</strong></p>
</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, [<span class="keyword">const</span> 类型 常量表达式, …]&gt;</span><br><span class="line"><span class="class"><span class="keyword">class</span> 类名</span></span><br><span class="line"><span class="class">&#123;</span> </span><br><span class="line">	<span class="comment">//成员定义;</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">//类的所有成员函数都是函数模板。</span></span><br></pre></td></tr></table></figure>
<ul>
<li>类模板的使用<ul>
<li>模板名&lt;参数列表&gt; 对象名；        </li>
</ul>
</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>期末复习</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title>软件安全设计</title>
    <url>/2019/06/14/%E8%BD%AF%E4%BB%B6%E5%AE%89%E5%85%A8%E8%AE%BE%E8%AE%A1/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<h1 id="软件安全设计"><a href="#软件安全设计" class="headerlink" title="软件安全设计"></a>软件安全设计</h1><h2 id="CH01软件与软件安全"><a href="#CH01软件与软件安全" class="headerlink" title="CH01软件与软件安全"></a>CH01软件与软件安全</h2><h3 id="计算环境与软件"><a href="#计算环境与软件" class="headerlink" title="计算环境与软件"></a>计算环境与软件</h3><h4 id="二进制基础"><a href="#二进制基础" class="headerlink" title="二进制基础"></a>二进制基础</h4><h5 id="位运算"><a href="#位运算" class="headerlink" title="位运算"></a>位运算</h5><p><strong>所谓位运算是指进行二进制位的运算。在系统软件中，常要处理二进位的问题。</strong></p>
<font color="red">**不同长度的数据进行位运算**</font>

<p>如果两个数据长度不同(例如long型和int型)进行位运算时(如a &amp; b,而a为long型,b为int型),系统会将二者按右端对齐。如果b为正数,则左侧16位补满0。若b为负数,左端应补满1。如果b为无符号整数型,则左侧添满0。</p>
<h4 id="指令系统与指令集"><a href="#指令系统与指令集" class="headerlink" title="指令系统与指令集"></a>指令系统与指令集</h4><p><strong>指令系统：</strong>计算机的指令系统就是指该计算机能够执行的全部指令的集合。</p>
<p><strong>指令系统也称指令集</strong></p>
<h3 id="软件的形式与概念"><a href="#软件的形式与概念" class="headerlink" title="软件的形式与概念"></a>软件的形式与概念</h3><h4 id="软件"><a href="#软件" class="headerlink" title="软件"></a>软件</h4><p>与一个系统（尤指计算机系统）有关的<strong>程序、步骤和有关文件</strong>编制的完整集合。特指特定类型计算机所使用的程序的总称，连同与计算机或程序有关的资料，例如手册、图表和操作指令。</p>
<p><strong>程序</strong></p>
<p>根据一定的需要事先编写的一系列控制计算机工作的命令，就称为<strong>计算机程序。</strong></p>
<p><strong>计算机系统的组成</strong></p>
<p>完整的计算机系统包括计算机硬件系统和计算机软件系统。</p>
<p><strong>软件的主要内容</strong></p>
<p>程序、步骤及数据、信息手册等相关资料</p>
<p>功能：针对一个系统（计算机），合理组织工作。</p>
<p>两个层次：</p>
<p>–直接与硬件相关</p>
<p>–合理组织工作，完成特定任务。</p>
<p><strong>软件的形式</strong></p>
<p>软件分为<strong>系统软件</strong>和<strong>应用软件</strong>，<font color="red">应用软件以系统软件为基础。</font></p>
<h3 id="信息安全与软件安全"><a href="#信息安全与软件安全" class="headerlink" title="信息安全与软件安全"></a>信息安全与软件安全</h3><h4 id="信息与信息安全"><a href="#信息与信息安全" class="headerlink" title="信息与信息安全"></a>信息与信息安全</h4><p><strong>信息安全属性</strong></p>
<p><strong>安全性，可用性，保密性，可控性，可靠性</strong></p>
<h4 id="软件安全"><a href="#软件安全" class="headerlink" title="软件安全"></a>软件安全</h4><p><strong>软件安全：</strong>软件在恶意攻击下能够正确地完成其功能。</p>
<p><strong>软件安全性：</strong>软件安全性是指软件不被恶意使用或者攻击进而造成用户信息资产损失的属性。</p>
<p><strong>软件安全属性：</strong></p>
<ol>
<li>可信性：保护敏感信息不被未授权用户访问</li>
<li>完整性：保护数据不被更改或破坏</li>
<li>可用性：确保资源被授权用户的使用</li>
</ol>
<p><strong>软件安全保护：</strong></p>
<p>(1) 软件<strong>自身安全</strong>：防止软件丢失、被破坏、被篡改、被伪造</p>
<p>(2) 软件<strong>存储安全</strong>：可靠存储，保密存储，压缩存储，备份存储</p>
<p>(3) 软件<strong>通信安全</strong>：安全传输、加密传输、网络安全下载、完整下载</p>
<p>(4) 软件<strong>信用安全</strong>：合法用户与非法用户，授权访问，防止软件滥用，</p>
<p>  防止软件窃取，软件的非法复制</p>
<p>(5) 软件<strong>运行安全</strong> ：确保软件正常运行，功能正常</p>
<p><strong>软件安全研究：</strong>如何设计、构造、验证和维护软件以保证其是安全的。</p>
<p>包括改进和实现软件安全的<strong>架构或结构、工具、方法</strong></p>
<h4 id="ISO7498-2"><a href="#ISO7498-2" class="headerlink" title="ISO7498-2"></a><strong>ISO7498-2</strong></h4><h5 id="主要内容"><a href="#主要内容" class="headerlink" title="主要内容"></a>主要内容</h5><p>在ISO7498-2中描述开放系统互连安全的体系架构，提出设计安全的信息系统的基础架构应该包含的：5种安全服务，对5种安全服务提供支持的8类安全机制，需要进行的5种OSI安全管理方式</p>
<h5 id="5种安全服务"><a href="#5种安全服务" class="headerlink" title="5种安全服务"></a>5种安全服务</h5><ul>
<li>鉴别服务、访问控制、数据完整性、数据保密性、抗抵赖</li>
</ul>
<h5 id="8种安全机制"><a href="#8种安全机制" class="headerlink" title="8种安全机制"></a>8种安全机制</h5><ul>
<li>加密、数字签名、访问控制、数据完整性、数据交换、业务流填充、路由控制、公证</li>
</ul>
<h5 id="5种普遍性安全管理机制"><a href="#5种普遍性安全管理机制" class="headerlink" title="5种普遍性安全管理机制"></a>5种普遍性安全管理机制</h5><ul>
<li>可信功能度、安全标记、事件检测、安全审计跟踪、安全恢复</li>
</ul>
<h4 id="软件安全的概念"><a href="#软件安全的概念" class="headerlink" title="软件安全的概念"></a>软件安全的概念</h4><h5 id="漏洞"><a href="#漏洞" class="headerlink" title="漏洞"></a>漏洞</h5><p>计算机系统具有的某种可能被入侵者恶意利用的<font color="red">属性</font>。</p>
<p>有时安全漏洞也称为脆弱性（Vulnerability）。</p>
<p><strong>本质：</strong>漏洞是系统的一组特性，恶意的主体（攻击者或者攻击程序）能够利用这组特性，通过已授权的手段和方式获取对资源的未经授权访问，或者对系统造成损害。</p>
<h5 id="脆弱状态"><a href="#脆弱状态" class="headerlink" title="脆弱状态"></a>脆弱状态</h5><p>从已授权的状态变换到未授权状态。</p>
<h5 id="攻击"><a href="#攻击" class="headerlink" title="攻击"></a>攻击</h5><p>攻击是以授权状态或脆弱状态开始，以<strong>受损状态为目标</strong>的状态变换</p>
<h5 id="安全事件"><a href="#安全事件" class="headerlink" title="安全事件"></a>安全事件</h5><p>当系统的某个漏洞被入侵者渗透（exploit）而造成泄密</p>
<h4 id="ISO9126标准"><a href="#ISO9126标准" class="headerlink" title="ISO9126标准"></a>ISO9126标准</h4><p>ISO9126标准：软件产品评价－质量特性及其使用指南</p>
<h5 id="6个质量特性"><a href="#6个质量特性" class="headerlink" title="6个质量特性"></a>6个质量特性</h5><ul>
<li><strong>功能性</strong><ul>
<li>准确性：软件提供给用户功能的精确度是否符合目标。（例如：运算结果的准确，数字发生偏差，多个0或少个0）</li>
<li>互操作性：软件与其它系统进行交互的能力。（例如：PC机中WORD和打印机完成打印互通）</li>
<li>保密安全性：软件保护信息和数据的安全能力。（主要是权限和密码）</li>
<li>功能性的依从性：遵循相关标准（国际标准、国内标准、行业标准、企业内部规范）</li>
</ul>
</li>
<li><strong>可靠性</strong><ul>
<li>成熟性：软件产品为避免软件内部的错误扩散而导至系统失效的能力（主要是对内错误的隔离）</li>
<li>容错性：软件防止外部接口错误扩散而导致系统失效的能力（主要是对外错误的隔离）</li>
<li>易恢复性：系统失效后，重新恢复原有的功能和性能的能力。</li>
<li>可靠性的依从性：遵循相关标准</li>
</ul>
</li>
<li><strong>易用性</strong><ul>
<li>易理解性：软件交互给用户的信息时，要清晰，准确，且要易懂，使用户能够快速理解软件。</li>
<li>易学性：软件使用户能学习其应用的能力。</li>
<li>易操作性：软件产品使用户能易于操作和控制它的能力。</li>
<li>易用性的依从性：遵循一定的标准。</li>
</ul>
</li>
<li><strong>效率</strong><ul>
<li>时间特性：软件处理特定的业务请求所需要的响应时间。</li>
<li>资源利用性：软件处理特定的业务请求所消耗的系统资源。</li>
<li>效率依从性：遵循一定的标准。</li>
</ul>
</li>
<li><strong>维护性</strong><ul>
<li>易分析性：软件提供辅助手段帮助开发人员定位缺陷产生的原因，判断出修改的地方。</li>
<li>易改变性：软件产品使得指定的修改容易实现的能力。（降低修复问题的成本）</li>
<li>稳定性：软件产品避免由于软件修改而造成意外结果的能力。</li>
<li>易测试性：软件提供辅助性手段帮助测试人员实现其测试意图。</li>
<li>维护性的依从性：遵循相关标准。</li>
</ul>
</li>
<li><strong>可移植性</strong><ul>
<li>适应性：软件产品无需作相应变动就能适应不同环境的能力。</li>
<li>易安装性：尽可能少的提供选择，方便用户直接安装。</li>
<li>共存性：软件产品在公共环境中与其它软件分享公共资源共存的软件。</li>
<li>易替换性：软件产品在同样的环境下，替代另一个相同用途的软件产品的能力。</li>
<li>可移植性的依从性：遵循相关的标准。</li>
</ul>
</li>
</ul>
<h5 id="9126质量模型缺陷"><a href="#9126质量模型缺陷" class="headerlink" title="9126质量模型缺陷"></a>9126质量模型缺陷</h5><ul>
<li>安全性是软件功能性的子属性</li>
<li>充分体现了对安全的忽视。</li>
</ul>
<p><strong>安全的代码（secure code）</strong>：  能够抵抗恶意攻击的代码；安全的代码同时也是健壮的代码（robust code）</p>
<p><strong>安全性代码（security code）</strong>：   实现安全功能的代码。</p>
<p><strong>安全的程序：</strong>安全隐含某种程度的信任（trust），程序实现了期望的机密性、完整性、可用性及其功能。</p>
<h2 id="CH02典型软件安全问题"><a href="#CH02典型软件安全问题" class="headerlink" title="CH02典型软件安全问题"></a>CH02典型软件安全问题</h2><h3 id="安全问题的来源"><a href="#安全问题的来源" class="headerlink" title="安全问题的来源"></a>安全问题的来源</h3><p><strong>根本来源：</strong>漏洞(<font color="red">漏洞是软件的属性，是软件安全威胁的根源</font>)、攻击者、软件存在的攻击路径－攻击面问题。</p>
<h4 id="漏洞-1"><a href="#漏洞-1" class="headerlink" title="漏洞"></a>漏洞</h4><h5 id="产生漏洞的原因"><a href="#产生漏洞的原因" class="headerlink" title="产生漏洞的原因"></a>产生漏洞的原因</h5><ol>
<li>软件或协议<strong>设计</strong>时的瑕疵</li>
<li>软件或协议<strong>实现</strong>中的弱点</li>
<li>软件<strong>本身</strong>的瑕疵</li>
<li><strong>系统和网络</strong>的错误配置</li>
</ol>
<h5 id="漏洞的两种类型"><a href="#漏洞的两种类型" class="headerlink" title="漏洞的两种类型"></a>漏洞的两种类型</h5><ul>
<li>设计漏洞：<ul>
<li>设计错误，往往发现于软件的安全功能特性中。</li>
</ul>
</li>
<li>实现漏洞：<ul>
<li>来源于软件实际编码中的安全缺陷。</li>
</ul>
</li>
</ul>
<h4 id="意外行为和缺陷"><a href="#意外行为和缺陷" class="headerlink" title="意外行为和缺陷"></a>意外行为和缺陷</h4><p><strong>意外行为（Unexpected Behavior）</strong>：也称程序安全缺陷，是由于程序脆弱性引起的不适当的程序行为。</p>
<p><strong>缺陷（Flaw）</strong>：缺陷可以是故障（Fault），或者失效（Failure）</p>
<p>程序安全缺陷可能来源于任何种类的<strong>软件错误</strong>：</p>
<ul>
<li>无意或疏忽的</li>
<li>故意或有意的</li>
</ul>
<h5 id="缺陷的类型："><a href="#缺陷的类型：" class="headerlink" title="缺陷的类型："></a>缺陷的类型：</h5><ul>
<li>有意的缺陷<ul>
<li>恶意的</li>
<li>非恶意的</li>
</ul>
</li>
<li>无意的缺陷<ul>
<li><strong>确认</strong>错误</li>
<li><strong>域</strong>的错误</li>
<li><strong>顺序化和混淆</strong>现象</li>
<li>不完全的<strong>身份识别和认证</strong></li>
<li><strong>边界条件</strong>违反</li>
<li>其它可利用的<strong>逻辑</strong>错误</li>
</ul>
</li>
</ul>
<h5 id="APPLE-DEVELOPER常见软件缺陷"><a href="#APPLE-DEVELOPER常见软件缺陷" class="headerlink" title="APPLE DEVELOPER常见软件缺陷"></a><strong>APPLE DEVELOPER常见软件缺陷</strong></h5><ul>
<li>buffer overflows   缓冲区溢出</li>
<li>invalidated input 未校验输入</li>
<li>race conditions 资源竞争</li>
<li>access-control problems 访问控制问题</li>
<li>weaknesses in authentication, authorization, or cryptographic practices 认证、授权、加密缺陷</li>
</ul>
<h3 id="常见的安全设计问题"><a href="#常见的安全设计问题" class="headerlink" title="常见的安全设计问题"></a>常见的安全设计问题</h3><ol>
<li><strong>密码技术使用的败笔</strong><ul>
<li>创建自己的密码技术</li>
<li>选用了不当的密码技术</li>
<li>依赖隐蔽式安全</li>
<li>编写到程序中的密钥</li>
<li>错误地处理私密信息</li>
</ul>
</li>
<li><strong>对用户及其许可权限进行跟踪的薄弱或缺失</strong><ul>
<li>会话管理薄弱或者缺失</li>
<li>身份鉴别薄弱或缺失</li>
<li>授权薄弱或缺失</li>
</ul>
</li>
<li><strong>有缺陷的输入验证</strong><ul>
<li>没有在安全的上下文环境中执行验证，如在服务器验证而在客户端没有验证</li>
<li>验证例程不集中，验证应尽可能靠近用户输入，并应集中以便于核实</li>
<li>不安全的组件边界</li>
</ul>
</li>
<li><strong>薄弱的结构性安全</strong><ul>
<li>过大的攻击面</li>
<li>在过高权限级别上运行进程</li>
<li>没有纵深防御</li>
<li>失效时的处理不安全</li>
</ul>
</li>
<li><strong>其他设计缺陷</strong><ul>
<li>代码和数据混在一起</li>
<li>错将信任寄予外部系统</li>
<li>不安全的默认值</li>
<li>未做审计日志</li>
</ul>
</li>
</ol>
<h3 id="编程语言问题"><a href="#编程语言问题" class="headerlink" title="编程语言问题"></a>编程语言问题</h3><h4 id="C-C-的问题"><a href="#C-C-的问题" class="headerlink" title="C/C++的问题"></a>C/C++的问题</h4><ol>
<li><p><strong>没有安全的本地字符串类型，也没有安全而易用的字符串处理函数。</strong></p>
<p><strong>PS：</strong></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">//C中以NULL终止符表示一个字符串的末尾。</span></span><br><span class="line"><span class="comment">//如：</span></span><br><span class="line">Char buffer[]=“small <span class="built_in">string</span>”</span><br><span class="line"><span class="comment">//没有确切地存储字符串的长度，该字符串的长度要</span></span><br><span class="line"><span class="comment">//程序员管理。</span></span><br><span class="line"><span class="comment">//当程序员处理这个长度犯错时，就会导致超过缓冲</span></span><br><span class="line"><span class="comment">//区结尾部分的内存被覆盖。</span></span><br></pre></td></tr></table></figure>
<p><strong>缓冲区溢出（BufferOverflow）</strong><br><strong>——一个最典型的例子：</strong></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">char</span> sample[<span class="number">10</span>];</span><br><span class="line"><span class="keyword">for</span> (i=<span class="number">0</span>; i&lt;<span class="number">10</span>; i++) sample[i] = <span class="string">&#x27;A&#x27;</span>;</span><br><span class="line">	sample[<span class="number">10</span>] =<span class="string">&#x27;B&#x27;</span>;   <span class="comment">//</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>缓冲区超限覆盖栈中的函数返回地址</strong></p>
<ul>
<li>用于从被调用的函数返回到某个位置的返回地址驻留在栈中，紧接在本地变量之后；</li>
<li>返回地址是驻留在栈中的一段隐蔽的数据，栈中其余部分是传递给该函数的变量；</li>
<li>编译后的程序在调用这个函数之前会将这个地址数据放在栈中，以使程序获知当这个函数执行完后转到哪里；</li>
<li>通过把栈中某个变量产生缓冲区溢出，就可以覆盖栈中的这个返回地址。</li>
</ul>
<p><strong>PS:</strong></p>
<p><strong>典型例子－栈溢出（Stack Smashing）</strong></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function">Void <span class="title">createFullName</span> <span class="params">(<span class="keyword">char</span>* firstName, Char* lastName)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">Char fullName[<span class="number">1024</span>];</span><br><span class="line">Strcpy(fullName, firstName);</span><br><span class="line">Strcat(fullName, “ “)</span><br><span class="line">Strcat(fullName, lastName);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">接受参数名字和姓氏，放到一起，中间用空格分隔；</span></span><br><span class="line"><span class="comment">变量fullName的声明方式，使其在堆栈中驻留；</span></span><br><span class="line"><span class="comment">如果firstName和lastName太长，可能会使fullName超出1024；</span></span><br><span class="line"><span class="comment">调用strcpy 和strcat函数破坏内存栈，会导致程序崩溃；</span></span><br><span class="line"><span class="comment">如果控制参数使得fullName发生缓冲区溢出，就可以造成程序的恶意攻击。</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>
<p><strong>预防栈溢出的方法：</strong></p>
<ul>
<li>精确控制输入变量的长度（如上述firstName和lastName的长度限制为511个字节）；</li>
<li>建议使用strncpy和strncat替代strcpy和strcat；</li>
<li>避免使用无界字符串；</li>
<li>创建一个新的或使用已有的字符串缓冲区模块。</li>
</ul>
</li>
<li><p><strong>printf类型的格式化函数－格式化字符串攻击</strong></p>
<p>例子：</p>
<p>   sprintf(target, “Name:%s, count:%d”, person, num);</p>
<p>该例子获取字符串Name和整型数count，放入target（目标缓冲区）</p>
<p>如果：</p>
<p>  sprintf（target，“Name: %s%s%s%s, count:%d”,num）；</p>
<p>此时该函数将从栈中读取四个字符串，但事实上栈中不存在这四个字符串，程序读取栈中原本用于其他目的的值。</p>
</li>
<li><p>整数溢出</p>
<p>在C语言中，整数的正负标识是默认的；</p>
<p>当一个整数值增长从而超过了其最大可能的值并循环到成为一个负数的时候，将发生整数溢出；</p>
<p>C语言没有任何措施预防整数溢出。</p>
<p>如果攻击者通过用户输入操纵整数长度，就可以让这个值溢出，引起程序的处理发生错误。</p>
<p>例：整数2147483647加1，发生溢出，成为</p>
<p>​               -2147483648</p>
<p><strong>PS：</strong></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function">Int <span class="title">copy_something</span><span class="params">(<span class="keyword">char</span> *buf, <span class="keyword">int</span> len)</span></span></span><br><span class="line"><span class="function">  </span>&#123;</span><br><span class="line">    <span class="keyword">char</span> kbuf[<span class="number">800</span>];</span><br><span class="line">     <span class="keyword">if</span>(len&gt;<span class="keyword">sizeof</span>(kbuf)</span><br><span class="line">          &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">-1</span>;                      <span class="comment">/*1*/</span></span><br><span class="line">          &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">memcpy</span>(kbuf, buf, len);    <span class="comment">/*2*/</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在 1 利用符号整数进行了一次边界检查；</p>
<p>如果能够控制程序，传递一个负值给len，则可能通过1的检查；</p>
<p>在2中，memcpy接受无符号数作为长度，len被解释为一个大的无符号数，导致超越缓冲区kbuf的末尾；</p>
<p>具有讽刺意味的是：1所进行的边界检查是为了预防缓冲区溢出。</p>
</li>
</ol>
<h3 id="平台的实现问题"><a href="#平台的实现问题" class="headerlink" title="平台的实现问题"></a>平台的实现问题</h3><p><strong>平台：</strong>平台是指程序在其中所<strong>运行的环境</strong>，包括<strong>操作系统</strong>以及与之<strong>交互的组件</strong>。</p>
<p><strong>平台问题1：符号链接</strong></p>
<p>符号链接（Symbolic link, 简写为symlink）：文件系统中指向其他文件的文件。符号链接等效于其指向的文件。程序打开的是一个符号链接，实际打开的是该符号链接指向的文件。</p>
<p>符号链接问题</p>
<p>攻击者可以使用程序预计要操作的文件名创建一个符号链接，使该文件名指向希望的文件；利用符号链接，攻击者事实上可以启动系统中的任何程序。</p>
<p>解决</p>
<p>程序员或使用者创建、打开、删除文件，或更改文件权限，必须检查该文件的符号链接，不可以基于文件名做任何安全方面的判定。</p>
<p>权限攻击的例子：如果程序以攻击者没有的权限运行，比如作为SUID（系统用户身份），攻击者可以借此发动一次权限提升。</p>
<p><strong>平台问题2：目录遍历</strong></p>
<p>典型例子：</p>
<p>CIFS是WINDOWS的文件共享协议，允许计算机通过网络访问彼此的文件系统。</p>
<p>利用目录遍历，攻击者可通过使用“..”符号上升到文件系统的上一级目录，从而对文件共享程序进行欺骗，进而获得对不在共享目录下的目录进行访问。</p>
<p><strong>平台问题3：字符转换</strong></p>
<p>平台支持不同类型的字符编码，存在多种不同的表示某个字符的方式。</p>
<p>程序接受用户的输入，为了满足安全需求，通常会要求进行安全检查，以确保输入的字符串对该程序设计是有效的。</p>
<p>当平台进行升级的时候可能会引入新的字符编码。</p>
<h3 id="常见的应用程序安全问题"><a href="#常见的应用程序安全问题" class="headerlink" title="常见的应用程序安全问题"></a>常见的应用程序安全问题</h3><p><strong>引起原因：</strong></p>
<ul>
<li>应用程序的某个组件的恶意数据引起，这些恶意数据在其另一个组件中被当作了合法代码；</li>
<li>对涉密信息的不当处理</li>
</ul>
<p><strong>应用安全问题1：SQL注入</strong></p>
<p>攻击者通过操纵程序的某种输入，在连接到SQL数据库的应用程序上执行自己所构造的查询。</p>
<p>​    <strong>预防SQL攻击方法：</strong>    </p>
<ul>
<li>过滤所有输入，确保输入字段只包含所需要的字符；</li>
<li>尽量避免使用动态生成的SQL。</li>
</ul>
<p>　<strong>SQL注入典型例子：</strong></p>
<p>​    但如果我们刻意的去绕过登录认证呢？猜想下面这个sql语句，单说用户名，开发人员很可能会这样去<strong>数据库</strong>里对比：<br> 　　Select <em> from sys_user where username=‘XXX’<br> 　　当然可能更复杂，假如我们在输入框里输入下面一句特殊的字符会如何？’or‘1=1<br> 　　这是段神奇的字符，因为这样这个sql就变成：<br> 　　Select </em> from sys_user where username=‘’or‘1=1’ ‘<br> 　　这样我们就跳过了用户名的验证，实现了入侵。</p>
<p>这样的结果，导致无条件越过用户名验证。</p>
<p><strong>应用安全问题2：跨站点执行脚本</strong></p>
<p>利用Internet上某些环境（或WEB站点）的受信任级别高于其他环境。</p>
<p>来自非受信环境的攻击者可在受信的环境注入数据，使其在受信环境作为脚本予以执行。</p>
<p>跨站点执行脚本还可以用来访问数据，如用户cookies。</p>
<p> <strong>跨站点执行脚本的例子：</strong></p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">假如有下面一个textbox：　　</span><br><span class="line"><span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span> <span class="attr">name</span>=<span class="string">&quot;address1&quot;</span> <span class="attr">value</span>=<span class="string">&quot;value1from&quot;</span>&gt;</span></span><br><span class="line">value后面的值是来自用户的输入，如果用户输入　</span><br><span class="line">&quot;/&gt;<span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="javascript">alert(<span class="built_in">document</span>.cookie)</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span><span class="tag">&lt;<span class="name">!-</span></span></span><br><span class="line"><span class="tag">那么就会变成　</span></span><br><span class="line">&lt;input type=&quot;text&quot; name=&quot;address1&quot; value=&quot;&quot;/&gt;&lt;script&gt;alert(document.cookie)&lt;/script&gt;&lt;!- &quot;&gt;　</span><br><span class="line">嵌入的JavaScript代码将会被执行　</span><br><span class="line">或者用户输入的是：</span><br><span class="line">&quot;onfocus=&quot;alert(document.cookie)</span><br><span class="line">那么就会变成</span><br><span class="line"><span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span> <span class="attr">name</span>=<span class="string">&quot;address1&quot;</span> <span class="attr">value</span>=<span class="string">&quot;&quot;</span><span class="attr">onfocus</span>=<span class="string">&quot;alert(document.cookie)&quot;</span>&gt;</span></span><br><span class="line">事件被触发的时候嵌入的JavaScript代码将会被执行</span><br></pre></td></tr></table></figure>
<h3 id="开发过程问题"><a href="#开发过程问题" class="headerlink" title="开发过程问题"></a>开发过程问题</h3><ul>
<li>安全需求和前提条件的文档记录缺乏</li>
<li>交流和文档匮乏</li>
<li>缺少安全过程</li>
</ul>
<h4 id="部署上的薄弱性"><a href="#部署上的薄弱性" class="headerlink" title="部署上的薄弱性"></a>部署上的薄弱性</h4><p>部署的执行者一般不属于开发团队</p>
<p>软件错误地设置文件或注册表的键值，使系统上的其他用户可以进行更改</p>
<p>使软件安装时具有不必要的权限。</p>
<h3 id="OWASP"><a href="#OWASP" class="headerlink" title="OWASP"></a>OWASP</h3><p><strong>The Open Web Application Security Project</strong></p>
<h4 id="OWASP-Top-10"><a href="#OWASP-Top-10" class="headerlink" title="OWASP Top 10"></a>OWASP Top 10</h4><p><strong>A1-注入：</strong>攻击者发送的恶意数据可以欺骗解释器，以执行计划外的命令或者在未被恰当授权时访问数据。</p>
<p><strong>A2-失效的身份认证</strong></p>
<p><strong>A3-跨站脚本：</strong>XSS允许攻击者在受害者的浏览器上执行脚本，从而劫持用户会话、危害网站、或者将用户转向至恶意网站。</p>
<p><strong>A4-不安全的直接对象引用</strong></p>
<p><strong>A5-安全配置错误</strong></p>
<p><strong>A6-敏感信息泄露</strong></p>
<p><strong>A7-功能及访问控制缺失</strong></p>
<p><strong>A8-跨站请求伪造（CSRF）</strong></p>
<p><strong>A9-使用含有已知漏洞的组件</strong></p>
<p><strong>A10-未验证的重定向和转发</strong></p>
<h2 id="CH03安全软件工程"><a href="#CH03安全软件工程" class="headerlink" title="CH03安全软件工程"></a>CH03安全软件工程</h2><h3 id="SSE-CMM"><a href="#SSE-CMM" class="headerlink" title="SSE-CMM"></a>SSE-CMM</h3><h4 id="开发SSE-CMM的目的"><a href="#开发SSE-CMM的目的" class="headerlink" title="开发SSE-CMM的目的"></a>开发SSE-CMM的目的</h4><p>降低开发和维护系统的花费；</p>
<p>提高工程进度和预算的一致性；</p>
<p>选择合适的承包者。</p>
<p><strong>发起者：</strong>国防部、国家安全局</p>
<h4 id="主要内容-1"><a href="#主要内容-1" class="headerlink" title="主要内容"></a>主要内容</h4><h5 id="能力方面"><a href="#能力方面" class="headerlink" title="能力方面"></a>能力方面</h5><h6 id="能力级别"><a href="#能力级别" class="headerlink" title="能力级别"></a>能力级别</h6><p><strong>能力级别1：非正式执行</strong></p>
<p><strong>公共特征</strong></p>
<p>执行基本实施</p>
<p><strong>能力级别2：计划与跟踪</strong></p>
<p><strong>公共特征</strong></p>
<p>计划执行</p>
<p>规范化执行</p>
<p>验证执行</p>
<p>跟踪执行</p>
<p><strong>能力级别3：充分定义</strong></p>
<p><strong>公共特征</strong></p>
<p>定义标准过程</p>
<p>执行已定义的过程</p>
<p>协调安全实施</p>
<p><strong>能力级别4：定量控制</strong></p>
<p><strong>公共特征</strong></p>
<p>建立可测的质量目标</p>
<p>客观地管理过程的执行</p>
<p><strong>能力级别５：连续改进</strong></p>
<p><strong>公共特征</strong></p>
<p>改进组织能力</p>
<p>改进过程的有效性</p>
<h5 id="域方面"><a href="#域方面" class="headerlink" title="域方面"></a>域方面</h5><p>工程和安全实施是安全工程过程中必须存在的性质，指出特殊过程区的目的并属于该过程区</p>
<p> 每个过程区（PA）是一组相关安全工程过程的性质，当这些性质全部实施后则能够达到过程区定义的目的。</p>
<p><strong>一组过程区指出活动的同一通用区</strong> </p>
<p><img src="/2019/06/14/%E8%BD%AF%E4%BB%B6%E5%AE%89%E5%85%A8%E8%AE%BE%E8%AE%A1/1.png" alt></p>
<h4 id="关于安全工程与评估"><a href="#关于安全工程与评估" class="headerlink" title="关于安全工程与评估"></a>关于安全工程与评估</h4><p><strong>安全工程分三个基本过程：风险、工程和保证</strong></p>
<p><strong>风险(风险信息)</strong></p>
<p><strong>风险过程是要<font color="red">确定</font>产品或者系统的危险性，并对这些危险性进行优先级排序</strong></p>
<p><strong>工程(解决方案)</strong></p>
<p><strong>工程过程是<font color="red">针对</font>面临的危险性，安全工程过程与相关工程过程一起来确定并实施解决方案</strong></p>
<p><strong>保证(保证论据)</strong></p>
<p><strong>保证过程是建立起对解决方案的<font color="red">信任</font>，并把这种信任传达给顾客</strong></p>
<h4 id="SSAM-SSE-CMM评定方法"><a href="#SSAM-SSE-CMM评定方法" class="headerlink" title="SSAM(SSE-CMM评定方法)"></a>SSAM(SSE-CMM评定方法)</h4><p>SSAM 为了进行评定，收集数据广泛、严格，每个数据有充分的证据。此方法在评定过程中最大程度地发挥了SSE-CMM模型的功效。</p>
<p>此方法：</p>
<ul>
<li>决定实施安全工程过程的能力</li>
<li>为了评定定义了安全工程环境</li>
<li>在评定时巧妙地使用了SSE-CMM体系结构中的两个方面。</li>
</ul>
<h3 id="SDL-安全开发生命周期模型"><a href="#SDL-安全开发生命周期模型" class="headerlink" title="SDL-安全开发生命周期模型"></a>SDL-安全开发生命周期模型</h3><p>Secure Development Lifecycle</p>
<p>微软可信计算(TrustWorthy Computing )努力的一个组成部分</p>
<ul>
<li>基于并行理念的标准软件开发过程</li>
<li>基于威胁建模和测试</li>
</ul>
<h4 id="SDL概览"><a href="#SDL概览" class="headerlink" title="SDL概览"></a>SDL概览</h4><p>SDL从三个方面考虑软件安全的保障。</p>
<h5 id="设计安全"><a href="#设计安全" class="headerlink" title="设计安全"></a>设计安全</h5><ul>
<li>为了保护软件自身以及软件处理的信息,并抵御攻击,软件应该从架构,设计和实现上进行考虑</li>
</ul>
<h5 id="缺省安全"><a href="#缺省安全" class="headerlink" title="缺省安全"></a>缺省安全</h5><ul>
<li><p>设计者应该假定安全缺陷将会出现。</p>
</li>
<li><p>为了当攻击者对软件存在的缺陷进行攻击时使损害降到最小, 软件的缺省状态应该保证安全。</p>
<p>比如 最小特权原则。</p>
</li>
</ul>
<h5 id="提交安全"><a href="#提交安全" class="headerlink" title="提交安全"></a>提交安全</h5><ul>
<li><p>工具和指南应该随着软件提供以帮助最终用户或管理员安全使用。</p>
</li>
<li><p>关于软件的更新应该容易提交。</p>
</li>
</ul>
<h4 id="SDL过程"><a href="#SDL过程" class="headerlink" title="SDL过程"></a>SDL过程</h4><p><strong>0：教育和意识</strong></p>
<p><strong>安全教育的内容</strong></p>
<p>安全设计基础：受攻击面分析、深度防御、最小特权、安全默认配置</p>
<p>威胁建模：设计威胁建模、编码威胁建模、测试威胁建模</p>
<p><strong>1：项目启动</strong></p>
<p>判断SDL是否覆盖应用、任命安全顾问、组建安全领导团队、确保在BUG追踪管理过程中包含安全、隐私类BUG、建立BUG标准</p>
<p><strong>2：定义并遵从设计最佳实践</strong></p>
<p><strong>常见安全设计原则</strong></p>
<p>经济机制、默认失效保护、安全中介、公开设计、权限分离、最小特权、最少公共机制、心里可接受程度</p>
<p><strong>受攻击面分析与降低</strong></p>
<p><strong>分析</strong></p>
<p>枚举所有接口、协议以及可执行代码的过程。</p>
<p><strong>软件的受攻击面</strong></p>
<p>代码、接口、服务、协议、其他</p>
<p><strong>降低</strong></p>
<p>核心观点：在所有代码中存在至少一个或多个漏洞的可能性一定不为零，一部分严重漏洞会导致用户不得不接受妥协。唯一解决上述问题的方法是将代码的利用率降至为零。</p>
<p><strong>受攻击面降低的方法：</strong></p>
<ul>
<li><p>降低默认执行的代码量</p>
</li>
<li><p>限制可访问到代码的人员范围</p>
</li>
<li><p>限定可访问到代码的人员身份</p>
</li>
<li><p>降低代码所需权限。</p>
</li>
</ul>
<p><strong>3：产品风险评估</strong></p>
<p><strong>安全风险评估</strong>、<strong>隐私影响分级</strong>、<strong>统一各种因素</strong></p>
<p><strong>4：风险分析</strong>/<strong>威胁建模</strong></p>
<p><strong>益处</strong></p>
<p>有助于整个风险管理过程</p>
<p>在系统进入编码阶段前发现系统威胁</p>
<p>开发团队通过威胁建模可以重新验证其架构与设计</p>
<p>有助于进一步明确针对应用以及环境采取相应的解决对策</p>
<p>有助于指导整个代码审核过程</p>
<p>指导整个渗透测试过程</p>
<p><strong>威胁建模过程</strong></p>
<ol>
<li><p>定义应用场景</p>
</li>
<li><p>收集外部依赖列表</p>
</li>
<li><p>定义安全假设</p>
</li>
<li><p>创建外部安全备注</p>
</li>
<li><p>绘制待建模应用的一个或多个数据流图</p>
</li>
<li><p>确定威胁类型</p>
</li>
<li><p>识别系统威胁</p>
</li>
<li><p>判断风险</p>
</li>
<li><p>规划消减措施</p>
</li>
</ol>
<p><strong>5：创建安全文档、工具以及客户最佳实践</strong></p>
<p><strong>6：安全编码策略</strong></p>
<p><strong>7：安全测试策略</strong></p>
<p>安全测试内容：模糊测试、渗透测试、运行时测试、重审威胁模型、重估受攻击模型</p>
<p><strong>8：安全推进过程</strong></p>
<p><strong>9：最终安全评审</strong></p>
<p><strong>10：安全响应规划</strong></p>
<p>使用SDL不能保证生产绝对安全的软件：</p>
<ul>
<li><p>开发团队一定会出错</p>
</li>
<li><p>新漏洞一定会变化</p>
</li>
<li><p>规则一定会变化</p>
</li>
</ul>
<p><strong>11：产品发布</strong></p>
<p><strong>12：遵从计划、尽可能补救、理解取舍之道</strong></p>
<h2 id="CH04软件安全测试"><a href="#CH04软件安全测试" class="headerlink" title="CH04软件安全测试"></a>CH04软件安全测试</h2><h3 id="软件安全测试"><a href="#软件安全测试" class="headerlink" title="软件安全测试"></a>软件安全测试</h3><p>安全性测试是指有关<strong>验证应用程序的安全等级和识别潜在安全性缺陷</strong>的过程。</p>
<p>应用程序级<strong>安全测试</strong>的主要目的是查找软件自身程序设计中存在的安全隐患，并检查应用程序对非法侵入的防范能力。</p>
<p>安全指标不同测试策略也不同。</p>
<h4 id="安全测试的法律问题"><a href="#安全测试的法律问题" class="headerlink" title="安全测试的法律问题"></a>安全测试的法律问题</h4><p>安全测试必须得到授权<br>安全测试工具的应用必须得到授权<br>穿透测试实验必须得到授权<br>在未得到明确授权的情况下，不允许针对第三方系统进行穿透测试的实验</p>
<h4 id="软件安全测试的方法"><a href="#软件安全测试的方法" class="headerlink" title="软件安全测试的方法"></a>软件安全测试的方法</h4><ul>
<li><strong>静态测试</strong></li>
</ul>
<p>主要通过对源代码进行安全扫描，根据程序中数据流、控制流、语义等信息与其特有软件安全规则库进行匹对，从中找出代码中潜在的安 全漏洞。</p>
<p>静态的源代码安全测试是非常有用的方法，可以在编码阶段找出所有可能存在安全风险的代码，这样开发人员可以在早期解决潜在的安全问题。</p>
<p>静态代码测试比较适用于早期的代码开发阶段，而不是测试阶段。</p>
<ul>
<li><strong>动态的测试</strong></li>
</ul>
<p>动态测试也称渗透测试，penetrate</p>
<p>渗透测试是常用的安全测试方法。是使用自动化工具或者人工的方法模拟黑客的输入，对应用系统进行攻击性测试，从中找出运行时刻所存在的安全漏洞。</p>
<p>渗透测试的特点就是真实有效，一般找出来的问题都是正确的，也是较为严重的。</p>
<p>渗透测试的缺点是模拟的测试数据只能到达有限的测试点，覆盖率很低。</p>
<ul>
<li><strong>程序数据扫描</strong></li>
</ul>
<p>一个有高安全性需求的软件， 在运行过程中数据是不能遭到破坏的，否则就会导致缓冲区溢出类型的攻击。</p>
<p>数据扫描的手段通常是进行内存测试，内存测试可以发现许多诸如缓冲区溢出之类的漏洞，而这类漏洞使用除此之外的测试手段都难以发现。</p>
<p>例如，利用专门的工具对软件运行时的内存信息进行扫描，检查是否存在导致隐患的信息。</p>
<h4 id="安全测试点"><a href="#安全测试点" class="headerlink" title="安全测试点"></a>安全测试点</h4><ul>
<li><p>程序安全性测试</p>
</li>
<li><p>数据安全性测试</p>
</li>
</ul>
<h4 id="典型问题"><a href="#典型问题" class="headerlink" title="典型问题"></a>典型问题</h4><h5 id="程序安全性测试典型问题参考"><a href="#程序安全性测试典型问题参考" class="headerlink" title="程序安全性测试典型问题参考"></a><strong>程序安全性测试典型问题参考</strong></h5><p>① 明确区分系统中不同用户权限;</p>
<p>② 系统中会不会出现用户冲突;</p>
<p>③ 系统会不会因用户的权限的改变造成混乱;</p>
<p>④ 用户登陆密码是否是可见、可复制;</p>
<p>⑤ 是否可以通过绝对途径登陆系统(拷贝用户登陆后的链接直接进入系统);</p>
<p>⑥ 用户推出系统后是否删除了所有鉴权标记，是否可以使用后退键而不通过输入口令进入系统。</p>
<h5 id="网络安全测试典型问题参考"><a href="#网络安全测试典型问题参考" class="headerlink" title="网络安全测试典型问题参考"></a><strong>网络安全测试典型问题参考</strong></h5><p>① 测试采取的防护措施是否正确装配好，有关系统的补丁是否打上;</p>
<p>② 模拟非授权攻击，看防护系统是否坚固;</p>
<p>③ 采用成熟的网络漏洞检查工具检查系统相关漏洞;</p>
<p>④ 采用各种木马检查工具检查系统木马情况;</p>
<p>⑤ 采用各种防外挂工具检查系统各组程序的客外挂漏洞。</p>
<h5 id="数据安全测试考虑问题参考："><a href="#数据安全测试考虑问题参考：" class="headerlink" title="数据安全测试考虑问题参考："></a><strong>数据安全测试考虑问题参考：</strong></h5><p>① 系统数据是否机密(比如对银行系统，这一点就特别重要，一般的网站就没有太高要求);</p>
<p>② 系统数据的完整性;</p>
<p>③ 系统数据可管理性;</p>
<p>④ 系统数据的独立性;</p>
<p>⑤ 系统数据可备份和恢复能力(数据备份是否完整，可否恢复，恢复是否可以完整)。</p>
<h3 id="安全漏洞分级"><a href="#安全漏洞分级" class="headerlink" title="安全漏洞分级"></a>安全漏洞分级</h3><h4 id="DREAD模型"><a href="#DREAD模型" class="headerlink" title="DREAD模型"></a>DREAD模型</h4><p><strong>DREAD模型</strong>：进行威胁程度级别分析的有效技术。</p>
<ul>
<li><p><strong>潜在的破坏（Damage potential）</strong></p>
<ul>
<li>如果该漏洞被利用，所产生的破坏程度</li>
</ul>
</li>
<li><p><strong>再现性（Reproducibility）</strong></p>
<ul>
<li>探测并利用该漏洞所需要的努力要多久</li>
</ul>
</li>
<li><p><strong>可利用性（Exploitability）</strong></p>
<ul>
<li>是否需要身份鉴别？</li>
</ul>
</li>
<li><p><strong>受影响用户（Affected users）</strong></p>
<ul>
<li>漏洞利用的影响面有多大</li>
</ul>
</li>
<li><p><strong>可发现性（Discoverability）</strong></p>
<ul>
<li>漏洞研究人员或黑客找出该漏洞的可能性</li>
</ul>
</li>
</ul>
<h4 id="TRAP模型"><a href="#TRAP模型" class="headerlink" title="TRAP模型"></a>TRAP模型</h4><p>基于可利用性提出。</p>
<p><strong>因素：</strong></p>
<p>时间（Time）</p>
<p>可靠性（Reliability）/再现性（Reproducibility）</p>
<p>访问（Access）</p>
<p>定位（Positioning）</p>
<h3 id="安全的常规测试方法"><a href="#安全的常规测试方法" class="headerlink" title="安全的常规测试方法"></a>安全的常规测试方法</h3><h4 id="基于风险的安全测试"><a href="#基于风险的安全测试" class="headerlink" title="基于风险的安全测试"></a>基于风险的安全测试</h4><p><strong>安全测试的目标</strong></p>
<p>在给定的时间和资源不变的情况下，尽可能多地找出最为严重的安全缺陷。</p>
<p><strong>威胁建模=风险建模</strong></p>
<p>基于风险的测试是软件测试的常规方法</p>
<h5 id="基于风险的测试的三个步骤"><a href="#基于风险的测试的三个步骤" class="headerlink" title="基于风险的测试的三个步骤"></a>基于风险的测试的三个步骤</h5><ol>
<li><p><strong>信息搜集</strong></p>
<p><strong>信息搜集的目的：</strong>熟悉程序的设计、了解程序访问入口点位置、了解程序所涉及的信息资产－需要保护的信息</p>
<p><strong>信息搜集的方法：</strong>程序设计文档的评审、与设计人员和架构师会谈、运行时分析－使用调试和诊断程序</p>
</li>
<li><p><strong>威胁（风险）建模</strong></p>
<p><strong>威胁建模的目的：</strong>排定测试优先级，找出测试区域，发现系统弱点</p>
<p><strong>威胁建模步骤：</strong></p>
<ol>
<li><p><strong>识别威胁路径</strong>：</p>
<p><strong>目的：</strong>识别应用程序级别最高的风险领域，确定相应的保护措施</p>
<p><strong>步骤：</strong></p>
<p>①了解应用程序平台和编程语言的整体强度</p>
<p>②确定用户的访问类别</p>
<p>③建立并分析数据流图</p>
</li>
<li><p><strong>识别威胁：</strong></p>
<p><strong>目的：</strong>深入识别沿威胁路径的处理，逐一理清与处理相关的每一种威胁。</p>
<p><strong>针对威胁路径的每一个处理组件的问题列表：</strong></p>
<p>–该组件执行什么样的处理</p>
<p>–该组件如何确定身份</p>
<p>–该组件信任数据或者其他组件吗</p>
<p>–该组件修改了什么数据</p>
<p>–该组件有何外部连接</p>
<p><strong>在一个威胁路径上的9个高风险活动：</strong></p>
<p>①数据解析 ②文件访问 ③数据库访问 ④生成子进程 ⑤身份鉴别    ⑥授权 ⑦同步或会话管理 ⑧处理私密数据 ⑨网络访问</p>
</li>
<li><p><strong>识别漏洞</strong></p>
<p><strong>目的：</strong>找出可能存在于组件中的实际漏洞。</p>
<p><strong>缓解措施：</strong></p>
<p>–数据验证测试</p>
<p>–资源监视</p>
<p>–关键功能的访问控制</p>
<p><strong>搜寻漏洞的方法及途径：</strong></p>
<p>–安全设计审查</p>
<p>–安全代码审查</p>
<p>–安全测试</p>
</li>
<li><p><strong>风险分级/排定优先级</strong></p>
</li>
</ol>
</li>
<li><p><strong>可用性分析</strong></p>
<p><strong>判定可利用性的目的：</strong>判断漏洞是否可被攻击者利用。</p>
<p><strong>原则：</strong>在开发中直接修补一个可能会被利用的问题比花时间判定其是否会被利用容易</p>
</li>
</ol>
<h4 id="白盒、黑盒和灰盒测试"><a href="#白盒、黑盒和灰盒测试" class="headerlink" title="白盒、黑盒和灰盒测试"></a>白盒、黑盒和灰盒测试</h4><h5 id="白盒测试"><a href="#白盒测试" class="headerlink" title="白盒测试"></a>白盒测试</h5><p>也称明盒测试、开盒测试或信息充分测试。</p>
<p>白盒测试可以看作是内部的攻击。</p>
<p>测试人员可以访问源代码和设计文档，可以进行威胁建模或逐行的代码检查。</p>
<p>白盒测试是找出漏洞最为有效的方法。</p>
<h5 id="黑盒测试"><a href="#黑盒测试" class="headerlink" title="黑盒测试"></a>黑盒测试</h5><p> 以局外人的身份对系统进行攻击，使用工具检查系统的攻击面，并探查系统的内部信息。</p>
<p>黑盒测试是白盒测试的补充。</p>
<p>方向工程团队利用黑盒测试验证隐蔽式安全方法的强度。</p>
<h5 id="灰盒测试"><a href="#灰盒测试" class="headerlink" title="灰盒测试"></a>灰盒测试</h5><p>组合使用白盒测和黑盒测试。</p>
<p>–白盒测试用于发现在设计和开发中详细说明的功能中的缺陷；</p>
<p>–黑盒测试在无法了解程序内部信息的时候找出缺陷。</p>
<p>程序开发中的调试运行是典型的灰盒测试方法。</p>
<h4 id="典型安全测试工具"><a href="#典型安全测试工具" class="headerlink" title="典型安全测试工具"></a>典型安全测试工具</h4><p><strong>JAVA代码安全分析工具：</strong></p>
<p>–IBM AppScan Source Edition</p>
<p>–Fotify  Static Code Analyzer</p>
<p>–Findbugs</p>
<p><strong>C++代码安全分析工具：</strong></p>
<p>–C++Test</p>
<p>–IBM AppScan Source Edition</p>
<p>–Fotify  Static Code Analyzer</p>
<p>Visual Studio（27.78%）</p>
<p><strong>JavaScript代码安全工具：</strong></p>
<p>–Google’s Closure Compiler</p>
<p>–JSHint</p>
<p><strong>Python代码安全工具：</strong></p>
<p>–Pychecker</p>
<p>–PyCharm</p>
<p>–Pylint</p>
<p>–PySEC，开源</p>
<p><strong>WEB应用安全测试工具：</strong></p>
<p>IBM AppScan</p>
<p>SoapUI</p>
<p>HP的WebInspect</p>
<p><strong>WEB应用的开源工具：</strong></p>
<p>Firebug</p>
<p>OWASP ZAP</p>
<p><strong>Android App安全测试工具：</strong></p>
<p>Android Tamer</p>
<p>AndroBugs</p>
<p>Mobisec</p>
<p><strong>SQL注入测试工具：</strong></p>
<p>SQLInjetor</p>
<p>SQL Power Injector</p>
<p>OWASP SQLiX</p>
<p><strong>网络状态监控与分析工具：</strong></p>
<p>Wireshark</p>
<h2 id="CH05编写安全的代码"><a href="#CH05编写安全的代码" class="headerlink" title="CH05编写安全的代码"></a>CH05编写安全的代码</h2><h3 id="SD3"><a href="#SD3" class="headerlink" title="SD3"></a>SD3</h3><h4 id="安全设计"><a href="#安全设计" class="headerlink" title="安全设计"></a>安全设计</h4><ul>
<li><p>安排具体的安全设计的人员；</p>
</li>
<li><p>进行安全教育；</p>
</li>
<li><p>确保威胁分析已经完成；</p>
</li>
<li><p>符合安全设计和编码的指导原则；</p>
</li>
<li><p>尽可能修补任何安全编程指南上的BUG;</p>
</li>
<li><p>确保安全指南是逐步改进的；</p>
</li>
<li><p>针对已经修复的缺陷开发回归测试；</p>
</li>
<li><p>简化代码和安全模型；</p>
</li>
<li><p>在打包以前完成穿透测试。</p>
</li>
</ul>
<h4 id="缺省安全-1"><a href="#缺省安全-1" class="headerlink" title="缺省安全"></a>缺省安全</h4><ul>
<li><p>缺省状态下，不要设置所有的特点和功能；</p>
</li>
<li><p>允许最小权限；</p>
</li>
<li><p>恰当的资源保护。</p>
</li>
</ul>
<h4 id="安全提交"><a href="#安全提交" class="headerlink" title="安全提交"></a>安全提交</h4><ul>
<li><p>确认程序给管理员提供了安全功能；</p>
</li>
<li><p>尽可能提供高质量的补丁；</p>
</li>
<li><p>提供足够的信息以使用户安全的使用软件。</p>
</li>
</ul>
<h3 id="安全规则"><a href="#安全规则" class="headerlink" title="安全规则"></a>安全规则</h3><ul>
<li><p>学习错误；</p>
</li>
<li><p>最小化攻击面；</p>
</li>
<li><p>使用深度防御；</p>
</li>
<li><p>使用最小权限；</p>
</li>
<li><p>应用缺省安全；</p>
</li>
<li><p>记住兼容性的倒退是痛苦的；</p>
</li>
<li><p>假定外部系统是不安全的；</p>
</li>
<li><p>基于错误计划；</p>
</li>
<li><p>切记安全的特性不等于安全特性；</p>
</li>
<li><p>Never depend on security through obscurity( 朦胧，晦涩，不分明) alone</p>
</li>
<li><p>不要混合编码和数据；</p>
</li>
<li><p>正确修复安全问题。</p>
</li>
</ul>
<h4 id="学习错误"><a href="#学习错误" class="headerlink" title="学习错误"></a>学习错误</h4><p>学习错误从填写一个文档开始，文档内容：<br>产品名称；产品版本；联系人；BUG数据库编号；<br>脆弱性描述；脆弱性的隐含意义；<br>在产品的缺省安装中，这个问题是否存在？<br>设计，开发和测试人员能够做什么来防止这个缺陷？<br>修复的细节，包括代码的区别，如果可以填写。</p>
<h4 id="最小化攻击面"><a href="#最小化攻击面" class="headerlink" title="最小化攻击面"></a>最小化攻击面</h4><p>需要计算下面的内容：<br>（1）打开socket、命名管道、RPC端点的数量；<br>（2）服务的数量；缺省运行服务的数量；服务以提高权限运行的数量；<br>（3）ISAPI过滤器和应用的数量；动态WEB页面数量；加入管理员组帐号的数量；<br>（4）文件，目录和注册键值的数量，带有弱访问控制列表。</p>
<h2 id="CH06信息系统的安全建模莫分析"><a href="#CH06信息系统的安全建模莫分析" class="headerlink" title="CH06信息系统的安全建模莫分析"></a>CH06信息系统的安全建模莫分析</h2><h3 id="信息系统及其特征"><a href="#信息系统及其特征" class="headerlink" title="信息系统及其特征"></a>信息系统及其特征</h3><h4 id="MIS"><a href="#MIS" class="headerlink" title="MIS"></a>MIS</h4><p>MIS是借助于自动化数据处理手段进行管理的系统，由计算机硬件、软件（包括：系统软件、应用软件和管理学软件包）、数据库各种规程和人共同组成。</p>
<p>是由人、计算机等组成的能进行管理信息的收集、传递、加工的信息系统。</p>
<h5 id="主要特征"><a href="#主要特征" class="headerlink" title="主要特征"></a>主要特征</h5><ul>
<li><p>依赖于计算机的；</p>
</li>
<li><p>涉及了计算机的软件和硬件；</p>
</li>
<li><p>实现数据的采集、传递、加工、处理功能。</p>
</li>
</ul>
<h5 id="系统主要特性"><a href="#系统主要特性" class="headerlink" title="系统主要特性"></a>系统主要特性</h5><p>1 整体性—系统的各个部分一定以整体目标为目标，追求全局最优；</p>
<p>2 目的性—一个系统一定是具有明确目标的，并完成一定的功能；</p>
<p>3 层次性—一个系统可以分为若干层次和子系统；</p>
<p>4 边界性—每一个系统都能够明显地区别于其他系统，系统之间有明确的界限；</p>
<p>5 关联性—系统包括若干元素，元素之间存在一定的关联性；</p>
<p>6 环境性—系统处于一定的环境之中并受环境影响。</p>
<h5 id="信息系统的类型"><a href="#信息系统的类型" class="headerlink" title="信息系统的类型"></a>信息系统的类型</h5><p>宏观的国家经济信息系统；</p>
<p>面向基层的企事业管理信息系统；</p>
<p>事务型管理信息系统；</p>
<p>办公型管理信息系统；</p>
<p>专业型管理信息系统等；</p>
<p>既有典型的MRP，ERP，SCM等通用的信息系统，也有针对特定业务的系统。</p>
<p>许许多多以计算机为核心的，实现数据的采集、存储、操作的系统都属于信息系统的范畴。</p>
<h5 id="运行环境要素"><a href="#运行环境要素" class="headerlink" title="运行环境要素"></a>运行环境要素</h5><ol>
<li><p>物理世界；</p>
</li>
<li><p>管理者实体—拥有授权管理、变更、修复和使用系统的人或者其他系统，其中一些被授权人可能缺乏有效管理系统的能力或具有恶意的目的；</p>
</li>
<li><p>使用者—在使用界面接受来自系统的服务的实体；</p>
</li>
<li>提供者—在系统的使用界面提供服务的实体；</li>
<li>基础组织—对系统提供信息源、通信链接、能源、冷气等特定服务的实体；</li>
<li>入侵者—企图超越所拥有的权限并且变更服务或阻止服务，变更系统的功能或性能或者存取秘密信息的实体。</li>
</ol>
<h3 id="信息系统的安全问题"><a href="#信息系统的安全问题" class="headerlink" title="信息系统的安全问题"></a>信息系统的安全问题</h3><p><strong>ISO7498-2标准中所定义的五种安全服务类型：</strong></p>
<ul>
<li><p>身份鉴别（Authentication）</p>
</li>
<li><p>访问控制（Access Control）</p>
</li>
<li><p>数据保密（Data Confidentiality）</p>
</li>
<li><p>数据完整性（ Data integrity）</p>
</li>
<li><p>抗抵赖（Non-reputation）</p>
</li>
</ul>
<h3 id="安全模型"><a href="#安全模型" class="headerlink" title="安全模型"></a>安全模型</h3><p><strong>系统使用者：</strong></p>
<p>用户    系统管理员    信息主管(企业主管)</p>
<p><strong>系统划分：</strong></p>
<p>用户界面逻辑    业务逻辑    异常检测机</p>
<p><strong>系统安全实现的主要功能：</strong></p>
<p>访问控制    抗抵赖    数据保密    身份鉴别    </p>
<p>授权机制    日志审计    系统异常探测</p>
<h4 id="用户界面逻辑"><a href="#用户界面逻辑" class="headerlink" title="用户界面逻辑"></a>用户界面逻辑</h4><p>用户界面逻辑部分：数据访问、登录控制。</p>
<p>在系统启动时，用户首先登录系统，通过系统验证后才可以完成数据访问功能。</p>
<h5 id="登录控制"><a href="#登录控制" class="headerlink" title="登录控制"></a>登录控制</h5><p><strong>主要功能：</strong>口令验证，口令修改，口令数据的加密，登录时间记录</p>
<p><strong>设计考虑：</strong></p>
<ol>
<li>用户ID：从权限数据中提取出相应的用户名。采用用户编号的原因是回避重名，简化输入，同时用户号本身也可以增加一定的安全性。</li>
<li>用户修改口令，而不是系统管理员：系统管理员<strong>对用户授权</strong>，但是口令由用户在用户界面输入，并加密存储至后台数据库中，以避免系统管理员获取用户口令造成泄密</li>
<li>初始口令的安全：系统的第一次运行关键是初始口令的赋予，由信息主管（或其他高层）完成用户身份的确认，同时要求用户第一次登录时必须更改初始口令。</li>
<li>口令安全：口令长度限制；口令字符集限制；口令有效期限制。</li>
<li>用户封锁：所谓的用户封锁是当出现用户多次登录系统失败的情况时，系统将锁定用户的操作并提示，解锁过程必须由系统管理员完成。</li>
</ol>
<h4 id="业务逻辑"><a href="#业务逻辑" class="headerlink" title="业务逻辑"></a>业务逻辑</h4><p>在系统的业务逻辑部分主要包括<strong>数据服务、权限管理、日志审计</strong>三个部分。</p>
<h5 id="数据服务"><a href="#数据服务" class="headerlink" title="数据服务"></a>数据服务</h5><p>主要安全任务是完成特定数据的加密、解密，日志数据的存储，权限及用户信息的存储。</p>
<h5 id="权限管理"><a href="#权限管理" class="headerlink" title="权限管理"></a>权限管理</h5><p>完成用户的授权，包括两个部分：系统管理员和信息主管。信息主管负责系统启动和初始授权，系统管理员负责日常权限管理、日志审计、系统状态监控、异常监测、用户锁定处理。</p>
<h5 id="日志审计"><a href="#日志审计" class="headerlink" title="日志审计"></a>日志审计</h5><p>对用户的操作行为进行跟踪，提供根据时间、用户、系统的检索手段。是保证安全，提高安全可信性的重要手段。</p>
<h4 id="异常探测机"><a href="#异常探测机" class="headerlink" title="异常探测机"></a>异常探测机</h4><p>异常探测机实现的主要功能：</p>
<p>–是日志的分析；</p>
<p>–网络状态的安全监测；</p>
<p>–提供一定的日志文件保护机制。</p>
<p><strong>异常检测独立于业务逻辑的目的</strong></p>
<p>1独立的程序，便于进一步发展，有较大的发展空间；</p>
<p>2位于业务和用户进程之外，能够对其进行监控；</p>
<p>3不对信息系统运行发生干扰；</p>
<p>4使该探测器成为系统的可选件。</p>
<h5 id="异常行为探测"><a href="#异常行为探测" class="headerlink" title="异常行为探测"></a>异常行为探测</h5><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">区别内容</th>
<th style="text-align:center">异常探测机</th>
<th style="text-align:center">IDS</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">检测范围</td>
<td style="text-align:center">网络内部行为</td>
<td style="text-align:center">网络外部行为</td>
</tr>
<tr>
<td style="text-align:center">实现方式</td>
<td style="text-align:center">软件</td>
<td style="text-align:center">硬件</td>
</tr>
<tr>
<td style="text-align:center">与系统关系</td>
<td style="text-align:center">可以存取系统数据</td>
<td style="text-align:center">不能存取系统数据</td>
</tr>
<tr>
<td style="text-align:center">保护目标</td>
<td style="text-align:center">信息系统</td>
<td style="text-align:center">网路</td>
</tr>
</tbody>
</table>
</div>
<h5 id="异常行为"><a href="#异常行为" class="headerlink" title="异常行为"></a>异常行为</h5><p><strong>用户身份的攻击：</strong>非法用户针对用户ID进行攻击，试图猜测用户身份。</p>
<p><strong>口令攻击：</strong>在已知用户身份的情况下，猜测口令，进行口令攻击。</p>
<p><strong>服务器的异常访问：</strong>这里是指服务器计算机和WEB<br>SERER等专用服务程序。类似DOS攻击的方式在局域网内也是有可能发生的。</p>
<p><strong>数据库异常连接：</strong>对数据库的访问主要是通过特定端口进行的，可能的威胁来自合法的客户端程序或者非法的客户端程序。</p>
<p><strong>数据库文件变动异常：</strong>系统中数据库文件的变动包括文件访问、拷贝、删除等操作。</p>
<p><strong>日志文件攻击：</strong>针对日志文件发起的包括文件删除、修改等非法操作。</p>
<h5 id="日志分析"><a href="#日志分析" class="headerlink" title="日志分析"></a>日志分析</h5><p><strong>针对日志文件自身的攻击主要有：</strong></p>
<ul>
<li>日志数据的删除<ul>
<li>系统本身不向用户提供日志数据的删除功能。</li>
<li>针对非法用户的攻击，如果是单独的日志文件，当系统启动后，该文件置于异常探测机的保护之下</li>
<li>如果是数据库数据，则依赖于操作系统和数据库本身的保护机制。</li>
<li>无论是系统操作员还是系统管理员的合法用户不具有日志文件删除的能力，而来自于客户端和服务器端的非法用户受到异常探测机、操作系统、数据库系统的安全机制约束。</li>
</ul>
</li>
<li>日志数据的修改<ul>
<li>系统不向用户提供日志修改功能。日志浏览也作为重要功能进行授权。</li>
<li>由于单独的日志文件置于了异常探测机的保护之下，所以可以避免合法用户的修改。非法用户试图对记录于数据库中的日志数据进行修改时，则受到操作系统和数据库系统的约束。</li>
</ul>
</li>
</ul>
<h6 id="日志数据审计和异常模式"><a href="#日志数据审计和异常模式" class="headerlink" title="日志数据审计和异常模式"></a><strong>日志数据审计和异常模式</strong></h6><ol>
<li>手动审计</li>
<li>自动审计和报警</li>
</ol>
<h5 id="网络异常探测机"><a href="#网络异常探测机" class="headerlink" title="网络异常探测机"></a>网络异常探测机</h5><p>网络异常探测机的主要功能是针对来自网络的信息进行分析，提供对信息系统的保护报警。</p>
<p>探测器并不是通用的系统异常探测器。</p>
<p><strong>功能</strong>：数据流量检测、服务端口连接数量检测、文件访问限制、日志文件保护</p>
<h2 id="CH07WEB应用安全"><a href="#CH07WEB应用安全" class="headerlink" title="CH07WEB应用安全"></a>CH07WEB应用安全</h2><h3 id="WEB应用"><a href="#WEB应用" class="headerlink" title="WEB应用"></a>WEB应用</h3><h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><ul>
<li>采用HTTP协议完成通信的应用程序</li>
<li><p>与后台WEB Server实现交互的程序</p>
</li>
<li><p>与互联网（Internet）服务器，包括Web Server，database server进行交互的程序</p>
</li>
<li><p>位于中间层，进行数据交互或者其他服务程序</p>
</li>
</ul>
<h4 id="安全现状"><a href="#安全现状" class="headerlink" title="安全现状"></a>安全现状</h4><ul>
<li><p>实现WEB应用安全非常困难</p>
<ul>
<li>WEB应用环境包括多个系统</li>
<li>WEB应用大部分运行于INTERNET，具有更广的攻击面</li>
</ul>
</li>
<li><p>在WEB应用的运行中，具有更多的临时决策，以支持系统的运行，系统状态具有更多的可变性</p>
</li>
<li><p>许多支持系统没有得到恰当的保护</p>
</li>
</ul>
<h4 id="微软WEB应用安全框架"><a href="#微软WEB应用安全框架" class="headerlink" title="微软WEB应用安全框架"></a>微软WEB应用安全框架</h4><h5 id="WEB应用安全建模"><a href="#WEB应用安全建模" class="headerlink" title="WEB应用安全建模"></a>WEB应用安全建模</h5><p><strong>活动：</strong>Web 应用程序的威胁建模</p>
<p><strong>目的：</strong>确定方案中的相关威胁和漏洞，以帮助您构建应用程序的安全设计。</p>
<p><strong>输入：</strong> </p>
<p>•主要用例和使用方案<br>•数据流<br>•数据架构<br>•部署关系图 </p>
<p><strong>输出：</strong> </p>
<p>•威胁列表<br>•漏洞列表 </p>
<p><strong>五个步骤：</strong></p>
<p><strong>步骤</strong> <strong>1</strong> <strong>：确定安全目标。</strong>目标清晰有助于将注意力集中在威胁建模活动上，以及确定后续步骤要做多少工作。<br><strong>步骤</strong> <strong>2</strong> <strong>：创建应用程序概述。</strong>逐条列出应用程序的重要特征和参与者有助于在步骤 4 中确定相关威胁。<br><strong>步骤</strong> <strong>3</strong> <strong>：分解应用程序。</strong>全面了解应用程序的结构可以更轻松地发现更相关、更具体的威胁。<br><strong>步骤</strong> <strong>4</strong> <strong>：确定威胁。</strong>使用步骤 2 和 3 中的详细信息来确定与应用程序方案和上下文相关的威胁。<br><strong>步骤</strong> <strong>5</strong> <strong>：确定漏洞。</strong>检查应用程序的各层以确定与威胁有关的弱点。使用漏洞类别来帮助关注最常出现错误的区域。 </p>
<h5 id="WEB应用安全框架"><a href="#WEB应用安全框架" class="headerlink" title="WEB应用安全框架"></a>WEB应用安全框架</h5><p>输入和数据验证<br>身份验证<br>授权<br>配置管理<br>敏感数据<br>会话管理<br>加密<br>参数操作<br>异常管理<br>审核与记录</p>
<h5 id="一个WEB应用安全模型"><a href="#一个WEB应用安全模型" class="headerlink" title="一个WEB应用安全模型"></a>一个WEB应用安全模型</h5><p>威胁建模：一种用于理解和消除系统安全威胁的形式化的方法</p>
<p><strong>方法：</strong></p>
<p><strong>信息收集</strong></p>
<p>•定位文档（Locate written document）<br>•访问相关人员（Interview stakeholders）<br>•探查系统（Inspect system）</p>
<p><strong>分析</strong></p>
<p>•用户Users<br>•构件，资产，动机 Components, assets, and motivation<br>•入口 Entry points<br>•弱点和威胁 Weaknesses and threats</p>
<p><strong>威胁消除</strong></p>
<p>•建立预算 Establish your budget.<br>•排序处理 Rank treats using a model that works for you.<br>•确立针对威胁的工作 Decide what to do with threats.</p>
<p><strong>消除选择：</strong></p>
<p>•忽略 Ignore risk. (<strong>Popular choice!</strong>)<br>•消除 Mitigate risk：入侵代价昂贵、安全代价昂贵、能够承受？<br>•接受 Accept risk.</p>
<p><strong>消除策略：</strong></p>
<p>•移除入口点.<br>•减少攻击面.<br>•区分.<br>•最小优先权原则</p>
<p><strong>消除技巧：</strong></p>
<p>•不要过度宽泛以避免不能自拔。建立子模型分支以处理复杂性。<br>•多数WEB APP具有共性-开发可重用的威胁模型库。<br>•由一个草稿开始（scratch），并且不要做任何假定。消除多数明显的（foolproof）威胁将导致简单的操作过程.</p>
<h2 id="CH08安全工程过程模型"><a href="#CH08安全工程过程模型" class="headerlink" title="CH08安全工程过程模型"></a>CH08安全工程过程模型</h2><h3 id="核心工作"><a href="#核心工作" class="headerlink" title="核心工作"></a>核心工作</h3><p>①安全目标定义<br>②敏感数据分析<br>③威胁分析<br>④安全设计<br>⑤受攻击面分析<br>⑥安全实现<br>⑦安全测试<br>⑧安全维护</p>
<h3 id="过程模型"><a href="#过程模型" class="headerlink" title="过程模型"></a>过程模型</h3><p><img src="/2019/06/14/%E8%BD%AF%E4%BB%B6%E5%AE%89%E5%85%A8%E8%AE%BE%E8%AE%A1/2.png" alt></p>
<h3 id="过程实施要点"><a href="#过程实施要点" class="headerlink" title="过程实施要点"></a>过程实施要点</h3><h4 id="安全实施能力培养"><a href="#安全实施能力培养" class="headerlink" title="安全实施能力培养"></a>安全实施能力培养</h4><p>团队安全能力范畴：<br>①软件安全的概念与意识；<br>②典型安全问题；<br>③开发语言的安全问题与工具；<br>④安全设计方法；<br>⑤数据及其敏感性；<br>⑥攻击面；<br>⑦威胁建模与分析；<br>⑧信息安全法律与政策；</p>
<h4 id="安全目标定义"><a href="#安全目标定义" class="headerlink" title="安全目标定义"></a>安全目标定义</h4><p>确定本项目需要达到的安全目标。形成规范的文档，作为工程过程中的指导原则。<br>安全目标定义应包括的内容：</p>
<p>①软件名称；<br>②软件开发目标及主要功能概述；<br>③软件主要用户及其分析；<br>④软件的关键信息与数据；<br>⑤软件各个部分及其总体需要达到的安全水平。</p>
<h4 id="资源及敏感数据分析"><a href="#资源及敏感数据分析" class="headerlink" title="资源及敏感数据分析"></a>资源及敏感数据分析</h4><p>确定本项目实施中所涉及的敏感数据，进行分类，给出明确的定义和敏感程度，以及保护措施。<br>软件操作的资源：网络端口，文件，服务器，URL，数据库…<br>软件操作的主要数据：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">数据名</th>
<th style="text-align:center">类型</th>
<th style="text-align:center">作用</th>
<th style="text-align:center">敏感程度</th>
<th style="text-align:center">安全要求</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
</div>
<h4 id="威胁分析"><a href="#威胁分析" class="headerlink" title="威胁分析"></a>威胁分析</h4><p>分析系统用户，部署，功能，确定系统威胁来源。<br>明确：系统关键工程，部署，各个部分及功能用户</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">威胁名称</th>
<th style="text-align:center">威胁来源</th>
<th style="text-align:center">说明</th>
<th style="text-align:center">重要程度</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
</div>
<h4 id="安全设计-1"><a href="#安全设计-1" class="headerlink" title="安全设计"></a>安全设计</h4><p>根据安全目标，敏感数据，威胁分析的内容，实现安全设计。包括架构，安全问题的应对措施等。<br>需明确：<br>①系统架构与安全性问题<br>②安全问题及其应对措施<br>③架构与安全目标的响应<br>④敏感数据的保护措施<br>⑤威胁的应对措施</p>
<h4 id="受攻击面分析"><a href="#受攻击面分析" class="headerlink" title="受攻击面分析"></a>受攻击面分析</h4><p>与安全设计对应，根据设计的架构，以及敏感信息，对受攻击面及攻击路径进行分析。<br>典型的受攻击面包括：端口，数据，文件…</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">攻击面</th>
<th style="text-align:center">类别</th>
<th style="text-align:center">威胁来源</th>
<th style="text-align:center">重要程度</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
</div>
<h4 id="安全实现"><a href="#安全实现" class="headerlink" title="安全实现"></a>安全实现</h4><h4 id="安全测试"><a href="#安全测试" class="headerlink" title="安全测试"></a>安全测试</h4><h4 id="安全维护"><a href="#安全维护" class="headerlink" title="安全维护"></a>安全维护</h4>]]></content>
      <categories>
        <category>大二</category>
      </categories>
      <tags>
        <tag>软件安全</tag>
      </tags>
  </entry>
  <entry>
    <title>DL面试知识点</title>
    <url>/2020/10/19/DL%E9%9D%A2%E8%AF%95%E7%9F%A5%E8%AF%86%E7%82%B9/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>【<strong>本文转载自<a href="https://github.com/amusi/Deep-Learning-Interview-Book">Github</a>,对其知识点进行补充</strong>】</p>
<h1 id="深度学习"><a href="#深度学习" class="headerlink" title="深度学习"></a>深度学习</h1><h2 id="神经网络中的Epoch、Iteration、Batchsize"><a href="#神经网络中的Epoch、Iteration、Batchsize" class="headerlink" title="神经网络中的Epoch、Iteration、Batchsize"></a>神经网络中的Epoch、Iteration、Batchsize</h2><p>神经网络中epoch与iteration是不相等的</p>
<ul>
<li><p>batchsize：中文翻译为批大小（批尺寸）。在深度学习中，一般采用SGD训练，即每次训练在训练集中取batchsize个样本训练；</p>
</li>
<li><p>iteration：中文翻译为迭代，1个iteration等于使用batchsize个样本训练一次；一个迭代 = 一个正向通过+一个反向通过</p>
</li>
<li><p>epoch：迭代次数，1个epoch等于使用训练集中的全部样本训练一次；一个epoch = 所有训练样本的一个正向传递和一个反向传递</p>
</li>
</ul>
<p>举个例子，训练集有1000个样本，batchsize=10，那么：训练完整个样本集需要：100次iteration，1次epoch。</p>
<p><img src="https://gss0.baidu.com/-vo3dSag_xI4khGko9WTAnF6hhy/zhidao/wh%3D600%2C800/sign=36204981f1039245a1e0e909b7a488fa/e61190ef76c6a7ef3bf5176af0faaf51f2de66af.jpg" alt="img"></p>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/67414365">神经网络中的Epoch、Iteration、Batchsize</a></li>
<li><a href="https://zhidao.baidu.com/question/716300338908227765.html">神经网络中epoch与iteration相等吗</a></li>
</ul>
<h2 id="反向传播（BP）"><a href="#反向传播（BP）" class="headerlink" title="反向传播（BP）"></a>反向传播（BP）</h2><p><img src="https://gitee.com/browallia/tuchuang/raw/master/img/20201019155522.png" alt></p>
<p><img src="https://gitee.com/browallia/tuchuang/raw/master/img/20201019155550.png" alt></p>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://www.jianshu.com/p/964345dddb70">一文搞懂反向传播算法</a></li>
<li><a href="https://www.browallia.top/2018/10/13/%E7%94%A8numpy%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E7%9A%84%E4%B8%89%E5%B1%82bp%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">numpy实现简单的BP神经网络</a></li>
</ul>
<h2 id="CNN本质和优势"><a href="#CNN本质和优势" class="headerlink" title="CNN本质和优势"></a>CNN本质和优势</h2><p>局部卷积（提取局部特征）</p>
<p>权值共享（降低训练难度）</p>
<p>Pooling（降维，将低层次组合为高层次的特征，保留主要特征，减少下一层的参数和计算量，防止过拟合）</p>
<p>多层次结构</p>
<h2 id="鞍点的定义和特点？"><a href="#鞍点的定义和特点？" class="headerlink" title="鞍点的定义和特点？"></a>鞍点的定义和特点？</h2><h2 id="鞍点的定义"><a href="#鞍点的定义" class="headerlink" title="鞍点的定义"></a>鞍点的定义</h2><p> 一个不是局部最小值的<strong>驻点（一阶导数为0的点）</strong>称为鞍点。数学含义是： 目标函数在此点上的梯度（一阶导数）值为 0， <strong>但从改点出发的一个方向是函数的极大值点，而在另一个方向是函数的极小值点。</strong></p>
<p><a href="https://blog.csdn.net/lanchunhui/article/details/52504859">极值点、驻点、鞍点、拐点</a></p>
<h2 id="神经网络数据预处理方法有哪些？"><a href="#神经网络数据预处理方法有哪些？" class="headerlink" title="神经网络数据预处理方法有哪些？"></a>神经网络数据预处理方法有哪些？</h2><p><a href="https://www.browallia.top/2019/10/21/CS231n-note-3/">1.3数据预处理</a></p>
<h2 id="神经网络怎样进行参数初始化？"><a href="#神经网络怎样进行参数初始化？" class="headerlink" title="神经网络怎样进行参数初始化？"></a>神经网络怎样进行参数初始化？</h2><p><a href="https://www.browallia.top/2019/10/21/CS231n-note-3/">1.3数据预处理</a></p>
<h2 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h2><p><img src="https://gitee.com/browallia/tuchuang/raw/master/img/Convolution_schematic.gif" alt></p>
<p>卷积的可以看作是<strong>滤波器</strong></p>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="http://ufldl.stanford.edu/tutorial/supervised/FeatureExtractionUsingConvolution/">Feature Extraction Using Convolution</a></li>
<li><p><a href="https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/convolution.html">convolution</a></p>
</li>
<li><p><a href="https://blog.csdn.net/chaipp0607/article/details/72236892?locationNum=9&amp;fps=1">理解图像卷积操作的意义</a></p>
</li>
<li><p><a href="https://www.cnblogs.com/Yu-FeiFei/p/6800519.html">关于深度学习中卷积核操作</a></p>
</li>
</ul>
<h3 id="卷积的反向传播过程"><a href="#卷积的反向传播过程" class="headerlink" title="卷积的反向传播过程"></a>卷积的反向传播过程</h3><ul>
<li>[ ] TODO</li>
</ul>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="http://cogprints.org/5869/1/cnn_tutorial.pdf">Notes on Convolutional Neural Network</a></li>
<li><p><a href="https://blog.csdn.net/zouxy09/article/details/9993371">Deep Learning论文笔记之（四）CNN卷积神经网络推导和实现</a></p>
</li>
<li><p><a href="http://deeplearning.stanford.edu/wiki/index.php/%E5%8F%8D%E5%90%91%E4%BC%A0%E5%AF%BC%E7%AE%97%E6%B3%95">反向传导算法</a></p>
</li>
<li><p><a href="https://www.cnblogs.com/tornadomeet/p/3468450.html">Deep learning：五十一(CNN的反向求导及练习)</a></p>
</li>
<li><p><a href="https://www.cnblogs.com/pinard/p/6494810.html">卷积神经网络(CNN)反向传播算法</a></p>
</li>
<li><p><a href="https://blog.csdn.net/walegahaha/article/details/51945421">卷积神经网络(CNN)反向传播算法公式详细推导</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/61863634">全连接神经网络中反向传播算法数学推导</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/61898234">卷积神经网络(CNN)反向传播算法推导</a></p>
</li>
</ul>
<h2 id="CNN-模型所需的计算力（flops）和参数（parameters）数量是怎么计算的？"><a href="#CNN-模型所需的计算力（flops）和参数（parameters）数量是怎么计算的？" class="headerlink" title="CNN 模型所需的计算力（flops）和参数（parameters）数量是怎么计算的？"></a>CNN 模型所需的计算力（flops）和参数（parameters）数量是怎么计算的？</h2><p>对于一个卷积层，假设其大小为 $h<em>w</em>c<em>n$ （其中c为input channel, n为output channel），输出的feature map尺寸为 $H</em>W$ ，则该卷积层的</p>
<ul>
<li><p>paras =<img src="https://www.zhihu.com/equation?tex=n+%5Ctimes+%28h+%5Ctimes+w+%5Ctimes+c+%2B+1%29" alt></p>
</li>
<li><p>FLOPs = <img src="https://www.zhihu.com/equation?tex=H%27+%5Ctimes+W%27+%5Ctimes+n+%5Ctimes%28h+%5Ctimes+w+%5Ctimes+c+%2B+1%29" alt></p>
</li>
</ul>
<ul>
<li>[ ] TODO</li>
</ul>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://www.zhihu.com/question/65305385/answer/256845252">CNN 模型所需的计算力（flops）和参数（parameters）数量是怎么计算的？</a></li>
<li><a href="https://blog.csdn.net/sinat_34460960/article/details/84779219">CNN中parameters和FLOPs计算</a></li>
<li><a href="https://blog.csdn.net/smallhujiu/article/details/80876875">FLOPS理解</a></li>
<li><a href="https://github.com/Lyken17/pytorch-OpCounter">PyTorch-OpCounter</a></li>
</ul>
<h2 id="池化（Pooling）"><a href="#池化（Pooling）" class="headerlink" title="池化（Pooling）"></a>池化（Pooling）</h2><p><strong>平均池化（Mean Pooling）</strong></p>
<p>mean pooling的前向传播就是把一个patch中的值求取平均来做pooling，那么反向传播的过程也就是把某个元素的梯度等分为n份分配给前一层，这样就保证池化前后的梯度（残差）之和保持不变，还是比较理解的，图示如下 </p>
<p><img src="https://img-blog.csdn.net/20170615205352655?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMjExOTAwODE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt></p>
<p><strong>最大池化（Max Pooling）</strong></p>
<p>max pooling也要满足梯度之和不变的原则，max pooling的前向传播是把patch中最大的值传递给后一层，而其他像素的值直接被舍弃掉。那么反向传播也就是把梯度直接传给前一层某一个像素，而其他像素不接受梯度，也就是为0。所以max pooling操作和mean pooling操作不同点在于需要记录下池化操作时到底哪个像素的值是最大，也就是max id，这个可以看caffe源码的pooling_layer.cpp，下面是caffe框架max pooling部分的源码</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">// If max pooling, we will initialize the vector index part.</span><br><span class="line"></span><br><span class="line">if (this-&gt;layer_param_.pooling_param().pool() == PoolingParameter_PoolMethod_MAX &amp;&amp; top.size() == 1)</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">    max_idx_.Reshape(bottom[0]-&gt;num(), channels_, pooled_height_,pooled_width_);</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdn.net/20170615211413093?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMjExOTAwODE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt></p>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/35769417">如何理解CNN中的池化？</a></li>
<li><a href="https://blog.csdn.net/qq_21190081/article/details/72871704">深度学习笔记（3）——CNN中一些特殊环节的反向传播</a></li>
</ul>
<h3 id="池化层怎么接收后面传过来的损失？"><a href="#池化层怎么接收后面传过来的损失？" class="headerlink" title="池化层怎么接收后面传过来的损失？"></a>池化层怎么接收后面传过来的损失？</h3><p><strong>Relu函数的导数计算</strong></p>
<script type="math/tex; mode=display">
f(x)=\left\{ \begin{aligned} 1 ,x>0\\0,x<=0   \end{aligned} \right.</script><p><strong>池化层的反向传播</strong></p>
<p>池化层没有激活函数，可以将池化看成用线性激活函数，所以直接做一次逆池化的操作，将池化后的单元映射到原来特征图的位置。</p>
<h2 id="感受野"><a href="#感受野" class="headerlink" title="感受野"></a>感受野</h2><p>在卷积神经网络中，感受野的定义是 卷积神经网络每一层输出的特征图（feature map）上的像素点在<strong>原始图像</strong>上映射的区域大小。</p>
<h3 id="感受野计算"><a href="#感受野计算" class="headerlink" title="感受野计算"></a>感受野计算</h3><p><strong>参考资料</strong></p>
<ul>
<li><a href="https://www.cnblogs.com/objectDetect/p/5947169.html">卷积神经网络物体检测之感受野大小计算</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/31004121">如何计算感受野(Receptive Field)——原理</a></li>
<li><a href="https://distill.pub/2019/computing-receptive-fields/">Computing Receptive Fields of Convolutional Neural Networks</a></li>
</ul>
<h3 id="卷积神经网络的感受野"><a href="#卷积神经网络的感受野" class="headerlink" title="卷积神经网络的感受野"></a>卷积神经网络的感受野</h3><p>(N-1)_RF = f(N_RF, stride, kernel) = (N_RF - 1) * stride + kernel</p>
<p>其中，RF是感受野。N_RF和RF有点像，<strong>N代表 neighbour</strong>，指的是第n层的 a feature在n-1层的RF，<strong>记住N_RF只是一个中间变量</strong>，不要和<strong>RF</strong>混淆。 stride是步长，ksize是卷积核大小。</p>
<p><strong>这个公式就是卷积之后特征图计算(N-ksize)/stride+1的逆公式</strong></p>
<p><strong>与padding没有关系，感受野只是表示两者的映射关系，与原始图的大小无关！</strong></p>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/44106492">卷积神经网络的感受野</a></li>
</ul>
<h2 id="权重初始化方法"><a href="#权重初始化方法" class="headerlink" title="权重初始化方法"></a>权重初始化方法</h2><p>权重初始化太小会造成网络崩溃，权重太大网络饱和，导致梯度消失。</p>
<h3 id="Xavier"><a href="#Xavier" class="headerlink" title="Xavier"></a>Xavier</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">w &#x3D; np.random.randn(fan_in, fan_out) &#x2F; np.sqrt(fan_in)</span><br></pre></td></tr></table></figure>
<h3 id="Kaiming初始化"><a href="#Kaiming初始化" class="headerlink" title="Kaiming初始化"></a>Kaiming初始化</h3><p>如果使用ReLU激活函数，会造成一半左右的神经元消失</p>
<p>在权重初始化的时候<code>w = np.random.randn(fan_in, fan_out) / np.sqrt(fan_in / 2)</code></p>
<h2 id="正则化方法"><a href="#正则化方法" class="headerlink" title="正则化方法"></a>正则化方法</h2><ol>
<li><p><a href="https://baike.baidu.com/item/%E6%AD%A3%E5%88%99%E5%8C%96%E6%96%B9%E6%B3%95/19145625?fr=aladdin#1">参数范数惩罚</a></p>
<p><img src="https://gitee.com/browallia/tuchuang/raw/master/img/20201126222217.png" alt></p>
<p>深度学习中只对网络权重θ添加约束，对偏置项不加约束。主要原因是偏置项一般需要较少的数据就能精确的拟合，不对其正则化也不会引起太大的方差。另外，正则化偏置参数反而可能会引起显著的欠拟合。</p>
</li>
<li><p><a href="https://baike.baidu.com/item/%E6%AD%A3%E5%88%99%E5%8C%96%E6%96%B9%E6%B3%95/19145625?fr=aladdin#2">L2参数正则化</a></p>
</li>
<li><p><a href="https://baike.baidu.com/item/%E6%AD%A3%E5%88%99%E5%8C%96%E6%96%B9%E6%B3%95/19145625?fr=aladdin#3">L1参数正则化</a></p>
</li>
<li><p><a href="https://baike.baidu.com/item/%E6%AD%A3%E5%88%99%E5%8C%96%E6%96%B9%E6%B3%95/19145625?fr=aladdin#4">L1正则化和L2正则化的区别</a></p>
<script type="math/tex; mode=display">
L1范数 \ ||w||_1 = \sum_{i=1}^n|w_i|\\L2范数||w||_2 = \sqrt{\sum_{i=1}^nw_i^2}\\</script><p>L1为曼哈顿距离</p>
<p>L2为欧式距离</p>
<ul>
<li>损失函数</li>
</ul>
<p>L1(LAD绝对值损失函数)和L2(LSE最小平方误差)都可以用作损失函数，LAE的<strong>鲁棒性</strong>更强，因为LSE会将误差放大，对样本更加敏感，导致模型会为了拟合一些异常样本进行调整会牺牲一些正常样本的训练效果。</p>
<ul>
<li>正则化</li>
</ul>
<p>L1正则化更倾向于稀疏解，常用来做特征选择，一定程度上可以防止过拟合。</p>
<p>L2正则化主要是用来防止模型过拟合，直观上理解是对较大的参数进行惩罚。</p>
<p><img src="https://gitee.com/browallia/tuchuang/raw/master/img/20201123194902.png" style="zoom: 67%;"></p>
<p>L1正则化输出稀疏，鲁棒性更强，但可能解不唯一，L2正则化有唯一解，计算相对容易</p>
</li>
<li><p><a href="https://baike.baidu.com/item/%E6%AD%A3%E5%88%99%E5%8C%96%E6%96%B9%E6%B3%95/19145625?fr=aladdin#5">数据集增强</a></p>
<p>利用一些数据增广操作</p>
</li>
<li><p><a href="https://baike.baidu.com/item/%E6%AD%A3%E5%88%99%E5%8C%96%E6%96%B9%E6%B3%95/19145625?fr=aladdin#6">噪音的鲁棒性</a></p>
</li>
<li><p><a href="https://baike.baidu.com/item/%E6%AD%A3%E5%88%99%E5%8C%96%E6%96%B9%E6%B3%95/19145625?fr=aladdin#7">向输出目标注入噪声</a></p>
</li>
<li><p><a href="https://baike.baidu.com/item/%E6%AD%A3%E5%88%99%E5%8C%96%E6%96%B9%E6%B3%95/19145625?fr=aladdin#8">半监督学习</a></p>
</li>
<li><p><a href="https://baike.baidu.com/item/%E6%AD%A3%E5%88%99%E5%8C%96%E6%96%B9%E6%B3%95/19145625?fr=aladdin#9">多任务学习</a></p>
</li>
<li><p><a href="https://baike.baidu.com/item/%E6%AD%A3%E5%88%99%E5%8C%96%E6%96%B9%E6%B3%95/19145625?fr=aladdin#10">提前终止</a></p>
</li>
<li><p><a href="https://baike.baidu.com/item/%E6%AD%A3%E5%88%99%E5%8C%96%E6%96%B9%E6%B3%95/19145625?fr=aladdin#11">参数绑定和共享</a></p>
</li>
<li><p><a href="https://baike.baidu.com/item/%E6%AD%A3%E5%88%99%E5%8C%96%E6%96%B9%E6%B3%95/19145625?fr=aladdin#12">稀疏表示</a></p>
</li>
<li><p><a href="https://baike.baidu.com/item/%E6%AD%A3%E5%88%99%E5%8C%96%E6%96%B9%E6%B3%95/19145625?fr=aladdin#13">集成化方法</a></p>
<p>模型ensemble</p>
</li>
</ol>
<p><strong>参考资料</strong></p>
<ul>
<li>[ ] <a href="https://baike.baidu.com/item/%E6%AD%A3%E5%88%99%E5%8C%96%E6%96%B9%E6%B3%95/19145625?fr=aladdin">正则化方法</a></li>
</ul>
<h2 id="Batch-Normalization（BN）"><a href="#Batch-Normalization（BN）" class="headerlink" title="Batch Normalization（BN）"></a>Batch Normalization（BN）</h2><h3 id="BN-原理"><a href="#BN-原理" class="headerlink" title="BN 原理"></a>BN 原理</h3><h4 id="为什么需要BN？"><a href="#为什么需要BN？" class="headerlink" title="为什么需要BN？"></a>为什么需要BN？</h4><p>传入一个模型的数据如果是独立同分布的，那么会加速模型的拟合以及简化训练等。因此需要对传入模型的数据进行<strong>白化</strong></p>
<p>白化一般有两个目的：</p>
<ol>
<li>去除特征之间的相关性（独立）</li>
<li>使所有的特征具有相同的均值和方差（同分布）</li>
</ol>
<p>典型的白化方法为PCA</p>
<p>但是白化的计算成本会很高，并且会改变分布，导致失去原有数据的表达能力，所以提出了Batch Normalization</p>
<h4 id="Internal-Covariate-Shift（ICS）"><a href="#Internal-Covariate-Shift（ICS）" class="headerlink" title="Internal Covariate Shift（ICS）"></a>Internal Covariate Shift（ICS）</h4><p>在深层神经网络中经过每一层之后的数据分布都会发生变化，通过叠加高层的输入分布变化会非常剧烈，这就使得高层需要不断去重新适应底层的参数更新所以会导致网络训练缓慢难以训练，为了训练好模型会非常谨慎的设定学习率，初始化权重等操作。</p>
<blockquote>
<p>大家都知道在统计机器学习中的一个经典假设是“源空间（source domain）和目标空间（target domain）的数据分布（distribution）是一致的”。如果不一致，那么就出现了新的机器学习问题，如 transfer learning / domain adaptation 等。而 covariate shift 就是分布不一致假设之下的一个分支问题，它是指源空间和目标空间的条件概率是一致的，但是其边缘概率不同，即：对所有</p>
<p><img src="https://www.zhihu.com/equation?tex=x%5Cin+%5Cmathcal%7BX%7D" alt="[公式]">,<img src="https://www.zhihu.com/equation?tex=P_s%28Y%7CX%3Dx%29%3DP_t%28Y%7CX%3Dx%29%5C%5C" alt="[公式]"></p>
<p>但是<img src="https://www.zhihu.com/equation?tex=P_s%28X%29%5Cne+P_t%28X%29%5C%5C" alt="[公式]">大家细想便会发现，的确，对于神经网络的各层输出，由于它们经过了层内操作作用，其分布显然与各层对应的输入信号分布不同，而且差异会随着网络深度增大而增大，可是它们所能“指示”的样本标记（label）仍然是不变的，这便符合了covariate shift的定义。由于是对层间信号的分析，也即是“internal”的来由。</p>
</blockquote>
<p>带来的问题</p>
<p><strong>1）上层网络需要不停调整来适应输入数据分布的变化，导致网络学习速度的降低</strong></p>
<p><strong>2）网络的训练过程容易陷入梯度饱和区，减缓网络收敛速度</strong></p>
<p><strong>3）每层的更新都会影响到其它层，因此每层的参数更新策略需要尽可能的谨慎。</strong></p>
<h4 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h4><p>1.将每个特征进行normalization，让每个特征成为均值为0方差为1分布。</p>
<p>2.利用参数进行线性变换操作，让数据恢复表达能力</p>
<h4 id="BN的作用"><a href="#BN的作用" class="headerlink" title="BN的作用"></a>BN的作用</h4><p><strong>（1）BN使得网络中每层输入数据的分布相对稳定，加速模型学习速度</strong></p>
<p><strong>（2）BN使得模型对网络中的参数不那么敏感，简化调参过程，使得网络学习更加稳定</strong></p>
<p><strong>（3）BN允许网络使用饱和性激活函数（例如sigmoid，tanh等），缓解梯度消失问题</strong></p>
<p><strong>（4）BN具有一定的正则化效果</strong></p>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/34879333">Batch Normalization原理与实战</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/33173246">BN</a></li>
</ul>
<h3 id="手写-BN"><a href="#手写-BN" class="headerlink" title="手写 BN"></a>手写 BN</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Batchnorm</span>(<span class="params">x, gamma, beta, bn_param</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># x_shape:[B, C, H, W]</span></span><br><span class="line">    running_mean = bn_param[<span class="string">&#x27;running_mean&#x27;</span>]</span><br><span class="line">    running_var = bn_param[<span class="string">&#x27;running_var&#x27;</span>]</span><br><span class="line">    results = <span class="number">0.</span></span><br><span class="line">    eps = <span class="number">1e-5</span></span><br><span class="line"></span><br><span class="line">    x_mean = np.mean(x, axis=(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>), keepdims=<span class="literal">True</span>)</span><br><span class="line">    x_var = np.var(x, axis=(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>), keepdims=True0)</span><br><span class="line">    x_normalized = (x - x_mean) / np.sqrt(x_var + eps)</span><br><span class="line">    results = gamma * x_normalized + beta</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 因为在测试时是单个图片测试，这里保留训练时的均值和方差，用在后面测试时用</span></span><br><span class="line">    running_mean = momentum * running_mean + (<span class="number">1</span> - momentum) * x_mean</span><br><span class="line">    running_var = momentum * running_var + (<span class="number">1</span> - momentum) * x_var</span><br><span class="line"></span><br><span class="line">    bn_param[<span class="string">&#x27;running_mean&#x27;</span>] = running_mean</span><br><span class="line">    bn_param[<span class="string">&#x27;running_var&#x27;</span>] = running_var</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> results, bn_param</span><br></pre></td></tr></table></figure>
<h3 id="BN-可以防止过拟合么？为什么"><a href="#BN-可以防止过拟合么？为什么" class="headerlink" title="BN 可以防止过拟合么？为什么"></a>BN 可以防止过拟合么？为什么</h3><p>在Batch Normalization中，由于我们使用mini-batch的均值与方差作为对整体训练样本均值与方差的估计，尽管每一个batch中的数据都是从总体样本中抽样得到，但不同mini-batch的均值与方差会有所不同，这就为网络的学习过程中增加了随机噪音，与Dropout通过关闭神经元给网络训练带来噪音类似，在一定程度上对模型起到了正则化的效果。</p>
<p>另外，原作者通过也证明了网络加入BN后，可以丢弃Dropout，模型也同样具有很好的泛化效果。</p>
<h3 id="BN-有哪些参数？"><a href="#BN-有哪些参数？" class="headerlink" title="BN 有哪些参数？"></a>BN 有哪些参数？</h3><script type="math/tex; mode=display">
输入向量X = (x_1,x_2,x_3,...,x_d)
\\经过网络层有y = f(x)
\\经过BN之后对输入数据进行了简化的白化操作。\\
h = f(g·\frac{x-\mu}{\sigma}+b)</script><p>首先对原始数据进行去均值除方差的操作编程均值为0方差为1的分布</p>
<p>再用可学习的参数g，b将输入的数据变成均值为b，方差为g2的分布</p>
<p>加入g,b参数的原因是<strong>保证模型的表达能力不因规范化而下降</strong>。可以让上层的网络利用下层学习的结果进行学习。</p>
<p>在旧参数中，X的均值取决于下层神经网络的复杂关联；但在新参数中， Y 的均值仅由 b来确定，去除了与下层计算的密切耦合。新参数很容易通过梯度下降来学习，简化了神经网络的训练。</p>
<h3 id="BN-的反向传播推导"><a href="#BN-的反向传播推导" class="headerlink" title="BN 的反向传播推导"></a>BN 的反向传播推导</h3><p><img src="https://gitee.com/browallia/tuchuang/raw/master/img/20201124155822.png" style="zoom:80%;"></p>
<p>我们可以看到，经过BN操作以后，权重的缩放值会被“抹去”，因此保证了输入数据分布稳定在一定范围内。另外，权重的缩放并不会影响到对$u$的梯度计算；并且当权重越大时，即$a$越大， $\frac{1}{a}$越小，意味着权重 $W$的梯度反而越小，这样BN就保证了梯度不会依赖于参数的scale，使得参数的更新处在更加稳定的状态。</p>
<p>因此，在使用Batch Normalization之后，抑制了参数微小变化随着网络层数加深被放大的问题，使得网络对参数大小的适应能力更强，此时我们可以设置较大的学习率而不用过于担心模型divergence的风险。</p>
<h3 id="BN-在训练和测试的区别？"><a href="#BN-在训练和测试的区别？" class="headerlink" title="BN 在训练和测试的区别？"></a>BN 在训练和测试的区别？</h3><p>训练时$\mu$和$\sigma$是从mini_batch的样本求得的均值和方差</p>
<p>在测试时,使用在训练时BN保留的每组mini-batch训练数据在网络中每一层的均值和方差，即用整个样本的均值和方差来对test数据进行归一化。</p>
<script type="math/tex; mode=display">
\mu_{test} = \mathbb{E}(\mu_{batch})
\\\sigma^2_{test} = \frac{m}{m-1}\mathbb{E}(\sigma^2_{test})</script><h2 id="Weight-Normalization（WN）"><a href="#Weight-Normalization（WN）" class="headerlink" title="Weight Normalization（WN）"></a>Weight Normalization（WN）</h2><h2 id="Layer-Normalization（LN）"><a href="#Layer-Normalization（LN）" class="headerlink" title="Layer Normalization（LN）"></a>Layer Normalization（LN）</h2><p>层规范化就是针对 BN 的上述不足而提出的。与 BN 不同，LN 是一种横向的规范化，如图所示。它综合考虑一层所有维度的输入，计算该层的平均输入值和输入方差，然后用同一个规范化操作来转换各个维度的输入。</p>
<script type="math/tex; mode=display">
\mu = \sum_i\frac{1}{H}x_i, \ \sigma = \sqrt{\frac{1}{H}\sum_i(x_i-\mu)^2+\epsilon}</script><p>即将该层所有输入的神经元进行归一化，将所有特征一起考虑，如果特征差距过大则会降低模型的表现能力</p>
<p>LN中同层神经元输入拥有相同的均值和方差，不同的输入样本有不同的均值和方差</p>
<p>LN主要用在RNN中</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ln</span>(<span class="params">x, b, s</span>):</span></span><br><span class="line">    _eps = <span class="number">1e-5</span></span><br><span class="line">    output = (x - x.mean(<span class="number">1</span>)[:,<span class="literal">None</span>]) / tensor.sqrt((x.var(<span class="number">1</span>)[:,<span class="literal">None</span>] + _eps))</span><br><span class="line">    output = s[<span class="literal">None</span>, :] * output + b[<span class="literal">None</span>,:]</span><br><span class="line">    <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>
<h2 id="Instance-Normalization（IN）"><a href="#Instance-Normalization（IN）" class="headerlink" title="Instance Normalization（IN）"></a>Instance Normalization（IN）</h2><p>IN对输入的每个图像实例进行归一化</p>
<p><img src="https://gitee.com/browallia/tuchuang/raw/master/img/20201124203005.png" style="zoom:80%;"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Instancenorm</span>(<span class="params">x, gamma, beta</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># x_shape:[B, C, H, W]</span></span><br><span class="line">    results = <span class="number">0.</span></span><br><span class="line">    eps = <span class="number">1e-5</span></span><br><span class="line"></span><br><span class="line">    x_mean = np.mean(x, axis=(<span class="number">2</span>, <span class="number">3</span>), keepdims=<span class="literal">True</span>)</span><br><span class="line">    x_var = np.var(x, axis=(<span class="number">2</span>, <span class="number">3</span>), keepdims=True0)</span><br><span class="line">    x_normalized = (x - x_mean) / np.sqrt(x_var + eps)</span><br><span class="line">    results = gamma * x_normalized + beta</span><br><span class="line">    <span class="keyword">return</span> results</span><br></pre></td></tr></table></figure>
<h2 id="Group-Normalization（GN）"><a href="#Group-Normalization（GN）" class="headerlink" title="Group Normalization（GN）"></a>Group Normalization（GN）</h2><p>主要是针对Batch Normalization对小batchsize效果差，GN将channel方向分group，然后每个group内做归一化，算(C//G)<em>H</em>W的均值，这样与batchsize无关，不受其约束。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">GroupNorm</span>(<span class="params">x, gamma, beta, G=<span class="number">16</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># x_shape:[B, C, H, W]</span></span><br><span class="line">    results = <span class="number">0.</span></span><br><span class="line">    eps = <span class="number">1e-5</span></span><br><span class="line">    x = np.reshape(x, (x.shape[<span class="number">0</span>], G, x.shape[<span class="number">1</span>]/<span class="number">16</span>, x.shape[<span class="number">2</span>], x.shape[<span class="number">3</span>]))</span><br><span class="line"></span><br><span class="line">    x_mean = np.mean(x, axis=(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>), keepdims=<span class="literal">True</span>)</span><br><span class="line">    x_var = np.var(x, axis=(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>), keepdims=True0)</span><br><span class="line">    x_normalized = (x - x_mean) / np.sqrt(x_var + eps)</span><br><span class="line">    results = gamma * x_normalized + beta</span><br><span class="line">    <span class="keyword">return</span> results</span><br></pre></td></tr></table></figure>
<h3 id="BN、LN、WN、IN和GN的区别"><a href="#BN、LN、WN、IN和GN的区别" class="headerlink" title="BN、LN、WN、IN和GN的区别"></a>BN、LN、WN、IN和GN的区别</h3><p>将输入的图像shape记为[N, C, H, W]，这几个方法主要的区别就是在，</p>
<ul>
<li>batchNorm是在batch上，对NHW做归一化，对小batchsize效果不好；</li>
<li>layerNorm在通道方向上，对CHW归一化，主要对RNN作用明显；</li>
<li>instanceNorm在图像像素上，对HW做归一化，用在风格化迁移；</li>
<li>GroupNorm将channel分组，然后再做归一化；</li>
<li>SwitchableNorm是将BN、LN、IN结合，赋予权重，让网络自己去学习归一化层应该使用什么方法。</li>
</ul>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://blog.csdn.net/liuxiao214/article/details/81037416">BatchNormalization、LayerNormalization、InstanceNorm、GroupNorm、SwitchableNorm总结</a></li>
</ul>
<h2 id="优化算法"><a href="#优化算法" class="headerlink" title="优化算法"></a>优化算法</h2><p>见<a href="https://www.browallia.top/2019/10/21/CS231n-note-3/">神经网络优化</a></p>
<ul>
<li>随机梯度下降（SGD）</li>
<li>Mini-Batch</li>
<li>动量（Momentum）</li>
<li>Nesterov 动量</li>
<li>AdaGrad</li>
<li>AdaDelta</li>
<li>RMSProp</li>
<li>Adam</li>
<li>Adamax</li>
<li>Nadam</li>
<li><a href="http://ruder.io/optimizing-gradient-descent/index.html#amsgrad">AMSGrad</a></li>
<li>AdaBound</li>
</ul>
<p><strong>参考资料</strong></p>
<ul>
<li><p><a href="https://exacity.github.io/deeplearningbook-chinese/Chapter8_optimization_for_training_deep_models/">《Deep Learning》第八章：深度模型中的优化</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/32626442">从 SGD 到 Adam —— 深度学习优化算法概览(一)</a></p>
</li>
<li><a href="https://zhuanlan.zhihu.com/p/37269222">Adam 究竟还有什么问题 —— 深度学习优化算法概览(二)</a></li>
<li><a href="http://ruder.io/optimizing-gradient-descent/">An overview of gradient descent optimization algorithms</a></li>
</ul>
<h3 id="梯度下降法"><a href="#梯度下降法" class="headerlink" title="梯度下降法"></a>梯度下降法</h3><p>在梯度下降中，对于$\theta$的更新，需要计算所有的样本然后求平均.其计算得到的是一个标准梯度。因而理论上来说一次更新的幅度是比较大的。</p>
<h3 id="mini-batch梯度下降法"><a href="#mini-batch梯度下降法" class="headerlink" title="mini-batch梯度下降法"></a>mini-batch梯度下降法</h3><p>为了克服SGD这种随机性带来的缺点，保留其优点。Mini-batch gradient descent 每次随机选择m个数据样本进行梯度下降的参数更新。m的取值可以是2，4，8，16，32，64，256等。这样做的好处是抵消了一部分随机性，又不会花费太多的时间。而且也能够在online streaming数据流的状态下使用。只要每次收集完m个数据后开始更新即可。</p>
<p>Batch size大，收敛速度会比较慢，因为参数每次更新所需要的样本量增加了，但是会沿着比较准确的方向进行。</p>
<h3 id="随机梯度下降法（SGD）"><a href="#随机梯度下降法（SGD）" class="headerlink" title="随机梯度下降法（SGD）"></a>随机梯度下降法（SGD）</h3><h4 id="SGD每步做什么，为什么能online-learning？"><a href="#SGD每步做什么，为什么能online-learning？" class="headerlink" title="SGD每步做什么，为什么能online learning？"></a>SGD每步做什么，为什么能online learning？</h4><ul>
<li>只对一个方向的敏感度高，会在不敏感的方向反复增减。</li>
<li>会找到局部极小值或者鞍点(梯度为零)，在高维参数空间中，局部最小值不常见，常见的是鞍点。</li>
<li>随机性，因为SGD使用的是minibatch(=1)，会产生噪声，如果在梯度下降时加入噪声会花费很长的时间</li>
</ul>
<p>online learning强调的是学习是实时的，流式的，每次训练不用使用全部样本，而是以之前训练好的模型为基础，每来一个样本就更新一次模型，这种方法叫做OGD（online gradient descent）。</p>
<h3 id="动量梯度下降法（Momentum）"><a href="#动量梯度下降法（Momentum）" class="headerlink" title="动量梯度下降法（Momentum）"></a>动量梯度下降法（Momentum）</h3><ul>
<li>在局部最优点或者鞍点时，梯度为0，但依旧会有一个速度，能够越过这个点继续进行梯度下降。</li>
<li>加入动量之后，噪声会被抵消，下降曲线更平滑。</li>
</ul>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/77503211">pytorch中的SGD</a></li>
</ul>
<h3 id="RMSprop"><a href="#RMSprop" class="headerlink" title="RMSprop"></a>RMSprop</h3><script type="math/tex; mode=display">
S_{dW}=\beta S_{dW}+\left ( 1-\beta  \right )dW^{2}</script><script type="math/tex; mode=display">
S_{db}=\beta S_{db}+\left ( 1-\beta  \right )db^{2}</script><script type="math/tex; mode=display">
W=W-\alpha\frac{dW}{\sqrt{S_{dW}}}, b=b-\alpha\frac{db}{\sqrt{S_{db}}}</script><ul>
<li>[ ] TODO</li>
</ul>
<h3 id="Adagrad"><a href="#Adagrad" class="headerlink" title="Adagrad"></a>Adagrad</h3><ul>
<li>[ ] TODO</li>
</ul>
<h3 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h3><p>Adam算法结合了Momentum和RMSprop梯度下降法，是一种极其常见的学习算法，被证明能有效适用于不同神经网络，适用于广泛的结构。</p>
<script type="math/tex; mode=display">
v_{dW}=\beta_{1} v_{dW}+\left ( 1-\beta_{1}  \right )dW</script><script type="math/tex; mode=display">
v_{db}=\beta_{1} v_{db}+\left ( 1-\beta_{1}  \right )db</script><script type="math/tex; mode=display">
S_{dW}=\beta_{2} S_{dW}+\left ( 1-\beta_{2}  \right )dW^{2}</script><script type="math/tex; mode=display">
S_{db}=\beta_{2} S_{db}+\left ( 1-\beta_{2}  \right )db^{2}</script><script type="math/tex; mode=display">
v_{dW}^{corrected}=\frac{v_{dW}}{1-\beta_{1}^{t}}</script><script type="math/tex; mode=display">
v_{db}^{corrected}=\frac{v_{db}}{1-\beta_{1}^{t}}</script><script type="math/tex; mode=display">
S_{dW}^{corrected}=\frac{S_{dW}}{1-\beta_{2}^{t}}</script><script type="math/tex; mode=display">
S_{db}^{corrected}=\frac{S_{db}}{1-\beta_{2}^{t}}</script><script type="math/tex; mode=display">
W:=W-\frac{av_{dW}^{corrected}}{\sqrt{S_{dW}^{corrected}}+\varepsilon }</script><p>超参数：</p>
<script type="math/tex; mode=display">
\alpha ,\beta _{1},\beta_{2},\varepsilon</script><script type="math/tex; mode=display">
\alpha ,\beta _{1},\beta_{2},\varepsilon</script><ul>
<li>[ ] TODO </li>
</ul>
<h4 id="Adam-优化器的迭代公式"><a href="#Adam-优化器的迭代公式" class="headerlink" title="Adam 优化器的迭代公式"></a>Adam 优化器的迭代公式</h4><ul>
<li>[ ] TODO</li>
</ul>
<h2 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h2><p>每个激活函数（或非线性函数）的输入都是一个数字，然后对其进行某种固定的数学操作。</p>
<p>见<a href="https://www.browallia.top/2019/10/15/CS231n-note-2/">2.1激活函数</a></p>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://yogayu.github.io/DeepLearningCourse/03/ActivateFunction.html">What is activate function?</a></li>
<li><a href="https://mp.weixin.qq.com/s/7DgiXCNBS5vb07WIKTFYRQ">资源 | 从ReLU到Sinc，26种神经网络激活函数可视化</a></li>
</ul>
<h3 id="Sigmoid-amp-Tanh"><a href="#Sigmoid-amp-Tanh" class="headerlink" title="Sigmoid&amp;Tanh"></a>Sigmoid&amp;Tanh</h3><p><img src="https://gitee.com/browallia/tuchuang/raw/master/img/20201124212701.png" alt></p>
<script type="math/tex; mode=display">
sigmoid(x) = \frac{1}{1+e^{-x}}\\
tanh(x) = 2sigmoid(2x)-1</script><p>sigmod函数饱和使梯度消失，并且是非零中心的</p>
<p>tanh也有饱和问题，但是是零中心的</p>
<h4 id="Sigmoid用作激活函数时，分类为什么要用交叉熵损失，而不用均方损失？"><a href="#Sigmoid用作激活函数时，分类为什么要用交叉熵损失，而不用均方损失？" class="headerlink" title="Sigmoid用作激活函数时，分类为什么要用交叉熵损失，而不用均方损失？"></a>Sigmoid用作激活函数时，分类为什么要用交叉熵损失，而不用均方损失？</h4><p><a href="https://blog.csdn.net/qq_29679623/article/details/99441913">https://blog.csdn.net/qq_29679623/article/details/99441913</a></p>
<p>当使用sigmoid作为激活函数的时候，常用<strong>交叉熵损失函数</strong>而不用<strong>均方误差损失函数</strong>，因为它可以<strong>完美解决平方损失函数权重更新过慢</strong>的问题，具有“误差大的时候，权重更新快；误差小的时候，权重更新慢”的良好性质。</p>
<h3 id="ReLU"><a href="#ReLU" class="headerlink" title="ReLU"></a>ReLU</h3><script type="math/tex; mode=display">
ReLU(x) = max(0,x)</script><p><img src="https://gitee.com/browallia/tuchuang/raw/master/img/20201124213722.png" alt></p>
<p>ReLU 相关变体</p>
<h4 id="ReLU-激活函数为什么比sigmoid和tanh好？"><a href="#ReLU-激活函数为什么比sigmoid和tanh好？" class="headerlink" title="ReLU 激活函数为什么比sigmoid和tanh好？"></a>ReLU 激活函数为什么比sigmoid和tanh好？</h4><ol>
<li>可以有效解决饱和问题带来的梯度消失问题</li>
<li>计算简单，导数为常数收敛速度快</li>
<li>Relu会使一部分神经元的输出为0，这样就造成了网络的稀疏性，并且减少了参数的相互依存关系，缓解了过拟合问题的发生</li>
</ol>
<h4 id="ReLU-激活函数为什么能解决梯度消失问题？"><a href="#ReLU-激活函数为什么能解决梯度消失问题？" class="headerlink" title="ReLU 激活函数为什么能解决梯度消失问题？"></a>ReLU 激活函数为什么能解决梯度消失问题？</h4><p>从信号方面来看，即神经元同时只对输入信号的少部分选择性响应，大量信号被刻意的屏蔽了，这样可以提高学习的精度，更好更快地提取稀疏特征。当 x<0 时，relu 硬饱和，而当 x>0 时，则不存在饱和问题。ReLU 能够在 x&gt;0 时保持梯度不衰减，从而缓解梯度消失问题。</0></p>
<h4 id="ReLU-有哪些变体？"><a href="#ReLU-有哪些变体？" class="headerlink" title="ReLU 有哪些变体？"></a>ReLU 有哪些变体？</h4><p>Leaky ReLU PReLU ELU</p>
<h2 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h2><h3 id="Dropout-基本原理"><a href="#Dropout-基本原理" class="headerlink" title="Dropout 基本原理"></a>Dropout 基本原理</h3><p>解决过拟合和模型耗时问题，随机选择部分神经元失活</p>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://blog.csdn.net/stdcoutzyx/article/details/49022443">理解dropout</a></li>
</ul>
<h3 id="Dropout-如何实现？"><a href="#Dropout-如何实现？" class="headerlink" title="Dropout 如何实现？"></a>Dropout 如何实现？</h3><ul>
<li>[ ] TODO</li>
</ul>
<h3 id="Drop-在训练和测试的区别"><a href="#Drop-在训练和测试的区别" class="headerlink" title="Drop 在训练和测试的区别"></a>Drop 在训练和测试的区别</h3><p>在测试的时候每个单元的参数需要乘p</p>
<h2 id="损失函数（Loss）"><a href="#损失函数（Loss）" class="headerlink" title="损失函数（Loss）"></a>损失函数（Loss）</h2><p>在机器学习中，损失函数（loss function）是用来估量模型的预测值f(x)与真实值Y的不一致程度，损失函数越小，一般就代表模型的鲁棒性越好，正是损失函数指导了模型的学习。</p>
<p><a href="https://zhuanlan.zhihu.com/p/58883095">常见的损失函数</a></p>
<h3 id="MSE"><a href="#MSE" class="headerlink" title="MSE"></a>MSE</h3><p><a href="https://rohanvarma.me/Loss-Functions/">参考</a></p>
<script type="math/tex; mode=display">
loss = \frac{1}{N}\sum_{i=1}^N(y_i-y_{predict_i})^2</script><p>均方误差主要用于回归，不经常用于分类</p>
<p>使用MSE的一个缺点就是其偏导值在输出概率值接近0或者接近1的时候非常小，这可能会造成模型刚开始训练时，偏导值几乎消失。</p>
<blockquote>
<p>如果假设您的输出是输入的实值函数，并且具有一定量的不可约高斯噪声，并且均值和方差恒定，那么使用MSE损失才有意义。 如果这些假设不成立（例如在分类的情况下），那么MSE亏损可能不是最好的选择。</p>
</blockquote>
<h3 id="Cross-Entropy-Loss（CE）"><a href="#Cross-Entropy-Loss（CE）" class="headerlink" title="Cross Entropy Loss（CE）"></a>Cross Entropy Loss（CE）</h3><script type="math/tex; mode=display">
二分类
\\loss=-\frac{1}{n}\sum_x[ylna+(1-y)ln(1-a)]
\\多分类
\\loss = -\frac{1}{n}\sum_iy_ilna_i</script><p>log损失函数是凸函数能够求得全局最优</p>
<p>如果用 MSE 计算 loss， 输出的曲线是波动的，有很多局部的极值点。 即，非凸优化问题 (non-convex)</p>
<p><img src="https://gitee.com/browallia/tuchuang/raw/master/img/20201126163847.png" alt></p>
<script type="math/tex; mode=display">
\frac{\partial L_i}{\partial w_i} = \frac{1}{N}\frac{\partial L_i}{\partial w_i}=\frac{1}{N}\frac{\partial L_i}{\partial p_i}\frac{\partial p_i}{\partial s_i}\frac{\partial s_i}{\partial w_i}</script><p><img src="https://gitee.com/browallia/tuchuang/raw/master/img/20201126170739.png" style="zoom:80%;"></p>
<p><img src="https://gitee.com/browallia/tuchuang/raw/master/img/20201126170817.png" style="zoom: 80%;"></p>
<p><img src="https://gitee.com/browallia/tuchuang/raw/master/img/20201126171024.png" style="zoom: 80%;"></p>
<p>并且在反向传播时CE可以很容易的进行计算</p>
<p><strong>优点</strong></p>
<p>在用梯度下降法做参数更新的时候，模型学习的速度取决于两个值：一、<strong>学习率</strong>；二、<strong>偏导值</strong>。其中，学习率是我们需要设置的超参数，所以我们重点关注偏导值。从上面的式子中，我们发现，偏导值的大小取决于$x_i$ 和 $[\sigma(s)-y]$ ，我们重点关注后者，后者的大小值反映了我们模型的错误程度，该值越大，说明模型效果越差，但是该值越大同时也会使得偏导值越大，从而模型学习速度更快。所以，使用逻辑函数得到概率，并结合交叉熵当损失函数时，在模型效果差的时候学习速度比较快，在模型效果好的时候学习速度变慢。</p>
<p><strong>缺点</strong></p>
<p>sigmoid(softmax)+cross-entropy loss 擅长于学习类间的信息，因为它采用了类间竞争机制，它只关心对于正确标签预测概率的准确性，忽略了其他非正确标签的差异，导致学习到的特征比较散。基于这个问题的优化有很多，比如对softmax进行改进，如L-Softmax、SM-Softmax、AM-Softmax等。</p>
<p><strong>pytorch中的CE Loss</strong></p>
<p>pytorch中的CE Loss是由softmax-log-NLL Loss(将label对应位置的值拿出来去掉负号求均值)组合而成的</p>
<h3 id="Hinge-Loss"><a href="#Hinge-Loss" class="headerlink" title="Hinge Loss"></a>Hinge Loss</h3><p>在机器学习中，<strong>hinge loss</strong>是一种损失函数，它通常用于”maximum-margin”的分类任务中，如支持向量机。数学表达式为：</p>
<script type="math/tex; mode=display">
L(y) = max(0, 1-y\hat{y})</script><h3 id="Focal-Loss"><a href="#Focal-Loss" class="headerlink" title="Focal Loss"></a>Focal Loss</h3><p><a href="https://zhuanlan.zhihu.com/p/80594704">参考资料</a></p>
<p>Focal Loss的引入主要是为了解决<strong>难易样本数量不平衡（注意，有区别于正负样本数量不平衡）</strong>的问题。</p>
<p>在普通的CE loss加上一个参数$\alpha$可以解决正负样本不平衡的问题。</p>
<script type="math/tex; mode=display">
CE = \begin{cases}-\alpha logp, \ y=1\\ -(1-\alpha)log(1-p), \ y=0\end{cases}</script><p>即减小负样本的权重</p>
<p>但是这样并不能解决难易样本不平衡的问题</p>
<p>样本可以分为四类</p>
<p><img src="https://gitee.com/browallia/tuchuang/raw/master/img/20201126195937.png" alt></p>
<p><strong>尽管</strong> $\alpha$<strong>平衡了正负样本，但对难易样本的不平衡没有任何帮助。</strong>而实际上，目标检测中大量的候选目标都是像下图一样的易分样本。</p>
<p><img src="https://gitee.com/browallia/tuchuang/raw/master/img/20201126200114.png" style="zoom:67%;"></p>
<p>这些样本的损失很低，但是由于数量极不平衡，易分样本的数量相对来讲太多，最终主导了总的损失。而本文的作者认为，<strong>易分样本（即，置信度高的样本）对模型的提升效果非常小，模型应该主要关注与那些难分样本</strong>（<strong>这个假设是有问题的，是GHM的主要改进对象</strong>）</p>
<p>一个简单的思想：<strong>把高置信度(p)样本的损失降低</strong></p>
<script type="math/tex; mode=display">
CE = \begin{cases}-\alpha (1-p)^\gamma logp, \ y=1\\ -(1-\alpha)p^\gamma log(1-p), \ y=0\end{cases}</script><p>实验表明$\gamma$取2, $\alpha$取0.25的时候效果最佳。</p>
<p><img src="https://gitee.com/browallia/tuchuang/raw/master/img/20201126200453.png" alt></p>
<p>在pytorch中</p>
<p><img src="https://gitee.com/browallia/tuchuang/raw/master/img/20201126200856.png" style="zoom:67%;"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">py_sigmoid_focal_loss</span>(<span class="params">pred,</span></span></span><br><span class="line"><span class="function"><span class="params">                          target,</span></span></span><br><span class="line"><span class="function"><span class="params">                          weight=None,</span></span></span><br><span class="line"><span class="function"><span class="params">                          gamma=<span class="number">2.0</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                          alpha=<span class="number">0.25</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                          reduction=<span class="string">&#x27;mean&#x27;</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                          avg_factor=None</span>):</span></span><br><span class="line">    pred_sigmoid = pred.sigmoid()</span><br><span class="line">    target = target.type_as(pred)</span><br><span class="line">    pt = (<span class="number">1</span> - pred_sigmoid) * target + pred_sigmoid * (<span class="number">1</span> - target)</span><br><span class="line">    focal_weight = (alpha * target + (<span class="number">1</span> - alpha) *</span><br><span class="line">                    (<span class="number">1</span> - target)) * pt.pow(gamma)</span><br><span class="line">    loss = F.binary_cross_entropy_with_logits(</span><br><span class="line">        pred, target, reduction=<span class="string">&#x27;none&#x27;</span>) * focal_weight</span><br><span class="line">    loss = weight_reduce_loss(loss, weight, reduction, avg_factor)</span><br><span class="line">    <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure>
<h2 id="1-1-卷积有什么作用？"><a href="#1-1-卷积有什么作用？" class="headerlink" title="1*1 卷积有什么作用？"></a>1*1 卷积有什么作用？</h2><ol>
<li>调整特征图的深度进行降维或者升维</li>
<li>减少参数</li>
<li><strong>跨通道的信息组合，并增加了非线性特征</strong></li>
</ol>
<p>使用1<em>1卷积核，实现降维和升维的操作其实就是channel间信息的线性组合变化，3</em>3，64channels的卷积核前面添加一个1<em>1，28channels的卷积核，就变成了3</em>3，28channels的卷积核，原来的64个channels就可以理解为跨通道线性组合变成了28channels，这就是通道间的信息交互。因为1*1卷积核，可以在保持feature map尺度不变的（即不损失分辨率）的前提下大幅增加非线性特性（利用后接的非线性激活函数），把网络做的很deep，增加非线性特性。</p>
<h2 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h2><ul>
<li>使用ReLU激活函数</li>
<li>Dropout</li>
<li>数据增广</li>
</ul>
<p>先给出AlexNet的一些参数和结构图： </p>
<p>卷积层：5层 </p>
<p>全连接层：3层 </p>
<p>深度：8层 </p>
<p>参数个数：60M </p>
<p>神经元个数：650k </p>
<p>分类数目：1000类</p>
<p><strong>参考资料</strong></p>
<p><a href="https://dgschwend.github.io/netscope/#/preset/alexnet">AlexNet</a></p>
<h2 id="VGG"><a href="#VGG" class="headerlink" title="VGG"></a>VGG</h2><p><strong>《Very Deep Convolutional Networks for Large-Scale Image Recognition》</strong></p>
<ul>
<li>arXiv：<a href="https://arxiv.org/abs/1409.1556">https://arxiv.org/abs/1409.1556</a></li>
<li>intro：ICLR 2015</li>
<li>homepage：<a href="http://www.robots.ox.ac.uk/~vgg/research/very_deep/">http://www.robots.ox.ac.uk/~vgg/research/very_deep/</a></li>
</ul>
<p><a href="https://arxiv.org/abs/1409.1556">VGG</a> 是Oxford的<strong>V</strong>isual <strong>G</strong>eometry <strong>G</strong>roup的组提出的（大家应该能看出VGG名字的由来了）。该网络是在ILSVRC 2014上的相关工作，主要工作是证明了增加网络的深度能够在一定程度上影响网络最终的性能。VGG有两种结构，分别是VGG16和VGG19，两者并没有本质上的区别，只是网络深度不一样。</p>
<p>VGG16相比AlexNet的一个改进是采用<strong>连续的几个3x3的卷积核代替AlexNet中的较大卷积核（11x11，7x7，5x5）</strong>。对于给定的感受野（与输出有关的输入图片的局部大小），<strong>采用堆积的小卷积核是优于采用大的卷积核，因为多层非线性层可以增加网络深度来保证学习更复杂的模式，而且代价还比较小（参数更少）</strong>。</p>
<p>简单来说，在VGG中，使用了3个3x3卷积核来代替7x7卷积核，使用了2个3x3卷积核来代替5*5卷积核，这样做的主要目的是在保证具有相同感知野的条件下，提升了网络的深度，在一定程度上提升了神经网络的效果。</p>
<p>比如，3个步长为1的3x3卷积核的一层层叠加作用可看成一个大小为7的感受野（其实就表示3个3x3连续卷积相当于一个7x7卷积），其参数总量为 3x(9xC^2) ，如果直接使用7x7卷积核，其参数总量为 49xC^2 ，这里 C 指的是输入和输出的通道数。很明显，27xC^2小于49xC^2，即减少了参数；而且3x3卷积核有利于更好地保持图像性质。</p>
<p>这里解释一下为什么使用2个3x3卷积核可以来代替5*5卷积核：</p>
<p>5x5卷积看做一个小的全连接网络在5x5区域滑动，我们可以先用一个3x3的卷积滤波器卷积，然后再用一个全连接层连接这个3x3卷积输出，这个全连接层我们也可以看做一个3x3卷积层。这样我们就可以用两个3x3卷积级联（叠加）起来代替一个 5x5卷积。</p>
<p>具体如下图所示：</p>
<p><img src="https://gitee.com/browallia/tuchuang/raw/master/img/20201126203259.png" alt></p>
<p>至于为什么使用3个3x3卷积核可以来代替7*7卷积核，推导过程与上述类似，大家可以自行绘图理解。</p>
<p>下面是VGG网络的结构（VGG16和VGG19都在）：</p>
<p><img src="https://gitee.com/browallia/tuchuang/raw/master/img/20201126203428.png" alt></p>
<ul>
<li>VGG16包含了16个隐藏层（13个卷积层和3个全连接层），如上图中的D列所示</li>
<li>VGG19包含了19个隐藏层（16个卷积层和3个全连接层），如上图中的E列所示</li>
</ul>
<p>VGG网络的结构非常一致，从头到尾全部使用的是3x3的卷积和2x2的max pooling。</p>
<p>如果你想看到更加形象化的VGG网络，可以使用<a href="https://mp.weixin.qq.com/s/gktWxh1p2rR2Jz-A7rs_UQ">经典卷积神经网络（CNN）结构可视化工具</a>来查看高清无码的<a href="https://dgschwend.github.io/netscope/#/preset/vgg-16">VGG网络</a>。</p>
<p><strong>VGG优点：</strong></p>
<ul>
<li>VGGNet的结构非常简洁，整个网络都使用了同样大小的卷积核尺寸（3x3）和最大池化尺寸（2x2）。</li>
<li>几个小滤波器（3x3）卷积层的组合比一个大滤波器（5x5或7x7）卷积层好：</li>
<li>验证了通过不断加深网络结构可以提升性能。</li>
</ul>
<p><strong>VGG缺点</strong>：</p>
<p>VGG耗费更多计算资源，并且使用了更多的参数（这里不是3x3卷积的锅），导致更多的内存占用（140M）。其中绝大多数的参数都是来自于第一个全连接层。VGG可是有3个全连接层啊！</p>
<p>PS：有的文章称：发现这些全连接层即使被去除，对于性能也没有什么影响，这样就显著降低了参数数量。</p>
<p>注：很多pretrained的方法就是使用VGG的model（主要是16和19），VGG相对其他的方法，参数空间很大，最终的model有500多m，AlexNet只有200m，GoogLeNet更少，所以train一个vgg模型通常要花费更长的时间，所幸有公开的pretrained model让我们很方便的使用。</p>
<p>关于感受野：</p>
<p>假设你一层一层地重叠了3个3x3的卷积层（层与层之间有非线性激活函数）。在这个排列下，第一个卷积层中的每个神经元都对输入数据体有一个3x3的视野。</p>
<p><strong>代码篇：VGG训练与测试</strong></p>
<p>这里推荐两个开源库，训练请参考<a href="https://github.com/machrisaa/tensorflow-vgg">tensorflow-vgg</a>，快速测试请参考<a href="https://www.cs.toronto.edu/~frossard/post/vgg16/">VGG-in TensorFlow</a>。</p>
<p>代码我就不介绍了，其实跟上述内容一致，跟着原理看code应该会很快。我快速跑了一下<a href="https://www.cs.toronto.edu/~frossard/post/vgg16/">VGG-in TensorFlow</a>，代码亲测可用，效果很nice，就是model下载比较烦。</p>
<p>贴心的Amusi已经为你准备好了<a href="https://www.cs.toronto.edu/~frossard/post/vgg16/">VGG-in TensorFlow</a>的测试代码、model和图像。需要的同学可以关注CVer微信公众号，后台回复：VGG。</p>
<p>天道酬勤，还有很多知识要学，想想都刺激~Fighting！</p>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://arxiv.org/abs/1409.1556">《Very Deep Convolutional Networks for Large-Scale Image Recognition》</a></li>
<li><p><a href="https://blog.csdn.net/wcy12341189/article/details/56281618">深度网络VGG理解</a></p>
</li>
<li><p><a href="https://blog.csdn.net/marsjhao/article/details/72955935">深度学习经典卷积神经网络之VGGNet</a></p>
</li>
<li><p><a href="https://dgschwend.github.io/netscope/#/preset/vgg-16">VGG16 结构可视化</a></p>
</li>
<li><p><a href="https://github.com/machrisaa/tensorflow-vgg">tensorflow-vgg</a></p>
</li>
<li><p><a href="https://www.cs.toronto.edu/~frossard/post/vgg16/">VGG-in TensorFlow</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/23518167">机器学习进阶笔记之五 | 深入理解VGG\Residual Network</a></p>
</li>
</ul>
<h2 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h2><p><strong>1.ResNet意义</strong></p>
<p>随着网络的加深，出现了训练集准确率下降的现象，我们可以确定这不是由于Overfit过拟合造成的(过拟合的情况训练集应该准确率很高)；所以作者针对这个问题提出了一种全新的网络，叫深度残差网络，它允许网络尽可能的加深，其中引入了全新的结构如图1；<br>这里问大家一个问题 </p>
<p>残差指的是什么？ </p>
<p>其中ResNet提出了两种mapping：一种是identity mapping，指的就是图1中”弯弯的曲线”，另一种residual mapping，指的就是除了”弯弯的曲线“那部分，所以最后的输出是 y=F(x)+x<br>identity mapping顾名思义，就是指本身，也就是公式中的x，而residual mapping指的是“差”，也就是y−x，所以残差指的就是F(x)部分。 </p>
<p>为什么ResNet可以解决“随着网络加深，准确率不下降”的问题？ </p>
<p>理论上，对于“随着网络加深，准确率下降”的问题，Resnet提供了两种选择方式，也就是identity mapping和residual mapping，如果网络已经到达最优，继续加深网络，residual mapping将被push为0，只剩下identity mapping，这样理论上网络一直处于最优状态了，网络的性能也就不会随着深度增加而降低了。</p>
<p>可以解决网络退化问题，缓解梯度消失的问题。</p>
<p><strong>2.ResNet结构</strong></p>
<p>它使用了一种连接方式叫做“shortcut connection”，顾名思义，shortcut就是“抄近道”的意思，看下图我们就能大致理解：</p>
<p><img src="https://gitee.com/browallia/tuchuang/raw/master/img/20201126204308.png" style="zoom:67%;"> </p>
<p><strong>ResNet的F(x)究竟长什么样子？</strong></p>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://blog.csdn.net/lanran2/article/details/79057994">ResNet解析</a></li>
<li><p><a href="https://blog.csdn.net/wspba/article/details/56019373">ResNet论文笔记</a></p>
</li>
<li><p><a href="https://www.jianshu.com/p/e58437f39f65">残差网络ResNet笔记</a></p>
</li>
<li><p><a href="https://blog.waya.ai/deep-residual-learning-9610bb62c355">Understand Deep Residual Networks — a simple, modular learning framework that has redefined state-of-the-art</a></p>
</li>
<li><p><a href="https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035">An Overview of ResNet and its Variants</a>     </p>
</li>
</ul>
<ul>
<li><a href="https://www.jianshu.com/p/46d76bd56766">译文</a></li>
<li><a href="https://medium.com/@14prakash/understanding-and-implementing-architectures-of-resnet-and-resnext-for-state-of-the-art-image-cf51669e1624">Understanding and Implementing Architectures of ResNet and ResNeXt for state-of-the-art Image Classification: From Microsoft to Facebook [Part 1]</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/28413039">给妹纸的深度学习教学(4)——同Residual玩耍</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/32173684">Residual Networks 理解</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/32206896">Identity Mapping in ResNet</a></li>
<li><a href="https://www.zhihu.com/question/53224378">resnet（残差网络）的F（x）究竟长什么样子？</a></li>
<li><a href="https://www.zhihu.com/question/64494691">ResNet到底在解决一个什么问题呢？</a></li>
</ul>
<p><strong>网络的深度为什么重要？</strong></p>
<p>因为CNN能够提取low/mid/high-level的特征，网络的层数越多，意味着能够提取到不同level的特征越丰富。并且，越深的网络提取的特征越抽象，越具有语义信息。</p>
<p><strong>为什么不能简单地增加网络层数？</strong></p>
<ul>
<li><p>对于原来的网络，如果简单地增加深度，会导致梯度弥散或梯度爆炸。</p>
</li>
<li><p>会出现另一个问题，就是<strong>退化问题</strong>，网络层数增加，但是在训练集上的准确率却饱和甚至下降了。这个不能解释为overfitting，因为overfit应该表现为在训练集上表现更好才对。退化问题说明了深度网络不能很简单地被很好地优化。</p>
<blockquote>
<p>F是求和前网络映射，H是从输入到求和后的网络映射。</p>
<p>比如把5映射到5.1，</p>
<p>那么引入残差前是F’(5)=5.1，</p>
<p>引入残差后是H(5)=5.1, H(5)=F(5)+5, F(5)=0.1。</p>
<p>这里的F’和F都表示网络参数映射，引入残差后的映射对输出的变化更敏感。比如原来是从5.1到5.2，映射F’的输出增加了1/51=2%，而对于残差结构从5.1到5.2，映射F是从0.1到0.2，增加了100%。明显后者输出变化对权重的调整作用更大，所以效果更好。</p>
<p>残差的思想都是去掉相同的主体部分，从而突出微小的变化，看到残差网络我第一反应就是差分放大器…</p>
</blockquote>
<p><img src="https://pic4.zhimg.com/80/v2-6c0aa95bc2bdc174b92453621c857fa7_720w.jpg" alt="img"></p>
</li>
</ul>
<h3 id="ResNet为什么不用Dropout"><a href="#ResNet为什么不用Dropout" class="headerlink" title="ResNet为什么不用Dropout?"></a>ResNet为什么不用Dropout?</h3><ul>
<li>[ ] TODO</li>
</ul>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://www.zhihu.com/question/325139089">https://www.zhihu.com/question/325139089</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/60923972">https://zhuanlan.zhihu.com/p/60923972</a></li>
</ul>
<h3 id="为什么-ResNet-不在一开始就使用residual-block-而是使用一个7×7的卷积？"><a href="#为什么-ResNet-不在一开始就使用residual-block-而是使用一个7×7的卷积？" class="headerlink" title="为什么 ResNet 不在一开始就使用residual block,而是使用一个7×7的卷积？"></a>为什么 ResNet 不在一开始就使用residual block,而是使用一个7×7的卷积？</h3><p>原因: 7x7卷积实际上是用来直接对<strong>输入图片</strong>降采样(early downsampling), 注意像7x7这样的大卷积核一般只出现在<strong>input layer</strong></p>
<p><strong>目的是:</strong>  尽可能<strong>保留原始图像的信息,</strong> 而不需要增加channels数.</p>
<p><strong>本质上是:</strong> 多channels的非线性激活层是非常昂贵的, 在<strong>input laye</strong>r用<strong>big kernel</strong>换多channels是划算的</p>
<p>注意一下, resnet接入residual block前pixel为56x56的layer, channels数才<strong>64</strong>, 但是同样大小的layer, 在vgg-19里已经有<strong>256</strong>个channels了.</p>
<p>这里要强调一下, 只有在input layer层, 也就是<strong>最靠近输入图片</strong>的那层, 才用大卷积, 原因如下:</p>
<p>深度学习领域, 有一种广泛的直觉，即更大的卷积更好，但更昂贵。输入层中的特征数量(224x224)是如此之小（相对于隐藏层），第一卷积可以非常大而不会大幅增加实际的权重数。<strong>如果你想在某个地方进行大卷积，第一层通常是唯一的选择</strong>。</p>
<p>我认为神经网络的第一层是最基本的，因为它基本上只是将数据嵌入到一个新的更大的向量空间中。ResNet在第二层之前没有开始其特征层跳过，所以看起来作者想要在开始整花里胡哨的layers之前尽可能保留图像里更多的primary features.</p>
<p>题外话, 同时期的GoogLeNet也在input layer用到了7x7大卷积, 所以resnet作者的灵感来源于GoogLeNet也说不定, 至于非要追问为啥这么用, 也许最直接的理由就是”深度学习就像炼丹, 因为这样网络工作得更好, 所以作者就这么用了”. </p>
<p>再说个有趣的例子, resnet模型是实验先于理论, 实验证明有效, 后面才陆续有人研究为啥有效, 比如<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1702.08591">The Shattered Gradients Problem: If resnets are the answer, then what is the question?</a>  可不就是炼丹么?</p>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://www.zhihu.com/question/330735327/answer/725695411">为什么resnet不在一开始就使用residual block,而是使用一个7×7的卷积？</a></li>
</ul>
<h3 id="什么是Bottlenet-layer？"><a href="#什么是Bottlenet-layer？" class="headerlink" title="什么是Bottlenet layer？"></a>什么是Bottlenet layer？</h3><p>对于常规ResNet，可以用于34层或者更少的网络中，对于Bottleneck Design的ResNet通常用于更深的如101这样的网络中，目的是减少计算和参数量（<strong>实用目的</strong>）。</p>
<h3 id="ResNet如何解决梯度消失？"><a href="#ResNet如何解决梯度消失？" class="headerlink" title="ResNet如何解决梯度消失？"></a>ResNet如何解决梯度消失？</h3><p>H(x) = F(x)+x</p>
<p>H’(x) = F’(x)+1</p>
<h3 id="ResNet网络越来越深，准确率会不会提升？"><a href="#ResNet网络越来越深，准确率会不会提升？" class="headerlink" title="ResNet网络越来越深，准确率会不会提升？"></a>ResNet网络越来越深，准确率会不会提升？</h3><ul>
<li>[ ] TODO</li>
</ul>
<h2 id="ResNet-v2"><a href="#ResNet-v2" class="headerlink" title="ResNet v2"></a>ResNet v2</h2><p><img src="https://gitee.com/browallia/tuchuang/raw/master/img/20201126220547.png" style="zoom:67%;"></p>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://arxiv.org/abs/1603.05027">《Identity Mappings in Deep Residual Networks》</a></li>
<li><a href="https://www.cnblogs.com/shouhuxianjian/p/7770658.html">Feature Extractor[ResNet v2]</a></li>
<li><a href="https://blog.csdn.net/lanran2/article/details/80247515">ResNetV2：ResNet深度解析</a></li>
<li><a href="https://blog.csdn.net/u014061630/article/details/80558661">ResNet v2论文笔记</a></li>
<li><a href="https://segmentfault.com/a/1190000011228906">[ResNet系] 002 ResNet-v2</a></li>
</ul>
<h3 id="ResNet-v1-与-ResNet-v2的区别"><a href="#ResNet-v1-与-ResNet-v2的区别" class="headerlink" title="ResNet v1 与 ResNet v2的区别"></a>ResNet v1 与 ResNet v2的区别</h3><p>原始的resnet是上图中的a的模式，我们可以看到相加后需要进入ReLU做一个非线性激活，这里一个改进就是砍掉了这个非线性激活，不难理解，<strong>如果将ReLU放在原先的位置，那么残差块输出永远是非负的，这制约了模型的表达能力</strong>，因此我们需要做一些调整，我们将这个ReLU移入了残差块内部，也就是图e的模式。</p>
<h3 id="ResNet-v2-的-ReLU-激活函数有什么不同？"><a href="#ResNet-v2-的-ReLU-激活函数有什么不同？" class="headerlink" title="ResNet v2 的 ReLU 激活函数有什么不同？"></a>ResNet v2 的 ReLU 激活函数有什么不同？</h3><ul>
<li>[ ] TODO</li>
</ul>
<h2 id="ResNeXt"><a href="#ResNeXt" class="headerlink" title="ResNeXt"></a>ResNeXt</h2><ul>
<li>[ ] TODO</li>
</ul>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://blog.csdn.net/u014380165/article/details/71667916">ResNeXt算法详解</a></li>
</ul>
<h2 id="学习率如何调整"><a href="#学习率如何调整" class="headerlink" title="学习率如何调整"></a>学习率如何调整</h2><ul>
<li>[ ] TODO</li>
</ul>
<h2 id="神经网络的深度和宽度作用"><a href="#神经网络的深度和宽度作用" class="headerlink" title="神经网络的深度和宽度作用"></a>神经网络的深度和宽度作用</h2><ul>
<li>[ ] TODO</li>
</ul>
<h2 id="网络压缩与量化"><a href="#网络压缩与量化" class="headerlink" title="网络压缩与量化"></a>网络压缩与量化</h2><ul>
<li>[ ] TODO</li>
</ul>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://blog.csdn.net/shuzfan/article/details/51678499">网络压缩-量化方法对比</a></li>
</ul>
<h2 id="Batch-Size"><a href="#Batch-Size" class="headerlink" title="Batch Size"></a>Batch Size</h2><ul>
<li>[ ] TODO</li>
</ul>
<p><strong>参考资料</strong></p>
<ul>
<li><p><a href="https://www.zhihu.com/question/61607442">怎么选取训练神经网络时的Batch size?</a></p>
</li>
<li><p><a href="https://blog.csdn.net/lien0906/article/details/79166196">谈谈深度学习中的 Batch_Size</a></p>
</li>
</ul>
<h2 id="BN和Dropout在训练和测试时的差别"><a href="#BN和Dropout在训练和测试时的差别" class="headerlink" title="BN和Dropout在训练和测试时的差别"></a>BN和Dropout在训练和测试时的差别</h2><ul>
<li>[ ] TODO</li>
</ul>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/61725100">BN和Dropout在训练和测试时的差别</a></li>
</ul>
<h2 id="深度学习调参有哪些技巧？"><a href="#深度学习调参有哪些技巧？" class="headerlink" title="深度学习调参有哪些技巧？"></a>深度学习调参有哪些技巧？</h2><p><strong>参考资料</strong></p>
<ul>
<li><a href="https://www.zhihu.com/question/25097993/answer/651617880">https://www.zhihu.com/question/25097993/answer/651617880</a></li>
</ul>
<h2 id="为什么深度学习中的模型基本用3x3和5x5的卷积（奇数），而不是2x2和4x4的卷积（偶数）？"><a href="#为什么深度学习中的模型基本用3x3和5x5的卷积（奇数），而不是2x2和4x4的卷积（偶数）？" class="headerlink" title="为什么深度学习中的模型基本用3x3和5x5的卷积（奇数），而不是2x2和4x4的卷积（偶数）？"></a>为什么深度学习中的模型基本用3x3和5x5的卷积（奇数），而不是2x2和4x4的卷积（偶数）？</h2><p><strong>参考资料</strong></p>
<ul>
<li><a href="https://www.zhihu.com/question/321773456">https://www.zhihu.com/question/321773456</a></li>
</ul>
<h2 id="深度学习训练中是否有必要使用L1获得稀疏解"><a href="#深度学习训练中是否有必要使用L1获得稀疏解" class="headerlink" title="深度学习训练中是否有必要使用L1获得稀疏解?"></a>深度学习训练中是否有必要使用L1获得稀疏解?</h2><ul>
<li>[ ] TODO</li>
</ul>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://www.zhihu.com/question/51822759">https://www.zhihu.com/question/51822759</a></li>
</ul>
<h2 id="EfficientNet"><a href="#EfficientNet" class="headerlink" title="EfficientNet"></a>EfficientNet</h2><ul>
<li>[ ] TODO</li>
</ul>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://www.zhihu.com/question/326833457">如何评价谷歌大脑的EfficientNet？</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/67834114">EfficientNet-可能是迄今为止最好的CNN网络</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/70369784">EfficientNet论文解读</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/69349360">EfficientNet：调参侠的福音（ICML 2019）</a></li>
</ul>
<h2 id="如何理解归一化（Normalization）对于神经网络（深度学习）的帮助？"><a href="#如何理解归一化（Normalization）对于神经网络（深度学习）的帮助？" class="headerlink" title="如何理解归一化（Normalization）对于神经网络（深度学习）的帮助？"></a>如何理解归一化（Normalization）对于神经网络（深度学习）的帮助？</h2><p>BN最早被认为通过降低所谓<strong>Internal Covariate Shift</strong>，这种想法的出处可考至<a href="https://link.zhihu.com/?target=http%3A//proceedings.mlr.press/v9/glorot10a/glorot10a.pdf">Understanding the difficulty of training deep feedforward neural networks</a>，想必这也是batch norm作者这么设计的初衷。但是这种想法并没有过多实验支持，比如说去年NeurlPS这篇paper作者做了实验，在batch norm之后加上一些随机扰动（non-zero mean and non-unit variance，人为引入covariate shift），发现效果仍然比不加好很多。为什么放在batch norm layer之后而不是之前？因为为了证伪batch norm通过forward pass这一步降低covariate shift来提升网络训练效率的。这样说来故事就变得很有趣了，也就是说我们大概都理解一些BN对BN层之前网络噪音的好处，那么能不能研究一下它对它后面layer的影响？所以这些研究从优化的角度，有如下几种观点。</p>
<ol>
<li>BN通过修改loss function， 可以令loss的和loss的梯度均满足更强的Lipschitzness性质（即函数f满足L-Lipschitz和 <img src="https://www.zhihu.com/equation?tex=%5Cbeta" alt="[公式]"> -smooth，令L和 <img src="https://www.zhihu.com/equation?tex=%5Cbeta" alt="[公式]"> 更小，后者其实等同于f Hessian的eigenvalue小于 <img src="https://www.zhihu.com/equation?tex=%5Cbeta" alt="[公式]"> ，可以作为光滑程度的度量，其实吧我觉得，一般convex optimization里拿这个度量算convergence rate是神器，对于non-convex optimization，不懂鸭，paper里好像也没写的样子），这么做的好处是当步子迈得大的时候，我们可以更自信地告诉自己计算出来的梯度可以更好地近似实际的梯度，因此也不容易让优化掉进小坑里。有意思的地方来了，是不是我在某些地方插入一个1/1000 layer，把梯度的L-Lipschitz变成1/1000L-Lipschitz就能让函数优化的更好了呢？其实不是的，因为单纯除以函数会改变整个优化问题，而BN做了不仅仅rescale这件事情，还让原来近似最优的点在做完变化之后，仍然保留在原来不远的位置。这也就是这篇文章的核心论点，BN做的是问题reparametrization而不是简单的scaling。 [1]</li>
<li>BN把优化这件事情分解成了优化参数的方向和长度两个任务，这么做呢可以解耦层与层之间的dependency因此会让curvature结构更易于优化。这篇证了convergence rate，但由于没有认真读，所以感觉没太多资格评价。[2]</li>
</ol>
<p>归一化手段是否殊途同归？很可能是的，在[1]的3.3作者也尝试了Lp normalization，也得到了和BN差不多的效果。至于Layer norm还是weight norm，可能都可以顺着这个思路进行研究鸭，无论是通过[1]还是[2]，可能今年的paper里就见分晓了，let’s see。</p>
<ol>
<li><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1805.11604">How Does Batch Normalization Help Optimization?</a> </li>
<li><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1805.10694">Exponential convergence rates for Batch Normalization: The power of length-direction decoupling in non-convex optimization</a></li>
</ol>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://www.zhihu.com/question/326034346/answer/708331566">如何理解归一化（Normalization）对于神经网络（深度学习）的帮助？</a></li>
</ul>
<h2 id="多标签分类怎么解决？"><a href="#多标签分类怎么解决？" class="headerlink" title="多标签分类怎么解决？"></a>多标签分类怎么解决？</h2><p>TODO</p>
<h2 id="反卷积（deconv）-转置卷积（trans）"><a href="#反卷积（deconv）-转置卷积（trans）" class="headerlink" title="反卷积（deconv）/转置卷积（trans）"></a>反卷积（deconv）/转置卷积（trans）</h2><p><strong>参考资料</strong></p>
<ul>
<li><a href="https://blog.csdn.net/a_a_ron/article/details/79181108">反卷积(Deconvolution)、上采样(UNSampling)与上池化(UnPooling)</a></li>
<li><a href="https://buptldy.github.io/2016/10/29/2016-10-29-deconv/">Transposed Convolution, Fractionally Strided Convolution or Deconvolution</a></li>
</ul>
<h2 id="空洞卷积（dilated-Atrous-conv）"><a href="#空洞卷积（dilated-Atrous-conv）" class="headerlink" title="空洞卷积（dilated/Atrous conv）"></a>空洞卷积（dilated/Atrous conv）</h2><ul>
<li>[ ] TODO</li>
</ul>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://www.zhihu.com/question/54149221">如何理解空洞卷积（dilated convolution）？</a></li>
</ul>
<h2 id="Pooling层原理"><a href="#Pooling层原理" class="headerlink" title="Pooling层原理"></a>Pooling层原理</h2><ul>
<li>[ ] TODO</li>
</ul>
<h2 id="depthwise卷积加速比推导"><a href="#depthwise卷积加速比推导" class="headerlink" title="depthwise卷积加速比推导"></a>depthwise卷积加速比推导</h2><ul>
<li>[ ] TODO</li>
</ul>
<h2 id="为什么降采用使用max-pooling，而分类使用average-pooling"><a href="#为什么降采用使用max-pooling，而分类使用average-pooling" class="headerlink" title="为什么降采用使用max pooling，而分类使用average pooling"></a>为什么降采用使用max pooling，而分类使用average pooling</h2><ul>
<li>[ ] TODO</li>
</ul>
<h2 id="max-pooling如何反向传播"><a href="#max-pooling如何反向传播" class="headerlink" title="max pooling如何反向传播"></a>max pooling如何反向传播</h2><ul>
<li>[ ] TODO</li>
</ul>
<h2 id="反卷积"><a href="#反卷积" class="headerlink" title="反卷积"></a>反卷积</h2><p>TODO</p>
<h2 id="组卷积（group-convolution）"><a href="#组卷积（group-convolution）" class="headerlink" title="组卷积（group convolution）"></a>组卷积（group convolution）</h2><ul>
<li>[ ] TODO</li>
</ul>
<p>在说明分组卷积之前我们用一张图来体会一下一般的卷积操作。 </p>
<p><img src="https://gitee.com/browallia/tuchuang/raw/master/img/20201126220834.png" style="zoom:80%;"></p>
<p>从上图可以看出，一般的卷积会对输入数据的整体一起做卷积操作，即输入数据：H1×W1×C1；而卷积核大小为h1×w1，通道为C1，一共有C2个，然后卷积得到的输出数据就是H2×W2×C2。这里我们假设输出和输出的分辨率是不变的。主要看这个过程是一气呵成的，这对于存储器的容量提出了更高的要求。 </p>
<p>但是分组卷积明显就没有那么多的参数。先用图片直观地感受一下分组卷积的过程。对于上面所说的同样的一个问题，分组卷积就如下图所示。 </p>
<p><img src="https://gitee.com/browallia/tuchuang/raw/master/img/20201126220857.png" style="zoom:67%;"></p>
<p>可以看到，图中将输入数据分成了2组（组数为g），需要注意的是，这种分组只是在深度上进行划分，即某几个通道编为一组，这个具体的数量由（C1/g）决定。因为输出数据的改变，相应的，卷积核也需要做出同样的改变。即每组中卷积核的深度也就变成了（C1/g），而卷积核的大小是不需要改变的，此时每组的卷积核的个数就变成了（C2/g）个，而不是原来的C2了。然后用每组的卷积核同它们对应组内的输入数据卷积，得到了输出数据以后，再用concatenate的方式组合起来，最终的输出数据的通道仍旧是C2。也就是说，分组数g决定以后，那么我们将并行的运算g个相同的卷积过程，每个过程里（每组），输入数据为H1×W1×C1/g，卷积核大小为h1×w1×C1/g，一共有C2/g个，输出数据为H2×W2×C2/g。</p>
<p>举个例子：</p>
<p>Group conv本身就极大地减少了参数。比如当输入通道为256，输出通道也为256，kernel size为3×3，不做Group conv参数为256×3×3×256。实施分组卷积时，若group为8，每个group的input channel和output channel均为32，参数为8×32×3×3×32，是原来的八分之一。而Group conv最后每一组输出的feature maps应该是以concatenate的方式组合。<br>Alex认为group conv的方式能够增加 filter之间的对角相关性，而且能够减少训练参数，不容易过拟合，这类似于正则的效果。</p>
<p><strong>参考资料</strong></p>
<ul>
<li><p><a href="https://blog.yani.io/filter-group-tutorial/">A Tutorial on Filter Groups (Grouped Convolution)</a></p>
</li>
<li><p><a href="https://blog.csdn.net/chaolei3/article/details/79374563">深度可分离卷积、分组卷积、扩张卷积、转置卷积（反卷积）的理解</a></p>
</li>
</ul>
<h2 id="交错组卷积（Interleaved-group-convolutions，IGC）"><a href="#交错组卷积（Interleaved-group-convolutions，IGC）" class="headerlink" title="交错组卷积（Interleaved group convolutions，IGC）"></a>交错组卷积（Interleaved group convolutions，IGC）</h2><p><strong>参考资料</strong></p>
<ul>
<li><a href="https://www.sohu.com/a/161110049_465975">学界 | MSRA王井东详解ICCV 2017入选论文：通用卷积神经网络交错组卷积</a></li>
<li><a href="https://edu.csdn.net/course/play/8320/171433?s=1">视频：基于交错组卷积的高效深度神经网络</a></li>
</ul>
<h2 id="空洞-扩张卷积（Dilated-Atrous-Convolution）"><a href="#空洞-扩张卷积（Dilated-Atrous-Convolution）" class="headerlink" title="空洞/扩张卷积（Dilated/Atrous Convolution）"></a>空洞/扩张卷积（Dilated/Atrous Convolution）</h2><p>Dilated convolution/Atrous convolution可以叫空洞卷积或者扩张卷积。</p>
<p>背景：语义分割中pooling 和 up-sampling layer层。pooling会降低图像尺寸的同时增大感受野，而up-sampling操作扩大图像尺寸，这样虽然恢复了大小，但很多细节被池化操作丢失了。</p>
<p>需求：能不能设计一种新的操作，不通过pooling也能有较大的感受野看到更多的信息呢？</p>
<p>目的：替代pooling和up-sampling运算，既增大感受野又不减小图像大小。</p>
<p>简述：在标准的 convolution map 里注入空洞，以此来增加 reception field。相比原来的正常convolution，dilated convolution 多了一个 hyper-parameter 称之为 dilation rate 指的是kernel的间隔数量(e.g. 正常的 convolution 是 dilatation rate 1)。</p>
<p>空洞卷积诞生于图像分割领域，图像输入到网络中经过CNN提取特征，再经过pooling降低图像尺度的同时增大感受野。由于图像分割是pixel−wise预测输出，所以还需要通过upsampling将变小的图像恢复到原始大小。upsampling通常是通过deconv(转置卷积)完成。因此图像分割FCN有两个关键步骤：池化操作增大感受野，upsampling操作扩大图像尺寸。这儿有个问题，就是虽然图像经过upsampling操作恢复了大小，但是很多细节还是被池化操作丢失了。那么有没有办法既增大了感受野又不减小图像大小呢？Dilated conv横空出世。</p>
<p><img src="/2020/10/19/DL%E9%9D%A2%E8%AF%95%E7%9F%A5%E8%AF%86%E7%82%B9/Users/58341/Desktop/Deep-L/Deep-Learning-Interview-Book/docs/imgs/DLIB-0016.png" alt="image.png"></p>
<p>注意事项：</p>
<p>1.为什么不直接使用5x5或者7x7的卷积核？这不也增加了感受野么？</p>
<p>答：增大卷积核能增大感受野，但是只是线性增长，参考答案里的那个公式，(kernel-1)*layer，并不能达到空洞卷积的指数增长。</p>
<p>2.2-dilated要在1-dilated的基础上才能达到7的感受野（如上图a、b所示）</p>
<p>关于空洞卷积的另一种概括：</p>
<p>Dilated Convolution问题的引出，是因为down-sample之后的为了让input和output的尺寸一致。我们需要up-sample，但是up-sample会丢失信息。如果不采用pooling，就无需下采样和上采样步骤了。但是这样会导致kernel 的感受野变小，导致预测不精确。。如果采用大的kernel话，一来训练的参数变大。二来没有小的kernel叠加的正则作用，所以kernel size变大行不通。</p>
<p>由此Dilated Convolution是在不改变kernel size的条件下，增大感受野。</p>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://arxiv.org/abs/1511.07122">《Multi-Scale Context Aggregation by Dilated Convolutions》</a> </li>
<li><p><a href="https://arxiv.org/abs/1706.05587">《Rethinking Atrous Convolution for Semantic Image Segmentation》</a></p>
</li>
<li><p><a href="https://www.zhihu.com/question/54149221">如何理解空洞卷积（dilated convolution）？</a></p>
</li>
<li><p><a href="https://blog.csdn.net/silence2015/article/details/79748729">Dilated/Atrous conv 空洞卷积/多孔卷积</a></p>
</li>
<li><p><a href="https://blog.csdn.net/guvcolie/article/details/77884530?locationNum=10&amp;fps=1">Multi-Scale Context Aggregation by Dilated Convolution 对空洞卷积（扩张卷积）、感受野的理解</a></p>
</li>
<li><p><a href="https://blog.csdn.net/chaolei3/article/details/79374563">对深度可分离卷积、分组卷积、扩张卷积、转置卷积（反卷积）的理解</a></p>
</li>
<li><p><a href="https://tensorflow.google.cn/api_docs/python/tf/nn/atrous_conv2d">tf.nn.atrous_conv2d</a></p>
</li>
</ul>
<h2 id="转置卷积（Transposed-Convolutions-deconvlution）"><a href="#转置卷积（Transposed-Convolutions-deconvlution）" class="headerlink" title="转置卷积（Transposed Convolutions/deconvlution）"></a>转置卷积（Transposed Convolutions/deconvlution）</h2><p>转置卷积（transposed Convolutions）又名反卷积（deconvolution）或是分数步长卷积（fractially straced convolutions）。反卷积（Transposed Convolution, Fractionally Strided Convolution or Deconvolution）的概念第一次出现是 Zeiler 在2010年发表的论文 Deconvolutional networks 中。</p>
<p><strong>转置卷积和反卷积的区别</strong></p>
<p>那什么是反卷积？从字面上理解就是卷积的逆过程。值得注意的反卷积虽然存在，但是在深度学习中并不常用。而转置卷积虽然又名反卷积，却不是真正意义上的反卷积。因为根据反卷积的数学含义，通过反卷积可以将通过卷积的输出信号，完全还原输入信号。而事实是，转置卷积只能还原shape大小，而不能还原value。你可以理解成，至少在数值方面上，转置卷积不能实现卷积操作的逆过程。所以说转置卷积与真正的反卷积有点相似，因为两者产生了相同的空间分辨率。但是又名反卷积（deconvolutions）的这种叫法是不合适的，因为它不符合反卷积的概念。</p>
<p>简单来说，转置矩阵就是一种上采样过程。</p>
<p>正常卷积过程如下，利用3x3的卷积核对4x4的输入进行卷积，输出结果为2x2</p>
<p><img src="https://github.com/vdumoulin/conv_arithmetic/blob/master/gif/no_padding_no_strides.gif?raw=true" alt="卷积过程"></p>
<p>转置卷积过程如下，利用3x3的卷积核对”做了补0”的2x2输入进行卷积，输出结果为4x4。</p>
<p><img src="https://github.com/vdumoulin/conv_arithmetic/blob/master/gif/no_padding_no_strides_transposed.gif?raw=true" alt="转置卷积"></p>
<p>上述的卷积运算和转置卷积是”尺寸”对应的，卷积的输入大小与转置卷积的输出大小一致，分别可以看成下采样和上采样操作。</p>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://buptldy.github.io/2016/10/29/2016-10-29-deconv/">Transposed Convolution, Fractionally Strided Convolution or Deconvolution</a></li>
<li>[深度学习 | 反卷积/转置卷积 的理解 transposed conv/deconv](</li>
</ul>
<h2 id="Inception系列（V1-V4）"><a href="#Inception系列（V1-V4）" class="headerlink" title="Inception系列（V1-V4）"></a>Inception系列（V1-V4）</h2><h3 id="InceptionV1"><a href="#InceptionV1" class="headerlink" title="InceptionV1"></a>InceptionV1</h3><ul>
<li>[ ] TODO</li>
</ul>
<h3 id="InceptionV2"><a href="#InceptionV2" class="headerlink" title="InceptionV2"></a>InceptionV2</h3><ul>
<li>[ ] TODO</li>
</ul>
<h3 id="InceptionV3"><a href="#InceptionV3" class="headerlink" title="InceptionV3"></a>InceptionV3</h3><ul>
<li>[ ] TODO</li>
</ul>
<h3 id="InceptionV4"><a href="#InceptionV4" class="headerlink" title="InceptionV4"></a>InceptionV4</h3><ul>
<li>[ ] TODO</li>
</ul>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://baijiahao.baidu.com/s?id=1601882944953788623&amp;wfr=spider&amp;for=pc">一文概览Inception家族的「奋斗史」</a></li>
<li><a href="https://blog.csdn.net/weixin_39953502/article/details/80966046">inception-v1,v2,v3,v4——论文笔记</a></li>
</ul>
<h2 id="DenseNet"><a href="#DenseNet" class="headerlink" title="DenseNet"></a>DenseNet</h2><ul>
<li>[ ] TODO</li>
</ul>
<h3 id="为什么-DenseNet-比-ResNet-好？"><a href="#为什么-DenseNet-比-ResNet-好？" class="headerlink" title="为什么 DenseNet 比 ResNet 好？"></a>为什么 DenseNet 比 ResNet 好？</h3><ul>
<li>[ ] TODO</li>
</ul>
<h3 id="为什么-DenseNet-比-ResNet-更耗显存？"><a href="#为什么-DenseNet-比-ResNet-更耗显存？" class="headerlink" title="为什么 DenseNet 比 ResNet 更耗显存？"></a>为什么 DenseNet 比 ResNet 更耗显存？</h3><ul>
<li>[ ] TODO</li>
</ul>
<h2 id="SE-Net"><a href="#SE-Net" class="headerlink" title="SE-Net"></a>SE-Net</h2><ul>
<li>[ ] TODO</li>
</ul>
<h3 id="Squeeze-Excitation结构是怎么实现的？"><a href="#Squeeze-Excitation结构是怎么实现的？" class="headerlink" title="Squeeze-Excitation结构是怎么实现的？"></a>Squeeze-Excitation结构是怎么实现的？</h3><p>TODO</p>
<h2 id="FCN"><a href="#FCN" class="headerlink" title="FCN"></a>FCN</h2><p>一句话概括就是：FCN将传统网络后面的全连接层换成了卷积层，这样网络输出不再是类别而是 heatmap；同时为了解决因为卷积和池化对图像尺寸的影响，提出使用上采样的方式恢复。</p>
<p>作者的FCN主要使用了三种技术：</p>
<ul>
<li><p>卷积化（Convolutional）</p>
</li>
<li><p>上采样（Upsample）</p>
</li>
<li>跳跃结构（Skip Layer）</li>
</ul>
<p>卷积化</p>
<p>卷积化即是将普通的分类网络，比如VGG16，ResNet50/101等网络丢弃全连接层，换上对应的卷积层即可。</p>
<p>上采样</p>
<p>此处的上采样即是反卷积（Deconvolution）。当然关于这个名字不同框架不同，Caffe和Kera里叫Deconvolution，而tensorflow里叫conv_transpose。CS231n这门课中说，叫conv_transpose更为合适。</p>
<p>众所诸知，普通的池化（为什么这儿是普通的池化请看后文）会缩小图片的尺寸，比如VGG16 五次池化后图片被缩小了32倍。为了得到和原图等大的分割图，我们需要上采样/反卷积。</p>
<p>反卷积和卷积类似，都是相乘相加的运算。只不过后者是多对一，前者是一对多。而反卷积的前向和后向传播，只用颠倒卷积的前后向传播即可。所以无论优化还是后向传播算法都是没有问题。</p>
<p>跳跃结构（Skip Layers）</p>
<p>（这个奇怪的名字是我翻译的，好像一般叫忽略连接结构）这个结构的作用就在于优化结果，因为如果将全卷积之后的结果直接上采样得到的结果是很粗糙的，所以作者将不同池化层的结果进行上采样之后来优化输出。</p>
<p>上采样获得与输入一样的尺寸<br>文章采用的网络经过5次卷积+池化后，图像尺寸依次缩小了 2、4、8、16、32倍，对最后一层做32倍上采样，就可以得到与原图一样的大小</p>
<p>作者发现，仅对第5层做32倍反卷积（deconvolution），得到的结果不太精确。于是将第 4 层和第 3 层的输出也依次反卷积（图５）</p>
<p><strong>参考资料</strong></p>
<p><a href="https://zhuanlan.zhihu.com/p/22308032">【总结】图像语义分割之FCN和CRF</a></p>
<p><a href="https://blog.csdn.net/zizi7/article/details/77093447">图像语义分割（1）- FCN</a></p>
<p><a href="https://www.cnblogs.com/gujianhan/p/6030639.html">全卷积网络 FCN 详解</a></p>
<h2 id="U-Net"><a href="#U-Net" class="headerlink" title="U-Net"></a>U-Net</h2><p>本文介绍一种编码器-解码器结构。编码器逐渐减少池化层的空间维度，解码器逐步修复物体的细节和空间维度。编码器和解码器之间通常存在快捷连接，因此能帮助解码器更好地修复目标的细节。U-Net 是这种方法中最常用的结构。</p>
<p>fcn(fully convolutional natwork)的思想是：修改一个普通的逐层收缩的网络，用上采样(up sampling)(？？反卷积)操作代替网络后部的池化(pooling)操作。因此，这些层增加了输出的分辨率。为了使用局部的信息，在网络收缩过程（路径）中产生的高分辨率特征(high resolution features) ，被连接到了修改后网络的上采样的结果上。在此之后，一个卷积层基于这些信息综合得到更精确的结果。</p>
<p>与fcn(fully convolutional natwork)不同的是，我们的网络在上采样部分依然有大量的特征通道(feature channels)，这使得网络可以将环境信息向更高的分辨率层(higher resolution layers)传播。结果是，扩张路径基本对称于收缩路径。网络不存在任何全连接层(fully connected layers)，并且，只使用每个卷积的有效部分，例如，分割图(segmentation map)只包含这样一些像素点，这些像素点的完整上下文都出现在输入图像中。为了预测图像边界区域的像素点，我们采用镜像图像的方式补全缺失的环境像素。这个tiling方法在使用网络分割大图像时是非常有用的，因为如果不这么做，GPU显存会限制图像分辨率。<br>我们的训练数据太少，因此我们采用弹性形变的方式增加数据。这可以让模型学习得到形变不变性。这对医学图像分割是非常重要的，因为组织的形变是非常常见的情况，并且计算机可以很有效的模拟真实的形变。在[3]中指出了在无监督特征学习中，增加数据以获取不变性的重要性。</p>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://blog.csdn.net/natsuka/article/details/78565229">U-net翻译</a></li>
</ul>
<h2 id="DeepLab-系列"><a href="#DeepLab-系列" class="headerlink" title="DeepLab 系列"></a>DeepLab 系列</h2><ul>
<li>[ ] TODO</li>
</ul>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://blog.csdn.net/u011974639/article/details/79148719">Semantic Segmentation —DeepLab(1,2,3)系列总结</a></li>
</ul>
<h2 id="边框回顾（Bounding-Box-Regression）"><a href="#边框回顾（Bounding-Box-Regression）" class="headerlink" title="边框回顾（Bounding-Box Regression）"></a>边框回顾（Bounding-Box Regression）</h2><p>如下图所示，绿色的框表示真实值Ground Truth, 红色的框为Selective Search提取的候选区域/框Region Proposal。那么即便红色的框被分类器识别为飞机，但是由于红色的框定位不准(IoU&lt;0.5)， 这张图也相当于没有正确的检测出飞机。</p>
<p><img src="https://www.julyedu.com/Public/Image/Question/1525499418_635.png" alt></p>
<p>如果我们能对红色的框进行微调fine-tuning，使得经过微调后的窗口跟Ground Truth 更接近， 这样岂不是定位会更准确。 而Bounding-box regression 就是用来微调这个窗口的。</p>
<p>边框回归是什么？</p>
<p>对于窗口一般使用四维向量(x,y,w,h)(x,y,w,h) 来表示， 分别表示窗口的中心点坐标和宽高。 对于图2, 红色的框 P 代表原始的Proposal, 绿色的框 G 代表目标的 Ground Truth， 我们的目标是寻找一种关系使得输入原始的窗口 P 经过映射得到一个跟真实窗口 G 更接近的回归窗口G^。</p>
<p><img src="https://www.julyedu.com/Public/Image/Question/1525499529_241.png" alt></p>
<p>所以，边框回归的目的即是：给定(Px,Py,Pw,Ph)寻找一种映射f， 使得f(Px,Py,Pw,Ph)=(Gx^,Gy^,Gw^,Gh^)并且(Gx^,Gy^,Gw^,Gh^)≈(Gx,Gy,Gw,Gh)</p>
<p>边框回归怎么做的？</p>
<p>那么经过何种变换才能从图2中的窗口 P 变为窗口G^呢？ 比较简单的思路就是: 平移+尺度放缩</p>
<p>先做平移(Δx,Δy)，Δx=Pwdx(P),Δy=Phdy(P)这是R-CNN论文的：<br>G^x=Pwdx(P)+Px,(1)<br>G^y=Phdy(P)+Py,(2)</p>
<p>然后再做尺度缩放(Sw,Sh), Sw=exp(dw(P)),Sh=exp(dh(P)),对应论文中：<br>G^w=Pwexp(dw(P)),(3)<br>G^h=Phexp(dh(P)),(4)</p>
<p>观察(1)-(4)我们发现， 边框回归学习就是dx(P),dy(P),dw(P),dh(P)这四个变换。</p>
<p>下一步就是设计算法那得到这四个映射。</p>
<p>线性回归就是给定输入的特征向量 X, 学习一组参数 W, 使得经过线性回归后的值跟真实值 Y(Ground Truth)非常接近. 即Y≈WX。 那么 Bounding-box 中我们的输入以及输出分别是什么呢？</p>
<p>Input:<br>RegionProposal→P=(Px,Py,Pw,Ph)这个是什么？ 输入就是这四个数值吗？其实真正的输入是这个窗口对应的 CNN 特征，也就是 R-CNN 中的 Pool5 feature（特征向量）。 (注：训练阶段输入还包括 Ground Truth， 也就是下边提到的t∗=(tx,ty,tw,th))</p>
<p>Output:<br>需要进行的平移变换和尺度缩放 dx(P),dy(P),dw(P),dh(P)，或者说是Δx,Δy,Sw,Sh。我们的最终输出不应该是 Ground Truth 吗？ 是的， 但是有了这四个变换我们就可以直接得到 Ground Truth。</p>
<p>这里还有个问题， 根据(1)~(4)我们可以知道， P 经过 dx(P),dy(P),dw(P),dh(P)得到的并不是真实值 G，而是预测值G^。的确，这四个值应该是经过 Ground Truth 和 Proposal 计算得到的真正需要的平移量(tx,ty)和尺度缩放(tw,th)。 </p>
<p>这也就是 R-CNN 中的(6)~(9)：<br>tx=(Gx−Px)/Pw,(6)</p>
<p>ty=(Gy−Py)/Ph,(7)</p>
<p>tw=log(Gw/Pw),(8)</p>
<p>th=log(Gh/Ph),(9)</p>
<p>那么目标函数可以表示为 d∗(P)=wT∗Φ5(P)，Φ5(P)是输入 Proposal 的特征向量，w∗是要学习的参数（*表示 x,y,w,h， 也就是每一个变换对应一个目标函数） , d∗(P) 是得到的预测值。</p>
<p>我们要让预测值跟真实值t∗=(tx,ty,tw,th)差距最小， 得到损失函数为：<br>Loss=∑iN(ti∗−w^T∗ϕ5(Pi))2</p>
<p>函数优化目标为：</p>
<p>W∗=argminw∗∑iN(ti∗−w^T∗ϕ5(Pi))2+λ||w^∗||2</p>
<p>利用梯度下降法或者最小二乘法就可以得到 w∗。</p>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="http://caffecn.cn/?/question/160">bounding box regression</a></li>
<li><p><a href="https://blog.csdn.net/zijin0802034/article/details/77685438">边框回归(Bounding Box Regression)详解</a></p>
</li>
<li><p><a href="https://www.julyedu.com/question/big/kp_id/26/ques_id/2139">什么是边框回归Bounding-Box regression，以及为什么要做、怎么做</a></p>
</li>
<li><p><a href="https://blog.csdn.net/u014722627/article/details/60574260">https://blog.csdn.net/u014722627/article/details/60574260</a>)</p>
</li>
</ul>
<h2 id="Xception"><a href="#Xception" class="headerlink" title="Xception"></a>Xception</h2><ul>
<li>[ ] TODO</li>
</ul>
<h2 id="SENet"><a href="#SENet" class="headerlink" title="SENet"></a>SENet</h2><p><strong>SENet</strong></p>
<p>论文：《Squeeze-and-Excitation Networks》 </p>
<p>论文链接：<a href="https://arxiv.org/abs/1709.01507">https://arxiv.org/abs/1709.01507</a> </p>
<p>代码地址：<a href="https://github.com/hujie-frank/SENet">https://github.com/hujie-frank/SENet</a></p>
<p>论文的动机是从特征通道之间的关系入手，希望显式地建模特征通道之间的相互依赖关系。另外，没有引入一个新的空间维度来进行特征通道间的融合，而是采用了一种全新的“特征重标定”策略。具体来说，就是通过学习的方式来自动获取到每个特征通道的重要程度，然后依照这个重要程度去增强有用的特征并抑制对当前任务用处不大的特征，通俗来讲，就是让网络利用全局信息有选择的增强有益feature通道并抑制无用feature通道，从而能实现feature通道自适应校准。 </p>
<p><img src="/2020/10/19/DL%E9%9D%A2%E8%AF%95%E7%9F%A5%E8%AF%86%E7%82%B9/Users/58341/Desktop/Deep-L/Deep-Learning-Interview-Book/docs/imgs/DLIB-0017.png" alt="Schema of SE-Inception and SE-ResNet modules"></p>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://blog.csdn.net/xjz18298268521/article/details/79078551">SENet学习笔记</a></li>
</ul>
<h2 id="SKNet"><a href="#SKNet" class="headerlink" title="SKNet"></a>SKNet</h2><ul>
<li>[ ] TODO</li>
</ul>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/59690223">SKNet——SENet孪生兄弟篇</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/60187262">后ResNet时代：SENet与SKNet</a></li>
</ul>
<h2 id="GCNet"><a href="#GCNet" class="headerlink" title="GCNet"></a>GCNet</h2><ul>
<li>[ ] TODO</li>
</ul>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/64988633">GCNet：当Non-local遇见SENet</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/65776424">2019 GCNet（attention机制，目标检测backbone性能提升）论文阅读笔记</a></li>
</ul>
<h2 id="Octave-Convolution"><a href="#Octave-Convolution" class="headerlink" title="Octave Convolution"></a>Octave Convolution</h2><ul>
<li>[ ] TODO</li>
</ul>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://www.zhihu.com/question/320462422/">如何评价最新的Octave Convolution？</a></li>
</ul>
<h2 id="MobileNet-系列（V1-V3）"><a href="#MobileNet-系列（V1-V3）" class="headerlink" title="MobileNet 系列（V1-V3）"></a>MobileNet 系列（V1-V3）</h2><ul>
<li>[ ] TODO</li>
</ul>
<h3 id="MobileNetV1"><a href="#MobileNetV1" class="headerlink" title="MobileNetV1"></a>MobileNetV1</h3><p><strong>参考资料</strong></p>
<ul>
<li><a href="https://blog.csdn.net/t800ghb/article/details/78879612">深度解读谷歌MobileNet</a></li>
</ul>
<h3 id="MobileNetV2"><a href="#MobileNetV2" class="headerlink" title="MobileNetV2"></a>MobileNetV2</h3><ul>
<li>[ ] TODO</li>
</ul>
<h3 id="MobileNetV3"><a href="#MobileNetV3" class="headerlink" title="MobileNetV3"></a>MobileNetV3</h3><ul>
<li><p>[ ] TODO</p>
</li>
<li><p><a href="https://www.zhihu.com/question/323419310">如何评价google Searching for MobileNetV3？</a></p>
</li>
</ul>
<h3 id="MobileNet系列为什么快？各有多少层？多少参数？"><a href="#MobileNet系列为什么快？各有多少层？多少参数？" class="headerlink" title="MobileNet系列为什么快？各有多少层？多少参数？"></a>MobileNet系列为什么快？各有多少层？多少参数？</h3><ul>
<li>[ ] TODO</li>
</ul>
<h3 id="MobileNetV1、MobileNetV2和MobileNetV3有什么区别"><a href="#MobileNetV1、MobileNetV2和MobileNetV3有什么区别" class="headerlink" title="MobileNetV1、MobileNetV2和MobileNetV3有什么区别"></a>MobileNetV1、MobileNetV2和MobileNetV3有什么区别</h3><p>MobileNetv1：在depthwise separable convolutions（参考Xception）方法的基础上提供了高校模型设计的两个选择：宽度因子（width multiplie）和分辨率因子（resolution multiplier）。深度可分离卷积depthwise separable convolutions（参考Xception）的本质是冗余信息更小的稀疏化表达。</p>
<p>下面介绍两幅Xception中 depthwise separable convolution的图示：</p>
<p><img src="/2020/10/19/DL%E9%9D%A2%E8%AF%95%E7%9F%A5%E8%AF%86%E7%82%B9/Users/58341/Desktop/Deep-L/Deep-Learning-Interview-Book/docs/imgs/DLIB-0018.png" alt="image.png"></p>
<p><img src="/2020/10/19/DL%E9%9D%A2%E8%AF%95%E7%9F%A5%E8%AF%86%E7%82%B9/Users/58341/Desktop/Deep-L/Deep-Learning-Interview-Book/docs/imgs/DLIB-0019.png" alt="image.png"></p>
<p>深度可分离卷积的过程是①用16个3×3大小的卷积核（1通道）分别与输入的16通道的数据做卷积（这里使用了16个1通道的卷积核，输入数据的每个通道用1个3×3的卷积核卷积），得到了16个通道的特征图，我们说该步操作是depthwise（逐层）的，在叠加16个特征图之前，②接着用32个1×1大小的卷积核（16通道）在这16个特征图进行卷积运算，将16个通道的信息进行融合（用1×1的卷积进行不同通道间的信息融合），我们说该步操作是pointwise（逐像素）的。这样我们可以算出整个过程使用了3×3×16+（1×1×16）×32 =656个参数。</p>
<p>注：上述描述与标准的卷积非常的不同，第一点在于使用非1x1卷积核时，是单channel的（可以说是1通道），即上一层输出的每个channel都有与之对应的卷积核。而标准的卷积过程，卷积核是多channel的。第二点在于使用1x1卷积核实现多channel的融合，并利用多个1x1卷积核生成多channel。表达的可能不是很清楚，但结合图示其实就容易明白了。</p>
<p>一般卷积核的channel也常称为深度（depth），所以叫做深度可分离，即原来为多channel组合，现在变成了单channel分离。</p>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://blog.csdn.net/t800ghb/article/details/78879612">深度解读谷歌MobileNet</a></li>
<li><a href="https://blog.csdn.net/chaolei3/article/details/79374563">对深度可分离卷积、分组卷积、扩张卷积、转置卷积（反卷积）的理解</a></li>
</ul>
<h3 id="MobileNetv2为什么会加shotcut？"><a href="#MobileNetv2为什么会加shotcut？" class="headerlink" title="MobileNetv2为什么会加shotcut？"></a>MobileNetv2为什么会加shotcut？</h3><ul>
<li>[ ] TODO</li>
</ul>
<h3 id="MobileNet-V2中的Residual结构最先是哪个网络提出来的？"><a href="#MobileNet-V2中的Residual结构最先是哪个网络提出来的？" class="headerlink" title="MobileNet V2中的Residual结构最先是哪个网络提出来的？"></a>MobileNet V2中的Residual结构最先是哪个网络提出来的？</h3><ul>
<li>[ ] TODO</li>
</ul>
<h2 id="ShuffleNet-系列（V1-V2-）"><a href="#ShuffleNet-系列（V1-V2-）" class="headerlink" title="ShuffleNet 系列（V1-V2++）"></a>ShuffleNet 系列（V1-V2++）</h2><ul>
<li>[ ] TODO</li>
</ul>
<h3 id="ShuffleNetV1"><a href="#ShuffleNetV1" class="headerlink" title="ShuffleNetV1"></a>ShuffleNetV1</h3><ul>
<li><p>[ ] TODO</p>
</li>
<li><p><a href="https://blog.csdn.net/u011974639/article/details/79200559">轻量级网络—ShuffleNet论文解读</a></p>
</li>
<li><a href="https://www.jianshu.com/p/29f4ec483b96">轻量级网络ShuffleNet v1</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/32304419">CNN模型之ShuffleNet</a></li>
</ul>
<h3 id="ShuffleNetV2"><a href="#ShuffleNetV2" class="headerlink" title="ShuffleNetV2"></a>ShuffleNetV2</h3><ul>
<li>[ ] TODO</li>
</ul>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/48261931">ShuffleNetV2：轻量级CNN网络中的桂冠</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/67009992">轻量级神经网络“巡礼”（一）—— ShuffleNetV2</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/42288448">ShufflenetV2_高效网络的4条实用准则</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/51566209">ShuffNet v1 和 ShuffleNet v2</a></li>
</ul>
<h2 id="IGC-系列（V1-V3）"><a href="#IGC-系列（V1-V3）" class="headerlink" title="IGC 系列（V1-V3）"></a>IGC 系列（V1-V3）</h2><ul>
<li>[ ] TODO</li>
</ul>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://mp.weixin.qq.com/s/ZLIL9A3RS0jj8knbXP9uFQ">微软资深研究员详解基于交错组卷积的高效DNN | 公开课笔记</a></li>
</ul>
<h2 id="深度可分离网络（Depth-separable-convolution）"><a href="#深度可分离网络（Depth-separable-convolution）" class="headerlink" title="深度可分离网络（Depth separable convolution）"></a>深度可分离网络（Depth separable convolution）</h2><ul>
<li>[ ] TODO</li>
</ul>
<h2 id><a href="#" class="headerlink" title=" "></a> </h2><h1 id="计算机视觉"><a href="#计算机视觉" class="headerlink" title="计算机视觉"></a>计算机视觉</h1><h2 id="IoU"><a href="#IoU" class="headerlink" title="IoU"></a>IoU</h2><p>IoU（Intersection over Union），又称重叠度/交并比。</p>
<p><strong>1 NMS</strong>：当在图像中预测多个proposals、pred bboxes时，由于预测的结果间可能存在高冗余（即同一个目标可能被预测多个矩形框），因此可以过滤掉一些彼此间高重合度的结果；具体操作就是根据各个bbox的score降序排序，剔除与高score bbox有较高重合度的低score bbox，那么重合度的度量指标就是IoU；</p>
<p><strong>2 mAP</strong>：得到检测算法的预测结果后，需要对pred bbox与gt bbox一起评估检测算法的性能，涉及到的评估指标为mAP，那么当一个pred bbox与gt bbox的重合度较高（如IoU score &gt; 0.5），且分类结果也正确时，就可以认为是该pred bbox预测正确，这里也同样涉及到IoU的概念；</p>
<p>提到IoU，大家都知道怎么回事，讲起来也都头头是道，我拿两个图示意下（以下两张图都不是本人绘制）：</p>
<p><img src="https://pic2.zhimg.com/80/v2-8fb0aa2eebc1931432eb0ed92059d2c1_hd.jpg" alt="img"></p>
<p>绿框：gt bbox；</p>
<p>红框：pred bbox；</p>
<p>那么IoU的计算如下：</p>
<p><img src="https://pic2.zhimg.com/80/v2-215e95291d2e4129206da27e7f5de6e9_hd.jpg" alt="img"></p>
<p>简单点说，就是<strong>gt bbox、pred bbox交集的面积 / 二者并集的面积</strong>；</p>
<p>好了，现在理解IoU的原理和计算方法了，就应该思考如何函数实现了，这也是我写本笔记的原因；</p>
<p>有次面试实习生的时候，一位同学讲各类目标检测算法头头是道，说到自己复现某某算法的mAP高达多少多少，问完他做的各种改进后，觉得小伙子还是挺不错的；</p>
<p>后来我是想着问问mAP的概念吧，但又觉得有点太复杂，不容易一下讲清楚细节，那就问问IoU吧，结果那位小朋友像傻逼一样看着我，说就是两个bbox的交并比啊，我说那要不你写段伪代码实现下吧，既然简单的话，应该实现起来还是很快的（一般我们也都会有这么个写伪代码的面试步骤，考考动手能力和思考能力吧）；然后那位自信满满的小伙子就立马下手开始写了，一般听完题目直接写代码的面试者，有两种可能性：</p>
<p>1 确实写过类似的代码，已经知道里面有哪些坑了，直接信手拈来；</p>
<p>2 没写过类似的代码，且把问题考虑简单化了；</p>
<p>我说你不用着急写，可以先想想两个bbox出现交集的各种情况，如两个bbox如何摆放，位置，以及二者不存在交集的情况等等（看到IoU的具体代码后，你会发现虽然只有寥寥几行代码，但其实已经处理好此类情况了），然后他画了几个图，瞬间表情严肃起来，然后我继续说你还得考虑一个bbox包围另一个bbox；两bbox并不是边角相交，而是两条边相交的特殊情况等等（说到这里我觉得自己也坏坏滴，故意把人家往歪路上牵。。。但主要是看得出来他确实不熟悉IoU的实现了），他就又画了若干种情况，最后开始写代码，刚开始还ok，写了十几行，后来越加越多，草稿纸上也涂涂改改越来越夸张，脸也越胀越红；我看了下他的代码，觉得他思路还行，考虑的还挺周全的，就给了他一个提示：你有没有考虑到你列举的这些情况，有一些可以合并的？他看了下，觉得是可以合并一些情况，就删减了部分代码，稿纸上就更乱了，然后又问他：可不可以继续合并；他就又继续思考了。。。大概是后来越想越复杂，就给我说这个原理他懂的，代码也看过，但现在确实是没能写出来；然后我安慰他，说如果没写过的话，确实是会把问题考虑简单化 / 复杂化，不过我并不是专门考个题目刁难你，而是因为你一直都在做目标检测，所以以为IoU的原理、实现你应该会比较熟悉的，写起代码也应该没问题的；而且你的思路也挺好的，先考虑各种复杂情况，再慢慢合并一些情况，先从1到N，再回到1就行，只不过可能到了N，没考虑到如何再回到1了；</p>
<p>再后来，也面试过其他实习生同学，问到了IoU的实现，很可惜，好像还没有一位同学能圆满写出来的。。。当然了，可能是我有时候过于抠细节了，不利于他们的发挥吧。。。</p>
<p>好了，以上都是废话，看看如何实现吧；</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># This is the python code for calculating bbox IoU,</span></span><br><span class="line"><span class="comment"># By running the script, we can get the IoU score between pred / gt bboxes</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Author: hzhumeng01 2018-10-19</span></span><br><span class="line"><span class="comment"># copyright @ netease, AI group</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function, absolute_import</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_IoU</span>(<span class="params">pred_bbox, gt_bbox</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    return iou score between pred / gt bboxes</span></span><br><span class="line"><span class="string">    :param pred_bbox: predict bbox coordinate</span></span><br><span class="line"><span class="string">    :param gt_bbox: ground truth bbox coordinate</span></span><br><span class="line"><span class="string">    :return: iou score</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># bbox should be valid, actually we should add more judgements, just ignore here...</span></span><br><span class="line">    <span class="comment"># assert ((abs(pred_bbox[2] - pred_bbox[0]) &gt; 0) and</span></span><br><span class="line">    <span class="comment">#         (abs(pred_bbox[3] - pred_bbox[1]) &gt; 0))</span></span><br><span class="line">    <span class="comment"># assert ((abs(gt_bbox[2] - gt_bbox[0]) &gt; 0) and</span></span><br><span class="line">    <span class="comment">#         (abs(gt_bbox[3] - gt_bbox[1]) &gt; 0))</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># -----0---- get coordinates of inters</span></span><br><span class="line">    ixmin = max(pred_bbox[<span class="number">0</span>], gt_bbox[<span class="number">0</span>])</span><br><span class="line">    iymin = max(pred_bbox[<span class="number">1</span>], gt_bbox[<span class="number">1</span>])</span><br><span class="line">    ixmax = min(pred_bbox[<span class="number">2</span>], gt_bbox[<span class="number">2</span>])</span><br><span class="line">    iymax = min(pred_bbox[<span class="number">3</span>], gt_bbox[<span class="number">3</span>])</span><br><span class="line">    iw = np.maximum(ixmax - ixmin + <span class="number">1.</span>, <span class="number">0.</span>)</span><br><span class="line">    ih = np.maximum(iymax - iymin + <span class="number">1.</span>, <span class="number">0.</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># -----1----- intersection</span></span><br><span class="line">    inters = iw * ih</span><br><span class="line"></span><br><span class="line">    <span class="comment"># -----2----- union, uni = S1 + S2 - inters</span></span><br><span class="line">    uni = ((pred_bbox[<span class="number">2</span>] - pred_bbox[<span class="number">0</span>] + <span class="number">1.</span>) * (pred_bbox[<span class="number">3</span>] - pred_bbox[<span class="number">1</span>] + <span class="number">1.</span>) +</span><br><span class="line">           (gt_bbox[<span class="number">2</span>] - gt_bbox[<span class="number">0</span>] + <span class="number">1.</span>) * (gt_bbox[<span class="number">3</span>] - gt_bbox[<span class="number">1</span>] + <span class="number">1.</span>) -</span><br><span class="line">           inters)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># -----3----- iou</span></span><br><span class="line">    overlaps = inters / uni</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> overlaps</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_max_IoU</span>(<span class="params">pred_bboxes, gt_bbox</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    given 1 gt bbox, &gt;1 pred bboxes, return max iou score for the given gt bbox and pred_bboxes</span></span><br><span class="line"><span class="string">    :param pred_bbox: predict bboxes coordinates, we need to find the max iou score with gt bbox for these pred bboxes</span></span><br><span class="line"><span class="string">    :param gt_bbox: ground truth bbox coordinate</span></span><br><span class="line"><span class="string">    :return: max iou score</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># bbox should be valid, actually we should add more judgements, just ignore here...</span></span><br><span class="line">    <span class="comment"># assert ((abs(gt_bbox[2] - gt_bbox[0]) &gt; 0) and</span></span><br><span class="line">    <span class="comment">#         (abs(gt_bbox[3] - gt_bbox[1]) &gt; 0))</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> pred_bboxes.shape[<span class="number">0</span>] &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="comment"># -----0---- get coordinates of inters, but with multiple predict bboxes</span></span><br><span class="line">        ixmin = np.maximum(pred_bboxes[:, <span class="number">0</span>], gt_bbox[<span class="number">0</span>])</span><br><span class="line">        iymin = np.maximum(pred_bboxes[:, <span class="number">1</span>], gt_bbox[<span class="number">1</span>])</span><br><span class="line">        ixmax = np.minimum(pred_bboxes[:, <span class="number">2</span>], gt_bbox[<span class="number">2</span>])</span><br><span class="line">        iymax = np.minimum(pred_bboxes[:, <span class="number">3</span>], gt_bbox[<span class="number">3</span>])</span><br><span class="line">        iw = np.maximum(ixmax - ixmin + <span class="number">1.</span>, <span class="number">0.</span>)</span><br><span class="line">        ih = np.maximum(iymax - iymin + <span class="number">1.</span>, <span class="number">0.</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># -----1----- intersection</span></span><br><span class="line">        inters = iw * ih</span><br><span class="line"></span><br><span class="line">        <span class="comment"># -----2----- union, uni = S1 + S2 - inters</span></span><br><span class="line">        uni = ((gt_bbox[<span class="number">2</span>] - gt_bbox[<span class="number">0</span>] + <span class="number">1.</span>) * (gt_bbox[<span class="number">3</span>] - gt_bbox[<span class="number">1</span>] + <span class="number">1.</span>) +</span><br><span class="line">               (pred_bboxes[:, <span class="number">2</span>] - pred_bboxes[:, <span class="number">0</span>] + <span class="number">1.</span>) * (pred_bboxes[:, <span class="number">3</span>] - pred_bboxes[:, <span class="number">1</span>] + <span class="number">1.</span>) -</span><br><span class="line">               inters)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># -----3----- iou, get max score and max iou index</span></span><br><span class="line">        overlaps = inters / uni</span><br><span class="line">        ovmax = np.max(overlaps)</span><br><span class="line">        jmax = np.argmax(overlaps)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> overlaps, ovmax, jmax</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line"></span><br><span class="line">    <span class="comment"># test1</span></span><br><span class="line">    pred_bbox = np.array([<span class="number">50</span>, <span class="number">50</span>, <span class="number">90</span>, <span class="number">100</span>])   <span class="comment"># top-left: &lt;50, 50&gt;, bottom-down: &lt;90, 100&gt;, &lt;x-axis, y-axis&gt;</span></span><br><span class="line">    gt_bbox = np.array([<span class="number">70</span>, <span class="number">80</span>, <span class="number">120</span>, <span class="number">150</span>])</span><br><span class="line">    <span class="keyword">print</span> (get_IoU(pred_bbox, gt_bbox))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># test2</span></span><br><span class="line">    pred_bboxes = np.array([[<span class="number">15</span>, <span class="number">18</span>, <span class="number">47</span>, <span class="number">60</span>],</span><br><span class="line">                          [<span class="number">50</span>, <span class="number">50</span>, <span class="number">90</span>, <span class="number">100</span>],</span><br><span class="line">                          [<span class="number">70</span>, <span class="number">80</span>, <span class="number">120</span>, <span class="number">145</span>],</span><br><span class="line">                          [<span class="number">130</span>, <span class="number">160</span>, <span class="number">250</span>, <span class="number">280</span>],</span><br><span class="line">                          [<span class="number">25.6</span>, <span class="number">66.1</span>, <span class="number">113.3</span>, <span class="number">147.8</span>]])</span><br><span class="line">    gt_bbox = np.array([<span class="number">70</span>, <span class="number">80</span>, <span class="number">120</span>, <span class="number">150</span>])</span><br><span class="line">    <span class="keyword">print</span> (get_max_IoU(pred_bboxes, gt_bbox))</span><br></pre></td></tr></table></figure>
<p>其实计算bbox间IoU唯一的难点就在计算intersection，代码的实现很简单：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ixmin = max(pred_bbox[<span class="number">0</span>], gt_bbox[<span class="number">0</span>])</span><br><span class="line">iymin = max(pred_bbox[<span class="number">1</span>], gt_bbox[<span class="number">1</span>])</span><br><span class="line">ixmax = min(pred_bbox[<span class="number">2</span>], gt_bbox[<span class="number">2</span>])</span><br><span class="line">iymax = min(pred_bbox[<span class="number">3</span>], gt_bbox[<span class="number">3</span>])</span><br><span class="line">iw = np.maximum(ixmax - ixmin + <span class="number">1.</span>, <span class="number">0.</span>)</span><br><span class="line">ih = np.maximum(iymax - iymin + <span class="number">1.</span>, <span class="number">0.</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>比较厉害的就是，以上短短六行代码就可以囊括所有pred bbox与gt bbox间的关系，不管是bboxes间相交 / 不相交，各种相交形式等等；我们在画图分析两个bbox间的关系时，会考虑各种情况，动手实践时会发现很复杂，是因为我们<strong>陷入了一种先入为主的思维</strong>，就是pred bbox与gt bbox有一个先后顺序，即我们认定了pred bbox为画图中的第一个bbox，gt bbox为第二个，这样在二者有不同位置关系时，就得考虑各种坐标判断情况，但若此时交换二者位置，其实并不影响我们计算IoU；</p>
<p>以上六行代码也印证了这个观点，直接计算两个bbox的相交边框坐标即可，若不相交得到的结果中，必有ixmax &lt; ixmin、iymax - iymin其一成立，此时iw、ih就为0了；</p>
<p>好了，以上就是IoU的计算，原理比较简单，具体分析比较复杂，实现却异常简单，但通过对问题的深入分析，也能加深我们对知识的理解；</p>
<p>代码我传到github上了，比较简单：<a href="https://github.com/humengdoudou/object_detection_mAP/blob/master/IoU_demo.py">IoU_demo.py</a></p>
<p><strong>参考资料</strong></p>
<ul>
<li><p><a href="https://zhuanlan.zhihu.com/p/47189358">目标检测番外篇(1)_IoU</a></p>
</li>
<li><p><a href="https://blog.csdn.net/u014061630/article/details/82818112">目标检测之 IoU</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/70768666">Detection基础模块之（一）IoU</a></p>
</li>
</ul>
<h3 id="如何计算-mIoU？"><a href="#如何计算-mIoU？" class="headerlink" title="如何计算 mIoU？"></a>如何计算 mIoU？</h3><p>Mean Intersection over Union(MIoU，均交并比)，为语义分割的标准度量。其计算两个集合的交集和并集之比，在语义分割问题中，这两个集合为真实值（ground truth）和预测值（predicted segmentation）。这个比例可以变形为TP（交集）比上TP、FP、FN之和（并集）。在每个类上计算IoU，然后取平均。</p>
<script type="math/tex; mode=display">
MIoU=\frac{1}{k+1}\sum^{k}_{i=0}{\frac{p_{ii}}{\sum_{j=0}^{k}{p_{ij}+\sum_{j=0}^{k}{p_{ji}-p_{ii}}}}}</script><p>pij表示真实值为i，被预测为j的数量。</p>
<p><strong>直观理解</strong></p>
<p><img src="/2020/10/19/DL%E9%9D%A2%E8%AF%95%E7%9F%A5%E8%AF%86%E7%82%B9/Users/58341/Desktop/文档们/Deep-L/Deep-Learning-Interview-Book/docs/imgs/DLIB-0020.png" alt></p>
<p>红色圆代表真实值，黄色圆代表预测值。橙色部分为两圆交集部分。</p>
<ul>
<li>MPA（Mean Pixel Accuracy，均像素精度）：计算橙色与红色圆的比例；</li>
<li>MIoU：计算两圆交集（橙色部分）与两圆并集（红色+橙色+黄色）之间的比例，理想情况下两圆重合，比例为1。</li>
</ul>
<p><strong>Tensorflow源码解析</strong></p>
<p>Tensorflow主要用<code>tf.metrics.mean_iou</code>来计算mIoU，下面解析源码：</p>
<p><strong>第一步：计算混淆矩阵</strong></p>
<p>混淆矩阵例子</p>
<p><img src="/2020/10/19/DL%E9%9D%A2%E8%AF%95%E7%9F%A5%E8%AF%86%E7%82%B9/Users/58341/Desktop/文档们/Deep-L/Deep-Learning-Interview-Book/docs/imgs/DLIB-0021.jpg" alt="img"></p>
<p><strong>Pytorch源码解</strong></p>
<p>Pytorch基本计算思路和上面是一样的，代码很简洁，就不过多介绍了。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">IOUMetric</span>:</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Class to calculate mean-iou using fast_hist method</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_classes</span>):</span></span><br><span class="line">        self.num_classes = num_classes</span><br><span class="line">        self.hist = np.zeros((num_classes, num_classes))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_fast_hist</span>(<span class="params">self, label_pred, label_true</span>):</span></span><br><span class="line">        mask = (label_true &gt;= <span class="number">0</span>) &amp; (label_true &lt; self.num_classes)</span><br><span class="line">        hist = np.bincount(</span><br><span class="line">            self.num_classes * label_true[mask].astype(int) +</span><br><span class="line">            label_pred[mask], minlength=self.num_classes ** <span class="number">2</span>).reshape(self.num_classes, self.num_classes)</span><br><span class="line">        <span class="keyword">return</span> hist</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add_batch</span>(<span class="params">self, predictions, gts</span>):</span></span><br><span class="line">        <span class="keyword">for</span> lp, lt <span class="keyword">in</span> zip(predictions, gts):</span><br><span class="line">            self.hist += self._fast_hist(lp.flatten(), lt.flatten())</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">evaluate</span>(<span class="params">self</span>):</span></span><br><span class="line">        acc = np.diag(self.hist).sum() / self.hist.sum()</span><br><span class="line">        acc_cls = np.diag(self.hist) / self.hist.sum(axis=<span class="number">1</span>)</span><br><span class="line">        acc_cls = np.nanmean(acc_cls)</span><br><span class="line">        iu = np.diag(self.hist) / (self.hist.sum(axis=<span class="number">1</span>) + self.hist.sum(axis=<span class="number">0</span>) - np.diag(self.hist))</span><br><span class="line">        mean_iu = np.nanmean(iu)</span><br><span class="line">        freq = self.hist.sum(axis=<span class="number">1</span>) / self.hist.sum()</span><br><span class="line">        fwavacc = (freq[freq &gt; <span class="number">0</span>] * iu[freq &gt; <span class="number">0</span>]).sum()</span><br><span class="line">        <span class="keyword">return</span> acc, acc_cls, iu, mean_iu, fwavacc</span><br></pre></td></tr></table></figure>
<p><strong>Python 简版实现</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#RT:RightTop</span></span><br><span class="line"><span class="comment">#LB:LeftBottom</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">IOU</span>(<span class="params">rectangle A, rectangleB</span>):</span></span><br><span class="line">    W = min(A.RT.x, B.RT.x) - max(A.LB.x, B.LB.x)</span><br><span class="line">    H = min(A.RT.y, B.RT.y) - max(A.LB.y, B.LB.y)</span><br><span class="line">    <span class="keyword">if</span> W &lt;= <span class="number">0</span> <span class="keyword">or</span> H &lt;= <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    SA = (A.RT.x - A.LB.x) * (A.RT.y - A.LB.y)</span><br><span class="line">    SB = (B.RT.x - B.LB.x) * (B.RT.y - B.LB.y)</span><br><span class="line">    cross = W * H</span><br><span class="line">    <span class="keyword">return</span> cross/(SA + SB - cross)</span><br></pre></td></tr></table></figure>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://github.com/rafaelpadilla/Object-Detection-Metrics">https://github.com/rafaelpadilla/Object-Detection-Metrics</a></li>
<li><a href="https://blog.csdn.net/jiongnima/article/details/84750819">mIoU（平均交并比）计算代码与逐行解析</a></li>
<li><a href="https://github.com/wasidennis/AdaptSegNet/blob/master/compute_iou.py">https://github.com/wasidennis/AdaptSegNet/blob/master/compute_iou.py</a></li>
<li><a href="https://tianws.github.io/skill/2018/10/30/miou/">mIoU源码解析</a></li>
</ul>
<h2 id="mAP"><a href="#mAP" class="headerlink" title="mAP"></a>mAP</h2><p><a href="https://zhuanlan.zhihu.com/p/55575423">参考资料</a></p>
<p>mAP定义及相关概念</p>
<ul>
<li>mAP: mean Average Precision, 即各类别AP的平均值</li>
<li>AP: PR曲线下面积，后文会详细讲解</li>
<li>PR曲线: Precision-Recall曲线</li>
<li>Precision: TP / (TP + FP)</li>
<li>Recall: TP / (TP + FN)</li>
<li>TP: IoU&gt;0.5的检测框数量（同一Ground Truth只计算一次）</li>
<li>FP: IoU&lt;=0.5的检测框，或者是检测到同一个GT的多余检测框的数量</li>
<li>FN: 没有检测到的GT的数量</li>
</ul>
<p>本笔记介绍目标检测的一个基本概念：AP、mAP（mean Average Precision），做目标检测的同学想必对这个词语耳熟能详了，不管是Pascal VOC，还是COCO，甚至是人脸检测的wider face数据集，都使用到了AP、mAP的评估方式，那么AP、mAP到底是什么？如何计算的？</p>
<p>如果希望一篇笔记讲明白目标检测中的mAP，感觉自己表达能力有限，可能搞不定，但如果希望一下能明白mAP含义的，可以参照引用链接；今天主要介绍下mAP的计算方式，假定前提为已经明白了precision、recall、tp、fp等概念，当然了，不明白也没关系，下一篇介绍Pascal VOC评估工具时会再详细介绍；</p>
<p><strong>1 图像检索mAP</strong></p>
<p>那么mAP到底是什么东西，如何计算？网上已经有了很多很多资料，但其实很多感觉都讲不清楚，我看到过一个在图像检索里面介绍得最好的示意图，我们先以图像检索中的mAP为例说明，其实目标检测中mAP与之几乎一样：</p>
<p><img src="https://pic2.zhimg.com/80/v2-7e1dd60163df014ad08ea15388fedd51_hd.jpg" alt="img"></p>
<p>以上是图像检索中mAP的计算案例，简要说明下：</p>
<p>1 查询图片1在图像库中检索相似图像，假设图像库中有五张相似图像，表示为图片1、…、图片5，排名不分先后；</p>
<p>2 检索（过程略），返回了top-10图像，如上图第二行，橙色表示相似的图像，灰色为无关图像；</p>
<p>3 接下来就是precision、recall的计算过程了，结合上图比较容易理解；</p>
<p>以返回图片6的节点为例：</p>
<p>top-6中，有3张图像确实为相似图像，另三张图像为无关图像，因此precision = 3 / 6；同时，总共五张相似图像，top-6检索出来了三张，因此recall = 3 / 5；</p>
<p>4 然后计算AP，可以看右边的计算方式，可以发现是把列出来的查询率(precision)相加取平均，那么最关键的问题来了：为什么选择这几张图像的precision求平均？可惜图中并没有告诉我们原因；</p>
<p>但其实不难，一句话就是：<strong>选择每个recall区间内对应的最高precision</strong>；</p>
<p>举个栗子，以上图橙色检索案例为例，当我们只选择top-1作为检索结果返回（也即只返回一个检索结果）时，检索性能为：</p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">top-1：recall = 1 / 5、precision = 1 / 1；# 以下类推；</span><br><span class="line">top-2：recall = 1 / 5、precision = 1 / 2；</span><br><span class="line">top-3：recall = 2 / 5、precision = 2 / 3；</span><br><span class="line">top-4：recall = 2 / 5、precision = 2 / 4；</span><br><span class="line">top-5：recall = 2 / 5、precision = 2 / 5；</span><br><span class="line">top-6：recall = 3 / 5、precision = 3 / 6；</span><br><span class="line">top-7：recall = 3 / 5、precision = 3 / 7；</span><br><span class="line">top-8：recall = 3 / 5、precision = 3 / 8；</span><br><span class="line">top-9：recall = 4 / 5、precision = 4 / 9；</span><br><span class="line">top-10：recall = 5 / 5、precision = 5 / 10；</span><br></pre></td></tr></table></figure>
<p>结合上面清单，先找找recall = 1 / 5区间下的最高precision，对应着precision = 1 / 1；</p>
<p>同理，recall = 2 / 5区间下的最高precision，对应着precision = 2 / 3；</p>
<p>recall = 3 / 5区间下的最高precision，对应着precision = 3 / 6；依次类推；</p>
<p>这样AP = (1 / 1 + 2 / 3 + 3 / 6 + 4 / 9 + 5 / 10) / 5；</p>
<p>那么mAP是啥？计算所有检索图像返回的AP均值，对应上图就是橙、绿突图像计算AP求均值，对应红色框；</p>
<p>这样mAP就计算完毕啦~~~是不是很容易理解？目标检测的mAP也是类似操作了；</p>
<p><strong>2 目标检测中mAP计算流程</strong></p>
<p>这里面我引用的是一篇博文，以下内容大多参考该博文，做了一些小修改；</p>
<p>下面的例子也很容易理解，假设检测人脸吧，gt label表示1为人脸，0为bg，某张图像中共检出了20个pred bbox，id：1 ~ 20，并对应了confidence score，gt label也很容易获得，pred bbox与gt bbox算IoU，给定一个threshold，那么就<strong>知道该pred bbox是否为正确的预测结果了，就对应了其gt label</strong>；—— 其实下表不应该这么理解的，但我们还是先这么认为，忽略差异吧，先直捣黄龙，table 1：</p>
<p><img src="https://pic3.zhimg.com/80/v2-f3d821d5661e41f6bbeddea2a7ce4972_hd.jpg" alt="img"></p>
<p>接下来对confidence score排序，得到table 2：</p>
<p><img src="https://pic1.zhimg.com/80/v2-dbcb5bac2c1e97e151cfe756d5cc55e8_hd.jpg" alt="img"></p>
<p><em>这张表很重要，接下来的precision和recall都是依照这个表计算的﻿，那么这里的confidence score其实就和图像检索中的相似度关联上了，具体地，就是如第一节的图像检索中，虽然我们计算mAP没在乎其检索返回的先后顺序，但top1肯定是与待检索图像最相似的，对应的similarity score最高，对人脸检测而言，pred bbox的confidence score最高，也说明该bbox最有可能是人脸；</em></p>
<p>然后计算precision和recall，这两个标准的定义如下：</p>
<p><img src="https://pic1.zhimg.com/80/v2-6b533fc4b307c03992a07b08812a12e4_hd.jpg" alt="img"></p>
<p>上面的图看看就行，能理解就理解，不理解可以参照第一节图像检索的例子来理解；</p>
<p>现以返回的top-5结果为例，如table 3：</p>
<p><img src="https://pic1.zhimg.com/80/v2-30ee6334f6aa93f9d10889fa4a3d1a10_hd.jpg" alt="img"></p>
<p>在这个例子中，true positives就是指id = 4、2的pred bbox，false positives就是指id = 13、19、6的pred bbox。方框内圆圈外的元素（false negatives + true negatives）是相对于方框内的元素而言，在这个例子中，是指confidence score排在top-5之外的元素，即table 4：</p>
<p><img src="https://pic1.zhimg.com/80/v2-e01ddf90fc9862e12ae5ab0d7416bc10_hd.jpg" alt="img"></p>
<p>其中，false negatives是指id = 9、16、7、20的4个pred bbox，true negatives是指id = 1、18、5、15、10、17、12、14、8、11、3的11个pred bbox；</p>
<p>那么，这个例子中Precision = 2 / 5 = 40%，意思是对于人脸检测而言，我们选定了5 pred bbox，其中正确的有2个，即准确率为40%；Recall = 2 / 6 = 33%，意思是该图像中共有6个人脸，但是因为我们只召回了2个，所以召回率为33%；</p>
<p>实际的目标检测任务中，我们通常不满足只通过top-5来衡量一个模型的好坏，而是需要知道从top-1到top-N（N是所有pred bbox，本文中为20）对应的precision和recall；显然随着我们选定的pred bbox越来也多，recall一定会越来越高，而precision整体上会呈下降趋势；把recall当成横坐标，precision当成纵坐标，即可得到常用的precision-recall曲线，以上例子的precision-recall曲线如fig 1：</p>
<p><img src="https://pic3.zhimg.com/80/v2-46dbabe907e601580c065aa03ee1a89a_hd.jpg" alt="img"></p>
<p>以上图像如何计算的？可以参照第一节图像检索中的栗子，还是比较容易理解的吧；</p>
<p>上面的每个红点，就相当于根据table 2，按照第一节中图像检索的方式计算出来的，也可以直接参照下面的table 5，自己心里算一算；</p>
<p>那么按照<strong>选择每个recall区间内对应的最高precision</strong>的计算方案，各个recall区间内对应的top-precision，就刚好如fig 1中的绿色框位置，可以进一步结合table 5中的绿色框理解；</p>
<p>好了，那么对这张图像而言，其AP = （1 / 1 + 2 / 2 + 3 / 6 + 4 / 7 + 5 / 11 + 6 / 16）/ 6；这是针对单张图像而言，所有图像也类似方式计算，那么就可以根据所有图像上的pred bbox，采用同样的方式，就计算出了所有图像上人脸这个类的AP；因为人脸检测只有一个类，如Pascal VOC这种20类的，每类都可以计算出一个AP，那么AP_total / 20，就是mAP啦；</p>
<p>但是等等，有没有发现table 5中，计算方式好像跟我们讲的有一点不一样？我们继续看看；</p>
<p><strong>3 Pascal VOC的两套mAP评估标准</strong></p>
<p>Pascal VOC中对mAP的计算经历了两次迭代，一种是VOC07的计算标准，对应绿色框：</p>
<p>首先设定一组阈值，T = [0、0.1、0.2、…、1]，然后对于recall大于每一个阈值Ti（比如recall &gt; 0.3），我们都会在该recall区间内得到一个对应的最大precision，这样我们就计算出了11个precision；——- 这里与上两节介绍的概念是一样的，只不过上面recall的区间是参照gt label来划分的，这里是我们人为划分的11个节点；</p>
<p>AP即为这11个precision的平均值，这种方法英文叫做11-point interpolated average precision；有了一个类的AP，所有类的AP均值即为mAP；</p>
<p>另一种是VOC10的计算标准，对应白色框：</p>
<p>新的计算方法假设N个pred bbox中有M个gt bbox，那么我们会得到M个recall节点（1 / M、2 / M、…、 M / M），对于<strong>每个recall值 r，我们可以计算出对应（r’ &gt; r）的最大precision，然后对这M个precision值取平均即得到最后的AP值</strong>，计算方法如table 5：</p>
<p><img src="https://pic4.zhimg.com/80/v2-525566cf829e30dcdc4156a3ada7303f_hd.jpg" alt="img"></p>
<p>从VOC07的绿框、VOC10的白框对比可知，差异主要在recall = 3 / 6下的precision，可以发现VOC07找的top-precision是在该recall区间段内的，但<strong>VOC10相当于是向后查找的，需确保该recall阈值以后的区间内，对应的是top-precision</strong>，可知4 / 7 &gt; 3 / 6，因此使用4 / 7替换了3 / 6，其他recall阈值下的操作方式类似；</p>
<p><strong>那么代码的实操中，就得从按照recall阈值从后往前计算了，这样就可以一遍就梭哈出所有结果，如果按recall从前往后计算，就有很多重复性计算（不断地重复向后recall区间内查找top-precision），然后呢，就可以使用到动态规划的方式做了，理论结合实践啊有木有~~~</strong></p>
<p>那么VOC10下，相应的Precision-Recall曲线如fig 2，可以发现这条曲线是单调递减的，剩下的AP计算方式就与VOC07相同了：</p>
<p>这里还需要继续一点，<strong>VOC07是11点插值的AP方式，等于是卡了11个离散的点，划分10个区间来计算AP</strong>，但VOC10是是<strong>根据recall值变化的区间来计算的</strong>，在这个栗子里，recall只变化了6次，但如果recall变化很多次，如100次、1000次、9999次等，就可以认为是<strong>一种 “伪” 连续的方式计算</strong>了；</p>
<p><img src="https://pic3.zhimg.com/80/v2-f86ce8588802e5cfee2d2f09303f98d2_hd.jpg" alt="img"></p>
<p><strong>总结</strong>：</p>
<p>AP衡量的是模型在每个类别上的好坏，mAP衡量的是模型在所有类别上的好坏，得到AP后mAP的计算就变得很简单了，就是取所有类别AP的平均值。</p>
<p><strong>3 代码</strong></p>
<p>直接上代码吧，这个函数假设我们已经得到了排序好的precision、recall的list，对应上图fig 2，进一步可以参照第一节中的清单理解；</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># VOC-style mAP，分为两个计算方式，之所有两个计算方式，是因为2010年后VOC更新了评估方法，因此就有了07-metric和else...</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">voc_ap</span>(<span class="params">rec, prec, use_07_metric=False</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    average precision calculations</span></span><br><span class="line"><span class="string">    [precision integrated to recall]</span></span><br><span class="line"><span class="string">    :param rec: recall list</span></span><br><span class="line"><span class="string">    :param prec: precision list</span></span><br><span class="line"><span class="string">    :param use_07_metric: 2007 metric is 11-recall-point based AP</span></span><br><span class="line"><span class="string">    :return: average precision</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> use_07_metric:</span><br><span class="line">        <span class="comment"># 11 point metric</span></span><br><span class="line">        ap = <span class="number">0.</span></span><br><span class="line">        <span class="comment"># VOC07是11点插值的AP方式，等于是卡了11个离散的点，划分10个区间来计算AP</span></span><br><span class="line">        <span class="keyword">for</span> t <span class="keyword">in</span> np.arange(<span class="number">0.</span>, <span class="number">1.1</span>, <span class="number">0.1</span>):</span><br><span class="line">            <span class="keyword">if</span> np.sum(rec &gt;= t) == <span class="number">0</span>:</span><br><span class="line">                p = <span class="number">0</span>    <span class="comment"># recall卡的阈值到顶了，1.1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                p = np.max(prec[rec &gt;= t])   <span class="comment"># VOC07：选择每个recall区间内对应的最高precision的计算方案</span></span><br><span class="line">            ap = ap + p / <span class="number">11.</span>    <span class="comment"># 11-recall-point based AP</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># correct AP calculation</span></span><br><span class="line">        <span class="comment"># first append sentinel values at the end</span></span><br><span class="line">        mrec = np.concatenate(([<span class="number">0.</span>], rec, [<span class="number">1.</span>]))</span><br><span class="line">        mpre = np.concatenate(([<span class="number">0.</span>], prec, [<span class="number">0.</span>]))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># compute the precision envelope</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(mpre.size - <span class="number">1</span>, <span class="number">0</span>, <span class="number">-1</span>):</span><br><span class="line">            mpre[i - <span class="number">1</span>] = np.maximum(mpre[i - <span class="number">1</span>], mpre[i])    <span class="comment"># 这个是不是动态规划？从后往前找之前区间内的top-precision，多么优雅的代码呀~~~</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># to calculate area under PR curve, look for points where X axis (recall) changes value</span></span><br><span class="line">        <span class="comment"># 上面的英文，可以结合着fig 2的绿框理解，一目了然</span></span><br><span class="line">        <span class="comment"># VOC10是是根据recall值变化的区间来计算的，如果recall变化很多次，就可以认为是一种 “伪” 连续的方式计算了，以下求的是recall的变化</span></span><br><span class="line">        i = np.where(mrec[<span class="number">1</span>:] != mrec[:<span class="number">-1</span>])[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算AP，这个计算方式有点玄乎，是一个积分公式的简化，应该是对应的fig 2中红色曲线以下的面积，之前公式的推导我有看过，现在有点忘了，麻烦各位同学补充一下</span></span><br><span class="line">        <span class="comment"># 现在理解了，不难，公式：sum (\Delta recall) * prec，其实结合fig2和下面的图，不就是算的积分么？如果recall划分得足够细，就可以当做连续数据，然后以下公式就是积分公式，算的precision、recall下面的面积了</span></span><br><span class="line">        ap = np.sum((mrec[i + <span class="number">1</span>] - mrec[i]) * mpre[i + <span class="number">1</span>])</span><br><span class="line">    <span class="keyword">return</span> ap</span><br></pre></td></tr></table></figure>
<p>通常VOC10标准下计算的mAP值会高于VOC07，原因如下，我就不详细介绍了：</p>
<blockquote>
<p><strong>Interpolated average precision</strong><br>Some authors choose an alternate approximation that is called the <em>interpolated average precision</em>. Often, they still call it average precision. Instead of using <em>P(k)</em>, the precision at a retrieval cutoff of <em>k</em> images, the interpolated average precision uses:</p>
</blockquote>
<p><img src="https://pic1.zhimg.com/80/v2-5bf4a2d116d55aa4685df9a10488fce0_hd.jpg" alt="img"></p>
<blockquote>
<p>In other words, instead of using the precision that was actually observed at cutoff <em>k</em>, the interpolated average precision uses the maximum precision observed across all cutoffs with higher recall. The full equation for computing the interpolated average precision is:</p>
</blockquote>
<p><img src="https://pic3.zhimg.com/80/v2-bce2e48f2913849f4029404cfbde9616_hd.jpg" alt="img"></p>
<blockquote>
<p>Visually, here’s how the interpolated average precision compares to the approximated average precision (to show a more interesting plot, this one isn’t from the earlier example):</p>
</blockquote>
<p><img src="https://pic1.zhimg.com/80/v2-7e00ce50249def8536978cc12a5cafe0_hd.jpg" alt="img"></p>
<blockquote>
<p><em>The approximated average precision closely hugs the actually observed curve. The interpolated average precision over estimates the precision at many points and produces a higher average precision value than the approximated average precision.</em></p>
<p>Further, there are variations on where to take the samples when computing the interpolated average precision. Some take samples at a fixed 11 points from 0 to 1: {0, 0.1, 0.2, …, 0.9, 1.0}. This is called the 11-point interpolated average precision. Others sample at every <em>k</em> where the recall changes.</p>
</blockquote>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/48992451">目标检测番外篇(2)_mAP</a></li>
<li><a href="https://www.zhihu.com/question/53405779">目标检测中的mAP是什么含义？</a></li>
<li><a href="https://github.com/rafaelpadilla/Object-Detection-Metrics">Object-Detection-Metrics</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/67279824">【目标检测】VOC mAP</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/60834912">白话mAP</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/60319755">Detection基础模块之（二）mAP</a></li>
</ul>
<h3 id="如何计算-mAP？"><a href="#如何计算-mAP？" class="headerlink" title="如何计算 mAP？"></a>如何计算 mAP？</h3><p>每类的AP/类别数</p>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://github.com/Cartucho/mAP">https://github.com/Cartucho/mAP</a></li>
<li><a href="https://github.com/rafaelpadilla/Object-Detection-Metrics">https://github.com/rafaelpadilla/Object-Detection-Metrics</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/67279824">【目标检测】VOC mAP</a></li>
</ul>
<h2 id="目标检测度量标准"><a href="#目标检测度量标准" class="headerlink" title="目标检测度量标准"></a>目标检测度量标准</h2><ul>
<li>mAP</li>
<li><p>FPS</p>
</li>
<li><p>[ ] TODO</p>
</li>
</ul>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://github.com/rafaelpadilla/Object-Detection-Metrics">Object-Detection-Metrics</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/70306015">目标检测的性能评价指标</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/60794316">【目标检测】基础知识：IoU、NMS、Bounding box regression</a></li>
</ul>
<h2 id="图像分割度量标准"><a href="#图像分割度量标准" class="headerlink" title="图像分割度量标准"></a>图像分割度量标准</h2><ul>
<li>[ ] TODO</li>
<li>PA</li>
<li>MP</li>
<li>mIoU</li>
<li>FWIoU</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">IOUMetric</span>:</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Class to calculate mean-iou using fast_hist method</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_classes</span>):</span></span><br><span class="line">        self.num_classes = num_classes</span><br><span class="line">        self.hist = np.zeros((num_classes, num_classes))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_fast_hist</span>(<span class="params">self, label_pred, label_true</span>):</span></span><br><span class="line">        mask = (label_true &gt;= <span class="number">0</span>) &amp; (label_true &lt; self.num_classes)</span><br><span class="line">        hist = np.bincount(</span><br><span class="line">            self.num_classes * label_true[mask].astype(int) +</span><br><span class="line">            label_pred[mask], minlength=self.num_classes ** <span class="number">2</span>).reshape(self.num_classes, self.num_classes)</span><br><span class="line">        <span class="keyword">return</span> hist</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add_batch</span>(<span class="params">self, predictions, gts</span>):</span></span><br><span class="line">        <span class="keyword">for</span> lp, lt <span class="keyword">in</span> zip(predictions, gts):</span><br><span class="line">            self.hist += self._fast_hist(lp.flatten(), lt.flatten())</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">evaluate</span>(<span class="params">self</span>):</span></span><br><span class="line">        acc = np.diag(self.hist).sum() / self.hist.sum()</span><br><span class="line">        acc_cls = np.diag(self.hist) / self.hist.sum(axis=<span class="number">1</span>)</span><br><span class="line">        acc_cls = np.nanmean(acc_cls)</span><br><span class="line">        iu = np.diag(self.hist) / (self.hist.sum(axis=<span class="number">1</span>) + self.hist.sum(axis=<span class="number">0</span>) - np.diag(self.hist))</span><br><span class="line">        mean_iu = np.nanmean(iu)</span><br><span class="line">        freq = self.hist.sum(axis=<span class="number">1</span>) / self.hist.sum()</span><br><span class="line">        fwavacc = (freq[freq &gt; <span class="number">0</span>] * iu[freq &gt; <span class="number">0</span>]).sum()</span><br><span class="line">        <span class="keyword">return</span> acc, acc_cls, iu, mean_iu, fwavacc</span><br></pre></td></tr></table></figure>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://arxiv.org/abs/1704.06857">《A Review on Deep Learning Techniques Applied to Semantic Segmentation》</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/38236530">图像语义分割准确率度量方法总结</a></li>
<li><a href="https://blog.csdn.net/u014593748/article/details/71698246">论文笔记 |　基于深度学习的图像语义分割技术概述之5.1度量标准</a></li>
</ul>
<h2 id="非极大值抑制NMS"><a href="#非极大值抑制NMS" class="headerlink" title="非极大值抑制NMS"></a>非极大值抑制NMS</h2><p>NMS的作用是将重复的检测框去掉</p>
<p>pytorch IoU代码</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># IOU计算</span></span><br><span class="line">    <span class="comment"># 假设box1维度为[N,4]   box2维度为[M,4]</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">iou</span>(<span class="params">self, box1, box2</span>):</span></span><br><span class="line">        N = box1.size(<span class="number">0</span>)</span><br><span class="line">        M = box2.size(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        lt = torch.max(  <span class="comment"># 左上角的点</span></span><br><span class="line">            box1[:, :<span class="number">2</span>].unsqueeze(<span class="number">1</span>).expand(N, M, <span class="number">2</span>),   <span class="comment"># [N,2]-&gt;[N,1,2]-&gt;[N,M,2]</span></span><br><span class="line">            box2[:, :<span class="number">2</span>].unsqueeze(<span class="number">0</span>).expand(N, M, <span class="number">2</span>),   <span class="comment"># [M,2]-&gt;[1,M,2]-&gt;[N,M,2]</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        rb = torch.min(</span><br><span class="line">            box1[:, <span class="number">2</span>:].unsqueeze(<span class="number">1</span>).expand(N, M, <span class="number">2</span>),</span><br><span class="line">            box2[:, <span class="number">2</span>:].unsqueeze(<span class="number">0</span>).expand(N, M, <span class="number">2</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        wh = rb - lt  <span class="comment"># [N,M,2]</span></span><br><span class="line">        wh[wh &lt; <span class="number">0</span>] = <span class="number">0</span>   <span class="comment"># 两个box没有重叠区域</span></span><br><span class="line">        inter = wh[:,:,<span class="number">0</span>] * wh[:,:,<span class="number">1</span>]   <span class="comment"># [N,M]</span></span><br><span class="line"></span><br><span class="line">        area1 = (box1[:,<span class="number">2</span>]-box1[:,<span class="number">0</span>]) * (box1[:,<span class="number">3</span>]-box1[:,<span class="number">1</span>])  <span class="comment"># (N,)</span></span><br><span class="line">        area2 = (box2[:,<span class="number">2</span>]-box2[:,<span class="number">0</span>]) * (box2[:,<span class="number">3</span>]-box2[:,<span class="number">1</span>])  <span class="comment"># (M,)</span></span><br><span class="line">        area1 = area1.unsqueeze(<span class="number">1</span>).expand(N,M)  <span class="comment"># (N,M)</span></span><br><span class="line">        area2 = area2.unsqueeze(<span class="number">0</span>).expand(N,M)  <span class="comment"># (N,M)</span></span><br><span class="line"></span><br><span class="line">        iou = inter / (area1+area2-inter)</span><br><span class="line">        <span class="keyword">return</span> iou</span><br></pre></td></tr></table></figure>
<p>NMS</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># NMS算法</span></span><br><span class="line">    <span class="comment"># bboxes维度为[N,4]，scores维度为[N,], 均为tensor</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">nms</span>(<span class="params">self, bboxes, scores, threshold=<span class="number">0.5</span></span>):</span></span><br><span class="line">        x1 = bboxes[:,<span class="number">0</span>]</span><br><span class="line">        y1 = bboxes[:,<span class="number">1</span>]</span><br><span class="line">        x2 = bboxes[:,<span class="number">2</span>]</span><br><span class="line">        y2 = bboxes[:,<span class="number">3</span>]</span><br><span class="line">        areas = (x2-x1)*(y2-y1)   <span class="comment"># [N,] 每个bbox的面积</span></span><br><span class="line">        _, order = scores.sort(<span class="number">0</span>, descending=<span class="literal">True</span>)    <span class="comment"># 降序排列 这里返回的是indices</span></span><br><span class="line"></span><br><span class="line">        keep = []</span><br><span class="line">        <span class="keyword">while</span> order.numel() &gt; <span class="number">0</span>:       <span class="comment"># torch.numel()返回张量元素个数</span></span><br><span class="line">            <span class="keyword">if</span> order.numel() == <span class="number">1</span>:     <span class="comment"># 保留框只剩一个</span></span><br><span class="line">                i = order.item()</span><br><span class="line">                keep.append(i)</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                i = order[<span class="number">0</span>].item()    <span class="comment"># 保留scores最大的那个框box[i]</span></span><br><span class="line">                keep.append(i)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 计算box[i]与其余各框的IOU(思路很好)</span></span><br><span class="line">            xx1 = x1[order[<span class="number">1</span>:]].clamp(min=x1[i])   <span class="comment"># [N-1,]</span></span><br><span class="line">            yy1 = y1[order[<span class="number">1</span>:]].clamp(min=y1[i])</span><br><span class="line">            xx2 = x2[order[<span class="number">1</span>:]].clamp(max=x2[i])</span><br><span class="line">            yy2 = y2[order[<span class="number">1</span>:]].clamp(max=y2[i])</span><br><span class="line">            inter = (xx2-xx1).clamp(min=<span class="number">0</span>) * (yy2-yy1).clamp(min=<span class="number">0</span>)   <span class="comment"># [N-1,]</span></span><br><span class="line"></span><br><span class="line">            iou = inter / (areas[i]+areas[order[<span class="number">1</span>:]]-inter)  <span class="comment"># [N-1,]</span></span><br><span class="line">            idx = (iou &lt;= threshold).nonzero().squeeze() <span class="comment"># 注意此时idx为[N-1,] 而order为[N,]</span></span><br><span class="line">            <span class="keyword">if</span> idx.numel() == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            order = order[idx+<span class="number">1</span>]  <span class="comment"># 修补索引之间的差值</span></span><br><span class="line">        <span class="keyword">return</span> torch.LongTensor(keep)   <span class="comment"># Pytorch的索引值为LongTensor</span></span><br></pre></td></tr></table></figure>
<p><img src="https://gitee.com/browallia/tuchuang/raw/master/img/20201129150151.png" style="zoom:50%;"></p>
<h2 id="目标检测中的Anchor"><a href="#目标检测中的Anchor" class="headerlink" title="目标检测中的Anchor"></a>目标检测中的Anchor</h2><p>anchor技术将问题转换为<strong>“这个固定参考框中有没有认识的目标，目标框偏离参考框多远”</strong>，不再需要多尺度遍历滑窗</p>
<p><img src="https://gitee.com/browallia/tuchuang/raw/master/img/20201201171632.png" style="zoom: 80%;"></p>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/55824651">目标检测中的Anchor</a></li>
</ul>
<h2 id="原始图片中的ROI如何映射到到feature-map"><a href="#原始图片中的ROI如何映射到到feature-map" class="headerlink" title="原始图片中的ROI如何映射到到feature map?"></a>原始图片中的ROI如何映射到到feature map?</h2><ul>
<li>[ ] TODO</li>
</ul>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/24780433">https://zhuanlan.zhihu.com/p/24780433</a></li>
<li><a href="http://www.cnblogs.com/objectDetect/p/5947169.html">http://www.cnblogs.com/objectDetect/p/5947169.html</a></li>
</ul>
<h2 id="请问Faster-R-CNN和SSD-中为什么用smooth-l1-loss，和l2有什么区别？"><a href="#请问Faster-R-CNN和SSD-中为什么用smooth-l1-loss，和l2有什么区别？" class="headerlink" title="请问Faster R-CNN和SSD 中为什么用smooth l1 loss，和l2有什么区别？"></a>请问Faster R-CNN和SSD 中为什么用smooth l1 loss，和l2有什么区别？</h2><ol>
<li>当预测框与 ground truth 差别过大时，梯度值不至于过大；</li>
<li>当预测框与 ground truth 差别很小时，梯度值足够小。</li>
</ol>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://www.zhihu.com/question/58200555/answer/621174180">请问faster rcnn和ssd 中为什么用smooth l1 loss，和l2有什么区别？</a></li>
</ul>
<h2 id="给定5个人脸关键点和5个对齐后的点，求怎么变换的？"><a href="#给定5个人脸关键点和5个对齐后的点，求怎么变换的？" class="headerlink" title="给定5个人脸关键点和5个对齐后的点，求怎么变换的？"></a>给定5个人脸关键点和5个对齐后的点，求怎么变换的？</h2><ul>
<li>[ ] TODO</li>
</ul>
<h2 id="Bounding-boxes-回归原理-公式"><a href="#Bounding-boxes-回归原理-公式" class="headerlink" title="Bounding boxes 回归原理/公式"></a>Bounding boxes 回归原理/公式</h2><ul>
<li>[ ] TODO</li>
</ul>
<h2 id="U-Net-和-FCN的区别"><a href="#U-Net-和-FCN的区别" class="headerlink" title="U-Net 和 FCN的区别"></a>U-Net 和 FCN的区别</h2><ul>
<li>[ ] TODO</li>
</ul>
<h2 id="介绍KCF算法"><a href="#介绍KCF算法" class="headerlink" title="介绍KCF算法"></a>介绍KCF算法</h2><ul>
<li>[ ] TODO</li>
</ul>
<h2 id="介绍MobileNet-SSD算法"><a href="#介绍MobileNet-SSD算法" class="headerlink" title="介绍MobileNet-SSD算法"></a>介绍MobileNet-SSD算法</h2><ul>
<li>[ ] TODO</li>
</ul>
<h2 id="目标检测中的多尺度训练-测试？"><a href="#目标检测中的多尺度训练-测试？" class="headerlink" title="目标检测中的多尺度训练/测试？"></a>目标检测中的多尺度训练/测试？</h2><ul>
<li>[ ] TODO</li>
</ul>
<p>多尺度训练对全卷积网络有效，一般设置几种不同尺度的图片，训练时每隔一定iterations随机选取一种尺度训练。这样训练出来的模型鲁棒性强，其可以接受任意大小的图片作为输入，使用尺度小的图片测试速度会快些，但准确度低，用尺度大的图片测试速度慢，但是准确度高。</p>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://www.zhihu.com/question/271781123">目标检测中的多尺度训练/测试？</a></li>
</ul>
<h2 id="目标检测中的正负样本不平衡问题"><a href="#目标检测中的正负样本不平衡问题" class="headerlink" title="目标检测中的正负样本不平衡问题"></a>目标检测中的正负样本不平衡问题</h2><ul>
<li><a href="https://arxiv.org/abs/1604.03540">OHEM</a></li>
<li><a href="https://arxiv.org/abs/1708.02002">Focal Loss</a></li>
<li><a href="https://arxiv.org/abs/1811.05181">GHM</a></li>
<li><a href="https://arxiv.org/abs/1904.04821">PISA</a></li>
<li><a href="https://arxiv.org/abs/1904.06373">AP-loss</a></li>
</ul>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/55036597">样本贡献不均：Focal Loss和 Gradient Harmonizing Mechanism</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/62314673">被忽略的Focal Loss变种</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/63954517">Soft Sampling：探索更有效的采样策略</a>：介绍了<strong>Focal Loss</strong>、<strong>GHM</strong>和<strong>PISA</strong></li>
</ul>
<h2 id="目标检测中的类别漏检问题该怎么解决？"><a href="#目标检测中的类别漏检问题该怎么解决？" class="headerlink" title="目标检测中的类别漏检问题该怎么解决？"></a>目标检测中的类别漏检问题该怎么解决？</h2><ul>
<li>[ ] TODO</li>
</ul>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://www.zhihu.com/question/372208101">目标检测中的类别漏检问题该怎么解决？</a></li>
</ul>
<h2 id="RPN"><a href="#RPN" class="headerlink" title="RPN"></a>RPN</h2><h3 id="RPN-的损失函数"><a href="#RPN-的损失函数" class="headerlink" title="RPN 的损失函数"></a>RPN 的损失函数</h3><ul>
<li>[ ] TODO</li>
</ul>
<h3 id="RPN中的anchor-box是怎么选取的？"><a href="#RPN中的anchor-box是怎么选取的？" class="headerlink" title="RPN中的anchor box是怎么选取的？"></a>RPN中的anchor box是怎么选取的？</h3><ul>
<li>[ ] TODO</li>
</ul>
<h2 id="RoI-Pooling"><a href="#RoI-Pooling" class="headerlink" title="RoI Pooling"></a>RoI Pooling</h2><ul>
<li>[ ] TODO</li>
</ul>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/59692298">你真的学会RoI Pooling了吗?</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/46927880">IoUNet(5)源码 RoIPooling(1)</a>  </li>
</ul>
<h2 id="RoI-Align"><a href="#RoI-Align" class="headerlink" title="RoI Align"></a>RoI Align</h2><ul>
<li>[ ] TODO</li>
</ul>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/46928697">IoUNet(6) 源码 RoIAlign(1)</a></li>
</ul>
<h2 id="为什么深度学习中的图像分割要先编码再解码？"><a href="#为什么深度学习中的图像分割要先编码再解码？" class="headerlink" title="为什么深度学习中的图像分割要先编码再解码？"></a>为什么深度学习中的图像分割要先编码再解码？</h2><ul>
<li>[ ] TODO</li>
</ul>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://www.zhihu.com/question/322191738">为什么深度学习中的图像分割要先编码再解码？</a></li>
</ul>
<h2 id="NMS"><a href="#NMS" class="headerlink" title="NMS"></a>NMS</h2><p>本笔记介绍目标检测的另一个基本概念：NMS（non-maximum suppression），做目标检测的同学想必对这个词语耳熟能详了；</p>
<p>在检测图像中的目标时，不可避免地会检出很多bboxes + cls scores，这些bbox之间有很多是冗余的，一个目标可能会被多个bboxes检出，如果所有bboxes都输出，就很影响体验和美观了（同一个目标输出100个bboxes，想想都后怕~~~），一种方案就是提升cls scores的阈值，减少bbox数量的输出；另一种方案就是使用NMS，将同一目标内的bboxes按照cls score + IoU阈值做筛选，剔除冗余地、低置信度的bbox；</p>
<p>可能又会问了：为什么目标检测时，会有这么多无效、冗余检测框呢？这个。。。我的理解，是因为图像中没有目标尺度、位置的先验知识，为保证对目标的高召回，就必须使用滑窗、anchor / default bbox密集采样的方式，尽管检测模型能对每个anchor / default bbox做出 cls + reg，可以一定程度上剔除误检，但没有结合检出bbox的cls score + IoU阈值做筛选，而NMS就可以做到这一点；</p>
<p><strong>1 NMS操作流程</strong></p>
<p>NMS用于剔除图像中检出的冗余bbox，标准NMS的具体做法为：</p>
<p><strong>step-1</strong>：将所有检出的output_bbox按cls score划分（如pascal voc分20个类，也即将output_bbox按照其对应的cls score划分为21个集合，1个bg类，只不过bg类就没必要做NMS而已）；</p>
<p><strong>step-2</strong>：在每个集合内根据各个bbox的cls score做降序排列，得到一个降序的list_k；</p>
<p><strong>step-3</strong>：从list_k中top1 cls score开始，计算该bbox_x与list中其他bbox_y的IoU，若IoU大于阈值T，则剔除该bbox_y，最终保留bbox_x，从list_k中取出；</p>
<p><strong>step-4</strong>：选择list_k中top2 cls score(步骤3取出top 1 bbox_x后，原list_k中的top 2就相当于现list_k中的top 1了，但如果step-3中剔除的bbox_y刚好是原list_k中的top 2，就依次找top 3即可，理解这么个意思就行)，重复step-3中的迭代操作，直至list_k中所有bbox都完成筛选；</p>
<p><strong>step-5</strong>：对每个集合的list_k，重复step-3、4中的迭代操作，直至所有list_k都完成筛选；</p>
<p>以上操作写的有点绕，不过如果理解NMS操作流程的话，再结合下图，应该还是非常好理解的；</p>
<p><img src="https://pic3.zhimg.com/80/v2-44f9d8d3f66e59e407a4edb5a02ea4ea_hd.jpg" alt="img"></p>
<p><strong>2 代码学习</strong></p>
<p><strong>2.1 test_RFB.py</strong></p>
<p>我选择了RFBNet里的代码介绍NMS，因为里面的流程基本上就是按照我说的操作进行了；</p>
<p>先看看test_RFB.py中的片段，通过以下代码可以发现，其对应着step-1、step5操作，就是说NMS操作是逐类进行的，图像中检出的所有bboxes，按照 cls 做划分，再每个类的bbox进一步做NMS；</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">out = net(x)      <span class="comment"># forward pass，这里相当于将图像 x 输入RFBNet，得到了pred cls + reg</span></span><br><span class="line">boxes, scores = detector.forward(out,priors) <span class="comment"># 结合priors，将pred reg（也即预测的offsets）解码成最终的pred bbox，如果理解anchor / default bbox操作流程，这个应该很好理解的；</span></span><br><span class="line">boxes = boxes[<span class="number">0</span>]</span><br><span class="line">scores=scores[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># scale each detection back up to the image</span></span><br><span class="line">boxes *= scale   <span class="comment"># （0，1）区间坐标的bbox做尺度反正则化</span></span><br><span class="line">boxes = boxes.cpu().numpy()</span><br><span class="line">scores = scores.cpu().numpy()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">1</span>, num_classes):      <span class="comment"># 对每个类 j 的pred bbox单独做NMS，为什么index从1开始？因为0是bg，做NMS无意义</span></span><br><span class="line">    inds = np.where(scores[:, j] &gt; thresh)[<span class="number">0</span>]     <span class="comment"># 找到该类 j 下，所有cls score大于thresh的bbox，为什么选择大于thresh的bbox？因为score小于阈值的bbox，直接可以过滤掉，无需劳烦NMS</span></span><br><span class="line">    <span class="keyword">if</span> len(inds) == <span class="number">0</span>:    <span class="comment"># 没有满足条件的bbox，返回空，跳过；</span></span><br><span class="line">        all_boxes[j][i] = np.empty([<span class="number">0</span>, <span class="number">5</span>], dtype=np.float32)</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    c_bboxes = boxes[inds]</span><br><span class="line">    c_scores = scores[inds, j]   <span class="comment"># 找到对应类 j 下的score即可</span></span><br><span class="line">    c_dets = np.hstack((c_bboxes, c_scores[:, np.newaxis])).astype(</span><br><span class="line">        np.float32, copy=<span class="literal">False</span>)   <span class="comment"># 将满足条件的bbox + cls score的bbox通过hstack完成合体</span></span><br><span class="line"></span><br><span class="line">    keep = nms(c_dets, <span class="number">0.45</span>, force_cpu=args.cpu)    <span class="comment"># NMS，返回需保存的bbox index：keep</span></span><br><span class="line">    c_dets = c_dets[keep, :]</span><br><span class="line">    all_boxes[j][i] = c_dets     <span class="comment"># i 对应每张图像，j 对应图像中类别 j 的bbox清单</span></span><br></pre></td></tr></table></figure>
<p>介绍以上代码处理流程，<strong>两个目的</strong>：</p>
<p>1 test_RFB.py的处理流程非常清晰，也很方便我们的理解；</p>
<p>2 for j in range(1, num_classes)操作表明了，NMS是逐类进行的，也即参与NMS的bbox都属于同一类；</p>
<p><strong>2.2 py_cpu_nms.py</strong></p>
<p>代码同样来自于FRBNet，结合注释可以发现引自Fast R-CNN；</p>
<p>这个代码是最简版的nms，跟第一节中NMS处理流程一致，非常适合学习，可以作为baseline，我加了个简单的main函数做测试；</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># --------------------------------------------------------</span></span><br><span class="line"><span class="comment"># Fast R-CNN</span></span><br><span class="line"><span class="comment"># Copyright (c) 2015 Microsoft</span></span><br><span class="line"><span class="comment"># Licensed under The MIT License [see LICENSE for details]</span></span><br><span class="line"><span class="comment"># Written by Ross Girshick</span></span><br><span class="line"><span class="comment"># --------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">py_cpu_nms</span>(<span class="params">dets, thresh</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Pure Python NMS baseline.&quot;&quot;&quot;</span></span><br><span class="line">    x1 = dets[:, <span class="number">0</span>]                     <span class="comment"># pred bbox top_x</span></span><br><span class="line">    y1 = dets[:, <span class="number">1</span>]                     <span class="comment"># pred bbox top_y</span></span><br><span class="line">    x2 = dets[:, <span class="number">2</span>]                     <span class="comment"># pred bbox bottom_x</span></span><br><span class="line">    y2 = dets[:, <span class="number">3</span>]                     <span class="comment"># pred bbox bottom_y</span></span><br><span class="line">    scores = dets[:, <span class="number">4</span>]              <span class="comment"># pred bbox cls score</span></span><br><span class="line"></span><br><span class="line">    areas = (x2 - x1 + <span class="number">1</span>) * (y2 - y1 + <span class="number">1</span>)    <span class="comment"># pred bbox areas</span></span><br><span class="line">    order = scores.argsort()[::<span class="number">-1</span>]              <span class="comment"># 对pred bbox按score做降序排序，对应step-2</span></span><br><span class="line"></span><br><span class="line">    keep = []    <span class="comment"># NMS后，保留的pred bbox</span></span><br><span class="line">    <span class="keyword">while</span> order.size &gt; <span class="number">0</span>:</span><br><span class="line">        i = order[<span class="number">0</span>]          <span class="comment"># top-1 score bbox</span></span><br><span class="line">        keep.append(i)   <span class="comment"># top-1 score的话，自然就保留了</span></span><br><span class="line">        xx1 = np.maximum(x1[i], x1[order[<span class="number">1</span>:]])   <span class="comment"># top-1 bbox（score最大）与order中剩余bbox计算NMS</span></span><br><span class="line">        yy1 = np.maximum(y1[i], y1[order[<span class="number">1</span>:]])</span><br><span class="line">        xx2 = np.minimum(x2[i], x2[order[<span class="number">1</span>:]])</span><br><span class="line">        yy2 = np.minimum(y2[i], y2[order[<span class="number">1</span>:]])</span><br><span class="line"></span><br><span class="line">        w = np.maximum(<span class="number">0.0</span>, xx2 - xx1 + <span class="number">1</span>)</span><br><span class="line">        h = np.maximum(<span class="number">0.0</span>, yy2 - yy1 + <span class="number">1</span>)</span><br><span class="line">        inter = w * h</span><br><span class="line">        ovr = inter / (areas[i] + areas[order[<span class="number">1</span>:]] - inter)      <span class="comment"># 无处不在的IoU计算~~~</span></span><br><span class="line"></span><br><span class="line">        inds = np.where(ovr &lt;= thresh)[<span class="number">0</span>]     <span class="comment"># 这个操作可以对代码断点调试理解下，结合step-3，我们希望剔除所有与当前top-1 bbox IoU &gt; thresh的冗余bbox，那么保留下来的bbox，自然就是ovr &lt;= thresh的非冗余bbox，其inds保留下来，作进一步筛选</span></span><br><span class="line">        order = order[inds + <span class="number">1</span>]   <span class="comment"># 保留有效bbox，就是这轮NMS未被抑制掉的幸运儿，为什么 + 1？因为ind = 0就是这轮NMS的top-1，剩余有效bbox在IoU计算中与top-1做的计算，inds对应回原数组，自然要做 +1 的映射，接下来就是step-4的循环</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> keep    <span class="comment"># 最终NMS结果返回</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    dets = np.array([[<span class="number">100</span>,<span class="number">120</span>,<span class="number">170</span>,<span class="number">200</span>,<span class="number">0.98</span>],</span><br><span class="line">                     [<span class="number">20</span>,<span class="number">40</span>,<span class="number">80</span>,<span class="number">90</span>,<span class="number">0.99</span>],</span><br><span class="line">                     [<span class="number">20</span>,<span class="number">38</span>,<span class="number">82</span>,<span class="number">88</span>,<span class="number">0.96</span>],</span><br><span class="line">                     [<span class="number">200</span>,<span class="number">380</span>,<span class="number">282</span>,<span class="number">488</span>,<span class="number">0.9</span>],</span><br><span class="line">                     [<span class="number">19</span>,<span class="number">38</span>,<span class="number">75</span>,<span class="number">91</span>, <span class="number">0.8</span>]])</span><br><span class="line"></span><br><span class="line">    py_cpu_nms(dets, <span class="number">0.5</span>)</span><br></pre></td></tr></table></figure>
<p><strong>2.2 bbox_utils.py</strong></p>
<p>同样是RFBNet中的nms代码，用pytorch实现的，其实和2.1小节中的NMS操作完全一致；</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Original author: Francisco Massa:</span></span><br><span class="line"><span class="comment"># https://github.com/fmassa/object-detection.torch</span></span><br><span class="line"><span class="comment"># Ported to PyTorch by Max deGroot (02/01/2017)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">nms</span>(<span class="params">boxes, scores, overlap=<span class="number">0.5</span>, top_k=<span class="number">200</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Apply non-maximum suppression at test time to avoid detecting too many</span></span><br><span class="line"><span class="string">    overlapping bounding boxes for a given object. ---- 这里面有一个细节，NMS仅用于测试阶段，为什么不用于训练阶段呢？可以评论留言下，我就不解释了，嘿嘿~~~</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        boxes: (tensor) The location preds for the img, Shape: [num_priors,4].</span></span><br><span class="line"><span class="string">        scores: (tensor) The class predscores for the img, Shape:[num_priors].</span></span><br><span class="line"><span class="string">        overlap: (float) The overlap thresh for suppressing unnecessary boxes.</span></span><br><span class="line"><span class="string">        top_k: (int) The Maximum number of box preds to consider.</span></span><br><span class="line"><span class="string">    Return:</span></span><br><span class="line"><span class="string">        The indices of the kept boxes with respect to num_priors.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    keep = torch.Tensor(scores.size(<span class="number">0</span>)).fill_(<span class="number">0</span>).long()</span><br><span class="line">    <span class="keyword">if</span> boxes.numel() == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> keep</span><br><span class="line">    x1 = boxes[:, <span class="number">0</span>]</span><br><span class="line">    y1 = boxes[:, <span class="number">1</span>]</span><br><span class="line">    x2 = boxes[:, <span class="number">2</span>]</span><br><span class="line">    y2 = boxes[:, <span class="number">3</span>]</span><br><span class="line">    area = torch.mul(x2 - x1, y2 - y1)    <span class="comment"># IoU初步准备</span></span><br><span class="line">    v, idx = scores.sort(<span class="number">0</span>)  <span class="comment"># sort in ascending order，对应step-2，不过是升序操作，非降序</span></span><br><span class="line">    <span class="comment"># I = I[v &gt;= 0.01]</span></span><br><span class="line">    idx = idx[-top_k:]  <span class="comment"># indices of the top-k largest vals，依然是升序的结果</span></span><br><span class="line">    xx1 = boxes.new()</span><br><span class="line">    yy1 = boxes.new()</span><br><span class="line">    xx2 = boxes.new()</span><br><span class="line">    yy2 = boxes.new()</span><br><span class="line">    w = boxes.new()</span><br><span class="line">    h = boxes.new()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># keep = torch.Tensor()</span></span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> idx.numel() &gt; <span class="number">0</span>:   <span class="comment"># 对应step-4，若所有pred bbox都处理完毕，就可以结束循环啦~</span></span><br><span class="line">        i = idx[<span class="number">-1</span>]  <span class="comment"># index of current largest val，top-1 score box，因为是升序的，所有返回index = -1的最后一个元素即可</span></span><br><span class="line">        <span class="comment"># keep.append(i)</span></span><br><span class="line">        keep[count] = i</span><br><span class="line">        count += <span class="number">1</span>    <span class="comment"># 不仅记数NMS保留的bbox个数，也作为index存储bbox</span></span><br><span class="line">        <span class="keyword">if</span> idx.size(<span class="number">0</span>) == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        idx = idx[:<span class="number">-1</span>]  <span class="comment"># remove kept element from view，top-1已保存，不需要了~~~</span></span><br><span class="line">        <span class="comment"># load bboxes of next highest vals</span></span><br><span class="line">        torch.index_select(x1, <span class="number">0</span>, idx, out=xx1)</span><br><span class="line">        torch.index_select(y1, <span class="number">0</span>, idx, out=yy1)</span><br><span class="line">        torch.index_select(x2, <span class="number">0</span>, idx, out=xx2)</span><br><span class="line">        torch.index_select(y2, <span class="number">0</span>, idx, out=yy2)</span><br><span class="line">        <span class="comment"># store element-wise max with next highest score</span></span><br><span class="line">        xx1 = torch.clamp(xx1, min=x1[i])   <span class="comment"># 对应 np.maximum(x1[i], x1[order[1:]]) </span></span><br><span class="line">        yy1 = torch.clamp(yy1, min=y1[i])</span><br><span class="line">        xx2 = torch.clamp(xx2, max=x2[i])</span><br><span class="line">        yy2 = torch.clamp(yy2, max=y2[i])</span><br><span class="line">        w.resize_as_(xx2)</span><br><span class="line">        h.resize_as_(yy2)</span><br><span class="line">        w = xx2 - xx1</span><br><span class="line">        h = yy2 - yy1</span><br><span class="line">        <span class="comment"># check sizes of xx1 and xx2.. after each iteration</span></span><br><span class="line">        w = torch.clamp(w, min=<span class="number">0.0</span>)    <span class="comment"># clamp函数可以去查查，类似max、mini的操作</span></span><br><span class="line">        h = torch.clamp(h, min=<span class="number">0.0</span>)</span><br><span class="line">        inter = w*h</span><br><span class="line">        <span class="comment"># IoU = i / (area(a) + area(b) - i)     </span></span><br><span class="line">        <span class="comment"># 以下两步操作做了个优化，area已经计算好了，就可以直接根据idx读取结果了，area[i]同理，避免了不必要的冗余计算</span></span><br><span class="line">        rem_areas = torch.index_select(area, <span class="number">0</span>, idx)  <span class="comment"># load remaining areas)</span></span><br><span class="line">        union = (rem_areas - inter) + area[i]     <span class="comment"># 就是area(a) + area(b) - i</span></span><br><span class="line">        IoU = inter/union  <span class="comment"># store result in iou，# IoU来啦~~~</span></span><br><span class="line">        <span class="comment"># keep only elements with an IoU &lt;= overlap</span></span><br><span class="line">        idx = idx[IoU.le(overlap)]   <span class="comment"># 这一轮NMS操作，IoU阈值小于overlap的idx，就是需要保留的bbox，其他的就直接忽略吧，并进行下一轮计算</span></span><br><span class="line">    <span class="keyword">return</span> keep, count</span><br></pre></td></tr></table></figure>
<p><strong>2.2 cpu_nms.pyx</strong></p>
<p>同样在RGBNet项目中，下面就是优化后的NNS操作，以及soft-NMS操作，我就不细讲了~~~</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># --------------------------------------------------------</span></span><br><span class="line"><span class="comment"># Fast R-CNN</span></span><br><span class="line"><span class="comment"># Copyright (c) 2015 Microsoft</span></span><br><span class="line"><span class="comment"># Licensed under The MIT License [see LICENSE for details]</span></span><br><span class="line"><span class="comment"># Written by Ross Girshick</span></span><br><span class="line"><span class="comment"># --------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">cimport numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">cdef inline np.float32_t max(np.float32_t a, np.float32_t b):</span><br><span class="line">    <span class="keyword">return</span> a <span class="keyword">if</span> a &gt;= b <span class="keyword">else</span> b</span><br><span class="line"></span><br><span class="line">cdef inline np.float32_t min(np.float32_t a, np.float32_t b):</span><br><span class="line">    <span class="keyword">return</span> a <span class="keyword">if</span> a &lt;= b <span class="keyword">else</span> b</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cpu_nms</span>(<span class="params">np.ndarray[np.float32_t, ndim=<span class="number">2</span>] dets, np.float thresh</span>):</span></span><br><span class="line">    cdef np.ndarray[np.float32_t, ndim=<span class="number">1</span>] x1 = dets[:, <span class="number">0</span>]</span><br><span class="line">    cdef np.ndarray[np.float32_t, ndim=<span class="number">1</span>] y1 = dets[:, <span class="number">1</span>]</span><br><span class="line">    cdef np.ndarray[np.float32_t, ndim=<span class="number">1</span>] x2 = dets[:, <span class="number">2</span>]</span><br><span class="line">    cdef np.ndarray[np.float32_t, ndim=<span class="number">1</span>] y2 = dets[:, <span class="number">3</span>]</span><br><span class="line">    cdef np.ndarray[np.float32_t, ndim=<span class="number">1</span>] scores = dets[:, <span class="number">4</span>]</span><br><span class="line"></span><br><span class="line">    cdef np.ndarray[np.float32_t, ndim=<span class="number">1</span>] areas = (x2 - x1 + <span class="number">1</span>) * (y2 - y1 + <span class="number">1</span>)</span><br><span class="line">    cdef np.ndarray[np.int_t, ndim=<span class="number">1</span>] order = scores.argsort()[::<span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line">    cdef int ndets = dets.shape[<span class="number">0</span>]</span><br><span class="line">    cdef np.ndarray[np.int_t, ndim=<span class="number">1</span>] suppressed = \</span><br><span class="line">            np.zeros((ndets), dtype=np.int)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># nominal indices</span></span><br><span class="line">    cdef int _i, _j</span><br><span class="line">    <span class="comment"># sorted indices</span></span><br><span class="line">    cdef int i, j</span><br><span class="line">    <span class="comment"># temp variables for box i&#x27;s (the box currently under consideration)</span></span><br><span class="line">    cdef np.float32_t ix1, iy1, ix2, iy2, iarea</span><br><span class="line">    <span class="comment"># variables for computing overlap with box j (lower scoring box)</span></span><br><span class="line">    cdef np.float32_t xx1, yy1, xx2, yy2</span><br><span class="line">    cdef np.float32_t w, h</span><br><span class="line">    cdef np.float32_t inter, ovr</span><br><span class="line"></span><br><span class="line">    keep = []</span><br><span class="line">    <span class="keyword">for</span> _i <span class="keyword">in</span> range(ndets):</span><br><span class="line">        i = order[_i]</span><br><span class="line">        <span class="keyword">if</span> suppressed[i] == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        keep.append(i)</span><br><span class="line">        ix1 = x1[i]</span><br><span class="line">        iy1 = y1[i]</span><br><span class="line">        ix2 = x2[i]</span><br><span class="line">        iy2 = y2[i]</span><br><span class="line">        iarea = areas[i]</span><br><span class="line">        <span class="keyword">for</span> _j <span class="keyword">in</span> range(_i + <span class="number">1</span>, ndets):</span><br><span class="line">            j = order[_j]</span><br><span class="line">            <span class="keyword">if</span> suppressed[j] == <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            xx1 = max(ix1, x1[j])</span><br><span class="line">            yy1 = max(iy1, y1[j])</span><br><span class="line">            xx2 = min(ix2, x2[j])</span><br><span class="line">            yy2 = min(iy2, y2[j])</span><br><span class="line">            w = max(<span class="number">0.0</span>, xx2 - xx1 + <span class="number">1</span>)</span><br><span class="line">            h = max(<span class="number">0.0</span>, yy2 - yy1 + <span class="number">1</span>)</span><br><span class="line">            inter = w * h</span><br><span class="line">            ovr = inter / (iarea + areas[j] - inter)</span><br><span class="line">            <span class="keyword">if</span> ovr &gt;= thresh:</span><br><span class="line">                suppressed[j] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> keep</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cpu_soft_nms</span>(<span class="params">np.ndarray[float, ndim=<span class="number">2</span>] boxes, float sigma=<span class="number">0.5</span>, float Nt=<span class="number">0.3</span>, float threshold=<span class="number">0.001</span>, unsigned int method=<span class="number">0</span></span>):</span></span><br><span class="line">    cdef unsigned int N = boxes.shape[<span class="number">0</span>]</span><br><span class="line">    cdef float iw, ih, box_area</span><br><span class="line">    cdef float ua</span><br><span class="line">    cdef int pos = <span class="number">0</span></span><br><span class="line">    cdef float maxscore = <span class="number">0</span></span><br><span class="line">    cdef int maxpos = <span class="number">0</span></span><br><span class="line">    cdef float x1,x2,y1,y2,tx1,tx2,ty1,ty2,ts,area,weight,ov</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(N):</span><br><span class="line">        maxscore = boxes[i, <span class="number">4</span>]</span><br><span class="line">        maxpos = i</span><br><span class="line"></span><br><span class="line">        tx1 = boxes[i,<span class="number">0</span>]</span><br><span class="line">        ty1 = boxes[i,<span class="number">1</span>]</span><br><span class="line">        tx2 = boxes[i,<span class="number">2</span>]</span><br><span class="line">        ty2 = boxes[i,<span class="number">3</span>]</span><br><span class="line">        ts = boxes[i,<span class="number">4</span>]</span><br><span class="line"></span><br><span class="line">        pos = i + <span class="number">1</span></span><br><span class="line">	<span class="comment"># get max box</span></span><br><span class="line">        <span class="keyword">while</span> pos &lt; N:</span><br><span class="line">            <span class="keyword">if</span> maxscore &lt; boxes[pos, <span class="number">4</span>]:</span><br><span class="line">                maxscore = boxes[pos, <span class="number">4</span>]</span><br><span class="line">                maxpos = pos</span><br><span class="line">            pos = pos + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">	<span class="comment"># add max box as a detection </span></span><br><span class="line">        boxes[i,<span class="number">0</span>] = boxes[maxpos,<span class="number">0</span>]</span><br><span class="line">        boxes[i,<span class="number">1</span>] = boxes[maxpos,<span class="number">1</span>]</span><br><span class="line">        boxes[i,<span class="number">2</span>] = boxes[maxpos,<span class="number">2</span>]</span><br><span class="line">        boxes[i,<span class="number">3</span>] = boxes[maxpos,<span class="number">3</span>]</span><br><span class="line">        boxes[i,<span class="number">4</span>] = boxes[maxpos,<span class="number">4</span>]</span><br><span class="line"></span><br><span class="line">	<span class="comment"># swap ith box with position of max box</span></span><br><span class="line">        boxes[maxpos,<span class="number">0</span>] = tx1</span><br><span class="line">        boxes[maxpos,<span class="number">1</span>] = ty1</span><br><span class="line">        boxes[maxpos,<span class="number">2</span>] = tx2</span><br><span class="line">        boxes[maxpos,<span class="number">3</span>] = ty2</span><br><span class="line">        boxes[maxpos,<span class="number">4</span>] = ts</span><br><span class="line"></span><br><span class="line">        tx1 = boxes[i,<span class="number">0</span>]</span><br><span class="line">        ty1 = boxes[i,<span class="number">1</span>]</span><br><span class="line">        tx2 = boxes[i,<span class="number">2</span>]</span><br><span class="line">        ty2 = boxes[i,<span class="number">3</span>]</span><br><span class="line">        ts = boxes[i,<span class="number">4</span>]</span><br><span class="line"></span><br><span class="line">        pos = i + <span class="number">1</span></span><br><span class="line">	<span class="comment"># NMS iterations, note that N changes if detection boxes fall below threshold</span></span><br><span class="line">        <span class="keyword">while</span> pos &lt; N:</span><br><span class="line">            x1 = boxes[pos, <span class="number">0</span>]</span><br><span class="line">            y1 = boxes[pos, <span class="number">1</span>]</span><br><span class="line">            x2 = boxes[pos, <span class="number">2</span>]</span><br><span class="line">            y2 = boxes[pos, <span class="number">3</span>]</span><br><span class="line">            s = boxes[pos, <span class="number">4</span>]</span><br><span class="line"></span><br><span class="line">            area = (x2 - x1 + <span class="number">1</span>) * (y2 - y1 + <span class="number">1</span>)</span><br><span class="line">            iw = (min(tx2, x2) - max(tx1, x1) + <span class="number">1</span>)</span><br><span class="line">            <span class="keyword">if</span> iw &gt; <span class="number">0</span>:</span><br><span class="line">                ih = (min(ty2, y2) - max(ty1, y1) + <span class="number">1</span>)</span><br><span class="line">                <span class="keyword">if</span> ih &gt; <span class="number">0</span>:</span><br><span class="line">                    ua = float((tx2 - tx1 + <span class="number">1</span>) * (ty2 - ty1 + <span class="number">1</span>) + area - iw * ih)</span><br><span class="line">                    ov = iw * ih / ua <span class="comment">#iou between max box and detection box</span></span><br><span class="line"></span><br><span class="line">                    <span class="keyword">if</span> method == <span class="number">1</span>: <span class="comment"># linear</span></span><br><span class="line">                        <span class="keyword">if</span> ov &gt; Nt: </span><br><span class="line">                            weight = <span class="number">1</span> - ov</span><br><span class="line">                        <span class="keyword">else</span>:</span><br><span class="line">                            weight = <span class="number">1</span></span><br><span class="line">                    <span class="keyword">elif</span> method == <span class="number">2</span>: <span class="comment"># gaussian</span></span><br><span class="line">                        weight = np.exp(-(ov * ov)/sigma)</span><br><span class="line">                    <span class="keyword">else</span>: <span class="comment"># original NMS</span></span><br><span class="line">                        <span class="keyword">if</span> ov &gt; Nt: </span><br><span class="line">                            weight = <span class="number">0</span></span><br><span class="line">                        <span class="keyword">else</span>:</span><br><span class="line">                            weight = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">                    boxes[pos, <span class="number">4</span>] = weight*boxes[pos, <span class="number">4</span>]</span><br><span class="line">		    </span><br><span class="line">		    <span class="comment"># if box score falls below threshold, discard the box by swapping with last box</span></span><br><span class="line">		    <span class="comment"># update N</span></span><br><span class="line">                    <span class="keyword">if</span> boxes[pos, <span class="number">4</span>] &lt; threshold:</span><br><span class="line">                        boxes[pos,<span class="number">0</span>] = boxes[N<span class="number">-1</span>, <span class="number">0</span>]</span><br><span class="line">                        boxes[pos,<span class="number">1</span>] = boxes[N<span class="number">-1</span>, <span class="number">1</span>]</span><br><span class="line">                        boxes[pos,<span class="number">2</span>] = boxes[N<span class="number">-1</span>, <span class="number">2</span>]</span><br><span class="line">                        boxes[pos,<span class="number">3</span>] = boxes[N<span class="number">-1</span>, <span class="number">3</span>]</span><br><span class="line">                        boxes[pos,<span class="number">4</span>] = boxes[N<span class="number">-1</span>, <span class="number">4</span>]</span><br><span class="line">                        N = N - <span class="number">1</span></span><br><span class="line">                        pos = pos - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            pos = pos + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    keep = [i <span class="keyword">for</span> i <span class="keyword">in</span> range(N)]</span><br><span class="line">    <span class="keyword">return</span> keep</span><br></pre></td></tr></table></figure>
<p><strong>参考代码：</strong></p>
<p><a href="https://link.zhihu.com/?target=https%3A//github.com/ruinmessi/RFBNet">https://github.com/ruinmessi/RFBNet</a>：RFBNet</p>
<p><a href="https://link.zhihu.com/?target=https%3A//github.com/rbgirshick/py-faster-rcnn">https://github.com/rbgirshick/py-faster-rcnn</a>：学习一百遍都不为过的faster rcnn</p>
<p>NMS_demo.py：<a href="https://github.com/humengdoudou/object_detection_mAP/blob/master/NMS_demo.py">https://github.com/humengdoudou/object_detection_mAP/blob/master/NMS_demo.py</a></p>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/49481833">目标检测番外篇(3)_NMS</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/64423753">浅谈NMS的多种实现</a></li>
</ul>
<h2 id="NMS及其变体"><a href="#NMS及其变体" class="headerlink" title="NMS及其变体"></a>NMS及其变体</h2><ul>
<li><p>NMS</p>
</li>
<li><p>Soft-NMS</p>
</li>
<li>Softer-NMS</li>
<li>IoU-guided NMS</li>
<li>ConvNMS</li>
<li>Pure NMS</li>
<li>Yes-Net</li>
<li>LNMS</li>
<li>INMS</li>
<li>Polygon NMS</li>
<li>MNMS</li>
</ul>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/70771042">Detection基础模块之（三）NMS及变体</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/28129034">NMS也能玩出花样来……</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/50126479">目标检测之非极大值抑制(NMS)各种变体</a></li>
</ul>
<h2 id="R-CNN-系列"><a href="#R-CNN-系列" class="headerlink" title="R-CNN 系列"></a>R-CNN 系列</h2><h3 id="R-CNN"><a href="#R-CNN" class="headerlink" title="R-CNN"></a>R-CNN</h3><ul>
<li>[ ] TODO</li>
</ul>
<h3 id="Fast-R-CNN"><a href="#Fast-R-CNN" class="headerlink" title="Fast R-CNN"></a>Fast R-CNN</h3><ul>
<li>[ ] TODO</li>
</ul>
<h3 id="Faster-R-CNN"><a href="#Faster-R-CNN" class="headerlink" title="Faster R-CNN"></a>Faster R-CNN</h3><ul>
<li>[ ] TODO</li>
</ul>
<h4 id="Faster-R-CNN-为什么用smooth-l1-loss，和l2有什么区别？"><a href="#Faster-R-CNN-为什么用smooth-l1-loss，和l2有什么区别？" class="headerlink" title="Faster R-CNN 为什么用smooth l1 loss，和l2有什么区别？"></a>Faster R-CNN 为什么用smooth l1 loss，和l2有什么区别？</h4><h2 id="SSD-算法"><a href="#SSD-算法" class="headerlink" title="SSD 算法"></a>SSD 算法</h2><ul>
<li>[ ] TODO</li>
</ul>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/65484308">SSD 论文原文完整翻译</a></li>
</ul>
<h2 id="YOLO系列（V1-V3）"><a href="#YOLO系列（V1-V3）" class="headerlink" title="YOLO系列（V1-V3）"></a>YOLO系列（V1-V3）</h2><h3 id="YOLOV1"><a href="#YOLOV1" class="headerlink" title="YOLOV1"></a>YOLOV1</h3><ul>
<li>[ ] TODO</li>
</ul>
<h3 id="YOLOv2算法"><a href="#YOLOv2算法" class="headerlink" title="YOLOv2算法"></a>YOLOv2算法</h3><ul>
<li>[ ] TODO</li>
</ul>
<h3 id="YOLOv3算法"><a href="#YOLOv3算法" class="headerlink" title="YOLOv3算法"></a>YOLOv3算法</h3><ul>
<li>[ ] TODO</li>
</ul>
<h3 id="YOLOv1-YOLOv2-YOLOv3的发展"><a href="#YOLOv1-YOLOv2-YOLOv3的发展" class="headerlink" title="YOLOv1 YOLOv2 YOLOv3的发展"></a>YOLOv1 YOLOv2 YOLOv3的发展</h3><ul>
<li>[ ] TODO</li>
</ul>
<h3 id="YOLOv2和YOLOv3的损失函数区别"><a href="#YOLOv2和YOLOv3的损失函数区别" class="headerlink" title="YOLOv2和YOLOv3的损失函数区别"></a>YOLOv2和YOLOv3的损失函数区别</h3><ul>
<li>[ ] TODO</li>
</ul>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://blog.csdn.net/hancoder/article/details/87994678">YOLOv1，YOLOv2，YOLOv3解读</a></li>
</ul>
<h2 id="RetinaNet（Focal-loss）"><a href="#RetinaNet（Focal-loss）" class="headerlink" title="RetinaNet（Focal loss）"></a>RetinaNet（Focal loss）</h2><p>《Focal Loss for Dense Object Detection》</p>
<ul>
<li>arXiv：<a href="https://arxiv.org/abs/1708.02002">https://arxiv.org/abs/1708.02002</a></li>
</ul>
<p>清华大学孔涛博士在知乎上这么写道：</p>
<p>目标的检测和定位中一个很困难的问题是，如何从数以万计的候选窗口中挑选包含目标物的物体。只有候选窗口足够多，才能保证模型的 Recall。</p>
<p>目前，目标检测框架主要有两种：</p>
<p>一种是 one-stage ，例如 YOLO、SSD 等，这一类方法速度很快，但识别精度没有 two-stage 的高，其中一个很重要的原因是，利用一个分类器很难既把负样本抑制掉，又把目标分类好。</p>
<p>另外一种目标检测框架是 two-stage ，以 Faster RCNN 为代表，这一类方法识别准确度和定位精度都很高，但存在着计算效率低，资源占用大的问题。</p>
<p>Focal Loss 从优化函数的角度上来解决这个问题，实验结果非常 solid，很赞的工作。</p>
<p>何恺明团队提出了用 Focal Loss 函数来训练。</p>
<p>因为，他在训练过程中发现，类别失衡是影响 one-stage 检测器准确度的主要原因。那么，如果能将“类别失衡”这个因素解决掉，one-stage 不就能达到比较高的识别精度了吗？</p>
<p>于是在研究中，何恺明团队采用 Focal Loss 函数来消除“类别失衡”这个主要障碍。</p>
<p>结果怎样呢？</p>
<p>为了评估该损失的有效性，该团队设计并训练了一个简单的密集目标检测器—RetinaNet。试验结果证明，当使用 Focal Loss 训练时，RetinaNet 不仅能赶上 one-stage 检测器的检测速度，而且还在准确度上超越了当前所有最先进的 two-stage 检测器。</p>
<p><strong>参考</strong></p>
<ul>
<li><a href="https://www.zhihu.com/question/63581984">如何评价Kaiming的Focal Loss for Dense Object Detection？</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/28442066">首发 | 何恺明团队提出 Focal Loss，目标检测精度高达39.1AP，打破现有记录</a></li>
</ul>
<h2 id="FPN-特征金字塔网络"><a href="#FPN-特征金字塔网络" class="headerlink" title="FPN 特征金字塔网络"></a>FPN 特征金字塔网络</h2><ul>
<li>[ ] TODO</li>
</ul>
<h2 id="Faster-R-CNN的RPN网络"><a href="#Faster-R-CNN的RPN网络" class="headerlink" title="Faster R-CNN的RPN网络"></a>Faster R-CNN的RPN网络</h2><p>RPN结构说明： </p>
<p>1) 从基础网络提取的第五卷积层特征进入RPN后分为两个分支，其中一个分支进行针对feature map（上图conv-5-3共有512个feature-map）的每一个位置预测共（9*4=36）个参数，其中9代表的是每一个位置预设的9种形状的anchor-box，4对应的是每一个anchor-box的预测值（该预测值表示的是预设anchor-box到ground-truth-box之间的变换参数），上图中指向rpn-bbox-pred层的箭头上面的数字36即是代表了上述的36个参数，所以rpn-bbox-pred层的feature-map数量是36，而每一张feature-map的形状（大小）实际上跟conv5-3一模一样的；</p>
<p>2) 另一分支预测该anchor-box所框定的区域属于前景和背景的概率（网上很对博客说的是，指代该点属于前景背景的概率，那样是不对的，不然怎么会有18个feature-map输出呢？否则2个就足够了），前景背景的真值给定是根据当前像素（anchor-box中心）是否在ground-truth-box内；</p>
<p>3) 上图RPN-data(python)运算框内所进行的操作是读取图像信息（原始宽高），groun-truth boxes的信息（bounding-box的位置，形状，类别）等，作好相应的转换，输入到下面的层当中。</p>
<p>4) 要注意的是RPN内部有两个loss层，一个是BBox的loss,该loss通过减小ground-truth-box与预测的anchor-box之间的差异来进行参数学习，从而使RPN网络中的权重能够学习到预测box的能力。实现细节是每一个位置的anchor-box与ground-truth里面的box进行比较，选择IOU最大的一个作为该anchor-box的真值，若没有，则将之class设为背景（概率值0，否则1），这样背景的anchor-box的损失函数中每个box乘以其class的概率后就不会对bbox的损失函数造成影响。另一个loss是class-loss,该处的loss是指代的前景背景并不是实际的框中物体类别，它的存在可以使得在最后生成roi时能快速过滤掉预测值是背景的box。也可实现bbox的预测函数不受影响，使得anchor-box能（专注于）正确的学习前景框的预测，正如前所述。所以，综合来讲，整个RPN的作用就是替代了以前的selective-search方法，因为网络内的运算都是可GPU加速的，所以一下子提升了ROI生成的速度。可以将RPN理解为一个预测前景背景，并将前景框定的一个网络，并进行单独的训练，实际上论文里面就有一个分阶段训练的训练策略，实际上就是这个原因。</p>
<p>5) 最后经过非极大值抑制，RPN层产生的输出是一系列的ROI-data，它通过ROI的相对映射关系，将conv5-3中的特征已经存入ROI-data中，以供后面的分类网使用。</p>
<p>另外两个loss层的说明：<br>也许你注意到了，最后还有两个loss层，这里的class-loss指代的不再是前景背景loss，而是真正的类别loss了，这个应该就很好理解了。而bbox-loss则是因为rpn提取的只是前景背景的预测，往往很粗糙，这里其实是通过ROI-pooling后加上两层全连接实现更精细的box修正（这里其实是我猜的）。<br>ROI-Pooing的作用是为了将不同大小的Roi映射（重采样）成统一的大小输入到全连接层去。</p>
<p>以上。</p>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://blog.csdn.net/mllearnertj/article/details/53709766">Faster-Rcnn中RPN（Region Proposal Network）的理解</a></li>
</ul>
<h2 id="ROI-Pooling、ROI-Align和ROI-Warping对比"><a href="#ROI-Pooling、ROI-Align和ROI-Warping对比" class="headerlink" title="ROI Pooling、ROI Align和ROI Warping对比"></a>ROI Pooling、ROI Align和ROI Warping对比</h2><ul>
<li>[ ] TODO</li>
</ul>
<p><strong>参考资料</strong></p>
<ul>
<li><a href="https://blog.csdn.net/lanyuxuan100/article/details/71124596">Mask-RCNN中的ROIAlign, ROIPooling及ROIWarp对比</a></li>
</ul>
<h2 id="DeepLab系列（V1-V3-）"><a href="#DeepLab系列（V1-V3-）" class="headerlink" title="DeepLab系列（V1-V3+）"></a>DeepLab系列（V1-V3+）</h2><ul>
<li>[ ] TODO</li>
</ul>
<h2 id="U-Net神经网络为什么会在医学图像分割表现好？"><a href="#U-Net神经网络为什么会在医学图像分割表现好？" class="headerlink" title="U-Net神经网络为什么会在医学图像分割表现好？"></a>U-Net神经网络为什么会在医学图像分割表现好？</h2><p><strong>参考资料</strong></p>
<ul>
<li><a href="https://www.zhihu.com/question/269914775">U-Net神经网络为什么会在医学图像分割表现好？</a></li>
</ul>
<h2 id="Scene-Parsing和Semantic-Segmentation有什么不同"><a href="#Scene-Parsing和Semantic-Segmentation有什么不同" class="headerlink" title="Scene Parsing和Semantic Segmentation有什么不同?"></a>Scene Parsing和Semantic Segmentation有什么不同?</h2><p><strong>参考资料</strong></p>
<ul>
<li><a href="https://www.zhihu.com/question/57726518">Scene Parsing和Semantic Segmentation有什么不同?</a></li>
</ul>
<h2 id="CenterNet"><a href="#CenterNet" class="headerlink" title="CenterNet"></a>CenterNet</h2><p>CornerNet介绍</p>
<h3 id="CornerPooling是怎么做的？"><a href="#CornerPooling是怎么做的？" class="headerlink" title="CornerPooling是怎么做的？"></a>CornerPooling是怎么做的？</h3><ul>
<li>[ ] TODO</li>
</ul>
<h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2><ul>
<li>[ ] 目标检测方向</li>
<li>[ ] 图像分割方向</li>
<li>[ ] 目标跟踪方向</li>
<li>[ ] 人脸（检测&amp;识别&amp;关键点）</li>
<li>[ ] OCR方向</li>
<li>[ ] SLAM方向</li>
<li>[ ] 超分辨率</li>
<li>[ ] 医疗影响方向</li>
<li>[ ] Re-ID</li>
</ul>
<h1 id="深度学习Tricks"><a href="#深度学习Tricks" class="headerlink" title="深度学习Tricks"></a>深度学习Tricks</h1><h3 id="Data-Augmentation"><a href="#Data-Augmentation" class="headerlink" title="Data Augmentation"></a>Data Augmentation</h3><p>由于好的深度学习模型都需要很大的数据集，所以为了加强模型的效果，在原有的数据集上，采用<strong>数据增强</strong>的方法进行数据集“<strong>扩充</strong>”，在现在的深度学习模型训练中，data augmentation几乎是必备的。</p>
<ul>
<li><p>常见的augmentation的方法有<strong>随机旋转、 水平/垂直翻转、随即剪裁、颜色抖动等</strong>，需要注意的是，一般旋转和剪裁是同时进行的。</p>
<p>pytorch中的augmentation<a href="https://cloud.tencent.com/developer/article/1528683">参考资料</a></p>
</li>
<li><p><strong>Fancy PCA</strong></p>
</li>
</ul>
<h3 id="Pre-Processing"><a href="#Pre-Processing" class="headerlink" title="Pre-Processing"></a>Pre-Processing</h3><p>对一个传入网络的巨大训练集来说，首先需要对数据进行预处理。</p>
<ul>
<li>zero-center归一化</li>
</ul>
<p>这种归一化对于不同的输入特征有不同的尺度(或单位)时，才有意义应用这种预处理，如果是图像(像素范围为0-255)则不用。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>X -= np.mean(X, axis = <span class="number">0</span>) <span class="comment"># zero-center</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>X /= np.std(X, axis = <span class="number">0</span>) <span class="comment"># normalize</span></span><br></pre></td></tr></table></figure>
<ul>
<li>PCA Whitening</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>X -= np.mean(X, axis = <span class="number">0</span>) <span class="comment"># zero-center</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>cov = np.dot(X.T, X) / X.shape[<span class="number">0</span>] <span class="comment"># compute the covariance matrix</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>U,S,V = np.linalg.svd(cov) <span class="comment"># compute the SVD factorization of the data covariance matrix</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Xrot = np.dot(X, U) <span class="comment"># decorrelate the data</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>Xwhite = Xrot / np.sqrt(S + <span class="number">1e-5</span>) <span class="comment"># divide by the eigenvalues (which are square roots of the singular values)</span></span><br></pre></td></tr></table></figure>
<p>这个方法的缺点是会增加数据的噪声，因为使输入具有相同的大小会延伸特征的维度。</p>
<h3 id="Initialization"><a href="#Initialization" class="headerlink" title="Initialization"></a>Initialization</h3><ul>
<li>all zero initialization</li>
</ul>
<p>如果神经元的权重初始化为相同，则它们之间就没有不对称的来源。</p>
<ul>
<li>small random initialization</li>
</ul>
<p>为了避免all zero带来的问题，并且将权重值初始化为靠近0</p>
<p>满足$weight \in 0.01\times N(0,1)$的高斯分布。</p>
<ul>
<li>Calibrating the variance</li>
</ul>
<p>上面的random initialization会随着输入的数量增多而方差变大，为了解决这个问题，可以将初始化权重除以输入神经元的数量</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>w = np.random.randn(n) / sqrt(n) <span class="comment"># calibrating the variances with 1/sqrt(n)</span></span><br></pre></td></tr></table></figure>
<p>通过校准神经元的方差进行的先前初始化未考虑ReLU。专门针对ReLUs进行了初始化，得出结论，网络中神经元的方差应为</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>w = np.random.randn(n) * sqrt(<span class="number">2.0</span>/n) <span class="comment"># current recommendation</span></span><br></pre></td></tr></table></figure>
<h4 id="During-Training"><a href="#During-Training" class="headerlink" title="During Training"></a>During Training</h4><ul>
<li><strong>Filters and pooling size</strong></li>
</ul>
<p>关于卷积核的尺寸和池化尺寸，卷积核一般采用3x3，stride=1的尺寸，可以保证特征图的输入大小不变，而池化采用的池化核尺寸为2x2。</p>
<ul>
<li><strong>Learning Rate</strong></li>
</ul>
<p>一般按照batch size大小来确定LR，从0.1开始，然后/2，/5进行递减，并且在固定的epoch进行decay</p>
<p><strong>关于batch size的大小与LR</strong></p>
<p>使用更大的batch size会导致减缓训练进度。对于凸问题，收敛速度会随着batch size的增加而降低。也就是说，在相同的epoch下，使用更大的batch size可能会导致验证集accuracy更低。</p>
<p>所以有一些trick来解决batch size增大的问题</p>
<ol>
<li><strong>Linear scaling learning rate</strong></li>
</ol>
<p>当我们选择初始学习率为0.1，batch size为256时，那么当我们将batch size增大至b时，就需要将初始学习率增加曾0.1×b/256</p>
<ol>
<li><strong>Learning rate warmup</strong></li>
</ol>
<p>选择若干个epoch进行warmup逐渐将学习率增加到指定的初始学习率</p>
<ol>
<li><strong>Zero $\gamma $</strong></li>
</ol>
<p>将batch normalization的两个参数都初始化为0</p>
<ol>
<li><strong>No bias decay</strong></li>
</ol>
<p>为了避免过拟合，对于权重weight和偏差bias，我们通常会使用weight decay。但在这里，仅对weight使用decay，而不对bias使用decay。</p>
<ul>
<li><strong>Fine-tune on pre-trained models</strong></li>
</ul>
<p>一个很好的适应新的数据集的方法是利用新的数据集在预训练的模型上进行fine-tune，需要依据新数据集的大小和与预训练数据集的相似程度来进行微调。</p>
<p><img src="https://gitee.com/browallia/tuchuang/raw/master/img/20201221003245.png" alt></p>
<h3 id="Activation-Functions"><a href="#Activation-Functions" class="headerlink" title="Activation Functions"></a>Activation Functions</h3><h3 id="Regularizations"><a href="#Regularizations" class="headerlink" title="Regularizations"></a>Regularizations</h3><h3 id="Insight-from-Figures"><a href="#Insight-from-Figures" class="headerlink" title="Insight from Figures"></a>Insight from Figures</h3><h3 id="Ensemble"><a href="#Ensemble" class="headerlink" title="Ensemble"></a>Ensemble</h3><p>可以将多个模型的训练结果进行融合，主要应用在比赛中</p>
<p><img src="https://gitee.com/browallia/tuchuang/raw/master/img/20201221004521.png" alt></p>
<h3 id="Mixup"><a href="#Mixup" class="headerlink" title="Mixup"></a>Mixup</h3><p>在mixup中，每次随机采样两个样本 $(x_i,y_i)$和 $(x_2,y_2)$，然后通过加权线性插值生成新的样本进行训练</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i,(images,target) <span class="keyword">in</span> enumerate(train_loader):</span><br><span class="line">    <span class="comment"># 1.input output</span></span><br><span class="line">    images = images.cuda(non_blocking=<span class="literal">True</span>)</span><br><span class="line">    target = torch.from_numpy(np.array(target)).float().cuda(non_blocking=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2.mixup</span></span><br><span class="line">    alpha=config.alpha</span><br><span class="line">    lam = np.random.beta(alpha,alpha)</span><br><span class="line">    index = torch.randperm(images.size(<span class="number">0</span>)).cuda()</span><br><span class="line">    inputs = lam*images + (<span class="number">1</span>-lam)*images[index,:]</span><br><span class="line">    targets_a, targets_b = target, target[index]</span><br><span class="line">    outputs = model(inputs)</span><br><span class="line">    loss = lam * criterion(outputs, targets_a) + (<span class="number">1</span> - lam) * criterion(outputs, targets_b)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3.backward</span></span><br><span class="line">    optimizer.zero_grad()   <span class="comment"># reset gradient</span></span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()        <span class="comment"># update parameters of net</span></span><br></pre></td></tr></table></figure>
<p>关于<a href="https://zhuanlan.zhihu.com/p/149964631">beta分布</a></p>
<h3 id="label-smoothing"><a href="#label-smoothing" class="headerlink" title="label smoothing"></a>label smoothing</h3><p><img src="https://gitee.com/browallia/tuchuang/raw/master/img/20201221152951.png" alt></p>
<ol>
<li>有正则化的效果</li>
<li>Label Smoothing起到的作用实际上是抑制了feature norm，此时softmax prob不能到达$(1-\alpha)$，loss曲面上不再存在平缓区域，处处都有较大的梯度指向各个类中心，所以特征会更加聚拢。</li>
</ol>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>面试准备</tag>
      </tags>
  </entry>
</search>

<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>2D-TAN-note</title>
    <url>/2020/06/30/2D-TAN-note/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script>]]></content>
  </entry>
  <entry>
    <title>CS231n note-1</title>
    <url>/2019/07/25/CS231n-note-1/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<h1 id="图像分类"><a href="#图像分类" class="headerlink" title="图像分类"></a>图像分类</h1><p><strong>目标</strong>：所谓图像分类问题，就是已有固定的分类标签集合，然后对于输入的图像，从分类标签集合中找出一个分类标签，最后把分类标签分配给该输入图像。虽然看起来挺简单的，但这可是计算机视觉领域的核心问题之一，并且有着各种各样的实际应用。在后面的课程中，我们可以看到计算机视觉领域中很多看似不同的问题（比如物体检测和分割），都可以被归结为图像分类问题。</p>
<p><img src="https://pic2.zhimg.com/baab9e4b97aceb77ec70abeda6be022d_r.jpg" alt="preview"></p>
<p><strong>图像分类流程</strong>。在课程视频中已经学习过，<strong>图像分类</strong>就是输入一个元素为像素值的数组，然后给它分配一个分类标签。完整流程如下：</p>
<ul>
<li><strong>输入</strong>：输入是包含N个图像的集合，每个图像的标签是K种分类标签中的一种。这个集合称为<em>训练集。</em></li>
<li><strong>学习</strong>：这一步的任务是使用训练集来学习每个类到底长什么样。一般该步骤叫做<em>训练分类器</em>或者<em>学习一个模型</em>。</li>
<li><strong>评价</strong>：让分类器来预测它未曾见过的图像的分类标签，并以此来评价分类器的质量。我们会把分类器预测的标签和图像真正的分类标签对比。毫无疑问，分类器预测的分类标签和图像真正的分类标签如果一致，那就是好事，这样的情况越多越好。</li>
</ul>
<h2 id="K-nearest算法（KNN）"><a href="#K-nearest算法（KNN）" class="headerlink" title="K-nearest算法（KNN）"></a>K-nearest算法（KNN）</h2><p>需要样本尽量高密度占据样本空间</p>
<p><strong>曼哈顿距离（L1）</strong></p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cdisplaystyle+d_1%28I_1%2CI_2%29%3D%5Csum_p%7CI%5Ep_1-I%5Ep_2%7C" alt="[公式]"></p>
<p>适合样本空间向量属性已知的情况，虽坐标轴变化值不同</p>
<p><strong>欧式距离（L2）</strong></p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cdisplaystyle+d_2%28I_1%2CI_2%29%3D%5Csqrt%7B+%5Csum_p%28I%5Ep_1-I%5Ep_2%29%5E2%7D" alt="[公式]"></p>
<p>适合样本向量为一般的通用向量</p>
<h3 id="超参数选择"><a href="#超参数选择" class="headerlink" title="超参数选择"></a><strong>超参数选择</strong></h3><p>选取超参数的正确方法是：将原始训练集分为训练集和<strong>验证集</strong>，我们在验证集上尝试不同的超参数，最后保留表现最好那个。如果训练数据量不够，使用<strong>交叉验证</strong>方法，它能帮助我们在选取最优超参数的时候减少噪声。</p>
<h3 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a><strong>交叉验证</strong></h3><p>有时候，训练集数量较小（因此验证集的数量更小），可以将训练集平均分成5份，其中4份用来训练，1份用来验证。然后我们循环着取其中4份来训练，其中1份来验证，最后取所有5次验证结果的平均值作为算法验证结果。</p>
<h1 id="线性分类"><a href="#线性分类" class="headerlink" title="线性分类"></a>线性分类</h1><p><img src="https://www.zhihu.com/equation?tex=%5Cdisplaystyle+f%28x_i%2CW%2Cb%29%3DWx_i%2Bb" alt="[å¬å¼]"></p>
<p><img src="https://pic2.zhimg.com/80/3c69a5c87a43bfb07e2b59bfcbd2f149_hd.jpg" alt="img"></p>
<h2 id="图像数据预处理"><a href="#图像数据预处理" class="headerlink" title="图像数据预处理"></a><strong>图像数据预处理</strong></h2><p>对输入的特征作归一化(normalization),对每个特征减去平均值去中心化，然后将数值分布区间变为[-1,1]，称为零均值中心化。</p>
<h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><h3 id="多类支持向量机损失-Multiclass-Support-Vector-Machine-Loss"><a href="#多类支持向量机损失-Multiclass-Support-Vector-Machine-Loss" class="headerlink" title="多类支持向量机损失 Multiclass Support Vector Machine Loss"></a>多类支持向量机损失 Multiclass Support Vector Machine Loss</h3><p>针对第j个类别的得分就是第j个元素：<img src="https://www.zhihu.com/equation?tex=s_j%3Df%28x_i%2CW%29_j" alt="[公式]">。针对第i个数据的多类SVM的损失函数定义如下：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cdisplaystyle+L_i%3D%5Csum_%7Bj%5Cnot%3Dy_i%7Dmax%280%2Cs_j-s_%7By_i%7D%2B%5CDelta%29" alt="[å¬å¼]"></p>
<p>在线性分类模型中，我们面对的是线性评分函数（<img src="https://www.zhihu.com/equation?tex=f%28x_i%2CW%29%3DWx_i" alt="[公式]">），可以将损失函数的公式稍微改写一下：</p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cdisplaystyle+L_i%3D%5Csum_%7Bj%5Cnot%3Dy_i%7Dmax%280%2Cw%5ET_jx_i-w%5ET_%7By_i%7Dx_i%2B%5CDelta%29" alt="[å¬å¼]"></p>
<p>其中$w_j$是权重$W$的第j行，被变形为列向量。然而，一旦开始考虑更复杂的评分函数$f$公式，这样做就不是必须的了。</p>
<p><img src="/2019/07/25/CS231n-note-1/1.png" alt></p>
<p>$max(0,-)$称为折叶损失函数，但也会有平方折叶损失SVM，如何选择这两种可以通过交叉验证来进行选择。</p>
<p><strong>损失函数的正则化(Regularization)</strong></p>
<p>为了防止过拟合，需要对损失函数进行正则化操作。不是为了拟合数据而是为了减轻模型的复杂度。</p>
<p>正则项</p>
<p>$\lambda R(W)$</p>
<p>超参数$\lambda$用来平衡Data loss项和Regularization</p>
<p><strong>常见的正则化</strong></p>
<p>批量归一化，随机深度</p>
<p><img src="/2019/07/25/CS231n-note-1/2.png" style="zoom:50%;"></p>
<p>L1 更倾向于稀疏解</p>
<p>L2 更倾向于鲁棒性更强的解（鲁棒性：鲁棒性是指异常样本对于算法的整体性能影响不大）</p>
<h3 id="多项式逻辑斯蒂克损失-softmax-loss"><a href="#多项式逻辑斯蒂克损失-softmax-loss" class="headerlink" title="多项式逻辑斯蒂克损失(softmax loss)"></a>多项式逻辑斯蒂克损失(softmax loss)</h3><p> 在Softmax分类器中，函数映射<img src="https://www.zhihu.com/equation?tex=f%28x_i%3BW%29%3DWx_i" alt="[公式]">保持不变，但将这些评分值视为每个分类的未归一化的对数概率，并且将折叶损失（hinge loss）替换为<strong>交叉熵损失</strong>（<strong>cross-entropy loss）</strong>。公式如下： </p>
<p> <img src="https://www.zhihu.com/equation?tex=%5Cdisplaystyle+Li%3D-log%28%5Cfrac%7Be%5E%7Bf_%7By_i%7D%7D%7D%7B%5Csum_je%5E%7Bf_j%7D%7D%29" alt="[公式]"> 或者 <img src="https://www.zhihu.com/equation?tex=L_i%3D-f_%7By_i%7D%2Blog%28%5Csum_je%5E%7Bf_j%7D%29" alt="[公式]"> </p>
<p> 在上式中，使用$f_j$来表示分类评分向量$f$中的第j个元素。和之前一样，整个数据集的损失值是数据集中所有样本数据的损失值$L_i$的均值与正则化损失$R(W)$之和。其中函数$f_j(z)=\frac{e^zj}{\sum_ke^zk}$被称作<strong>softmax 函数</strong>：其输入值是一个向量，向量中元素为任意实数的评分值（$z$中的)，函数对</p>
<p>其进行压缩，输出一个向量，其中每个元</p>
<p>素值在0到1之间，且所有元素之和为1。 </p>
<h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><h3 id="梯度"><a href="#梯度" class="headerlink" title="梯度"></a>梯度</h3><p>​    在权重空间中找到一个方向，沿着该方向能降低损失函数的损失值。其实不需要随机寻找方向，因为可以直接计算出最好的方向，这就是从数学上计算出最陡峭的方向。这个方向就是损失函数的<strong>梯度（gradient）</strong> </p>
<h3 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a><strong>梯度下降</strong></h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 普通的梯度下降</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">  weights_grad = evaluate_gradient(loss_fun, data, weights)</span><br><span class="line">  weights += - step_size * weights_grad <span class="comment"># 进行梯度更新</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 普通的小批量数据梯度下降</span></span><br><span class="line"><span class="comment">#可以减少运算成本</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">  data_batch = sample_training_data(data, <span class="number">256</span>) <span class="comment"># 256个数据</span></span><br><span class="line">  weights_grad = evaluate_gradient(loss_fun, data_batch, weights)</span><br><span class="line">  weights += - step_size * weights_grad <span class="comment"># 参数更新</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>CS231n-note-3</title>
    <url>/2019/10/21/CS231n-note-3/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<h1 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h1><h2 id="卷积核-w"><a href="#卷积核-w" class="headerlink" title="卷积核($w$)"></a>卷积核($w$)</h2><p>通常遍历输入向量的所有通道，Input为32 X 32 X 3。</p>
<p><img src="/2019/10/21/CS231n-note-3/1.png" style="zoom:50%;"></p>
<p>卷积核在输入的向量上滑动，至于图像的一个局部区域发生关联，进行点积运算$w^Tx+b    $     $w为filter$</p>
<p><strong>卷积核滑动</strong></p>
<p>在图像空间滑动，计算出每个位置的点积(滑动的方式可以改变)</p>
<h3 id="激活映射"><a href="#激活映射" class="headerlink" title="激活映射"></a>激活映射</h3><blockquote>
<p><strong>PS</strong></p>
<p><strong>7X7X3</strong> input(spatially)</p>
<p>assume <strong>3X3X3</strong> filter</p>
<p>可以得到一个<strong>5X5X<font color="red">1</font></strong>的output</p>
</blockquote>
<p><font color="red"><strong>有多少个卷积核则Output的深度为多少</strong></font>。</p>
<p><strong>步长(stride)</strong></p>
<p>控制滑动的步长可以得到不同的output。</p>
<p>如果stride=3则无法fitinput的纬度，则不采用。</p>
<p><strong>Output size：</strong></p>
<p>$(N-F) / stride + 1$</p>
<p>可以增加像素(PS：补0)来改变输出的维度,<strong>保持输出维度和输入维度相同</strong>。</p>
<h3 id="Pooling-layer"><a href="#Pooling-layer" class="headerlink" title="Pooling layer"></a>Pooling layer</h3><p> 将生成的表示更加小以及更易于控制，是参数更少。</p>
<p><img src="/2019/10/21/CS231n-note-3/2.png" style="zoom:67%;"></p>
<p>进行降采样(downsampling)，只在平面上进行降采样，不在深度上降采样。</p>
<h4 id="最大池化法-max-pooling"><a href="#最大池化法-max-pooling" class="headerlink" title="最大池化法(max pooling)"></a>最大池化法(max pooling)</h4><p>池化层中也有一个卷积核(卷积核和步长使扫描区域不重合)，在滑动过程中不进行点积计算而是只取最大值。</p>
<p>最大值可以反映在这个区域内神经元受激程度，所以最大池化法比均值池化法用的更多。</p>
<p><img src="/2019/10/21/CS231n-note-3/3.png" alt></p>
<p><strong>一般在池化层不进行0像素填补</strong></p>
<p>Common settings</p>
<p>F = 2, S = 2</p>
<p>F = 3, S = 3</p>
<p><strong>一般的卷积神经网络结构</strong></p>
<p>CONV + RELU + POOL + FC</p>
<h2 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h2><p>见note-2</p>
<h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><p>一般对于图像，做零均值化的预处理(均值指所有输入图像的均值)</p>
<p> <strong>均值减法（<em>Mean subtraction</em>）</strong>是预处理最常用的形式。它对数据中每个独立<em>特征</em>减去平均值，从几何上可以理解为在每个维度上都将数据云的中心都迁移到原点。在numpy中，该操作可以通过代码<strong>X -= np.mean(X, axis=0)</strong>实现。而对于图像，更常用的是对所有像素都减去一个值，可以用<strong>X -= np.mean(X)</strong>实现，也可以在3个颜色通道上分别操作。</p>
<h4 id="权重初始化"><a href="#权重初始化" class="headerlink" title="权重初始化"></a>权重初始化</h4><p>权重初始化太小会造成网络崩溃，权重太大网络饱和，导致梯度消失。</p>
<h5 id="Xavier初始化"><a href="#Xavier初始化" class="headerlink" title="Xavier初始化"></a>Xavier初始化</h5><p><code>w = np.random.randn(fan_in, fan_out) / np.sqrt(fan_in)</code></p>
<p>如果使用ReLU激活函数，会造成一半左右的神经元消失</p>
<p>在权重初始化的时候<code>w = np.random.randn(fan_in, fan_out) / np.sqrt(fan_in / 2)</code></p>
<h2 id="批量归一化-Bathch-Normalization"><a href="#批量归一化-Bathch-Normalization" class="headerlink" title="批量归一化(Bathch Normalization)"></a>批量归一化(Bathch Normalization)</h2><p><strong>起因</strong>：在高斯范围内激活，将数据变为单位高斯数据</p>
<p> 批量归一化可以理解为在网络的每一层之前都做预处理，只是这种操作以另一种方式与网络集成在了一起 </p>
<p><strong>归一化公式</strong></p>
<script type="math/tex; mode=display">
\hat x^{(k)} = \frac{x^{(k)}-E[x^{(k)}]}{\sqrt{Var[x^{(k)}]}}</script><p>$k$代表输入的每个维度，分别对每一个维度独立计算经验均值和方差。</p>
<p><strong>运用</strong>：通常在全连接层或者卷积层之后、非线性层(激活函数层)之前加入BN。</p>
<p><strong>作用</strong>： 批量归一化使我们可以使用更高的学习率，而对初始化则不必那么小心 。</p>
<p>在完成归一化操作之后，还(需要)进行额外的缩放操作</p>
<script type="math/tex; mode=display">
y^{(k)}=\gamma^{(k)}\hat x^{(k)}  + \beta^{(k)}</script><p>可以学习$\gamma$和$\beta$以调整网络的饱和程度，若将其学习为均值和方差则可以完成于原数据的恒等映射。</p>
<p><strong>总结</strong></p>
<p><img src="/2019/10/21/CS231n-note-3/4.png" style="zoom: 67%;"></p>
<ul>
<li>改进了整个网络的梯度流</li>
<li>有了更高的鲁棒性，允许使用更广范围的学习率和不同的初始化下进行学习</li>
<li>可以看作一种正则化方法</li>
</ul>
<h2 id="Babysitting-the-Learning-Process"><a href="#Babysitting-the-Learning-Process" class="headerlink" title="Babysitting the Learning Process"></a>Babysitting the Learning Process</h2><p><strong>step1:</strong>数据预处理</p>
<p><strong>step2：</strong>网络构造</p>
<p><strong>step3：</strong>检验网络是否合理</p>
<p><strong>step3：</strong>进行训练</p>
<h1 id="神经网络优化"><a href="#神经网络优化" class="headerlink" title="神经网络优化"></a>神经网络优化</h1><h2 id="Fancier-Optimization"><a href="#Fancier-Optimization" class="headerlink" title="Fancier Optimization"></a>Fancier Optimization</h2><h3 id="SGD"><a href="#SGD" class="headerlink" title="SGD"></a>SGD</h3><p><strong>SGD的问题</strong></p>
<ul>
<li>只对一个方向的敏感度高，会在不敏感的方向反复增减。</li>
<li>会找到局部极小值或者鞍点(梯度为零)，在高维参数空间中，局部最小值不常见，常见的是鞍点。</li>
<li>随机性，因为SGD使用的是minibatch(=1)，会产生噪声，如果在梯度下降时加入噪声会花费很长的时间</li>
</ul>
<p><strong>解决：</strong></p>
<p><strong>SGD+Momentum</strong></p>
<p><img src="/2019/10/21/CS231n-note-3/5.png" style="zoom: 33%;"></p>
<ul>
<li><p>在局部最优点或者鞍点时，梯度为0，但依旧会有一个速度，能够越过这个点继续进行梯度下降。</p>
</li>
<li><p>加入动量之后，噪声会被抵消，下降曲线更平滑。</p>
</li>
</ul>
<p><strong>Nesterov Momentum</strong></p>
<p><img src="/2019/10/21/CS231n-note-3/6.png" style="zoom:33%;"></p>
<h3 id="AdaGrad-amp-RMSProp"><a href="#AdaGrad-amp-RMSProp" class="headerlink" title="AdaGrad&amp;RMSProp"></a>AdaGrad&amp;RMSProp</h3><p><img src="/2019/10/21/CS231n-note-3/7.png" style="zoom:50%;"></p>
<p><strong>AdaGrad</strong>对于凸函数来说效果比较好，在接近极值点时会减小步长。</p>
<h3 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h3><p>结合momentum&amp;AdaGrad&amp;RMSProp，加入第一动量和第二动量。</p>
<p><img src="/2019/10/21/CS231n-note-3/8.png" style="zoom:50%;"></p>
<p>有可能first_moment以及second_moment趋于0，人为造成第一步步长很大。</p>
<p><strong>改进：</strong></p>
<p><img src="/2019/10/21/CS231n-note-3/9.png" style="zoom:50%;"></p>
<p><code>beta1=0.9,beta2=0.999,lr=1e-3or5e-4 is a great initialization point for many models.</code></p>
<h3 id="关于Learning-Rate"><a href="#关于Learning-Rate" class="headerlink" title="关于Learning Rate"></a>关于Learning Rate</h3><p>Learning rate decacy over time</p>
<ul>
<li>指数衰减</li>
</ul>
<script type="math/tex; mode=display">
\alpha = \alpha_0e^{-kt}</script><ul>
<li>1/t衰减</li>
</ul>
<script type="math/tex; mode=display">
\alpha = \alpha_0/(1+kt)</script><p><strong>ps：</strong>SGDlr衰减很常见，但是Adam优化lr衰减很少用</p>
<h3 id="Second-Order-Optimization-TODO"><a href="#Second-Order-Optimization-TODO" class="headerlink" title="Second-Order Optimization(TODO)"></a>Second-Order Optimization(TODO)</h3><p><img src="/2019/10/21/CS231n-note-3/10.png" style="zoom:50%;"></p>
<p>牛顿法-拟牛顿法</p>
<h2 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h2><h3 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h3><p>在正向传播时随机将一层中的节点置零()然后继续传播。</p>
<p><code>hyperparameter=0.5 is common</code></p>
<p> 一般在全连接层使用Dropout,在卷积层中，可能是将某一通道全部置零。</p>
<ul>
<li>避免了特征之间的联系/组合</li>
<li>可以看作model集成</li>
</ul>
<p>在<strong>predict</strong>函数中不进行随机失活，但是对于两个隐层的输出都要乘以$p$，调整其数值范围。 最后输出的期望值为原输出*hyperparameter。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">p = <span class="number">0.5</span> <span class="comment"># 激活神经元的概率. p值更高 = 随机失活更弱</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_step</span>(<span class="params">X</span>):</span></span><br><span class="line">  <span class="string">&quot;&quot;&quot; X中是输入数据 &quot;&quot;&quot;</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment"># 3层neural network的前向传播</span></span><br><span class="line">  H1 = np.maximum(<span class="number">0</span>, np.dot(W1, X) + b1)</span><br><span class="line">  U1 = np.random.rand(*H1.shape) &lt; p <span class="comment"># 第一个随机失活遮罩</span></span><br><span class="line">  H1 *= U1 <span class="comment"># drop!</span></span><br><span class="line">  H2 = np.maximum(<span class="number">0</span>, np.dot(W2, H1) + b2)</span><br><span class="line">  U2 = np.random.rand(*H2.shape) &lt; p <span class="comment"># 第二个随机失活遮罩</span></span><br><span class="line">  H2 *= U2 <span class="comment"># drop!</span></span><br><span class="line">  out = np.dot(W3, H2) + b3</span><br><span class="line">  </span><br><span class="line">  <span class="comment"># 反向传播:计算梯度... (略)</span></span><br><span class="line">  <span class="comment"># 进行参数更新... (略)</span></span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">X</span>):</span></span><br><span class="line">  <span class="comment"># 前向传播时模型集成</span></span><br><span class="line">  H1 = np.maximum(<span class="number">0</span>, np.dot(W1, X) + b1) * p <span class="comment"># 注意：激活数据要乘以p</span></span><br><span class="line">  H2 = np.maximum(<span class="number">0</span>, np.dot(W2, H1) + b2) * p <span class="comment"># 注意：激活数据要乘以p</span></span><br><span class="line">  out = np.dot(W3, H2) + b3</span><br></pre></td></tr></table></figure>
<p><strong>Inverted dropout</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot; </span></span><br><span class="line"><span class="string">反向随机失活: 推荐实现方式.</span></span><br><span class="line"><span class="string">在训练的时候drop和调整数值范围，测试时不做任何事.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">p = <span class="number">0.5</span> <span class="comment"># 激活神经元的概率. p值更高 = 随机失活更弱</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_step</span>(<span class="params">X</span>):</span></span><br><span class="line">  <span class="comment"># 3层neural network的前向传播</span></span><br><span class="line">  H1 = np.maximum(<span class="number">0</span>, np.dot(W1, X) + b1)</span><br><span class="line">  U1 = (np.random.rand(*H1.shape) &lt; p) / p <span class="comment"># 第一个随机失活遮罩. 注意/p!</span></span><br><span class="line">  H1 *= U1 <span class="comment"># drop!</span></span><br><span class="line">  H2 = np.maximum(<span class="number">0</span>, np.dot(W2, H1) + b2)</span><br><span class="line">  U2 = (np.random.rand(*H2.shape) &lt; p) / p <span class="comment"># 第二个随机失活遮罩. 注意/p!</span></span><br><span class="line">  H2 *= U2 <span class="comment"># drop!</span></span><br><span class="line">  out = np.dot(W3, H2) + b3</span><br><span class="line">  <span class="comment"># 反向传播:计算梯度... (略)</span></span><br><span class="line">  <span class="comment"># 进行参数更新... (略)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">X</span>):</span></span><br><span class="line">  <span class="comment"># 前向传播时模型集成</span></span><br><span class="line">  H1 = np.maximum(<span class="number">0</span>, np.dot(W1, X) + b1) <span class="comment"># 不用数值范围调整了</span></span><br><span class="line">  H2 = np.maximum(<span class="number">0</span>, np.dot(W2, H1) + b2)</span><br><span class="line">  out = np.dot(W3, H2) + b3</span><br></pre></td></tr></table></figure>
<p>运用dropout可能会用更长的时间进行训练，但是在收敛之后，模型的鲁棒性会更好。</p>
<h3 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h3><h3 id="Data-Augmentation"><a href="#Data-Augmentation" class="headerlink" title="Data Augmentation"></a>Data Augmentation</h3><ul>
<li>transform image</li>
<li>crops and scales</li>
<li>Color Jitter(色彩抖动) </li>
</ul>
<h3 id="DropConnect"><a href="#DropConnect" class="headerlink" title="DropConnect"></a>DropConnect</h3><p>随即将权重的一些值置零。</p>
<h3 id="Fractional-Max-Poolong-TODO"><a href="#Fractional-Max-Poolong-TODO" class="headerlink" title="Fractional Max Poolong(TODO)"></a>Fractional Max Poolong(TODO)</h3><p>在最大池化层进行部分随机池化。</p>
<h3 id="Stochastic-Depth-随即深度"><a href="#Stochastic-Depth-随即深度" class="headerlink" title="Stochastic Depth(随即深度)"></a>Stochastic Depth(随即深度)</h3><p>在训练中，随机丢弃一些层，只用部分层。</p>
<h2 id="迁移学习"><a href="#迁移学习" class="headerlink" title="迁移学习"></a>迁移学习</h2><p>不需要超大的样本集</p>
<p><img src="/2019/10/21/CS231n-note-3/11.png" style="zoom:80%;"></p>
<p>预训练模型</p>
<ul>
<li><a href="https://github.com/pytorch/vision">PyTorch</a></li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
        <tag>卷积神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>CS231n-note-2</title>
    <url>/2019/10/15/CS231n-note-2/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<h1 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h1><h2 id="计算图"><a href="#计算图" class="headerlink" title="计算图"></a>计算图</h2><p> <img src="https://pic1.zhimg.com/80/0799b3d6e5e92245ee937db3c26d1b80_hd.png" alt="img" style="zoom: 80%;"> </p>
<p>根据链式法则进行反向传播，算出每个结点的梯度。</p>
<ul>
<li>max门：一个是1 一个是0</li>
<li>乘法门：梯度互换</li>
</ul>
<p>梯度会在分支节点处累加</p>
<p><strong>sigmod函数</strong></p>
<script type="math/tex; mode=display">
\sigma(x) = \frac{1}{1+e^{-x}}</script><p><strong>梯度</strong>为</p>
<script type="math/tex; mode=display">
\frac{d\sigma(x)}{dx}=(1-\sigma(x))\sigma(x)</script><h2 id="雅可比矩阵"><a href="#雅可比矩阵" class="headerlink" title="雅可比矩阵"></a>雅可比矩阵</h2><p> 在向量分析中，<strong>雅可比矩阵</strong>是函数的一阶偏导数以一定方式排列成的矩阵，其行列式称为<strong>雅可比行列式</strong>。 </p>
<p>由球坐标系 到直角坐标系的转化由F函数给出 ：</p>
<p><img src="https://gss1.bdstatic.com/-vo3dSag_xI4khGkpoWK1HF6hhy/baike/pic/item/d1160924ab18972b11ff25b2edcd7b899f510a84.jpg" alt="img"></p>
<p><img src="https://gss1.bdstatic.com/-vo3dSag_xI4khGkpoWK1HF6hhy/baike/pic/item/728da9773912b31b5d59e9518d18367adab4e195.jpg" alt="img"></p>
<p><img src="https://gss3.bdstatic.com/-Po3dSag_xI4khGkpoWK1HF6hhy/baike/pic/item/8601a18b87d6277f65d3174023381f30e824fc81.jpg" alt="img"></p>
<p><img src="https://gss3.bdstatic.com/-Po3dSag_xI4khGkpoWK1HF6hhy/baike/pic/item/08f790529822720e2ffec68270cb0a46f21fab91.jpg" alt="img"></p>
<p>此坐标变换的雅可比矩阵是</p>
<p><img src="https://gss2.bdstatic.com/9fo3dSag_xI4khGkpoWK1HF6hhy/baike/pic/item/810a19d8bc3eb135a1f593c3ad1ea8d3fd1f4493.jpg" alt="img"></p>
<hr>
<p>在实际的运用中，不用计算$4096*4096$的雅可比矩阵（如果输入向量为4096维）。</p>
<p>一般的雅可比矩阵为对角矩阵，只用算出每一个维度的梯度。</p>
<p><img src="/2019/10/15/CS231n-note-2/1.png" alt></p>
<p> <strong>矩阵函数的梯度矩阵是其Jacobian矩阵的转置【Transposition】</strong></p>
<h1 id="构造神经网络"><a href="#构造神经网络" class="headerlink" title="构造神经网络"></a>构造神经网络</h1><p> <img src="https://pic2.zhimg.com/80/d0cbce2f2654b8e70fe201fec2982c7d_hd.png" alt="img"></p>
<p> 一个神经元前向传播的实例代码如下  </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Neuron</span>(<span class="params">object</span>):</span></span><br><span class="line">  <span class="comment"># ... </span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">inputs</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot; 假设输入和权重是1-D的numpy数组，偏差是一个数字 &quot;&quot;&quot;</span></span><br><span class="line">    cell_body_sum = np.sum(inputs * self.weights) + self.bias</span><br><span class="line">    firing_rate = <span class="number">1.0</span> / (<span class="number">1.0</span> + math.exp(-cell_body_sum)) <span class="comment"># sigmoid激活函数</span></span><br><span class="line">    <span class="keyword">return</span> firing_rate</span><br></pre></td></tr></table></figure>
<h2 id="常用激活函数"><a href="#常用激活函数" class="headerlink" title="常用激活函数"></a>常用激活函数</h2><p> 每个激活函数（或非线性函数）的输入都是一个数字，然后对其进行某种固定的数学操作。 </p>
<h3 id="Sigmod"><a href="#Sigmod" class="headerlink" title="Sigmod"></a>Sigmod</h3><p> <img src="/2019/10/15/CS231n-note-2/3.png" alt="img"> </p>
<p> 左边是Sigmoid非线性函数，将实数压缩到[0,1]之间。右边是tanh函数，将实数压缩到[-1,1]。 </p>
<script type="math/tex; mode=display">
\sigma(x) = \frac{1}{1+e^{-x}}</script><p>它输入实数值并将其“挤压”到0到1范围内。更具体地说，很大的负数变成0，很大的正数变成1。在历史上，sigmoid函数非常常用，这是因为它对于神经元的激活频率有良好的解释：从完全不激活（0）到在求和后的最大频率处的完全饱和（<strong>saturated</strong>）的激活（1）。然而现在sigmoid函数已经不太受欢迎，实际很少使用了，这是因为它有两个主要缺点：</p>
<ul>
<li><em>Sigmoid函数饱和使梯度消失</em>。sigmoid神经元有一个不好的特性，就是当神经元的激活在接近0或1处时会饱和：在这些区域，梯度几乎为0。回忆一下，在反向传播的时候，这个（局部）梯度将会与整个损失函数关于该门单元输出的梯度相乘。因此，如果局部梯度非常小，那么相乘的结果也会接近零，这会有效地“杀死”梯度，几乎就有没有信号通过神经元传到权重再到数据了。还有，为了防止饱和，必须对于权重矩阵初始化特别留意。比如，如果初始化权重过大，那么大多数神经元将会饱和，导致网络就几乎不学习了。</li>
<li><em>Sigmoid函数的输出不是零中心的</em>。这个性质并不是我们想要的，因为在神经网络后面层中的神经元得到的数据将不是零中心的。这一情况将影响梯度下降的运作，因为如果输入神经元的数据总是正数（比如在$f=w^T+b$中每个元素都$x&gt;0$），那么关于$w$的梯度在反向传播的过程中，将会要么全部是正数，要么全部是负数（具体依整个表达式$f$而定)。这将会导致梯度下降权重更新时出现z字型的下降。然而，可以看到整个批量的数据的梯度被加起来后，对于权重的最终更新将会有不同的正负，这样就从一定程度上减轻了这个问题。因此，该问题相对于上面的神经元饱和问题来说只是个小麻烦，没有那么严重。</li>
</ul>
<p><img src="/2019/10/15/CS231n-note-2/4.PNG" style="zoom:50%;"></p>
<h3 id="Tanh"><a href="#Tanh" class="headerlink" title="Tanh"></a>Tanh</h3><script type="math/tex; mode=display">
tanh(x)=2\sigma(2x)-1</script><p> tanh非线性函数图像如上图右边所示。它将实数值压缩到[-1,1]之间。和sigmoid神经元一样，它也存在饱和问题，但是和sigmoid神经元不同的是，它的输出是零中心的。因此，在实际操作中，<em>tanh非线性函数比sigmoid非线性函数更受欢迎</em>。tanh神经元是一个简单放大的sigmoid神经元 </p>
<h3 id="ReLU"><a href="#ReLU" class="headerlink" title="ReLU"></a>ReLU</h3><p> <img src="/2019/10/15/CS231n-note-2/7.png" alt></p>
<p> 左边是ReLU（校正线性单元：Rectified Linear Unit）激活函数，当 $x=0$ 时函数值为0。当$x&gt;0$时函数的斜率为1。 </p>
<script type="math/tex; mode=display">
f(x) = max(0,x)</script><ul>
<li><p>优点：相较于sigmoid和tanh函数，ReLU对于随机梯度下降的收敛有巨大的加速作用（ <a href="https://link.zhihu.com/?target=http%3A//www.cs.toronto.edu/~fritz/absps/imagenet.pdf">Krizhevsky </a>等的论文指出有6倍之多）。据称这是由它的线性，非饱和的公式导致的。(右图)</p>
</li>
<li><p>优点：sigmoid和tanh神经元含有指数运算等耗费计算资源的操作，而ReLU可以简单地通过对一个矩阵进行阈值计算得到。</p>
</li>
<li><p>缺点：在训练的时候，ReLU单元比较脆弱并且可能“死掉”。举例来说，当一个很大的梯度流过ReLU的神经元的时候，可能会导致梯度更新到一种特别的状态，在这种状态下神经元将无法被其他任何数据点再次激活。如果这种情况发生，那么从此所以流过这个神经元的梯度将都变成0。也就是说，这个ReLU单元在训练中将不可逆转的死亡，因为这导致了数据多样化的丢失。例如，如果学习率设置得太高，可能会发现网络中40%的神经元都会死掉（在整个训练集中这些神经元都不会被激活）。通过合理设置学习率，这种情况的发生概率会降低。</p>
<p><img src="/2019/10/15/CS231n-note-2/5.png" style="zoom: 33%;"></p>
</li>
</ul>
<h3 id="Leaky-ReLU"><a href="#Leaky-ReLU" class="headerlink" title="Leaky ReLU"></a>Leaky ReLU</h3><p><img src="/2019/10/15/CS231n-note-2/8.png" alt></p>
<script type="math/tex; mode=display">
f(x) = max(0.01x,x)</script><p> Leaky ReLU是为解决“ReLU死亡”问题的尝试。ReLU中当x&lt;0时，函数值为0。而Leaky ReLU则是给出一个很小的负数梯度值，比如0.01。</p>
<h4 id="Parametric-Rectifier-PReLU"><a href="#Parametric-Rectifier-PReLU" class="headerlink" title="Parametric Rectifier(PReLU)"></a>Parametric Rectifier(PReLU)</h4><script type="math/tex; mode=display">
f(x)=max(\alpha x,x)</script><p>$\alpha$可以作为反向传播训练的参数。</p>
<h3 id="ELU"><a href="#ELU" class="headerlink" title="ELU"></a>ELU</h3><script type="math/tex; mode=display">
\left\{
\begin{aligned}
x  & &  x\geq0\\
\alpha(e^x -1)  & &  x<0
\end{aligned}
\right.</script><p><img src="/2019/10/15/CS231n-note-2/2.png" style="zoom:67%;"></p>
<p>会获得均值接近0的输出。</p>
<h3 id="Maxout"><a href="#Maxout" class="headerlink" title="Maxout"></a>Maxout</h3><script type="math/tex; mode=display">
max(w_1^Tx+b_1,w_2^T+b_2)</script><p> ReLU和Leaky ReLU都是这个公式的特殊情况 。 这样Maxout神经元就拥有ReLU单元的所有优点（线性操作和不饱和），而没有它的缺点（死亡的ReLU单元）。然而和ReLU对比，它每个神经元的参数数量增加了一倍，这就导致整体参数的数量激增。 </p>
<h3 id="Summury"><a href="#Summury" class="headerlink" title="Summury"></a>Summury</h3><p><img src="/2019/10/15/CS231n-note-2/6.png" alt></p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>CS231n-note-4</title>
    <url>/2019/10/28/CS231n-note-4/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<h1 id="深度学习软件"><a href="#深度学习软件" class="headerlink" title="深度学习软件"></a>深度学习软件</h1><h2 id="PyTorch-TODO"><a href="#PyTorch-TODO" class="headerlink" title="PyTorch(TODO)"></a>PyTorch(TODO)</h2><h3 id="组成-三层"><a href="#组成-三层" class="headerlink" title="组成(三层)"></a>组成(三层)</h3><h4 id="Tensor"><a href="#Tensor" class="headerlink" title="Tensor"></a>Tensor</h4><p>运行在GPU上的命令式数组(Imperative ndarray)</p>
<h4 id="Variable"><a href="#Variable" class="headerlink" title="Variable"></a>Variable</h4><p>计算图中的节点，存储数据和梯度</p>
<h4 id="Module"><a href="#Module" class="headerlink" title="Module"></a>Module</h4><p>一个神经网络的层</p>
<h1 id="CNN架构"><a href="#CNN架构" class="headerlink" title="CNN架构"></a>CNN架构</h1><p><strong>AlexNet</strong>：8layers</p>
<p><strong>ZFNet</strong>：在AlexNet基础上调整了超参数</p>
<p><strong>VGG</strong>：16/19layers(全部采用3X3的卷积核——更有利于加深神经网络的深度)</p>
<p><strong>GoogleNet</strong>:</p>
<p>22layers，高效的“Inception”层，无全连接层</p>
<p>Inception层是设计好的一个局部网络拓朴，对输入的层进行并行操作，然后将每个滤波器的输出进行深度上的串联，通过0填充保持输出尺寸一致。</p>
<p><img src="/2019/10/28/CS231n-note-4/1.png" alt="1572427047546" style="zoom: 50%;"></p>
<p>利用1X1卷积核进行深度的压缩对模型进行改进。 </p>
<p><img src="/2019/10/28/CS231n-note-4/2.png" alt="1572427217649" style="zoom:50%;"></p>
<p><strong>ResNet</strong>: 152layers</p>
<p><img src="/2019/10/28/CS231n-note-4/3.png" alt="1572428187168" style="zoom:50%;"></p>
<p>ResNet的整体结构</p>
<p><img src="/2019/10/28/CS231n-note-4/4.png" style="zoom:50%;"></p>
<h1 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h1><p><img src="/2019/10/28/CS231n-note-4/5.png" alt="1572832029309" style="zoom:67%;"></p>
<p><strong>Vanilla RNN</strong></p>
<script type="math/tex; mode=display">
h_t = f_w(h_{t-1},x_t)\\
h_t = tanh(W_{hh}h_{t-1}+W_{xh}x_t)\\
y_t = W_{hy}h_t</script><p>Loss是每一个时步下的loss之和</p>
<p>W的梯度是每个节点的W梯度值和  </p>
<p><strong>Vanilla RNN梯度流</strong></p>
<p><img src="/2019/10/28/CS231n-note-4/7.png" alt="1572869122126" style="zoom:50%;"></p>
<p>在计算h0梯度时会发生梯度爆炸或者梯度消失   </p>
<p>当梯度爆炸，L2范式大于一个阙值时可以进行剪枝。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">grad_norm = np.sum(grad * grad)</span><br><span class="line"><span class="keyword">if</span> grad_norm &gt; threshold</span><br><span class="line">	grad *= (threshold / grad_norm)</span><br></pre></td></tr></table></figure>
<p>当梯度消失时可以采用更深的RNN网络，比如LSTM。</p>
<p><strong>LSTM(长短期记忆网络)</strong></p>
<p><img src="/2019/10/28/CS231n-note-4/blog\source\_posts\CS231n-note-4\8.png" alt="1572870827165" style="zoom: 50%;"></p>
<p> ht为隐藏状态，ct为单元状态，保留在lstm内部不会暴露到外面。</p>
<p>LSTM状态变化图</p>
<p><img src="/2019/10/28/CS231n-note-4/9.png" alt="1572882658486" style="zoom:50%;"></p>
<p>利用加法和乘法门可以很好的解决梯度消失和梯度爆炸问题。</p>
<p><strong>图像标注</strong></p>
<p><img src="/2019/10/28/CS231n-note-4/6.png" alt></p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>CS231n-note-5</title>
    <url>/2019/11/05/CS231n-note-5/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<h1 id="图像识别和分割"><a href="#图像识别和分割" class="headerlink" title="图像识别和分割"></a>图像识别和分割</h1><h2 id="分割"><a href="#分割" class="headerlink" title="分割"></a>分割</h2><h3 id="语义分割"><a href="#语义分割" class="headerlink" title="语义分割"></a>语义分割</h3><p>只将像素进行分割并贴上对应的分类标签。</p>
<h4 id="Idea-1"><a href="#Idea-1" class="headerlink" title="Idea-1"></a><strong>Idea-1</strong></h4><p>sliding windows，利用滑动窗口来对个像素进行分类，计算量太大</p>
<h4 id="idea-2"><a href="#idea-2" class="headerlink" title="idea-2"></a><strong>idea-2</strong></h4><p>全连接卷积神经网络，可以生成一个CxHxW的张量，对每个像素进行评分，数据集获取昂贵且困难。并且模型训练代价很高。</p>
<h4 id="idea-3"><a href="#idea-3" class="headerlink" title="idea-3"></a><strong>idea-3</strong></h4><p>不采用全连接(同尺寸)卷积神经网络，而是采用downsampling和upsampling，在中间层可以用池化或者跨卷积来降低清晰度，但是可以让网络建立的很深。</p>
<h5 id="upsampling"><a href="#upsampling" class="headerlink" title="upsampling"></a>upsampling</h5><h6 id="去池化-Unpooling"><a href="#去池化-Unpooling" class="headerlink" title="去池化(Unpooling)"></a>去池化(Unpooling)</h6><p><img src="/2019/11/05/CS231n-note-5/1.png" alt="1572945307155" style="zoom:50%;"></p>
<h6 id="Max-Unpooling"><a href="#Max-Unpooling" class="headerlink" title="Max Unpooling"></a>Max Unpooling</h6><p><img src="/2019/11/05/CS231n-note-5/2.png" alt="1572945525749" style="zoom:50%;"></p>
<p>将池化层和去池化层相对应，其最大元素的相应位置将会被记录。</p>
<h6 id="转置卷积"><a href="#转置卷积" class="headerlink" title="转置卷积"></a>转置卷积</h6><p>正常卷积和跨卷积(可以进行downsampling)并且可以学习参数进行下采样</p>
<p>转置卷积</p>
<p>在进行转置卷积时，将每个元素(标量)乘以过滤器(卷积核)，然后将加权后的卷积核叠加于新的输出。</p>
<p><img src="/2019/11/05/CS231n-note-5/3.png" alt="1572946348192" style="zoom:50%;"></p>
<p>sample：</p>
<p><img src="/2019/11/05/CS231n-note-5/4.png" alt="1572946547455" style="zoom:50%;"></p>
<p>卷积矩阵化</p>
<p><img src="/2019/11/05/CS231n-note-5/5.png" alt="1572955265649" style="zoom:50%;"></p>
<p>$4<em>4input &lt;—&gt; 4</em>4output$</p>
<p><img src="/2019/11/05/CS231n-note-5/6.png" alt="1572955416177" style="zoom:50%;"></p>
<p>$4<em>4input &lt;—&gt;2</em>2output$</p>
<h2 id="分类和定位"><a href="#分类和定位" class="headerlink" title="分类和定位"></a>分类和定位</h2><p><img src="/2019/11/05/CS231n-note-5/7.png" alt="1572956657061" style="zoom:50%;"></p>
<p>定位一般使用回归损失函数。</p>
<h2 id="识别"><a href="#识别" class="headerlink" title="识别"></a>识别</h2><p>固定几类对象，再输入图片之后将识别图中对象框起来并预测该对象的从属类别。</p>
<p>输入图片的包含对象数量是不确定的。</p>
<h3 id="候选区域方法-Region-Proposals"><a href="#候选区域方法-Region-Proposals" class="headerlink" title="候选区域方法(Region Proposals)"></a><strong>候选区域方法(Region Proposals)</strong></h3><p>将输入的图像划分为若干(很多)区域，在应用卷积神经网络对其进行分类。</p>
<p>R-CNN    效率低</p>
<p>Fast R-CNN 不用事先确定候选区而是通过一个卷积神经网络生成特征映射，在特征映射上通过固定函数像素划分确定候选区</p>
<p>Faster R-CNN在确定备选区时自己进行区域选择网络的训练</p>
<h3 id="Detection-without-Proposals"><a href="#Detection-without-Proposals" class="headerlink" title="Detection without Proposals"></a><strong>Detection without Proposals</strong></h3><h4 id="YOLO-You-Only-Look-Once-SSD-Single-Shot-Detection"><a href="#YOLO-You-Only-Look-Once-SSD-Single-Shot-Detection" class="headerlink" title="YOLO(You Only Look Once)/SSD(Single Shot Detection)"></a>YOLO(You Only Look Once)/SSD(Single Shot Detection)</h4><p>利用回归，将输入图片划分为网格。 然后预测每个基本的方框的类别权重以及距离对象的信息。</p>
<p><img src="/2019/11/05/CS231n-note-5/8.png" alt="1572970026182" style="zoom:50%;"></p>
<h3 id="目标分割"><a href="#目标分割" class="headerlink" title="目标分割"></a>目标分割</h3><p><img src="/2019/11/05/CS231n-note-5/9.png" alt="1572972443690" style="zoom:50%;"></p>
<p> 两个分支，一个分支进行分类，一个分支进行类似语义分割确定对象的区域。  </p>
<h3 id="DeepDream-amp-Feature-Inversion"><a href="#DeepDream-amp-Feature-Inversion" class="headerlink" title="DeepDream&amp;Feature Inversion"></a>DeepDream&amp;Feature Inversion</h3><p>DeepDream：放大存在的特征</p>
<p>Feature Inversion：特征反演</p>
<h3 id="纹理拼接-amp-风格迁移"><a href="#纹理拼接-amp-风格迁移" class="headerlink" title="纹理拼接&amp;风格迁移"></a>纹理拼接&amp;风格迁移</h3><p>Gram Matrix</p>
<p><img src="/2019/11/05/CS231n-note-5/10.png" alt="1573008687755" style="zoom:50%;"></p>
<p><img src="/2019/11/05/CS231n-note-5/11.png" alt="1573008897926" style="zoom:50%;"></p>
<p>传统风格迁移会消耗大量的资源</p>
<p><strong>Fast Style Transfer</strong></p>
<h1 id="可视化和理解卷积神经网络"><a href="#可视化和理解卷积神经网络" class="headerlink" title="可视化和理解卷积神经网络"></a>可视化和理解卷积神经网络</h1>]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>计算机视觉</tag>
      </tags>
  </entry>
  <entry>
    <title>DETR-note</title>
    <url>/2020/06/03/DETR-note/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<h1 id="Transformer和Attention"><a href="#Transformer和Attention" class="headerlink" title="Transformer和Attention"></a>Transformer和Attention</h1><h3 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h3><p>Transformer本质上是一个Encoder-Decoder的结构</p>
<p><img src="/2020/06/03/DETR-note/1.png" style="zoom: 67%;"></p>
<p>在paper中，encoder和decoder都由6个block组成，编码器的输出作为解码器的输入。</p>
<p>encoders每个block都是独立的单元，不会share weights。每个block又由以下的两部分组成(self-attention和FFN)</p>
<p><img src="/2020/06/03/DETR-note/2.png" style="zoom:67%;"></p>
<p>在decoder部分每个block也和encoder相似，只是在两层之间加了一个attention层(类似于seq2seq的attention机制，可以让decoder更加关注input相关的部分)。</p>
<h4 id="编码器"><a href="#编码器" class="headerlink" title="编码器"></a>编码器</h4><p><img src="/2020/06/03/DETR-note/3.png" style="zoom:67%;"></p>
<p>编码器接受单词的词嵌入列表作为输入(列表中每个向量为512-d)。单词在通过self-attention层时会依赖单词之间的关系，但是在通过Feed Forward时没有这些依赖关系，可以并行进行。</p>
<h5 id="self-attention"><a href="#self-attention" class="headerlink" title="self-attention"></a>self-attention</h5><p>类似于RNN中的隐藏层，self-attention的作用是将其他单词的信息融入到正在处理的单词中。</p>
<p>PS： ”<code>The animal didn&#39;t cross the street because it was too tired</code>” 在处理it时会将前文the animal等信息加到it中。</p>
<p><strong>三个向量</strong></p>
<p>self-attention的<strong>第一步</strong>就是从输入的词嵌入向量列表生成三个向量(64-d)</p>
<p><img src="/2020/06/03/DETR-note/4.png" style="zoom:67%;"></p>
<hr>
<p><strong>query vector</strong>：与其他单词的key vector相乘计算得分<br><strong>key vector</strong>：与其他单词query vector相乘代表对其他单词在语义上的影响<br><strong>value vector</strong>：</p>
<p> <strong>第二步</strong>是对输入的单词进行得分计算，得分决定了这个词在句子中有多重视其他部分。</p>
<p>得分的计算是由其他单词的key vector和该单词的query vector进行点积计算。</p>
<p><strong>第三步</strong>是对每个得分除以$\sqrt{d_k}$然后进行softmax可以得出每个位置的单词对该位置的贡献。</p>
<p><strong>第四步</strong>是将每个单词的value vector与求出来的softmax权重相乘，可以关注语义上联系很强的单词。</p>
<p><strong>第五步</strong>是将所有带权重的value vector进行求和，当作self-attention的输出。</p>
<p><img src="/2020/06/03/DETR-note/5.png" style="zoom:50%;"></p>
<p>在实际的运算中是以矩阵来进行运算的。</p>
<p><img src="/2020/06/03/DETR-note/6.png" style="zoom:50%;"></p>
<h5 id="multi-head机制"><a href="#multi-head机制" class="headerlink" title="multi-head机制"></a>multi-head机制</h5><ol>
<li>多头注意力扩展了模型专注于不同位置的能力</li>
<li>可以将每个词嵌入投射到不同的子空间</li>
</ol>
<p>n个注意力头会产生n个z输出，通过$W^0$与拼接好的输出进行相乘得到最后融合多个注意力头的Z</p>
<p><img src="/2020/06/03/DETR-note/7.png" style="zoom:50%;"></p>
<p>self-attention的总体计算过程</p>
<p><img src="/2020/06/03/DETR-note/8.png" style="zoom:67%;"></p>
<h5 id="Position-Encoding"><a href="#Position-Encoding" class="headerlink" title="Position Encoding"></a>Position Encoding</h5><p>在词嵌入中，将每个单词的位置编码(向量)加入到嵌入向量中，描述单词的输入顺序。</p>
<p><img src="/2020/06/03/DETR-note/9.png" style="zoom:67%;"><img src="/2020/06/03/DETR-note/10.png" alt></p>
<p>(Positional Embedding左半部分通过正弦函数求出，右半部分通过余弦函数求出)</p>
<h5 id="Residuals"><a href="#Residuals" class="headerlink" title="Residuals"></a>Residuals</h5><p><img src="/2020/06/03/DETR-note/10.png" style="zoom:67%;"></p>
<h4 id="解码器"><a href="#解码器" class="headerlink" title="解码器"></a>解码器</h4><p> <img src="https://jalammar.github.io/images/t/transformer_decoding_2.gif" alt="img"> </p>
<p>编码器通过处理输入序列开启工作。顶端编码器的输出之后会变转化为一个包含向量K（键向量）和V（值向量）的注意力向量集 。这些向量将被每个解码器用于自身的“编码-解码注意力层”，而这些层可以帮助解码器关注输入序列哪些位置合适 。</p>
<p> 这个“编码-解码注意力层”工作方式基本就像多头自注意力层一样，只不过它是通过在它下面的层来创造查询矩阵，并且从编码器的输出中取得键/值矩阵。 </p>
<p><strong>整体结构</strong></p>
<p><img src="/2020/06/03/DETR-note/11.png" style="zoom:80%;"></p>
<h2 id="DETR"><a href="#DETR" class="headerlink" title="DETR"></a>DETR</h2><h3 id="二分图匹配损失函数-bipartite-matiching-loss"><a href="#二分图匹配损失函数-bipartite-matiching-loss" class="headerlink" title="二分图匹配损失函数(bipartite matiching loss)"></a>二分图匹配损失函数(bipartite matiching loss)</h3><p>图片经过CNN提取特征输入Transformer模型，输出N个固定prediction box(class, bbox)格式。GT的bbox也以(class,bbox)的形式存在，并且补齐N个$(\emptyset,*)$ bbox。</p>
<p>通过最佳匹配算法(匈牙利算法)来确定GT的最佳匹配框，然后可以计算损失函数。</p>
<p>将输出的bbox与GT的bbox对应起来，寻找一个最佳的对应关系，使得loss最小。(这样做的好处是可以将多个输出相同object的框选择一个最优的输出bbox与GT标注框对应，迫使模型学习输出更多不同object的bbox，并且匈牙利算法会对预测的object数大于GT的object数进行惩罚)</p>
<h3 id="DETR结构"><a href="#DETR结构" class="headerlink" title="DETR结构"></a>DETR结构</h3><p><img src="/2020/06/03/DETR-note/12.png" alt></p>
<ol>
<li><p>将图像经过CNN提取的特征与object的位置positional encoding结合送入transformer encoder中。</p>
<p>(由于transformer只接受序列化输入，所以将(C,H,W) flatten 得到(C, HXW)的序列化特征)</p>
</li>
<li><p>将encoder的输出特征传入decoder(相当于一个特征映射的过程，encoder能够学习更多的其他位置的特征)，decoder的输入是object queries，object queries首先是n个随机变量，经过decoder融合encoder输出的图像信息得出n个合适的bbox输出（n个object queries可以当作n个不同的人从n个不同的角度对图像进行观测，<strong>注意</strong>图像不同的地方，<strong>是需要学习的</strong>）</p>
</li>
</ol>
<p><strong>具体结构</strong></p>
<p><img src="/2020/06/03/DETR-note/13.png" style="zoom:80%;"></p>
<h3 id="实现代码"><a href="#实现代码" class="headerlink" title="实现代码"></a>实现代码</h3><p><strong>pytorch</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torchvision.models <span class="keyword">import</span> resnet50</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DETR</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_classes, hidden_dim, nheads,</span></span></span><br><span class="line"><span class="function"><span class="params">num_encoder_layers, num_decoder_layers</span>):</span></span><br><span class="line">	super().__init__()</span><br><span class="line"><span class="comment"># We take only convolutional layers from ResNet-50 model</span></span><br><span class="line">	self.backbone = nn.Sequential(*list(resnet50(pretrained=<span class="literal">True</span>).children())[:<span class="number">-2</span>])</span><br><span class="line">	self.conv = nn.Conv2d(<span class="number">2048</span>, hidden_dim, <span class="number">1</span>)</span><br><span class="line">    self.transformer = nn.Transformer(hidden_dim, nheads,</span><br><span class="line">	num_encoder_layers, num_decoder_layers)</span><br><span class="line">	self.linear_class = nn.Linear(hidden_dim, num_classes + <span class="number">1</span>)</span><br><span class="line">	self.linear_bbox = nn.Linear(hidden_dim, <span class="number">4</span>)</span><br><span class="line">	self.query_pos = nn.Parameter(torch.rand(<span class="number">100</span>, hidden_dim))</span><br><span class="line">	self.row_embed = nn.Parameter(torch.rand(<span class="number">50</span>, hidden_dim // <span class="number">2</span>))</span><br><span class="line">	self.col_embed = nn.Parameter(torch.rand(<span class="number">50</span>, hidden_dim // <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, inputs</span>):</span></span><br><span class="line">		x = self.backbone(inputs)</span><br><span class="line">		h = self.conv(x)</span><br><span class="line">		H, W = h.shape[<span class="number">-2</span>:]</span><br><span class="line">		pos = torch.cat([</span><br><span class="line">		self.col_embed[:W].unsqueeze(<span class="number">0</span>).repeat(H, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">		self.row_embed[:H].unsqueeze(<span class="number">1</span>).repeat(<span class="number">1</span>, W, <span class="number">1</span>),</span><br><span class="line">			], dim=<span class="number">-1</span>).flatten(<span class="number">0</span>, <span class="number">1</span>).unsqueeze(<span class="number">1</span>)</span><br><span class="line">		h = self.transformer(pos + h.flatten(<span class="number">2</span>).permute(<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>),</span><br><span class="line">		self.query_pos.unsqueeze(<span class="number">1</span>))</span><br><span class="line">		<span class="keyword">return</span> self.linear_class(h), self.linear_bbox(h).sigmoid()</span><br><span class="line"></span><br><span class="line">detr = DETR(num_classes=<span class="number">91</span>, hidden_dim=<span class="number">256</span>, nheads=<span class="number">8</span>, num_encoder_layers=<span class="number">6</span>, num_decoder_layers=<span class="number">6</span>)</span><br><span class="line">detr.eval()</span><br><span class="line">inputs = torch.randn(<span class="number">1</span>, <span class="number">3</span>, <span class="number">800</span>, <span class="number">1200</span>)</span><br><span class="line">logits, bboxes = detr(inputs)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>Django学习笔记（一）</title>
    <url>/2019/03/12/Django%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<h2 id="Django文件"><a href="#Django文件" class="headerlink" title="Django文件"></a>Django文件</h2><h3 id="urls-py"><a href="#urls-py" class="headerlink" title="urls.py"></a>urls.py</h3><p>网址入口，关联到对应的views.py中的一个函数（或者generic类），访问网址就对应一个函数。</p>
<h3 id="views-py"><a href="#views-py" class="headerlink" title="views,py"></a>views,py</h3><p>处理用户发出的请求，从urls.py中对应过来, 通过渲染templates中的网页可以将显示内容，比如登陆后的用户名，用户请求的数据，输出到网页。</p>
<h3 id="models-py"><a href="#models-py" class="headerlink" title="models.py"></a>models.py</h3><p>与数据库操作相关，存入或读取数据时用到这个，当然用不到数据库的时候 你可以不使用。</p>
<h3 id="forms-py"><a href="#forms-py" class="headerlink" title="forms.py"></a>forms.py</h3><p>表单，用户在浏览器上输入数据提交，对数据的验证工作以及输入框的生成等工作，当然你也可以不使用。</p>
<p><strong>templates 文件夹</strong></p>
<p>views.py 中的函数渲染templates中的Html模板，得到动态内容的网页，当然可以用缓存来提高速度。</p>
<h3 id="admin-py"><a href="#admin-py" class="headerlink" title="admin.py"></a>admin.py</h3><p>后台，可以用很少量的代码就拥有一个强大的后台。</p>
<h3 id="settings-py"><a href="#settings-py" class="headerlink" title="settings.py"></a>settings.py</h3><p>Django 的设置，配置文件，比如 DEBUG 的开关，静态文件的位置等。</p>
<h2 id="Django安装"><a href="#Django安装" class="headerlink" title="Django安装"></a>Django安装</h2><h3 id="Django"><a href="#Django" class="headerlink" title="Django"></a>Django</h3><p>Windows下在Anaconda Prompt中用pip install Django安装</p>
<h3 id="虚拟环境依赖安装（搭建多个开发环境）"><a href="#虚拟环境依赖安装（搭建多个开发环境）" class="headerlink" title="虚拟环境依赖安装（搭建多个开发环境）"></a>虚拟环境依赖安装（搭建多个开发环境）</h3><p>Windows下Anaconda Prompt中用</p>
<p>pip install virtualenv virtualenvwrapper-win</p>
<p>安装</p>
<h4 id="虚拟环境使用方法"><a href="#虚拟环境使用方法" class="headerlink" title="虚拟环境使用方法"></a>虚拟环境使用方法</h4><p><strong>mkvirtualenv</strong> zqxt：创建运行环境zqxt</p>
<p><strong>workon</strong> zqxt: 工作在 zqxt 环境 或 从其它环境切换到 zqxt 环境</p>
<p><strong>deactivate</strong>: 退出终端环境</p>
<p><strong>rmvirtualenv</strong> ENV：删除运行环境ENV</p>
<p><strong>mkproject</strong> mic：创建mic项目和运行环境mic</p>
<p><strong>mktmpenv</strong>：创建临时运行环境</p>
<p><strong>lsvirtualenv</strong>: 列出可用的运行环境</p>
<p><strong>lssitepackages</strong>: 列出当前环境安装了的包</p>
<p>创建的环境是独立的，互不干扰，无需sudo权限即可使用 pip 来进行包的管理。</p>
]]></content>
      <categories>
        <category>Web学习</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title>Django学习笔记（二）</title>
    <url>/2019/03/12/Django%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<h2 id="Django基本命令"><a href="#Django基本命令" class="headerlink" title="Django基本命令"></a>Django基本命令</h2><h3 id="创建project"><a href="#创建project" class="headerlink" title="创建project"></a>创建project</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$django-admin startproject myproject</span><br></pre></td></tr></table></figure>
<p>进入myproject目录</p>
<h3 id="使用开发服务器"><a href="#使用开发服务器" class="headerlink" title="使用开发服务器"></a>使用开发服务器</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$ python manage.py runserver</span><br></pre></td></tr></table></figure>
<p>会报错</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">You&#39;re accessing the development server over HTTPS, but it only supports HTTP.</span><br></pre></td></tr></table></figure>
<p>django 默认的runserver使用的是http协议，如果需要https协议，需要以下3个库</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">django-extensions </span><br><span class="line">django-werkzeug-debugger-runserver </span><br><span class="line">pyOpenSSL</span><br></pre></td></tr></table></figure>
<p>安装</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pip install django-extensions</span><br><span class="line"></span><br><span class="line">pip install django-werkzeug-debugger-runserver</span><br><span class="line"></span><br><span class="line">pip install pyOpenSSL</span><br></pre></td></tr></table></figure>
<p>配置django的settings.py文件</p>
<p>在INSTALLED_APPS下添加</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;werkzeug_debugger_runserver&#x27;</span>,</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;django_extensions&#x27;</span>,</span><br></pre></td></tr></table></figure>
<p>在终端以https的方式运行</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$python manage.py runserver_plus --cert server.crt</span><br></pre></td></tr></table></figure>
<h3 id="创建APP"><a href="#创建APP" class="headerlink" title="创建APP"></a>创建APP</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$ python manage.py startapp learn</span><br></pre></td></tr></table></figure>
<h3 id="创建数据库表或更改数据库表或字段"><a href="#创建数据库表或更改数据库表或字段" class="headerlink" title="创建数据库表或更改数据库表或字段"></a>创建数据库表或更改数据库表或字段</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 1. 创建更改的文件</span></span><br><span class="line">python manage.py makemigrations</span><br><span class="line"><span class="comment"># 2. 将生成的py文件应用到数据库</span></span><br><span class="line">python manage.py migrate</span><br></pre></td></tr></table></figure>
<h3 id="清空数据库"><a href="#清空数据库" class="headerlink" title="清空数据库"></a>清空数据库</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$python manage.py flush</span><br></pre></td></tr></table></figure>
<h3 id="创建超级管理员"><a href="#创建超级管理员" class="headerlink" title="创建超级管理员"></a>创建超级管理员</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$python manage.py createsuperuser</span><br><span class="line"></span><br><span class="line"><span class="comment"># 按照提示输入用户名和对应的密码就好了邮箱可以留空，用户名和密码必填</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改 用户密码可以用：</span></span><br><span class="line">$python manage.py changepassword username</span><br></pre></td></tr></table></figure>
<h3 id="Django项目环境终端"><a href="#Django项目环境终端" class="headerlink" title="Django项目环境终端"></a>Django项目环境终端</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$python manage.py shell</span><br></pre></td></tr></table></figure>
<h3 id="数据库命令行"><a href="#数据库命令行" class="headerlink" title="数据库命令行"></a>数据库命令行</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$python manage.py dbshell</span><br></pre></td></tr></table></figure>
<p>Django 会自动进入在settings.py中设置的数据库，如果是 MySQL 或 postgreSQL,会要求输入数据库用户密码。</p>
<p>在这个终端可以执行数据库的SQL语句。如果对SQL比较熟悉，可能喜欢这种方式。</p>
<h2 id="视图"><a href="#视图" class="headerlink" title="视图"></a>视图</h2><p>在/views.py中输入代码</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> django.http <span class="keyword">import</span> HttpResponse</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">index</span>(<span class="params">request</span>):</span></span><br><span class="line">    <span class="keyword">return</span> HttpResponse(<span class="string">&quot;Hello, world. You&#x27;re at the learn index.&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>如果想看见效果，我们需要将一个 URL 映射到它</p>
<p>为了创建 URLconf，请在 learn目录里新建一个 <code>urls.py</code> 文件。</p>
<p>在urls.py中输入代码</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> django.urls <span class="keyword">import</span> path</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> . <span class="keyword">import</span> views</span><br><span class="line"></span><br><span class="line">urlpatterns = [</span><br><span class="line">    path(<span class="string">&#x27;&#x27;</span>, views.index, name=<span class="string">&#x27;index&#x27;</span>),</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">path函数有四个参数</span></span><br><span class="line"><span class="string">两个必须参数：route 和 view，两个可选参数：kwargs 和 name。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@route:</span></span><br><span class="line"><span class="string">route 是一个匹配 URL 的准则（类似正则表达式）。当 Django 响应一个请求时，它会从 urlpatterns 的第一项开始，按顺序依次匹配列表中的项，直到找到匹配的项。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">这些准则不会匹配 GET 和 POST 参数或域名。例如，URLconf 在处理请求 https://www.example.com/myapp/ 时，它会尝试匹配 myapp/ 。处理请求 https://www.example.com/myapp/?page=3 时，也只会尝试匹配 myapp/。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@view:</span></span><br><span class="line"><span class="string">当 Django 找到了一个匹配的准则，就会调用这个特定的视图函数，并传入一个 HttpRequest 对象作为第一个参数，被“捕获”的参数以关键字参数的形式传入。稍后，我们会给出一个例子。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@kwargs:</span></span><br><span class="line"><span class="string">任意个关键字参数可以作为一个字典传递给目标视图函数。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@name:</span></span><br><span class="line"><span class="string">为你的 URL 取名能使你在 Django 的任意地方唯一地引用它，尤其是在模板中。这个有用的特性允许你只改一个文件就能全局地修改某个 URL 模式。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>下一步是要在根 URLconf 文件中指定我们创建的 <code>learn.urls</code> 模块。在 <code>vx/urls.py</code> 文件的 <code>urlpatterns</code> 列表里插入一个 <code>include()</code>， 如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> django.contrib <span class="keyword">import</span> admin</span><br><span class="line"><span class="keyword">from</span> django.urls <span class="keyword">import</span> include, path</span><br><span class="line"></span><br><span class="line">urlpatterns = [</span><br><span class="line">    path(<span class="string">&#x27;learn/&#x27;</span>, include(<span class="string">&#x27;learn.urls&#x27;</span>)),</span><br><span class="line">    path(<span class="string">&#x27;admin/&#x27;</span>, admin.site.urls),</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>函数 <code>include()</code>允许引用其它 URLconfs。每当 Django 遇到 <code>:func：~django.urls.include</code>时，它会截断与此项匹配的 URL 的部分，并将剩余的字符串发送到 URLconf 以供进一步处理。</p>
<p>我们设计 <code>include()</code>的理念是使其可以即插即用。因为应用有它自己的URLconf( <code>vx/urls.py</code> )，他们能够被放在<code>&quot;/vx/&quot; ， &quot;/fun_vx/&quot; ，&quot;/content/vx/&quot;</code>，或者其他任何路径下，这个应用都能够正常工作。</p>
<p>当包括其它 URL 模式时你应该总是使用 <code>include()</code> ， <code>admin.site.urls</code> 是唯一例外。</p>
<p>运行</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$python manage.py runserver_plus --cert server.crt</span><br></pre></td></tr></table></figure>
<p>访问<code>.../learn</code>即可看见简单的文字视图</p>
<h2 id="数据库配置"><a href="#数据库配置" class="headerlink" title="数据库配置"></a>数据库配置</h2><p><code>vx/settings.py</code>是Django项目设置的python模块。</p>
<p>通常，这个配置文件使用 SQLite 作为默认数据库。如果你不熟悉数据库，或者只是想尝试下 Django，这是最简单的选择。Python 内置 SQLite，所以你无需安装额外东西来使用它。当你开始一个真正的项目时，你可能更倾向使用一个更具扩展性的数据库，例如 PostgreSQL，避免中途切换数据库这个令人头疼的问题。</p>
<p>如果你想使用其他数据库，你需要安装合适的 <a href="https://docs.djangoproject.com/zh-hans/2.1/topics/install/#database-installation">database bindings</a> ，然后改变设置文件中 <a href="https://docs.djangoproject.com/zh-hans/2.1/ref/settings/#std:setting-DATABASES"><code>DATABASES</code></a> <code>&#39;default&#39;</code> 项目中的一些键值：</p>
<ul>
<li><a href="https://docs.djangoproject.com/zh-hans/2.1/ref/settings/#std:setting-DATABASE-ENGINE"><code>ENGINE</code></a> — 可选值有 <code>&#39;django.db.backends.sqlite3&#39;</code>，<code>&#39;django.db.backends.postgresql&#39;</code>，<code>&#39;django.db.backends.mysql&#39;</code>，或 <code>&#39;django.db.backends.oracle&#39;</code>。其它 <a href="https://docs.djangoproject.com/zh-hans/2.1/ref/databases/#third-party-notes">可用后端</a>。</li>
<li><a href="https://docs.djangoproject.com/zh-hans/2.1/ref/settings/#std:setting-NAME"><code>NAME</code></a> - 数据库的名称。如果使用的是 SQLite，数据库将是你电脑上的一个文件，在这种情况下， <a href="https://docs.djangoproject.com/zh-hans/2.1/ref/settings/#std:setting-NAME"><code>NAME</code></a> 应该是此文件的绝对路径，包括文件名。默认值 <code>os.path.join(BASE_DIR, &#39;db.sqlite3&#39;)</code> 将会把数据库文件储存在项目的根目录。</li>
</ul>
<p>在编辑/settings之前，将TIME_ZONE设置为自己所在时区</p>
<p>通常， <a href="https://docs.djangoproject.com/zh-hans/2.1/ref/settings/#std:setting-INSTALLED_APPS"><code>INSTALLED_APPS</code></a> 默认包括了以下 Django 的自带应用：</p>
<ul>
<li><a href="https://docs.djangoproject.com/zh-hans/2.1/ref/contrib/admin/#module-django.contrib.admin"><code>django.contrib.admin</code></a> — 管理员站点， 你很快就会使用它。</li>
<li><a href="https://docs.djangoproject.com/zh-hans/2.1/topics/auth/#module-django.contrib.auth"><code>django.contrib.auth</code></a> — 认证授权系统。</li>
<li><a href="https://docs.djangoproject.com/zh-hans/2.1/ref/contrib/contenttypes/#module-django.contrib.contenttypes"><code>django.contrib.contenttypes</code></a> — 内容类型框架。</li>
<li><a href="https://docs.djangoproject.com/zh-hans/2.1/topics/http/sessions/#module-django.contrib.sessions"><code>django.contrib.sessions</code></a> — 会话框架。</li>
<li><a href="https://docs.djangoproject.com/zh-hans/2.1/ref/contrib/messages/#module-django.contrib.messages"><code>django.contrib.messages</code></a> — 消息框架。</li>
<li><a href="https://docs.djangoproject.com/zh-hans/2.1/ref/contrib/staticfiles/#module-django.contrib.staticfiles"><code>django.contrib.staticfiles</code></a> — 管理静态文件的框架。</li>
</ul>
<p>这些应用被默认启用是为了给常规项目提供方便。</p>
<p>默认开启的某些应用需要至少一个数据表，所以，在使用他们之前需要在数据库中创建一些表。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$python manage.py migrate</span><br></pre></td></tr></table></figure>
<h2 id="创造模型"><a href="#创造模型" class="headerlink" title="创造模型"></a>创造模型</h2><p>在 Django 里写一个数据库驱动的 Web 应用的第一步是定义模型 - 也就是数据库结构设计和附加的其它元数据。</p>
<p>在learn/models.py中创建python类</p>
<h2 id="激活模型"><a href="#激活模型" class="headerlink" title="激活模型"></a>激活模型</h2><p>创建模型的代码给了 Django 很多信息，通过这些信息，Django 可以：</p>
<ul>
<li>为这个应用创建数据库 schema（生成 <code>CREATE TABLE</code> 语句）。</li>
<li>创建可以与 <code>Question</code> 和 <code>Choice</code> 对象进行交互的 Python 数据库 API。</li>
</ul>
<p>但是首先得把 <code>learn</code> 应用安装到我们的项目里。</p>
<p>为了在我们的工程中包含这个应用，我们需要在配置类 <a href="https://docs.djangoproject.com/zh-hans/2.1/ref/settings/#std:setting-INSTALLED_APPS"><code>INSTALLED_APPS</code></a> 中添加设置。因为 <code>learnConfig</code> 类写在文件 <code>learn/apps.py</code> 中，所以它的点式路径是 <code>&#39;learn.apps.learnConfig&#39;</code>。在文件 <code>mysite/settings.py</code>中 <a href="https://docs.djangoproject.com/zh-hans/2.1/ref/settings/#std:setting-INSTALLED_APPS"><code>INSTALLED_APPS</code></a> 子项添加点式路径。</p>
<p>运行命令进行模型迁移</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$python manage.py  makemigrations learn</span><br></pre></td></tr></table></figure>
<p>运行<code>migrate</code>命令在数据库里创建新定义的模型的数据表</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$python manage.py migrate</span><br></pre></td></tr></table></figure>
<p>迁移是非常强大的功能，它能让你在开发过程中持续的改变数据库结构而不需要重新删除和创建表 - 它专注于使数据库平滑升级而不会丢失数据。我们会在后面的教程中更加深入的学习这部分内容，现在，你只需要记住，改变模型需要这三步：</p>
<ul>
<li>编辑 <code>models.py</code> 文件，改变模型。</li>
<li>运行 <a href="https://docs.djangoproject.com/zh-hans/2.1/ref/django-admin/#django-admin-makemigrations"><code>python manage.py makemigrations</code></a> 为模型的改变生成迁移文件。</li>
<li>运行 <a href="https://docs.djangoproject.com/zh-hans/2.1/ref/django-admin/#django-admin-migrate"><code>python manage.py migrate</code></a> 来应用数据库迁移。</li>
</ul>
]]></content>
      <categories>
        <category>Web学习</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title>Django学习笔记（三）</title>
    <url>/2019/03/12/Django%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<h1 id="初试API"><a href="#初试API" class="headerlink" title="初试API"></a>初试API</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$python manage.py shell</span><br></pre></td></tr></table></figure>
<h1 id="创建一个管理员账号"><a href="#创建一个管理员账号" class="headerlink" title="创建一个管理员账号"></a>创建一个管理员账号</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$python manage.py createsuperuser</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Web学习</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title>FCN note</title>
    <url>/2020/04/13/FCN-note/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<h1 id="FCN：Semantic-Segmentation"><a href="#FCN：Semantic-Segmentation" class="headerlink" title="FCN：Semantic Segmentation"></a>FCN：Semantic Segmentation</h1><p>图像的语义分割，简言之就是对一张图片上的所有像素点进行分类</p>
<h4 id="1-FCN介绍"><a href="#1-FCN介绍" class="headerlink" title="1 FCN介绍"></a>1 FCN介绍</h4><p>​    与传统的CNN解决的分类与检测问题不同，语义分割是一个空间密集型的预测任务，是<strong>像素级别</strong>的，需要对图像上所有的像素进行分类。 由于CNN在进行convolution和pooling过程中丢失了图像细节，即feature map size逐渐变小，所以不能很好地指出物体的具体轮廓、指出每个像素具体属于哪个物体，无法做到精确的分割。 </p>
<p>​    FCN是针对语义分割训练的的一个端到端的网络, 是处理语义分割问题的基本框架，后续算法其实都是在这个框架中改进而来。 </p>
<h5 id="1-1-卷积化"><a href="#1-1-卷积化" class="headerlink" title="1.1 卷积化"></a>1.1 卷积化</h5><p>​    在一般的分类任务中在conv层之后一般会有全连接层,将二维的图像特征压缩为一维,可以训练输出一个标量,成为分类标签。这样做会失去部分的空间信息，不适用于分割的操作。</p>
<p>​    语义分割输出为分割图，信息是二维的，所以在进行网络构建的时候抛弃了全连接层而是采用了卷积层，叫做卷积化。</p>
<p><img src="/2020/04/13/FCN-note/1.png" alt></p>
<h5 id="1-2-上采样-Upsampling"><a href="#1-2-上采样-Upsampling" class="headerlink" title="1.2 上采样(Upsampling)"></a>1.2 上采样(Upsampling)</h5><p>上采样与下采样相反，我们需要得到原图像的分割图就需要将缩小的特征恢复到原来的size。</p>
<p>上采样一般有两种方式：</p>
<ul>
<li>Resize 即图片缩放</li>
<li>Deconvolution（反卷积） 也叫做Transposed Convolution（转置卷积）</li>
</ul>
<p>常用的方式就是反卷积</p>
<p>反卷积通俗的来讲就是将普通的卷积操作反过来做。</p>
<p>PS：</p>
<p>输入为2X2矩阵，kernel_size = 3, pad = 0, stride = 1,进行反卷积操作会变成4X4的矩阵</p>
<p><img src="/2020/04/13/FCN-note/1.gif" style="zoom:50%;"></p>
<p>反卷积公式如下</p>
<p>$output = (input-1)<em>stride + outputpadding-2</em>padding+kernel_size$</p>
<p>upsampling的意义在于小尺寸的高纬度feature map恢复成原来图像的大小，再做像素预测，获取每个像素的分类信息。</p>
<p>为了更好地将图像还原成原来的尺寸，在FCN中还加入了crop层，</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#caffe中的crop层定义</span></span><br><span class="line">layer &#123;</span><br><span class="line">  name: <span class="string">&quot;score_pool4c&quot;</span></span><br><span class="line">  type: <span class="string">&quot;Crop&quot;</span></span><br><span class="line">  bottom: <span class="string">&quot;score_pool4&quot;</span>  <span class="comment"># 需要裁切的blob</span></span><br><span class="line">  bottom: <span class="string">&quot;upscore2&quot;</span>     <span class="comment"># 用于指示裁切尺寸的blob，和输出blob一样大</span></span><br><span class="line">  top: <span class="string">&quot;score_pool4c&quot;</span>    <span class="comment"># 输出blob</span></span><br><span class="line">  crop_param &#123;</span><br><span class="line">    axis: <span class="number">2</span></span><br><span class="line">    offset: <span class="number">5</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>相当于在图像的W，H纬度进行剪裁。用python的语法表示为</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">score_pool4c = score_pool4[:, :, <span class="number">5</span>:<span class="number">5</span>+crop_h, <span class="number">5</span>:<span class="number">5</span>+crop_w]</span><br></pre></td></tr></table></figure>
<h5 id="1-3-跳跃结构-Skip-Architecture"><a href="#1-3-跳跃结构-Skip-Architecture" class="headerlink" title="1.3 跳跃结构(Skip Architecture)"></a>1.3 跳跃结构(Skip Architecture)</h5><p>​    如果只用最后一层池化结果进行上采样的话得到的结果通常十分粗糙，所以FCN采用了将不同池化层的结果进行上采样最后叠加的结构来增加精确度。</p>
<p><img src="/2020/04/13/FCN-note/2.png" style="zoom:80%;"></p>
<p> 效果：FCN-32s &lt; FCN-16s &lt; FCN-8s，即<strong>使用多层feature融合有利于提高分割准确性</strong>。 </p>
<p><img src="/2020/04/13/FCN-note/3.png" style="zoom:80%;"></p>
<h4 id="2-代码实现"><a href="#2-代码实现" class="headerlink" title="2 代码实现"></a>2 代码实现</h4><p><strong>FCN model代码</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FCN8s</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_classes, pretrained=True, caffe=False</span>):</span></span><br><span class="line">        super(FCN8s, self).__init__()</span><br><span class="line">        vgg = models.vgg16()</span><br><span class="line">        <span class="keyword">if</span> pretrained:</span><br><span class="line">            <span class="keyword">if</span> caffe:</span><br><span class="line">                <span class="comment"># load the pretrained vgg16 used by the paper&#x27;s author</span></span><br><span class="line">                vgg.load_state_dict(torch.load(vgg16_caffe_path))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                vgg.load_state_dict(torch.load(vgg16_path))</span><br><span class="line">        features, classifier = list(vgg.features.children()), list(vgg.classifier.children())</span><br><span class="line"></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        100 padding for 2 reasons:</span></span><br><span class="line"><span class="string">            1) support very small input size</span></span><br><span class="line"><span class="string">            2) allow cropping in order to match size of different layers&#x27; feature maps</span></span><br><span class="line"><span class="string">        Note that the cropped part corresponds to a part of the 100 padding</span></span><br><span class="line"><span class="string">        Spatial information of different layers&#x27; feature maps cannot be align exactly because of cropping, which is bad</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        features[<span class="number">0</span>].padding = (<span class="number">100</span>, <span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> f <span class="keyword">in</span> features:</span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;MaxPool&#x27;</span> <span class="keyword">in</span> f.__class__.__name__:</span><br><span class="line">                f.ceil_mode = <span class="literal">True</span></span><br><span class="line">            <span class="keyword">elif</span> <span class="string">&#x27;ReLU&#x27;</span> <span class="keyword">in</span> f.__class__.__name__:</span><br><span class="line">                f.inplace = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">        self.features3 = nn.Sequential(*features[: <span class="number">17</span>])</span><br><span class="line">        self.features4 = nn.Sequential(*features[<span class="number">17</span>: <span class="number">24</span>])</span><br><span class="line">        self.features5 = nn.Sequential(*features[<span class="number">24</span>:])</span><br><span class="line"></span><br><span class="line">        self.score_pool3 = nn.Conv2d(<span class="number">256</span>, num_classes, kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.score_pool4 = nn.Conv2d(<span class="number">512</span>, num_classes, kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.score_pool3.weight.data.zero_()</span><br><span class="line">        self.score_pool3.bias.data.zero_()</span><br><span class="line">        self.score_pool4.weight.data.zero_()</span><br><span class="line">        self.score_pool4.bias.data.zero_()</span><br><span class="line"></span><br><span class="line">        fc6 = nn.Conv2d(<span class="number">512</span>, <span class="number">4096</span>, kernel_size=<span class="number">7</span>)</span><br><span class="line">        fc6.weight.data.copy_(classifier[<span class="number">0</span>].weight.data.view(<span class="number">4096</span>, <span class="number">512</span>, <span class="number">7</span>, <span class="number">7</span>))</span><br><span class="line">        fc6.bias.data.copy_(classifier[<span class="number">0</span>].bias.data)</span><br><span class="line">        fc7 = nn.Conv2d(<span class="number">4096</span>, <span class="number">4096</span>, kernel_size=<span class="number">1</span>)</span><br><span class="line">        fc7.weight.data.copy_(classifier[<span class="number">3</span>].weight.data.view(<span class="number">4096</span>, <span class="number">4096</span>, <span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        fc7.bias.data.copy_(classifier[<span class="number">3</span>].bias.data)</span><br><span class="line">        score_fr = nn.Conv2d(<span class="number">4096</span>, num_classes, kernel_size=<span class="number">1</span>)</span><br><span class="line">        score_fr.weight.data.zero_()</span><br><span class="line">        score_fr.bias.data.zero_()</span><br><span class="line">        self.score_fr = nn.Sequential(</span><br><span class="line">            fc6, nn.ReLU(inplace=<span class="literal">True</span>), nn.Dropout(), fc7, nn.ReLU(inplace=<span class="literal">True</span>), nn.Dropout(), score_fr</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.upscore2 = nn.ConvTranspose2d(num_classes, num_classes, kernel_size=<span class="number">4</span>, stride=<span class="number">2</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.upscore_pool4 = nn.ConvTranspose2d(num_classes, num_classes, kernel_size=<span class="number">4</span>, stride=<span class="number">2</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.upscore8 = nn.ConvTranspose2d(num_classes, num_classes, kernel_size=<span class="number">16</span>, stride=<span class="number">8</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.upscore2.weight.data.copy_(get_upsampling_weight(num_classes, num_classes, <span class="number">4</span>))</span><br><span class="line">        self.upscore_pool4.weight.data.copy_(get_upsampling_weight(num_classes, num_classes, <span class="number">4</span>))</span><br><span class="line">        self.upscore8.weight.data.copy_(get_upsampling_weight(num_classes, num_classes, <span class="number">16</span>))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x_size = x.size()</span><br><span class="line">        pool3 = self.features3(x)</span><br><span class="line">        pool4 = self.features4(pool3)</span><br><span class="line">        pool5 = self.features5(pool4)</span><br><span class="line"></span><br><span class="line">        score_fr = self.score_fr(pool5)</span><br><span class="line">        upscore2 = self.upscore2(score_fr)</span><br><span class="line"></span><br><span class="line">        score_pool4 = self.score_pool4(<span class="number">0.01</span> * pool4)</span><br><span class="line">        upscore_pool4 = self.upscore_pool4(score_pool4[:, :, <span class="number">5</span>: (<span class="number">5</span> + upscore2.size()[<span class="number">2</span>]), <span class="number">5</span>: (<span class="number">5</span> + upscore2.size()[<span class="number">3</span>])]</span><br><span class="line">                                           + upscore2)</span><br><span class="line"></span><br><span class="line">        score_pool3 = self.score_pool3(<span class="number">0.0001</span> * pool3)</span><br><span class="line">        upscore8 = self.upscore8(score_pool3[:, :, <span class="number">9</span>: (<span class="number">9</span> + upscore_pool4.size()[<span class="number">2</span>]), <span class="number">9</span>: (<span class="number">9</span> + upscore_pool4.size()[<span class="number">3</span>])]</span><br><span class="line">                                 + upscore_pool4)</span><br><span class="line">        <span class="keyword">return</span> upscore8[:, :, <span class="number">31</span>: (<span class="number">31</span> + x_size[<span class="number">2</span>]), <span class="number">31</span>: (<span class="number">31</span> + x_size[<span class="number">3</span>])].contiguous()</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>语义分割</tag>
      </tags>
  </entry>
  <entry>
    <title>FPN-note</title>
    <url>/2020/05/06/FPN-note/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<h1 id="FPN-Feature-Pyramid-Networks-for-Object-Detection"><a href="#FPN-Feature-Pyramid-Networks-for-Object-Detection" class="headerlink" title="FPN(Feature Pyramid Networks for Object Detection)"></a>FPN(Feature Pyramid Networks for Object Detection)</h1><p>FPN解决的主要问题是检测算法在处理多尺度变化问题时的不足以及对小物体检测不友好的问题。传统的方法是构造图像特征金字塔，但是计算量很大，FPN通过独特的构造避免了计算量过高的问题，并且有良好的多尺度处理性能。</p>
<p><img src="/2020/05/06/FPN-note/1.png" alt></p>
<p>图a为传统的多尺度特征提取方法，计算量极大。</p>
<p>图b为单一特征的检测系统，有很大的局限性。</p>
<p>图c为网络多层次结构提取特征，但是存在底层语义较弱的问题。</p>
<p>图d为FPN金字塔特征提取，能够让各个不同尺度的特征都拥有较强的语义信息。</p>
<h2 id="FPN算法"><a href="#FPN算法" class="headerlink" title="FPN算法"></a>FPN算法</h2><p> FPN包含两个部分：第一部分是自底向上的过程，第二部分是自顶向下和侧向连接的融合过程。 </p>
<h3 id="自底向上过程"><a href="#自底向上过程" class="headerlink" title="自底向上过程"></a>自底向上过程</h3><p> 自底向上的过程和普通的CNN没有区别。现代的CNN网络一般都是按照特征图大小划分为不同的stage，每个stage之间特征图的尺度比例相差为2。在FPN中，每个stage对应了一个特征金字塔的级别（level），并且每个stage的最后一层特征被选为对应FPN中相应级别的特征。以ResNet为例，选取conv2、conv3、conv4、conv5层的最后一个残差block层特征作为FPN的特征，记为{C2、C3、C4、C5}。这几个特征层相对于原图的步长分别为4、8、16、32。 </p>
<h3 id="自顶向下过程"><a href="#自顶向下过程" class="headerlink" title="自顶向下过程"></a>自顶向下过程</h3><p>自顶向下的过程通过上采样（up-sampling）的方式将顶层的小特征图（例如20）放大到上一个stage的特征图一样的大小（例如40）。这样的好处是既利用了顶层较强的语义特征（利于分类），又利用了底层的高分辨率信息（利于定位）。上采样的方法可以用最近邻差值实现。为了将高层语义特征和底层的精确定位能力结合，作者提出类似于残差网络的侧向连接结构。侧向连接将上一层经过上采样后和当前层分辨率一致的特征，通过相加的方法进行融合。（这里为了修正通道数量，将当前层先经过1x1卷积操作。）如图所示。</p>
<p><img src="/2020/05/06/FPN-note/2.png" style="zoom:80%;"></p>
<p>具体的，C5层先经过1x1卷积，得到M5特征。M5通过上采样，再加上C4经过1x1卷积后的特征，得到M4。这个过程再做两次，分别得到M3和M2。M层特征再经过3x3卷积，得到最终的P2、P3、P4、P5层特征。另外，和传统的图像金字塔方式一样，所有M层的通道数都设计成一样的，本文都用d=256。细节图如下所示（以ResNet为例）： </p>
<p><img src="/2020/05/06/FPN-note/3.png" style="zoom:67%;"></p>
<p> FPN本身不是检测算法，只是一个特征提取器。它需要和其他检测算法结合才能使用。 RetinaNet就是一个运用了FPN的网络。</p>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>以Resnet为Backbone</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PyramidFeatures</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, C3_size, C4_size, C5_size, feature_size=<span class="number">256</span></span>):</span></span><br><span class="line">        super(PyramidFeatures, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># upsample C5 to get P5 from the FPN paper</span></span><br><span class="line">        self.P5_1 = nn.Conv2d(C5_size, feature_size, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>)</span><br><span class="line">        self.P5_upsampled = nn.Upsample(scale_factor=<span class="number">2</span>, mode=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">        self.P5_2 = nn.Conv2d(feature_size, feature_size, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># add P5 elementwise to C4</span></span><br><span class="line">        self.P4_1 = nn.Conv2d(C4_size, feature_size, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>)</span><br><span class="line">        self.P4_upsampled = nn.Upsample(scale_factor=<span class="number">2</span>, mode=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line">        self.P4_2 = nn.Conv2d(feature_size, feature_size, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># add P4 elementwise to C3</span></span><br><span class="line">        self.P3_1 = nn.Conv2d(C3_size, feature_size, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>)</span><br><span class="line">        self.P3_2 = nn.Conv2d(feature_size, feature_size, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># &quot;P6 is obtained via a 3x3 stride-2 conv on C5&quot;</span></span><br><span class="line">        self.P6 = nn.Conv2d(C5_size, feature_size, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># &quot;P7 is computed by applying ReLU followed by a 3x3 stride-2 conv on P6&quot;</span></span><br><span class="line">        self.P7_1 = nn.ReLU()</span><br><span class="line">        self.P7_2 = nn.Conv2d(feature_size, feature_size, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, inputs</span>):</span></span><br><span class="line">        C3, C4, C5 = inputs</span><br><span class="line"></span><br><span class="line">        P5_x = self.P5_1(C5)</span><br><span class="line">        P5_upsampled_x = self.P5_upsampled(P5_x)</span><br><span class="line">        P5_x = self.P5_2(P5_x)</span><br><span class="line"></span><br><span class="line">        P4_x = self.P4_1(C4)</span><br><span class="line">        P4_x = P5_upsampled_x + P4_x</span><br><span class="line">        P4_upsampled_x = self.P4_upsampled(P4_x)</span><br><span class="line">        P4_x = self.P4_2(P4_x)</span><br><span class="line"></span><br><span class="line">        P3_x = self.P3_1(C3)</span><br><span class="line">        P3_x = P3_x + P4_upsampled_x</span><br><span class="line">        P3_x = self.P3_2(P3_x)</span><br><span class="line"></span><br><span class="line">        P6_x = self.P6(C5)</span><br><span class="line"></span><br><span class="line">        P7_x = self.P7_1(P6_x)</span><br><span class="line">        P7_x = self.P7_2(P7_x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> [P3_x, P4_x, P5_x, P6_x, P7_x]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux下的信号量机制与编程</title>
    <url>/2019/04/22/Linux%E4%B8%8B%E7%9A%84%E4%BF%A1%E5%8F%B7%E9%87%8F%E6%9C%BA%E5%88%B6%E4%B8%8E%E7%BC%96%E7%A8%8B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<h1 id="信号量"><a href="#信号量" class="headerlink" title="信号量"></a>信号量</h1><p>当我们在多用户系统，多进程系统，或是两者混合的系统中使用线程操作编写程序时，我们经常会发现我们有段临界代码，在此处我们需要保证一个进程（或是一个线程的执行）需要排他的访问一个资源。</p>
<p>为了解决这个问题，引用了信号量机制，我们可以使用互斥或信号量来控制一个多线程程序对于临界区的访问。</p>
<p>信号量是一个特殊的变量，他是一个整数，并且只有两个操 作可以使得其值增加：等待(wait)与信号(signal)。</p>
<p><strong>用于等待(wait)的P(信号量变量)</strong><br><strong>用于信号(signal)的V(信号量变量)</strong></p>
<h2 id="二值信号量"><a href="#二值信号量" class="headerlink" title="二值信号量"></a>二值信号量</h2><p>二值信号量使是只有0和1两个值的变量</p>
<p>假如有一个信号量为mutex，有如下两个操作</p>
<ul>
<li>P(mutex)/wait(mutex)    若mutex大于0,mutex减为0;若mutex等于0,则挂起该进程</li>
<li>V(mutex)/signal(mutex)     若有进程被挂起等待mutex则释放mutex使被挂起的进程执行,若没有,则mutex加到1</li>
</ul>
<font color="red">**mutex取值只能为1/0**</font>

<p>也叫互斥信号量,可以用其管理临界区资源的控制权</p>
<h1 id="Linux中的信号量工具"><a href="#Linux中的信号量工具" class="headerlink" title="Linux中的信号量工具"></a>Linux中的信号量工具</h1><h2 id="信号量函数"><a href="#信号量函数" class="headerlink" title="信号量函数"></a>信号量函数</h2><p>信号量函数定义:</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/sem.h&gt;/*有可能还需要包含sys/types.h与sys/ipc.h文件*/</span></span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">semctl</span><span class="params">(<span class="keyword">int</span> sem_id, <span class="keyword">int</span> sem_num, <span class="keyword">int</span> command, ...)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">semget</span><span class="params">(<span class="keyword">key_t</span> key, <span class="keyword">int</span> num_sems, <span class="keyword">int</span> sem_flags)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">semop</span><span class="params">(<span class="keyword">int</span> sem_id, struct sembuf *sem_ops, <span class="keyword">size_t</span> num_sem_ops)</span></span>;</span><br></pre></td></tr></table></figure>
<p>这些函数用于操作信号量值数组</p>
<h3 id="semget函数"><a href="#semget函数" class="headerlink" title="semget函数"></a>semget函数</h3><p><strong>semget的作用： 创建一个新信号量 或者 取得一个已有的信号量</strong></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">semget</span><span class="params">(<span class="keyword">key_t</span> key, <span class="keyword">int</span> num_sems, <span class="keyword">int</span> sem_flags)</span></span>;</span><br></pre></td></tr></table></figure>
<ul>
<li><p><strong>key</strong>是整数值(唯一非零),可以任意指定一个正整数,semget可以根据key,<strong>新创建一个信号量</strong>,返回改信号量的标识,不相关的进程可以通过它访问这个创建的信号量,代表程序可能会使用某个资源.如果在两个进程中使用相同的key则key将负责两个进程的协调工作.</p>
<p><strong>PS:</strong></p>
<p>​    同一个key值返回的信号量标识相同</p>
<p>​    不同的key值会创建不同的信号量,且信号量之间没有任何关系</p>
</li>
<li><p><strong>num_sems</strong>表示需要的信号量数目,一般为1</p>
</li>
<li><p><strong>sem_flags</strong>是一组标志,与fopen函数的 “w” “b” “r”类似,最低的9位二进制数字代表了这个信号量的权限信息.如IPC_CREATE | 0666,这些标记可以与 IPC_CREAT进行或操作来创建新的信号量,同时又可以用于取一个已有的信号量,使用IPC_CREAT | IPC_EXCL 来确保新建信号量，如果信号量已经有了会返回错误。</p>
<p><strong>PS:</strong></p>
<p>​    IPC_CREAT   如果共享内存不存在，则创建一个共享内存，否则打开操作。</p>
<p>​    IPC_EXCL     只有在共享内存不存在的时候，新的共享内存才建立，否则就产生错误。</p>
</li>
</ul>
<p>semget函数成功返回一个相应信号量标识符(非0),失败返回-1.</p>
<h3 id="semop函数"><a href="#semop函数" class="headerlink" title="semop函数"></a>semop函数</h3><p><strong>semop函数用于对信号量进行操作。</strong></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">semop</span><span class="params">(<span class="keyword">int</span> sem_id, struct sembuf *sem_opa, <span class="keyword">size_t</span> num_sem_ops)</span></span>;</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>sem_id</strong>,表示对哪一个信号量进行操作,由semget函数返回</li>
<li><strong>sembuf *sem_ops</strong></li>
</ul>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">sembuf</span> &#123;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">short</span> sem_num;  <span class="comment">//要处理的信号量的下标,即指定对哪个信号灯进行操作(0,1,2...)若为二值信号量则为0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">short</span> sem_op;     <span class="comment">//要执行的操作,1表示加一,-1表示减一</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">short</span> sem_flg;     <span class="comment">//操作标志,通常设置为SEM_UNDO。这会使得操作系统跟踪当前进程对信号量所					  //做的改变，而且如果进程终止而没有释放这个信号量， 如果信号量为这个进					 //程所占有，这个标记可以使得操作系统自动释放这个信号量。</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>size_t num_sem_ops</strong>表示操作次数一般为1</li>
</ul>
<h3 id="semctl函数"><a href="#semctl函数" class="headerlink" title="semctl函数"></a>semctl函数</h3><p><strong>semctl用于直接控制信号量的信息，例如初始化一个值或删除信号量。</strong></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">semctl</span><span class="params">(<span class="keyword">int</span> sem_id, <span class="keyword">int</span> sem_num, <span class="keyword">int</span> command, ...)</span></span>;</span><br></pre></td></tr></table></figure>
<ul>
<li><p><strong>sem_id</strong>,表示对哪一个信号量进行操作,由semget函数返回</p>
</li>
<li><p><strong>sem_num</strong>,要处理的信号量的下标,即指定对哪个信号灯进行操作(0,1,2…)若为二值信号量则为0</p>
</li>
<li><p><strong>command</strong>,表示要执行的动作</p>
<ul>
<li>SETVAL：用于初始化信号量为一个已知的值。所需要的值作为联合semun.val成员来传递。在信号量第一次使用之前需要设置信号量。</li>
<li>IPC_RMID：当信号量不再需要时用于删除一个信号量标识。</li>
</ul>
</li>
<li><p><strong>union semun</strong> </p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">union</span> semun&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> val;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">semid_ds</span> *<span class="title">buf</span>;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">short</span> *<span class="built_in">array</span>;</span><br><span class="line"></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>这个声明一般包含在sem.h里面，也有可能没有，没有的话需要自己声明。</p>
</li>
</ul>
<p>根据command的不同，返回值也不同。对于 SETVAL和IPC_RMID 成功返回0 失败返回-1</p>
<h2 id="信号量的使用"><a href="#信号量的使用" class="headerlink" title="信号量的使用"></a>信号量的使用</h2><h3 id="创建信号量"><a href="#创建信号量" class="headerlink" title="创建信号量"></a>创建信号量</h3><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> sem_id;</span><br><span class="line">sem_id = semget((<span class="keyword">key_t</span>)<span class="number">1234</span>, <span class="number">2</span>, <span class="number">0666</span> | IPC_CREAT);</span><br><span class="line"><span class="keyword">if</span> (sem_id == <span class="number">-1</span>)</span><br><span class="line">    <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">&quot;Failed to create semapore\n&quot;</span>);</span><br></pre></td></tr></table></figure>
<h3 id="设置信号量初值"><a href="#设置信号量初值" class="headerlink" title="设置信号量初值"></a>设置信号量初值</h3><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">set_semvalue</span><span class="params">(<span class="keyword">int</span> sem_id, <span class="keyword">int</span> index, <span class="keyword">int</span> value)</span><span class="comment">//index为信号量中的第几个信号灯</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">		<span class="keyword">union</span> semun sem_union;</span><br><span class="line">		sem_union.val = value;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">if</span> (semctl(sem_id, index, SETVAL, sem_union) == <span class="number">-1</span>) </span><br><span class="line">			<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="删除信号量"><a href="#删除信号量" class="headerlink" title="删除信号量"></a>删除信号量</h3><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">del_semvalue</span><span class="params">(<span class="keyword">int</span> sem_id)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="keyword">if</span> (semctl(sem_id, <span class="number">0</span>, IPC_RMID) == <span class="number">-1</span>)</span><br><span class="line">		<span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">&quot;Failed to delete semapore\n&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="P操作"><a href="#P操作" class="headerlink" title="P操作"></a>P操作</h3><p>P操作是通过调用<strong>semop</strong>函数实现的。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">P</span><span class="params">(<span class="keyword">int</span> sem_id, <span class="keyword">int</span> index)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">sembuf</span> <span class="title">sem_b</span>;</span></span><br><span class="line"></span><br><span class="line">	sem_b.sem_num = index;</span><br><span class="line">	sem_b.sem_op = <span class="number">-1</span>;</span><br><span class="line">	sem_b.sem_flg = SEM_UNDO;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> (semop(sem_id, &amp;sem_b, <span class="number">1</span>) == <span class="number">-1</span>)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">&quot;semapore_p failed\n&quot;</span>);</span><br><span class="line">		<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="V操作"><a href="#V操作" class="headerlink" title="V操作"></a>V操作</h3><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">V</span><span class="params">(<span class="keyword">int</span> sem_id, <span class="keyword">int</span> index)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">		<span class="class"><span class="keyword">struct</span> <span class="title">sembuf</span> <span class="title">sem_b</span>;</span></span><br><span class="line"></span><br><span class="line">		sem_b.sem_num = index;</span><br><span class="line">		sem_b.sem_op = <span class="number">1</span>;</span><br><span class="line">		sem_b.sem_flg = SEM_UNDO;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">if</span> (semop(sem_id, &amp;sem_b, <span class="number">1</span>) == <span class="number">-1</span>)</span><br><span class="line">		&#123;</span><br><span class="line">				<span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">&quot;semapore_v failed\n&quot;</span>);</span><br><span class="line">				<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>Linux编程</tag>
      </tags>
  </entry>
  <entry>
    <title>Faster_RCNN 笔记</title>
    <url>/2020/04/11/Faster-RCNN-%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<p>Faster RCNN是在2016提出的用于目标检测的网络结构，并且与之前的网络不同，已经将特征提取(feature extraction)，proposal提取，bounding box regression，classification都整合在了一个网络之中。由于RCNN的准确度很大一部分依赖于proposal区域的选择，所以候选区确定尤为重要。Faster RCNN中的RPN是一个最为突出也是最重要的部分。</p>
<h3 id="Faster-RCNN的基本结构"><a href="#Faster-RCNN的基本结构" class="headerlink" title="Faster_RCNN的基本结构"></a>Faster_RCNN的基本结构</h3><p><img src="/2020/04/11/Faster-RCNN-%E7%AC%94%E8%AE%B0/1.png" style="zoom:67%;"></p>
<p><strong>1.Conv layers</strong></p>
<p>Faster RCNN首先使用了基础的Conv layer(conv+relu+pooling)提取输入图像的feature maps。提取出来的feature maps共享用于后续的RPN层以及全连接层。</p>
<p><strong><font color="red">2.RPN(Region Proposal Networks)</font></strong></p>
<p>RPN是Faster RCNN中最重要的部分，用于生成region proposals。RPN中引入了一个重要的概念anchor，通过每个位置的anchor(共有k个选框生成)，输出2k个score评估选框是否为目标，4k个score确定选框的位置。 <strong>正是anchor的引入实现了通过单一尺度图像特征映射并使用单一滤波器解决多尺度问题。</strong>softmax判断anchors属于positive或者negative，再利用bounding box regression修正anchors获得精确的proposals。 </p>
<p><strong>3.Roi Pooling</strong></p>
<p>该层收集输入的feature maps和proposals，综合这些信息后提取proposal feature maps，送入后续全连接层判定目标类别。</p>
<p><strong>4.Classification</strong></p>
<p>利用proposal feature maps计算proposal的类别，同时再次bounding box regression获得检测框最终的精确位置。 </p>
<h3 id="Faster-RCNN结构分析"><a href="#Faster-RCNN结构分析" class="headerlink" title="Faster RCNN结构分析"></a>Faster RCNN结构分析</h3><p><img src="/2020/04/11/Faster-RCNN-%E7%AC%94%E8%AE%B0/2.png" style="zoom:80%;"></p>
<p>​    上图是基于VGG16的Faster RCNN网络结构，输入任意尺寸的image，缩放至固定大小MXN，然后经过Conv layers提取feature maps先送入RPN网络中，通过3X3的卷积生成positive anchors以及对应的bounding box regression偏移量，输出proposals进入Roi poooling层通过proposal feature map进行classification。</p>
<h4 id="1-Conv-layers"><a href="#1-Conv-layers" class="headerlink" title="1 Conv layers"></a>1 Conv layers</h4><p>卷积层一共包括常规的三种层(conv,relu,pooling)</p>
<p><strong>conv层</strong></p>
<p>kernel_size = 3, pad = 1, stride = 1</p>
<p><strong>pooling层</strong></p>
<p>kernel_size = 3, pad = 1, stride = 1</p>
<p>在经过conv层之后，输入输出矩阵尺度不变。</p>
<p>最后变成M/16，N/16的feature map</p>
<h4 id="2-Region-Proposal-Networks-RPN"><a href="#2-Region-Proposal-Networks-RPN" class="headerlink" title="2 Region Proposal Networks(RPN)"></a>2 Region Proposal Networks(RPN)</h4><p>​     经典的检测方法生成检测框都非常耗时，如OpenCV adaboost使用滑动窗口+图像金字塔生成检测框；或如R-CNN使用SS(Selective Search)方法生成检测框。而Faster RCNN则抛弃了传统的滑动窗口和SS方法，直接使用RPN生成检测框，这也是Faster R-CNN的巨大优势，能极大提升检测框的生成速度。 </p>
<h5 id="2-1-anchors"><a href="#2-1-anchors" class="headerlink" title="2.1 anchors"></a>2.1 anchors</h5><pre><code> 遍历Conv layers计算获得的feature maps，为每一个点都配备这9种anchors作为初始的检测框。 之后可以通过bbox regression修正检测的位置。
</code></pre><p><img src="/2020/04/11/Faster-RCNN-%E7%AC%94%E8%AE%B0/3.png" alt></p>
<p>​    </p>
<p>​    在原文中最后的conv5层输出了256个特征图，即每个点对应256-dimensions。在最后conv5层之后进入RPN层利用3X3的卷积输出，维度也是256-d，在conv5输出的feature map上每个点对应k个anchor(默认k = 9)。每个anchor需要判断是都为positive anchor，每个点有256-d转化为cls = 2k scores，每个anchor又有4个偏移量确定位置(x, y, w, h)，reg = 4k scores。在进行训练时会随机选取1:1数量的positive anchor和negative anchor进行训练。</p>
<h5 id="2-2-每个anchor的输出"><a href="#2-2-每个anchor的输出" class="headerlink" title="2.2 每个anchor的输出"></a>2.2 每个anchor的输出</h5><p>在mmdetection的源代码rpn_head.py中对anchor的卷积描述为</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.rpn_cls = nn.Conv2d(self.feat_channels,</span><br><span class="line">                         self.num_anchors * self.cls_out_channels, <span class="number">1</span>)</span><br><span class="line">self.rpn_reg = nn.Conv2d(self.feat_channels, self.num_anchors * <span class="number">4</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>cls做了1X1的卷积输出为2k，代表该anchor是否为positive。</p>
<p>reg做了1X1的卷积输出为4k，代表该anchor对应region proposal的位置。</p>
<p> <strong>RPN最终就是在原图尺度上，设置了密密麻麻的候选Anchor。然后用cnn去判断哪些Anchor是里面有目标的positive anchor，哪些是没目标的negative anchor。所以，仅仅是个二分类而已！</strong> </p>
<h5 id="2-3-bbox-regression原理"><a href="#2-3-bbox-regression原理" class="headerlink" title="2.3 bbox regression原理"></a>2.3 bbox regression原理</h5><p>如图所示绿色框为飞机的Ground Truth(GT)，红色为提取的positive anchors，即便红色的框被分类器识别为飞机，但是由于红色的框定位不准，这张图相当于没有正确的检测出飞机。所以我们希望采用一种方法对红色的框进行微调，使得positive anchors和GT更加接近。</p>
<p><img src="/2020/04/11/Faster-RCNN-%E7%AC%94%E8%AE%B0/4.png" alt></p>
<p>bbox regression的目标是寻找一种关系使输入的anchor A经过映射得到跟真实窗口G更接近的回归窗口G’。（TODO）</p>
<p>对应于Faster RCNN原文，positive anchor与ground truth之间的平移量 <img src="https://www.zhihu.com/equation?tex=%28t_x%2C+t_y%29" alt="[公式]"> 与尺度因子 <img src="https://www.zhihu.com/equation?tex=%28t_w%2C+t_h%29" alt="[公式]"> 如下：</p>
<p><img src="https://www.zhihu.com/equation?tex=t_x%3D%28x-x_a%29%2Fw_a%5C+%5C+%5C+%5C++t_y%3D%28y-y_a%29%2Fh_a%5C%5C" alt="[公式]"></p>
<p><img src="https://www.zhihu.com/equation?tex=t_w%3D%5Clog%28w%2Fw_a%29%5C+%5C+%5C+%5C+t_h%3D%5Clog%28h%2Fh_a%29%5C%5C" alt="[公式]"></p>
<p>对于训练bouding box regression网络回归分支，输入是cnn feature Φ，监督信号是Anchor与GT的差距 <img src="https://www.zhihu.com/equation?tex=%28t_x%2C+t_y%2C+t_w%2C+t_h%29" alt="[公式]">，即训练目标是：输入 Φ的情况下使网络输出与监督信号尽可能接近。那么当bouding box regression工作时，再输入Φ时，回归网络分支的输出就是每个Anchor的平移量和变换尺度 <img src="https://www.zhihu.com/equation?tex=%28t_x%2C+t_y%2C+t_w%2C+t_h%29" alt="[公式]">，显然即可用来修正Anchor位置了。</p>
<p><strong>对proposals进行bounding box regression</strong></p>
<p><img src="/2020/04/11/Faster-RCNN-%E7%AC%94%E8%AE%B0/6.png" alt></p>
<p>经卷积输出后的图像为(W,H,36)，相当于feature map每个店都有9个anchors，每个anchors有四个用于回归的变换量。</p>
<h5 id="2-4-Proposal-layer"><a href="#2-4-Proposal-layer" class="headerlink" title="2.4 Proposal layer"></a>2.4 Proposal layer</h5><p><img src="/2020/04/11/Faster-RCNN-%E7%AC%94%E8%AE%B0/5.png" alt></p>
<p>Propsal layer负责综合所有的$[d_x(A), d_y(A),d_w(A),d_h(A)]$变换量和positive anchors，计算出精准的proposal，送入后续的RoIl Pooling Layer。</p>
<p> Proposal Layer有3个输入：positive vs negative anchors分类器结果rpn_cls_prob_reshape，对应的bbox reg的 $[d_x(A), d_y(A),d_w(A),d_h(A)]$变换量rpn_bbox_pred，以及im_info；另外还有参数feature_stride=16。<br>首先解释im_info。对于一副任意大小PxQ图像，传入Faster RCNN前首先reshape到固定MxN，im_info=[M, N, scale_factor]则保存了此次缩放的所有信息。然后经过Conv Layers，经过4次pooling变为WxH=(M/16)x(N/16)大小，其中feature_stride=16则保存了该信息，用于计算anchor偏移量。 </p>
<ol>
<li>对<strong>所有</strong> anchors 做bbox regression回归（learning offset）</li>
<li>对 <strong>foreground</strong> (iou&gt;0.7) softmax scores由大到小排序anchors，提取 6000/12000(test/train) anchors(<strong>已经在上一步进行好了 coord reg</strong>)</li>
<li>限定超出图像边界的 foreground anchors 为图像边界（防止后续roi pooling时proposal超出图像边界）</li>
<li>剔除非常小的foreground anchors <strong>(__C.TRAIN.RPN_MIN_SIZE = 16)</strong></li>
<li>进行 NMS(threshold=0.7)</li>
<li><p>提取 NMS 后的前300/2000(test/train) 个 fg anchor 结果作为proposal输出</p>
<p>RPN网络结构总结起来就是：<br><strong>生成anchors -&gt; softmax分类器提取positvie anchors -&gt; bbox reg回归positive anchors -&gt; Proposal Layer生成proposals</strong> </p>
</li>
</ol>
<h4 id="3-RoI-Pooling"><a href="#3-RoI-Pooling" class="headerlink" title="3 RoI Pooling"></a>3 RoI Pooling</h4><p>RoI Pooling负责收集proposal并计算出proposal feature maps，送入后面的classification网络。</p>
<p>RoI Pooling层有两个输入：</p>
<p>1.原始的feature maps</p>
<p>2.RPN输出的proposal boxes</p>
<p>与传统网络不同，传入的图像尺寸必须是固定值，就需要进行crop或者wrap，但效果都不好，破坏了图像原始的信息，这正是需要引入RoIl Pooling的理由。</p>
<h5 id="3-1-RoI-Pooling原理"><a href="#3-1-RoI-Pooling原理" class="headerlink" title="3.1 RoI Pooling原理"></a>3.1 RoI Pooling原理</h5><p>TODO</p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>OCR手写识别_NoTe1</title>
    <url>/2019/11/07/OCR%E6%89%8B%E5%86%99%E8%AF%86%E5%88%AB-NoTe1/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>OCR手写识别</tag>
      </tags>
  </entry>
  <entry>
    <title>POSIX信号量</title>
    <url>/2019/04/22/POSIX%E4%BF%A1%E5%8F%B7%E9%87%8F/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<h1 id="POSIX信号量的操作"><a href="#POSIX信号量的操作" class="headerlink" title="POSIX信号量的操作"></a>POSIX信号量的操作</h1><p>POSIX信号量有两种：<strong>有名信号量</strong>和<strong>无名信号量</strong>，无名信号量也被称作基于内存的信号量。有名信号量通过IPC名字进行进程间的同步，而无名信号量如果不是放在进程间的共享内存区中，是不能用来进行进程间同步的，只能用来进行线程同步。</p>
<h2 id="POSIX三种操作"><a href="#POSIX三种操作" class="headerlink" title="POSIX三种操作"></a>POSIX三种操作</h2><h3 id="创建信号量"><a href="#创建信号量" class="headerlink" title="创建信号量"></a>创建信号量</h3><p>创建的过程还要求初始化信号量的值。</p>
<p>根据信号量取值（代表可用资源的数目）的不同，POSIX信号量还可以分为：</p>
<ul>
<li><p>二值信号量：信号量的值只有0和1，这和互斥量很类型，若资源被锁住，信号量的值为0，若资源可用，则信号量的值为1；</p>
</li>
<li><p>计数信号量：信号量的值在0到一个大于1的限制值（POSIX指出系统的最大限制值至少要为32767）。该计数表示可用的资源的个数。</p>
</li>
</ul>
<h3 id="等待信号量-wait-P操作"><a href="#等待信号量-wait-P操作" class="headerlink" title="等待信号量(wait)/P操作"></a>等待信号量(wait)/P操作</h3><p>该操作会检查信号量的值，如果其值小于或等于0，那就阻塞，直到该值变成大于0，然后等待进程将信号量的值减1，进程获得共享资源的访问权限。为原子操作。</p>
<h3 id="挂出一个信号量-post-V操作"><a href="#挂出一个信号量-post-V操作" class="headerlink" title="挂出一个信号量(post)/V操作"></a>挂出一个信号量(post)/V操作</h3><p>该操作将信号量的值加1，如果有进程阻塞着等待该信号量，那么其中一个进程将被唤醒。</p>
<h2 id="POSIX信号量函数接口"><a href="#POSIX信号量函数接口" class="headerlink" title="POSIX信号量函数接口"></a>POSIX信号量函数接口</h2><h3 id="有名信号量的创建和删除"><a href="#有名信号量的创建和删除" class="headerlink" title="有名信号量的创建和删除"></a>有名信号量的创建和删除</h3><p><strong>创建</strong></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;semaphore.h&gt;</span></span></span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">sem_t</span> *<span class="title">sem_open</span><span class="params">(<span class="keyword">const</span> <span class="keyword">char</span> *name, <span class="keyword">int</span> oflag)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">sem_t</span> *<span class="title">sem_open</span><span class="params">(<span class="keyword">const</span> <span class="keyword">char</span> *name, <span class="keyword">int</span> oflag,</span></span></span><br><span class="line"><span class="function"><span class="params">                  <span class="keyword">mode_t</span> mode, <span class="keyword">unsigned</span> <span class="keyword">int</span> value)</span></span>;</span><br><span class="line">                              <span class="comment">//成功返回信号量指针，失败返回SEM_FAILED</span></span><br></pre></td></tr></table></figure>
<ul>
<li>信号量通过name参数即信号量的名字来进行标识</li>
<li><strong>oflag</strong>参数可以为：0，O_CREAT，O_EXCL，<strong>0</strong>表示打开一个已存在的信号量，如果为<strong>O_CREAT</strong>，表示如果信号量不存在就创建一个信号量，如果存在则打开被返回。此时mode和value需要指定。如果为<strong>O_CREAT | O_EXCL</strong>，表示如果信号量已存在会返回错误。</li>
<li><strong>mode</strong>参数用于创建信号量时，表示信号量的权限位，和open函数一样包括：S_IRUSR，S_IWUSR，S_IRGRP，S_IWGRP，S_IROTH，S_IWOTH。</li>
<li><strong>value</strong>表示创建信号量时，信号量的初始值。</li>
</ul>
<p><strong>删除</strong></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;semaphore.h&gt;</span></span></span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">sem_close</span><span class="params">(<span class="keyword">sem_t</span> *sem)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">sem_unlink</span><span class="params">(<span class="keyword">const</span> <span class="keyword">char</span> *name)</span></span>;</span><br><span class="line">                              <span class="comment">//成功返回0，失败返回-1</span></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>sem_close</strong></li>
<li></li>
</ul>
<h1 id="互斥量和信号量的差别"><a href="#互斥量和信号量的差别" class="headerlink" title="互斥量和信号量的差别"></a>互斥量和信号量的差别</h1><ul>
<li>互斥量必须由给它上锁的线程解锁。而信号量不需要由等待它的线程进行挂出，可以在其他进程进行挂出操作。</li>
<li><p>互斥量要么被锁住，要么是解开状态，只有这两种状态。而信号量的值可以支持多个进程成功进行wait操作。</p>
</li>
<li><p>信号量的挂出操作总是被记住，因为信号量有一个计数值，挂出操作总会将该计数值加1，然而当向条件变量发送一个信号时，如果没有线程等待在条件变量，那么该信号会丢失。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>Linux编程</tag>
      </tags>
  </entry>
  <entry>
    <title>PSPNet-note</title>
    <url>/2020/04/15/PSPNet-note/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<h3 id="Pyramid-Scene-Parseing-Network-Note"><a href="#Pyramid-Scene-Parseing-Network-Note" class="headerlink" title="Pyramid Scene Parseing Network  Note"></a>Pyramid Scene Parseing Network  Note</h3><p>​    PSPNet 采用金字塔池化模块搭建的场景分析网络 ， <strong>基于语义分割的场景解析，其目的是赋予图像中每个像素一个类别标签</strong>。 </p>
<h4 id="1-PSPNet介绍"><a href="#1-PSPNet介绍" class="headerlink" title="1 PSPNet介绍"></a>1 PSPNet介绍</h4><p>由于传统的FCN存在缺陷：</p>
<p><img src="/2020/04/15/PSPNet-note/1.png" alt></p>
<ol>
<li>不匹配上下文关系， <strong>FCN将水中的“boat”预测为“car”</strong> 。</li>
<li>类别混淆，将摩天大楼一部分识别成了其他。</li>
<li><p>不显著的类别难以预测，可能会忽略小的东西。</p>
<p>基于对FCN的透彻分析，作者提出了能够获取全局场景的深度网络PSPNet，可以融合局部特征和全局特征，有较好的效果。</p>
</li>
</ol>
<h5 id="1-1-Pyramid-Pooling-Module（金字塔池化模块）"><a href="#1-1-Pyramid-Pooling-Module（金字塔池化模块）" class="headerlink" title="1.1  Pyramid Pooling Module（金字塔池化模块）"></a>1.1  <strong>Pyramid Pooling Module</strong>（金字塔池化模块）</h5><p>​     金字塔池化模块Pyramid Pooling Module由一组不同尺度的池化块组成 </p>
<p><img src="/2020/04/15/PSPNet-note/2.png" alt></p>
<p>​    该模块融合了4种不同金字塔尺度的特征，第一行红色是最粗糙的特征–全局池化生成单个bin输出，后面三行是不同尺度的池化特征。为了保证全局特征的权重，如果金字塔共有N个级别，则在每个级别后使用1X1的卷积将对于级别通道降为原本的1/N。再通过双线性插值获得未池化前的大小，最终concat到一起。<br>​    在POOL过程中，论文一共采用了$1X1,2X2,3X3,6X6$ 4个等级的池化尺寸(即<strong>输出尺寸</strong>)进行池化。</p>
<h5 id="1-2-基于ResNet的预训练辅助损失函数"><a href="#1-2-基于ResNet的预训练辅助损失函数" class="headerlink" title="1.2 基于ResNet的预训练辅助损失函数"></a>1.2 基于ResNet的预训练辅助损失函数</h5><p><img src="/2020/04/15/PSPNet-note/3.png" alt></p>
<pre><code> 在ResNet101的基础上做了改进，除了使用后面的softmax分类做loss，额外的在第四阶段添加了一个辅助的loss， 叫做**auxiliary loss**， 两个loss一起传播，使用不同的权重，共同优化参数。后续的实验证明这样做有利于快速收敛。 
</code></pre><h4 id="2-代码实现"><a href="#2-代码实现" class="headerlink" title="2 代码实现"></a>2 代码实现</h4><p>金字塔池化以及PSPNet网络架构</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">_PyramidPoolingModule</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_dim, reduction_dim, setting</span>):</span></span><br><span class="line">        super(_PyramidPoolingModule, self).__init__()</span><br><span class="line">        self.features = []</span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> setting:</span><br><span class="line">            self.features.append(nn.Sequential(</span><br><span class="line">                nn.AdaptiveAvgPool2d(s),</span><br><span class="line">                nn.Conv2d(in_dim, reduction_dim, kernel_size=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">                nn.BatchNorm2d(reduction_dim, momentum=<span class="number">.95</span>),</span><br><span class="line">                nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">            ))</span><br><span class="line">        self.features = nn.ModuleList(self.features)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x_size = x.size()</span><br><span class="line">        out = [x]</span><br><span class="line">        <span class="keyword">for</span> f <span class="keyword">in</span> self.features:</span><br><span class="line">            out.append(F.upsample(f(x), x_size[<span class="number">2</span>:], mode=<span class="string">&#x27;bilinear&#x27;</span>))</span><br><span class="line">        out = torch.cat(out, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PSPNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_classes, pretrained=True, use_aux=True</span>):</span></span><br><span class="line">        super(PSPNet, self).__init__()</span><br><span class="line">        self.use_aux = use_aux</span><br><span class="line">        resnet = models.resnet101()</span><br><span class="line">        <span class="keyword">if</span> pretrained:</span><br><span class="line">            resnet.load_state_dict(torch.load(res101_path))</span><br><span class="line">        self.layer0 = nn.Sequential(resnet.conv1, resnet.bn1, resnet.relu, resnet.maxpool)</span><br><span class="line">        self.layer1, self.layer2, self.layer3, self.layer4 = resnet.layer1, resnet.layer2, resnet.layer3, resnet.layer4</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> n, m <span class="keyword">in</span> self.layer3.named_modules():</span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;conv2&#x27;</span> <span class="keyword">in</span> n:</span><br><span class="line">                m.dilation, m.padding, m.stride = (<span class="number">2</span>, <span class="number">2</span>), (<span class="number">2</span>, <span class="number">2</span>), (<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">            <span class="keyword">elif</span> <span class="string">&#x27;downsample.0&#x27;</span> <span class="keyword">in</span> n:</span><br><span class="line">                m.stride = (<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">for</span> n, m <span class="keyword">in</span> self.layer4.named_modules():</span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;conv2&#x27;</span> <span class="keyword">in</span> n:</span><br><span class="line">                m.dilation, m.padding, m.stride = (<span class="number">4</span>, <span class="number">4</span>), (<span class="number">4</span>, <span class="number">4</span>), (<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">            <span class="keyword">elif</span> <span class="string">&#x27;downsample.0&#x27;</span> <span class="keyword">in</span> n:</span><br><span class="line">                m.stride = (<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        self.ppm = _PyramidPoolingModule(<span class="number">2048</span>, <span class="number">512</span>, (<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">6</span>))</span><br><span class="line">        self.final = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">4096</span>, <span class="number">512</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">512</span>, momentum=<span class="number">.95</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Dropout(<span class="number">0.1</span>),</span><br><span class="line">            nn.Conv2d(<span class="number">512</span>, num_classes, kernel_size=<span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> use_aux:</span><br><span class="line">            self.aux_logits = nn.Conv2d(<span class="number">1024</span>, num_classes, kernel_size=<span class="number">1</span>)</span><br><span class="line">            initialize_weights(self.aux_logits)</span><br><span class="line"></span><br><span class="line">        initialize_weights(self.ppm, self.final)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x_size = x.size()</span><br><span class="line">        x = self.layer0(x)</span><br><span class="line">        x = self.layer1(x)</span><br><span class="line">        x = self.layer2(x)</span><br><span class="line">        x = self.layer3(x)</span><br><span class="line">        <span class="keyword">if</span> self.training <span class="keyword">and</span> self.use_aux:</span><br><span class="line">            aux = self.aux_logits(x)</span><br><span class="line">        x = self.layer4(x)</span><br><span class="line">        x = self.ppm(x)</span><br><span class="line">        x = self.final(x)</span><br><span class="line">        <span class="keyword">if</span> self.training <span class="keyword">and</span> self.use_aux:</span><br><span class="line">            <span class="keyword">return</span> F.upsample(x, x_size[<span class="number">2</span>:], mode=<span class="string">&#x27;bilinear&#x27;</span>), F.upsample(aux, x_size[<span class="number">2</span>:], mode=<span class="string">&#x27;bilinear&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> F.upsample(x, x_size[<span class="number">2</span>:], mode=<span class="string">&#x27;bilinear&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>语义分割</tag>
      </tags>
  </entry>
  <entry>
    <title>python爬虫框架Scrapy(二)</title>
    <url>/2019/04/08/python%E7%88%AC%E8%99%AB%E6%A1%86%E6%9E%B6Scrapy-%E4%BA%8C/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<h1 id="爬虫编写"><a href="#爬虫编写" class="headerlink" title="爬虫编写"></a>爬虫编写</h1><ol>
<li><p>item读取数据</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tr_list = response.xpath(<span class="string">&quot;//table[@class=&#x27;tablelist&#x27;]/tr&quot;</span>)[<span class="number">1</span>:<span class="number">-1</span>]</span><br><span class="line">       <span class="keyword">for</span> tr <span class="keyword">in</span> tr_list:</span><br><span class="line">           item = &#123;&#125;</span><br><span class="line">           item[<span class="string">&#x27;title&#x27;</span>] = tr.xpath(<span class="string">&quot;./td[1]/a/text()&quot;</span>).extract_first()</span><br><span class="line">           item[<span class="string">&#x27;position&#x27;</span>] = tr.xpath(<span class="string">&quot;./td[2]/text()&quot;</span>).extract_first()</span><br><span class="line">           item[<span class="string">&#x27;number&#x27;</span>] = tr.xpath(<span class="string">&quot;./td[3]/text()&quot;</span>).extract_first()</span><br><span class="line">           item[<span class="string">&#x27;place&#x27;</span>] = tr.xpath(<span class="string">&quot;./td[4]/text()&quot;</span>).extract_first()</span><br><span class="line">           item[<span class="string">&#x27;publish_date&#x27;</span>] = tr.xpath(<span class="string">&quot;./td[5]/text()&quot;</span>).extract_first()</span><br><span class="line">           logging.warning(item)</span><br><span class="line">           <span class="keyword">yield</span> item</span><br></pre></td></tr></table></figure>
</li>
<li><p>构造Request对象实现翻页</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#下一页URL地址</span></span><br><span class="line">      next_url = response.xpath(<span class="string">&quot;//a[@id=&#x27;next&#x27;]/@href&quot;</span>).extract_first()</span><br><span class="line">      <span class="keyword">if</span> next_url != <span class="string">&quot;javascript:;&quot;</span>:</span><br><span class="line">          next_url = <span class="string">&quot;http://hr.tencent.com/&quot;</span> + next_url</span><br><span class="line">      <span class="keyword">yield</span> scrapy.Request(</span><br><span class="line">          next_url,</span><br><span class="line">          callback=self.parse</span><br><span class="line">      )</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">scrapy.Request(url[,callback,method=<span class="string">&#x27;GET&#x27;</span>,headers,body,cookies,meta,dont_filter=<span class="literal">False</span>])</span><br></pre></td></tr></table></figure>
<p><img src="/2019/04/08/python%E7%88%AC%E8%99%AB%E6%A1%86%E6%9E%B6Scrapy-%E4%BA%8C/1.png" alt></p>
</li>
<li><p>构造Request对象实现详情页爬取</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def parse_detail(self,response):</span><br><span class="line">	...</span><br></pre></td></tr></table></figure>
</li>
</ol>
]]></content>
      <categories>
        <category>python爬虫</category>
      </categories>
      <tags>
        <tag>scrapy</tag>
      </tags>
  </entry>
  <entry>
    <title>Retinanet&amp;focal-loss</title>
    <url>/2020/05/12/Retinanet-focal-loss/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<p>RetinaNet只是原来FPN网络与FCN网络的组合应用，因此在目标网络检测框架上它并无特别亮眼创新。文章中最大的创新来自于Focal loss的提出及在单阶段目标检测网络RetinaNet（实质为Resnet + FPN + FCN）的成功应用。Focal loss是一种改进了的交叉熵(cross-entropy, CE)loss，它通过在原有的CE loss上乘了个使易检测目标对模型训练贡献削弱的指数式，从而使得Focal loss成功地解决了在目标检测时，正负样本区域极不平衡而目标检测loss易被大批量负样本所左右的问题。此问题是单阶段目标检测框架（如SSD/Yolo系列）与双阶段目标检测框架（如Faster-RCNN/R-FCN等）accuracy gap的最大原因。</p>
<h1 id="Focal-Loss"><a href="#Focal-Loss" class="headerlink" title="Focal Loss"></a>Focal Loss</h1><p>Focal Loss主要解决的是类别不平衡问题，常规的单阶段目标检测网络像SSD一般在模型训练时会先大密度地在模型终端的系列feature maps上生成出10,000甚至100,0000个目标候选区域。然后再分别对这些候选区域进行分类与位置回归识别。而在这些生成的数万个候选区域中，绝大多数都是不包含待检测目标的图片背景，这样就造成了机器学习中经典的训练样本正负不平衡的问题。它往往会造成最终算出的training loss为占绝对多数但包含信息量却很少的负样本所支配，少样正样本提供的关键信息却不能在一般所用的training loss中发挥正常作用，从而无法得出一个能对模型训练提供正确指导的loss。</p>
<h2 id="Focal-Loss定义"><a href="#Focal-Loss定义" class="headerlink" title="Focal Loss定义"></a>Focal Loss定义</h2><p>$FL(p_t)=-\alpha_t(1-p_t)^rlog(p_t)$</p>
<p>下图为focal loss与常规CE loss的对比。从中，我们易看出focal loss所加的指数式系数可对正负样本对loss的贡献自动调节。当某样本类别比较明确些，它对整体loss的贡献就比较少；而若某样本类别不易区分，则对整体loss的贡献就相对偏大。这样得到的loss最终将集中精力去诱导模型去努力分辨那些难分的目标类别，于是就有效提升了整体的目标检测准度。不过在此focus loss计算当中，我们引入了一个新的hyper parameter即γ。一般来说新参数的引入，往往会伴随着模型使用难度的增加。在本文中，作者有试者对其进行调节，线性搜索后得出将γ设为2时，模型检测效果最好。</p>
<p><img src="/2020/05/12/Retinanet-focal-loss/1.png" style="zoom:80%;"></p>
<p>在最终所用的focal loss上，作者还引入了α系数，它能够使得focal loss对不同类别更加平衡。实验表明它会比原始的focal loss效果更好。</p>
<p>Focal loss还很大程度上避免了正负样本不平衡带来的模型初始化问题。</p>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="Retinanet"><a href="#Retinanet" class="headerlink" title="Retinanet"></a>Retinanet</h1><p> RetinaNet本质上是Resnet + FPN + 两个FCN子网络。 </p>
<h2 id="RetinaNet检测框架"><a href="#RetinaNet检测框架" class="headerlink" title="RetinaNet检测框架"></a>RetinaNet检测框架</h2><p><img src="/2020/05/12/Retinanet-focal-loss/2.png" style="zoom:80%;"></p>
<p>一般主干网络可选用任一有效的特征提取网络如vgg16或resnet系列，此处作者分别尝试了resnet-50与resnet-101。而FPN则是对resnet-50里面自动形成的多尺度特征进行了强化利用，从而得到了表达力更强、包含多尺度目标区域信息的feature maps集合。最后在FPN所吐出的feature maps集合上，分别使用了两个FCN子网络（它们有着相同的网络结构却各自独立，并不share参数）用来完成目标框类别分类与位置回归任务。</p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>PolarMask-note</title>
    <url>/2020/05/28/PolarMask-note/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<h1 id="PolorMask：one-stage实例分割新思路"><a href="#PolorMask：one-stage实例分割新思路" class="headerlink" title="PolorMask：one-stage实例分割新思路"></a>PolorMask：one-stage实例分割新思路</h1><h2 id="前置知识"><a href="#前置知识" class="headerlink" title="前置知识"></a>前置知识</h2><h3 id="FCOS"><a href="#FCOS" class="headerlink" title="FCOS"></a>FCOS</h3><p>​    FCOS是一个基于全卷积的one-stage检测网络，类似于语义分割针对每个像素进行预测。FCOS是anchor free，proposal free的检测器，可以减少大量的内存计算以及内存占用，并且不需要调优设计anchor和proposal的超参数。事实上这个anchor free方法还是有anchor的只不过不再是box形式，而是用点作为anchor，既减少了anchor数量又取消了超参。此外文章还提出了一个思路：<strong>将检测问题可以统一到其他FCN_solvable问题，可以简单的重用其他任务的idea。</strong></p>
<p>​    网络结构图如下：</p>
<p><img src="/2020/05/28/PolarMask-note/1.png" style="zoom:80%;"></p>
<p>​    可以从图中看出网络结构中也运用了FPN的结构但是没有使用backbone的所有卷积层，但考虑了多尺度的问题直接加入了P5的下采样P6/P7。最后的损失函数也分为三个分支，classification、regression(不同于boxes，回归的4D向量为[l, r, t, b]代表每个像素点向四周的延伸)、centerness。</p>
<p>​    文章还解决了重叠区域问题，引入了参数$m<em>i$为特征层$i$的最大距离，如果一个像素点(x, y)满足$max(l^<em>,t^</em>,r^<em>,b^</em>)&gt;m_i \or max(l^<em>,t^</em>,r^<em>,b^</em>)&lt;m</em>{i-1}$ 那么在该特征层将其视为负样本，不进行回归。</p>
<p>​    此外，作者还运用了Center-ness($\sqrt{\frac{min(l^<em>,r^</em>)}{max(l^<em>, r^</em>)}\times\frac{min(t^<em>, b^</em>)}{max(t^<em>,b^</em>)}}$)对离物体中心较远质量差的预测边框进行了抑制。通过BCE Loss来进行训练。可以在预测时降低远离物体中心边框的得分。</p>
<h3 id="PolorMask解决的问题"><a href="#PolorMask解决的问题" class="headerlink" title="PolorMask解决的问题"></a>PolorMask解决的问题</h3><p>将实例分割问题转化为基于<strong>实例中心分类(instance center classification)</strong>和<strong>密集距离回归(dense distance regression)</strong>的极坐标轮廓建模问题。提供了一种新的建模方式，让实例分割建模变得简单且高效。</p>
<h3 id="PolorMask细节"><a href="#PolorMask细节" class="headerlink" title="PolorMask细节"></a>PolorMask细节</h3><h4 id="Polor-Representation"><a href="#Polor-Representation" class="headerlink" title="Polor Representation"></a>Polor Representation</h4><p>文章提出了一种新的mask表示，极坐标轮廓表示。这种表示方法有三个优势：</p>
<ol>
<li>极坐标的原点可以看作物体的中心</li>
<li>轮廓上的点由距离和角度确定</li>
<li>角度是确定的，所以将点连接到轮廓十分方便。(这是笛卡尔坐标系不存在的优势)</li>
</ol>
<h4 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h4><p><img src="/2020/05/28/PolarMask-note/2.png" style="zoom:80%;"></p>
<p><em>ps：k = nr_class of dataset, n = the number of raws</em></p>
<p>在网络结构上，PolorMask与FCOS十分相似，只是在head部分将bbox分支换成了mask分支。在网络结构复杂度上与FCOS相似。</p>
<h4 id="Polar-Segmentation建模"><a href="#Polar-Segmentation建模" class="headerlink" title="Polar Segmentation建模"></a><strong>Polar Segmentation建模</strong></h4><p>经过网络可以得到中心点的位置和n(n=36 is best in our setting)根射线的距离，根据角度和长度计算出轮廓上的这些点的坐标，从0°开始连接这些点，最后把联通区域内的区域当做实例分割的结果。 </p>
<h4 id="center-sample-中心采样"><a href="#center-sample-中心采样" class="headerlink" title="center sample(中心采样)"></a>center sample(中心采样)</h4><p>采取了在实例质心周围1.5个步幅内的像素点为正采样，否则为负采样，这样做的好处是避免了正负样本的过于不平衡以及有更多的候选点作为真正的中心。</p>
<h4 id="Polar-IoU-Loss-amp-Polar-Centerness"><a href="#Polar-IoU-Loss-amp-Polar-Centerness" class="headerlink" title="Polar IoU Loss &amp; Polar Centerness"></a>Polar IoU Loss &amp; Polar Centerness</h4><p><strong>Polar IoU Loss</strong></p>
<p><img src="/2020/05/28/PolarMask-note/4.png" style="zoom:80%;"></p>
<p>采用从0-2Π的积分形式来进行IoU计算<br>$IoU = \frac{\int<em>0^{2\pi}1/2min(d_i,\tilde{d_i})^2d\theta}{\int_0^{2\pi}1/2max(d_i,\tilde{d_i})^2d\theta}=\lim</em>{N\rightarrow\infty}\frac{\sum<em>{i=1}^N1/2d</em>{min}^2\Delta \theta<em>i}{\sum</em>{i=1}^N1/2d<em>{max}^2\Delta \theta_i}-&gt;Polar IoU=\frac{\sum</em>{i=1}^Ndmin}{\sum<em>{i=1}^Ndmax}-&gt;PolarIoULoss=log\frac{\sum</em>{i=1}^Ndmin}{\sum_{i=1}^Ndmax}$<br>Polar IoU Loss采用的是BCE LOSS，在不用调权重的情况下，相比Smooth L1 Loss提了2.6个点</p>
<p><strong>Polar Centerness</strong></p>
<p>Polar Centerness是基于FCOS的Center ness的变化，也是为了定义高质量的正样本抑制低质量的正样本。</p>
<p>$Polar \ Centerness=\sqrt\frac{min({d_1,d_2,…,d_n})}{max({d_1,d_2,…,d_n})}$如下图所示，右边的mask更加符合要求。</p>
<p><img src="/2020/05/28/PolarMask-note/3.png" style="zoom:80%;"></p>
<h3 id="实验部分"><a href="#实验部分" class="headerlink" title="实验部分"></a>实验部分</h3><ul>
<li>关于实例中心的选择：实验表明使用质心(mass-center)比检测框中心(box-center)有更好的效果(可能是质心相比检测框中心更普遍在实例中？)</li>
<li>关于polar segmentation的建模上限问题：作者在这实验证明了IoU能够达到90左右，逐像素法也会因下采样等操作而达不到100%。</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th style="text-align:center">Number of rays</th>
<th style="text-align:center">Loss</th>
<th style="text-align:center">centerness</th>
<th style="text-align:center">box brunch</th>
<th>backbone</th>
<th>scale</th>
</tr>
</thead>
<tbody>
<tr>
<td>influence</td>
<td style="text-align:center">实验表明当数量增加时性能会提升但到72时接近饱和</td>
<td style="text-align:center">Polar IoU Loss 表现明显优于Smooth L1 Loss</td>
<td style="text-align:center">Polar centerness在大实例/高精度表现更好</td>
<td style="text-align:center">polar mask无需边界框</td>
<td>更好的特征提取网络会提高性能</td>
<td>较大的图像尺寸会以较低的推理速度产生较高的精度</td>
</tr>
<tr>
<td>best</td>
<td style="text-align:center">36</td>
<td style="text-align:center">-</td>
<td style="text-align:center">-</td>
<td style="text-align:center">-</td>
<td>ResNeXt-101</td>
<td>-</td>
</tr>
</tbody>
</table>
</div>
<h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a><strong>优点</strong></h4><ol>
<li>不需要检测框，与FCOS一样是简洁高效的结构，包括在loss部分都不需要过多的超参数调节，在推理速度实验上也略优于two-stage model和其他one-stage model</li>
<li>将目标检测和实例分割统一到了一个模型，为之后anchor free模型的研究与改进提供了一个思路</li>
</ol>
<h4 id="不足"><a href="#不足" class="headerlink" title="不足"></a><strong>不足</strong></h4><ol>
<li>在精度方面与sota模型还是有差距</li>
<li>center采样的过程在论文中没有详细描述这样采样的原因是什么</li>
<li>在数据处理会更加复杂，会处理实例质心相关的问题</li>
</ol>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>实例分割</tag>
      </tags>
  </entry>
  <entry>
    <title>python爬虫框架Scrapy(一)</title>
    <url>/2019/04/07/python%E7%88%AC%E8%99%AB%E6%A1%86%E6%9E%B6Scrapy-%E4%B8%80/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<h1 id="Scrapy框架简介"><a href="#Scrapy框架简介" class="headerlink" title="Scrapy框架简介"></a>Scrapy框架简介</h1><p><img src="/2019/04/07/python%E7%88%AC%E8%99%AB%E6%A1%86%E6%9E%B6Scrapy-%E4%B8%80/1.jpg" alt></p>
<p><img src="/2019/04/07/python%E7%88%AC%E8%99%AB%E6%A1%86%E6%9E%B6Scrapy-%E4%B8%80/2.jpg" alt></p>
<p>-Spider MiddlewaresSpider只对response进行过滤处理，不对数据进行处理</p>
<h1 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h1><h2 id="创建项目"><a href="#创建项目" class="headerlink" title="创建项目"></a>创建项目</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">scrapy startproject myspider </span><br></pre></td></tr></table></figure>
<h2 id="生成爬虫"><a href="#生成爬虫" class="headerlink" title="生成爬虫"></a>生成爬虫</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">scrapy genspider response response.cn</span><br><span class="line"><span class="comment">#@response 爬虫名称</span></span><br><span class="line"><span class="comment">#@response.cn 爬虫域名范围</span></span><br></pre></td></tr></table></figure>
<p>在生成的response.py文件中包含以下代码</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PixviSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;pixvi&#x27;</span>  <span class="comment">#爬虫名</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;pixiv.net&#x27;</span>] <span class="comment">#爬虫范围，需要爬取的url地址你必须在这个域名下</span></span><br><span class="line">    start_urls = [<span class="string">&#x27;http://www.pixiv.net/&#x27;</span>] <span class="comment">#初始响应网站，需要有内容爬取的内容</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span><span class="comment">#parse函数名称不能修改</span></span><br><span class="line">        <span class="comment">#处理start_ urls对应的响应</span></span><br><span class="line">        item = response.xpath() <span class="comment">#返回的是一个含有selector对象的列表</span></span><br><span class="line">        <span class="keyword">yield</span> item<span class="comment">#生成器可以遍历不占用太多空间</span></span><br></pre></td></tr></table></figure>
<h2 id="运行爬虫"><a href="#运行爬虫" class="headerlink" title="运行爬虫"></a>运行爬虫</h2><p>在项目文件夹下运行</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">scrapy crawl response</span><br></pre></td></tr></table></figure>
<h3 id="pipline"><a href="#pipline" class="headerlink" title="pipline"></a>pipline</h3><p>生成的item数据会传入pipline中，在使用pipline之前要先在settings.py中去掉</p>
<p>可以创建多个pipline：</p>
<p>​    1.可能有多个爬虫</p>
<p>​    2.可能爬取的数据需要不同的处理（如写入不同的数据库）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Test1Pipeline</span>(<span class="params">object</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span>(<span class="params">self, item, spider</span>):</span><span class="comment">#实现存储方法，函数名同样不能改变</span></span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure>
<p>如有多个pipline，每个pipline都要return item以传入下一个管道，不能缺少return</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#ITEM_PIPELINES = &#123;</span></span><br><span class="line"><span class="comment">#    &#x27;test1.pipelines.Test1Pipeline&#x27;: 300,</span></span><br><span class="line"><span class="comment">#&#125;</span></span><br></pre></td></tr></table></figure>
<p>的注释。</p>
<p>300表示举例pipline的远近，越小越先执行</p>
<p>若有多个爬虫，则可以</p>
<p>​    1.在item中加入<code>item[&#39;come_from&#39;] = &#39;spider1&#39;</code></p>
<p>​    <code>if item[&#39;come_from&#39;] == &#39;spider1&#39;:</code></p>
<p>​        …</p>
<p>​    2.在pipline.py中直接用</p>
<p>​    <code>if spider.name == &#39;spider1&#39;:</code></p>
<p>​        …</p>
<h3 id="logging模块"><a href="#logging模块" class="headerlink" title="logging模块"></a>logging模块</h3><p>logging模块是输出日志的模块</p>
<p>可以在settings.py中加入<code>LOG_LEVEL = &#39;WARNING&#39;</code>来使程序输出warning及以上级别的日志</p>
<p>logging模块可以代替print输出数据并知晓数据来自哪一个文件</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"></span><br><span class="line">logger = logging.getlogger(__name__)</span><br><span class="line">logger.warning(item)</span><br></pre></td></tr></table></figure>
<p>运行结果</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="number">2019</span><span class="number">-04</span><span class="number">-08</span> <span class="number">17</span>:<span class="number">30</span>:<span class="number">19</span> [test1.spiders.pixvi] WARNING: &#123;<span class="string">&#x27;come_from&#x27;</span>: <span class="string">&#x27;pixvi&#x27;</span>&#125;</span><br><span class="line"><span class="number">2019</span><span class="number">-04</span><span class="number">-08</span> <span class="number">17</span>:<span class="number">30</span>:<span class="number">19</span> [test1.pipelines] WARNING: ----------</span><br><span class="line"><span class="number">2019</span><span class="number">-04</span><span class="number">-08</span> <span class="number">17</span>:<span class="number">30</span>:<span class="number">19</span> [test1.spiders.pixvi] WARNING: &#123;<span class="string">&#x27;come_from&#x27;</span>: <span class="string">&#x27;pixvi&#x27;</span>&#125;</span><br><span class="line"><span class="number">2019</span><span class="number">-04</span><span class="number">-08</span> <span class="number">17</span>:<span class="number">30</span>:<span class="number">19</span> [test1.pipelines] WARNING: ----------</span><br><span class="line"><span class="number">2019</span><span class="number">-04</span><span class="number">-08</span> <span class="number">17</span>:<span class="number">30</span>:<span class="number">19</span> [test1.spiders.pixvi] WARNING: &#123;<span class="string">&#x27;come_from&#x27;</span>: <span class="string">&#x27;pixvi&#x27;</span>&#125;</span><br><span class="line"><span class="number">2019</span><span class="number">-04</span><span class="number">-08</span> <span class="number">17</span>:<span class="number">30</span>:<span class="number">19</span> [test1.pipelines] WARNING: ----------</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>即可以打印输出内容的时间，文件来源，等级，内容</p>
<p>在settings.py中加入<code>LOG_FILE = ./XXX.log</code>即可把日志内容保存在文件中</p>
]]></content>
      <categories>
        <category>python爬虫</category>
      </categories>
      <tags>
        <tag>scrapy</tag>
      </tags>
  </entry>
  <entry>
    <title>关于Github+Hexo+NexT的配置</title>
    <url>/2018/09/30/%E5%85%B3%E4%BA%8EGithub-Hexo-NexT%E7%9A%84%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script>]]></content>
  </entry>
  <entry>
    <title>用numpy实现简单的三层BP神经网络</title>
    <url>/2018/10/13/%E7%94%A8numpy%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E7%9A%84%E4%B8%89%E5%B1%82bp%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<pre><code>最近在看吴恩达老师的机器学习视频，讲到神经网络时有些模糊，于是决定自己用代码实现一下最基本的神经网络。
</code></pre><h2 id="关于BP算法"><a href="#关于BP算法" class="headerlink" title="关于BP算法"></a>关于BP算法</h2><p><a href="https://www.cnblogs.com/charlotte77/p/5629865.html">一文弄懂神经网络中的反向传播法</a></p>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p><img src="https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1539375900277&amp;di=d82dc6982d05663fcb6076f511a8a510&amp;imgtype=0&amp;src=http%3A%2F%2Fwww.alonely.com.cn%2Fd%2Ffile%2FXML%2F2016-08-28%2Fgvovpkjgawn.png" alt="三层神经网络"><br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NeuralNetwork</span>(<span class="params">object</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,input_nodes,hidden_nodes,output_nodes,learning_rate</span>):</span></span><br><span class="line">        <span class="comment">#设定输入层，隐藏层，输出层的节点个数</span></span><br><span class="line">        self.input_nodes = input_nodes+<span class="number">1</span></span><br><span class="line">        <span class="comment"># +1 设置偏执神经元来进行修正</span></span><br><span class="line">        self.hidden_nodes = hidden_nodes</span><br><span class="line">        self.output_nodes = output_nodes</span><br><span class="line"></span><br><span class="line">        <span class="comment">#初始化权值和学习速率</span></span><br><span class="line">        self.weight_input_to_hidden = np.random.normal(<span class="number">0.0</span>,self.hidden_nodes**<span class="number">-0.5</span>,(self.hidden_nodes,self.input_nodes))</span><br><span class="line">        self.weight_hidden_to_output = np.random.normal(<span class="number">0.0</span>,self.output_nodes**<span class="number">-0.5</span>,(self.output_nodes,self.hidden_nodes))</span><br><span class="line"></span><br><span class="line">        self.lr = learning_rate</span><br><span class="line"></span><br><span class="line">    <span class="comment">#激励函数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">Sigmoid</span>(<span class="params">self,x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">1.0</span> / (<span class="number">1.0</span> + np.exp(-x))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">self,input_list,target_list</span>):</span></span><br><span class="line">        inputs = np.array(input_list,ndmin=<span class="number">2</span>).T</span><br><span class="line">        targets = np.array(target_list,ndmin=<span class="number">2</span>).T</span><br><span class="line"></span><br><span class="line">        <span class="comment">#前向传播</span></span><br><span class="line">        hidden_inputs = np.dot(self.weight_input_to_hidden,inputs)</span><br><span class="line">        hidden_outputs= self.Sigmoid(hidden_inputs)</span><br><span class="line"></span><br><span class="line">        final_inputs = np.dot(self.weight_hidden_to_output,hidden_outputs)</span><br><span class="line">        final_outputs = self.Sigmoid(final_inputs)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#反向传播</span></span><br><span class="line">        outputs_errors = (final_outputs - targets) * final_outputs * (<span class="number">1</span> - final_outputs)</span><br><span class="line">        hidden_errors = np.dot(self.weight_hidden_to_output.T,outputs_errors)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#梯度下降</span></span><br><span class="line">        self.weight_input_to_hidden -= np.dot((hidden_errors * hidden_outputs * (<span class="number">1</span> - hidden_outputs)),inputs.T) * self.lr</span><br><span class="line">        self.weight_hidden_to_output -= np.dot(outputs_errors,hidden_outputs.T) *self.lr</span><br><span class="line"></span><br><span class="line">        print(<span class="string">&quot;误差:&quot;</span>)</span><br><span class="line">        print(<span class="number">1</span>/<span class="number">2</span> * np.square((final_outputs-targets)))</span><br><span class="line">    <span class="comment">#测试函数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span>(<span class="params">self,inputs_list</span>):</span></span><br><span class="line">        inputs = np.array(inputs_list,ndmin=<span class="number">2</span>).T</span><br><span class="line"></span><br><span class="line">        hidden_inputs = np.dot(self.weight_input_to_hidden,inputs)</span><br><span class="line">        hidden_outputs = self.Sigmoid(hidden_inputs)</span><br><span class="line"></span><br><span class="line">        final_inputs = np.dot(self.weight_hidden_to_output,hidden_outputs)</span><br><span class="line">        final_outputs = self.Sigmoid(final_inputs)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> final_outputs</span><br><span class="line"></span><br><span class="line">	<span class="comment">#测试用神经网络实现异或功能</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    cases = [[<span class="number">0</span>,<span class="number">0</span>,<span class="number">0.1</span>],</span><br><span class="line">             [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0.1</span>],</span><br><span class="line">             [<span class="number">1</span>,<span class="number">0</span>,<span class="number">0.1</span>],</span><br><span class="line">             [<span class="number">1</span>,<span class="number">1</span>,<span class="number">0.1</span>]]</span><br><span class="line"></span><br><span class="line">    labels = [[<span class="number">0</span>],[<span class="number">1</span>],[<span class="number">1</span>],[<span class="number">0</span>]]</span><br><span class="line">    <span class="comment">#迭代10000次</span></span><br><span class="line">    limit = <span class="number">10000</span>               </span><br><span class="line">    nn = NeuralNetwork(<span class="number">2</span>,<span class="number">4</span>,<span class="number">1</span>,<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(limit):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">4</span>):</span><br><span class="line">            nn.train(cases[i],labels[i])</span><br><span class="line"></span><br><span class="line">    a = nn.run([<span class="number">1</span>,<span class="number">1</span>,<span class="number">0.1</span>])</span><br><span class="line">    print(a)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure></p>
<p>只在输入层加入了偏执神经元，在第二层并没有添加，在第二层添加对拟合效果的提升并不是很大(主要是实现会更复杂一些(逃</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>神经网络</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>C++期末复习</title>
    <url>/2019/12/26/C++%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<h4 id="第一章-引论"><a href="#第一章-引论" class="headerlink" title="第一章 引论"></a>第一章 引论</h4><ul>
<li>面向对象的核心概念：<ul>
<li><strong>数据封装</strong>：对内保护信息加强联系，对外提供访问接口。</li>
<li><strong>继承</strong>：整体和部分的关系，一般和特殊的关系。基类和派生类。</li>
<li><strong>多态性</strong>：一个符号有多种含义。表现为函数重载（普通函数重载，运算符重载）</li>
<li><strong>泛型编程</strong>：主要依托模板（Template）</li>
</ul>
</li>
</ul>
<h4 id="第二章-数据类型"><a href="#第二章-数据类型" class="headerlink" title="第二章 数据类型"></a>第二章 数据类型</h4><ul>
<li><strong>指针</strong></li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span>作用于指针</span><br><span class="line">三种形式：</span><br><span class="line"><span class="number">1</span>)<span class="keyword">const</span> <span class="keyword">int</span> *p;</span><br><span class="line">p是变量，但指向了常量；</span><br><span class="line"><span class="number">2</span>)<span class="keyword">int</span> * <span class="keyword">const</span> p;</span><br><span class="line">p是常量，但指向了变量；</span><br><span class="line"><span class="number">3</span>)<span class="keyword">const</span> <span class="keyword">int</span> * <span class="keyword">const</span> p;</span><br><span class="line">常量指针指向了常量</span><br></pre></td></tr></table></figure>
<ul>
<li><p><strong>引用&amp;</strong></p>
<ul>
<li><p>引用就是对象的<strong>别名</strong></p>
</li>
<li><p><strong>独立引用必须初始化</strong></p>
</li>
<li><p><strong>参数引用-&gt;实参和形参相同</strong></p>
</li>
<li><p>非常量引用不能指向常量</p>
</li>
<li><p><strong>引用作为返回类型</strong>（避免内存复制，直接返回对象）</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> &amp;<span class="title">f</span><span class="params">(<span class="keyword">int</span> &amp;i)</span></span>&#123;<span class="keyword">return</span> i;&#125;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">返回一个左值对象(左值 != 左值引用)</span></span><br><span class="line"><span class="comment">可以出现在=左边</span></span><br><span class="line"><span class="comment">++f() (√)	b = f() (√)</span></span><br><span class="line"><span class="comment">f(a)返回a这个对象	f(2) (X)</span></span><br><span class="line"><span class="comment">int* g();</span></span><br><span class="line"><span class="comment">*g() = (√)</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>
<p><strong>运算符</strong> </p>
</li>
<li><p>new delete    new[]    delete[]</p>
</li>
<li><p>sizeof()</p>
</li>
</ul>
</li>
<li><p>数组</p>
<ul>
<li><p>指向数组的指针：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> <span class="built_in">array</span>[<span class="number">10</span>];</span><br><span class="line"><span class="keyword">int</span> (*pa)[<span class="number">10</span>];</span><br><span class="line">pa = &amp;<span class="built_in">array</span>; <span class="comment">//请注意&amp;的存在</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>指针数组：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> <span class="built_in">array</span>[<span class="number">10</span>];</span><br><span class="line"><span class="keyword">int</span> *pa[<span class="number">10</span>]; <span class="comment">//指针数组的每一个元素都是指针</span></span><br><span class="line">pb[<span class="number">0</span>] = &amp;<span class="built_in">array</span>[<span class="number">0</span>];</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<h4 id="第三章-异常处理"><a href="#第三章-异常处理" class="headerlink" title="第三章 异常处理"></a>第三章 异常处理</h4><ul>
<li>异常抛出</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">viod <span class="title">f</span><span class="params">()</span> <span class="keyword">try</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="keyword">if</span>()	<span class="keyword">throw</span> <span class="string">&quot;error&quot;</span>;<span class="comment">//std::out_of_range(&quot;index out of range&quot;);</span></span><br><span class="line">&#125;<span class="keyword">catch</span>(<span class="keyword">const</span> <span class="keyword">char</span> * e)&#123;<span class="comment">//const std::out_of_range &amp;e</span></span><br><span class="line">	<span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; e &lt;&lt; <span class="built_in">endl</span>;<span class="comment">//e.what();</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="第四章-函数"><a href="#第四章-函数" class="headerlink" title="第四章 函数"></a>第四章 函数</h4><ul>
<li><strong>函数的类型</strong></li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> (<span class="keyword">int</span>) f; <span class="comment">//error</span></span><br><span class="line"><span class="function"><span class="keyword">typedef</span> <span class="title">int</span> <span class="params">(<span class="keyword">int</span>)</span> F</span>; <span class="comment">//error</span></span><br><span class="line"><span class="function"><span class="keyword">typedef</span> <span class="keyword">int</span> <span class="title">FF</span><span class="params">(<span class="keyword">int</span>)</span></span>; <span class="comment">//OK</span></span><br></pre></td></tr></table></figure>
<ul>
<li><p><strong>函数的参数</strong></p>
<ul>
<li><p>传值 传指针 传引用</p>
</li>
<li><p>const作用于参数</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">func</span><span class="params">(<span class="keyword">const</span> <span class="keyword">int</span> *pi)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="keyword">int</span> a = *pi;	<span class="comment">//正确</span></span><br><span class="line">	*pi = <span class="number">0</span>;	<span class="comment">//错误，因为pi指向的单元被视为常量</span></span><br><span class="line">	pi = &amp;a;	<span class="comment">//正确，因为pi不是常量指针</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>缺省参数</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//所有取缺省值的参数都必须出现在不取缺省值的参数的右边。亦即，一旦开始定义取缺省值的参数，就不可以再说明非缺省的参数</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">f1</span><span class="params">(<span class="keyword">int</span> x = <span class="number">10</span>, <span class="keyword">int</span> y)</span></span>;    	<span class="comment">//error</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">f2</span><span class="params">(<span class="keyword">int</span> x, <span class="keyword">int</span> y = <span class="number">0</span>)</span></span>; 	   	<span class="comment">//ok</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">f3</span><span class="params">(<span class="keyword">int</span> x = <span class="number">10</span>, <span class="keyword">int</span> y = <span class="number">0</span>)</span></span>; <span class="comment">//ok</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p><strong>函数返回值</strong></p>
<ul>
<li>返回值类型<ul>
<li>函数返回一个值类型，实际上是将返回的值放到一个临时对象中。调用者可以拷贝临时对象的值以供以后使用。函数Strlen()返回一个整数值，这个值被存储在一个临时变量（对象）中。临时对象是<strong>匿名</strong>的，并且被当做<strong>常量</strong>，因此<strong>不能作为左值</strong>使用。</li>
</ul>
</li>
<li>返回指针<ul>
<li>函数返回指针，实际上也是返回一个值，只不过这个值是某个单元的地址。</li>
<li>该指针指向的对象必须还是<strong>有效</strong>的  </li>
<li>函数内部分配了内存要在适当的时候利用返回的指针释放掉内存。</li>
</ul>
</li>
<li>返回引用<ul>
<li>实际上返回的是一个对象，是个左值，只不过是匿名的。  </li>
<li>与返回指针一样，函数返回的引用单元也必须在被调函数返回后一直<strong>有效</strong>。</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>函数重载</strong>（唯一依据是<strong>参数列表</strong>）</p>
</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">f(<span class="keyword">int</span> i = <span class="number">0</span>)/f()	<span class="comment">//不算</span></span><br><span class="line">f(<span class="keyword">int</span> *)/f(<span class="keyword">int</span> [])/f(<span class="keyword">int</span> [<span class="number">5</span>])<span class="comment">//不算</span></span><br><span class="line">f(<span class="keyword">int</span>)/f(<span class="keyword">const</span> <span class="keyword">int</span>)<span class="comment">//不算</span></span><br><span class="line">f(<span class="keyword">int</span> ())/f(<span class="keyword">int</span>(*)())<span class="comment">//不算</span></span><br><span class="line">f(<span class="keyword">int</span> i)/f(<span class="keyword">int</span>&amp; i)	<span class="comment">//算</span></span><br><span class="line">	<span class="keyword">int</span> a;</span><br><span class="line">	f(a);	<span class="comment">//可以存在但编译会出问题</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="第五章-类和对象（全部重点）"><a href="#第五章-类和对象（全部重点）" class="headerlink" title="第五章 类和对象（全部重点）"></a>第五章 类和对象（全部重点）</h4><ul>
<li>类的定义</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">className</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">	属性列表;</span><br><span class="line">	行为列表;</span><br><span class="line">&#125;;  <span class="comment">//注意这个分号的存在。很多的编译错误源于这个分号的缺漏</span></span><br></pre></td></tr></table></figure>
<ul>
<li>类和对象</li>
</ul>
<p>与其它类型一样，类只是一种形式化的规格说明。要使用类提供的功能，必须使用类的<strong>实例</strong>（类的静态成员(5.3.3)例外）。类的实例称为“对象”。一个类可以定义多个对象。定义对象的过程称为“实例化(instantiation)”，而一个对象也称为类的“实例(instance)”。</p>
<p><strong>关系</strong></p>
<p>•类代表了一组对象的<strong>共同性</strong>；对象被赋予了<strong>具体的性质</strong>。</p>
<p>•类在概念上是一种<strong>抽象机制</strong>，它抽象了一类对象的存储和操作特性；对象是类的一个实现，占据了物理存储器。</p>
<p>•在系统实现中，类是一种<strong>共享机制</strong>，它提供了一类对象共享其类的操作实现。这些操作通过类的实例（对象）来完成。</p>
<p>•类是一种<strong>封装机制</strong>，它将一组数据和对该组数据的操作封装在一起；对象是这种封转机制的具体实现。</p>
<p>•类是对象的<strong>模型</strong>，对象承袭了类中的数据和方法(操作)。只是各实例对象的数据初始化状态和各个数据成员的值不同。</p>
<ul>
<li><p><strong>访问控制</strong></p>
<ul>
<li>如果没有访问控制修饰符默认为private</li>
<li>private</li>
<li>protected</li>
<li>public</li>
</ul>
</li>
<li><p><strong>类的成员</strong></p>
<ul>
<li><p>在一般情况下，一个类不能包含该类类型的对象作为成员  </p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Zoo</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">	Zoo *p;  <span class="comment">//ok</span></span><br><span class="line">	Zoo &amp;r; <span class="comment">//ok 这个引用成员必须被初始化。</span></span><br><span class="line">	<span class="comment">//Zoo o; //错误，类定义依赖于自身。</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
</li>
<li><p>静态成员</p>
<ul>
<li><p>静态成员变量是所有类对象共享的，需要在类定义外额外分配存储</p>
</li>
<li><p>静态数据成员属于类，而不属于对象。访问方式</p>
<p>类名::静态共有数据成员 </p>
</li>
<li><p>一般使用静态成员函数来访问静态数据成员。</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="第六章-深入类和对象"><a href="#第六章-深入类和对象" class="headerlink" title="第六章 深入类和对象"></a>第六章 深入类和对象</h4><ul>
<li><p><strong>构造函数</strong></p>
<ul>
<li><p>构造函数的调用是<strong>自动进行</strong>的。这甚至不是一种程序员的可选项，而是编译器实施的一种强制性机制。每当创建类的一个新对象时，编译器将在创建的地方自动生成调用构造函数的代码，用以完成对象的初始化工作。在必要的时候，需要给出构造函数的参数。</p>
<p>类的构造函数的作用是：</p>
<p>–(1) 分配一个对象的数据成员的存储空间；（该功能由系统自动完成。）</p>
<p>–(2) 执行构造函数（体），一般是初始化一个对象的部分或全体数据成员。</p>
</li>
<li><p><strong>复制构造函数</strong></p>
<ul>
<li><p>进行两个类对象之间的复制</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> 类名</span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	类名(<span class="keyword">const</span> 类名&amp;[, other parameters]); <span class="comment">//copy constructor</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
</li>
<li><p>何处会调用复制构造函数</p>
<p>显式定义复制对象时，如下例所示：</p>
<p>–array a1;</p>
<p>–array a2(a1); //调用a2的复制构造函数</p>
<p>–array a3 = a2; //这不是对象间的赋值，而是复制（初始化）！</p>
<p>实参和形参结合时。如例中t和a结合时，将会调用形参t的复制构造函数来复制实参对象r；</p>
<p>函数返回值对象（非指针和引用）时。如例中f()返回一个临时对象，这个临时对象就是用其复制构造函数从return的返回表达式t中复制而来。这个临时对象是匿名的，并且被视为常量对象。</p>
</li>
<li><p>如果一个类没有显示定义复制构造函数，c++编译器会为该类合成一个隐式的缺省复制构造函数。</p>
</li>
<li><p>浅复制与深复制</p>
<ul>
<li>浅复制共享同一内存空间，析构出错。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>析构函数</strong></p>
<ul>
<li><p>析构函数的作用是：</p>
<p>1.执行析构函数（一般没有具体的工作）；</p>
<p>2.释放对象的存储空间。（该功能由系统自动完成。）</p>
<p>3.释放对象占用的资源。这项工作要有程序员设定。</p>
</li>
</ul>
</li>
<li><p><strong>对象和指针</strong></p>
<ul>
<li><strong>this指针</strong></li>
</ul>
</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//this指针只能出现在类的非静态成员函数中，并且常用于需要自引用的地方。</span></span><br><span class="line"><span class="function"><span class="built_in">array</span>&amp; <span class="title">array::me</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>​         <strong>指向类对象的指针</strong></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">f</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="built_in">array</span> a;</span><br><span class="line">	<span class="built_in">array</span> *pa = &amp;a; <span class="comment">//指针指向一个编译器对象</span></span><br><span class="line">	pa-&gt;traverse(print);</span><br><span class="line">	<span class="comment">//delete pa; //error，不能用这种方式来释放编译器对象</span></span><br><span class="line">	pa-&gt;~<span class="built_in">array</span>(); <span class="comment">//但可以显式调用这个对象的析构函数：</span></span><br><span class="line"> </span><br><span class="line">	pa = <span class="keyword">new</span> <span class="built_in">array</span>(); </span><br><span class="line">	pa-&gt;traverse(print);</span><br><span class="line">	<span class="keyword">delete</span> pa; <span class="comment">//OK             </span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​        <strong>指向类成员的指针</strong></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">//类型名 类名::*指针; </span></span><br><span class="line"><span class="comment">//类型名 (类名::*指针)(参数表);</span></span><br><span class="line">ptr = &amp;X::b;</span><br><span class="line">fptr = &amp;X::f;</span><br><span class="line"><span class="comment">//要用.*或者-&gt;*调用</span></span><br></pre></td></tr></table></figure>
<ul>
<li><strong>友元关系</strong>（提高效率、非必须）<strong>友元能够访问一个类的所有成员</strong><ul>
<li>友元关系不具备传递性</li>
<li>不具有对称性</li>
</ul>
</li>
<li><p>友元类定义在类中表示该友元类能访问本类的所有成员。</p>
</li>
<li><p>对象作为函数的参数/返回值  （复制构造函数的重要性）</p>
</li>
<li>常成员函数<ul>
<li>只读取属性而不修改它们。</li>
</ul>
</li>
<li>包围类的成员对嵌套类是不可见的。嵌套类的作用域对包围类来说也是封闭的。<ul>
<li>可以定义友元类来解决问题。</li>
</ul>
</li>
</ul>
<h4 id="第七章-运算符重载"><a href="#第七章-运算符重载" class="headerlink" title="第七章 运算符重载"></a>第七章 运算符重载</h4><ul>
<li>运算符重载的原型</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">返回值类型 <span class="keyword">operator</span> @ (参数列表);</span><br></pre></td></tr></table></figure>
<ul>
<li><p>双目运算符</p>
<ul>
<li>类似于+=，运算的结果可以作为左值使用</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">complex</span>&amp; <span class="keyword">operator</span> += (<span class="keyword">const</span> <span class="built_in">complex</span>&amp; rhs)</span><br><span class="line">&#123;</span><br><span class="line">	real += rhs.real;</span><br><span class="line">	imag += rhs.imag;</span><br><span class="line">	<span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><p>类似于+，运算符作为友元重载</p>
<p>参与运算的两个操作数都不变，运算结果是个新产生的值。</p>
</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">friend</span> Comlex <span class="keyword">operator</span> + (<span class="keyword">const</span> <span class="built_in">complex</span>&amp; lhs, <span class="keyword">const</span> comlex&amp; rhs)</span><br><span class="line">&#123;	</span><br><span class="line">	<span class="comment">//返回临时对象</span></span><br><span class="line">	<span class="keyword">return</span>	<span class="built_in">complex</span>(lhs.real + rhs.real, lhs.imag + rhs.imag);</span><br><span class="line">	<span class="comment">//调用构造函数</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>运算符重载形式</p>
<ul>
<li><p><img src="/2019/12/26/C++%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/Users\58341\AppData\Roaming\Typora\typora-user-images\1577638560890.png" alt="1577638560890" style="zoom:80%;"></p>
</li>
<li><p>对于重载的单目运算符</p>
<ul>
<li><p>作为成员重载时，函数没有参数，运算作用在lhs上；函数返回lhs的左值引用；</p>
</li>
<li><p>作为友元重载是，函数有一个参数（并且是左值引用），运算作用在参数对象上；函数返回参数对象的左值引用。当然，这是不推荐的重载方式。</p>
<p>这条规则关于参数个数有例外，就是当@是后缀++/—时。</p>
</li>
</ul>
</li>
<li><p>对于作为成员重载的双目运算符</p>
<ul>
<li>函数有一个参数，这个参数就是rhs，并且是常量；</li>
<li>产生的结果保存到lhs中；</li>
<li>函数的返回值是lhs的左值引用。</li>
</ul>
</li>
<li><p>对于作为友元重载的双目运算符</p>
<ul>
<li>有两个参数（即左右操作数），并且都是常量，且这两个参数中至少有一个是将该运算符函数作为友元对待的类的对象。；</li>
<li>函数产生一个新值，即返回值是一个对象（非引用非指针）。这会引起复制构造函数的调用，因此，最好为类提供一个复制构造函数。</li>
</ul>
</li>
<li><p>对于关系和逻辑运算符，它们应该产生一个bool类型的结果。如果使用的编译器不支持bool类型，那么应该返回一个替代的整型值：1表示真，0表示假。</p>
</li>
<li><p>如果作为成员重载的运算只是读取对象的属性而不会改变它们，那么建议将该函数设为常成员。</p>
</li>
</ul>
</li>
<li><p>常用运算符的重载(<strong>掌握</strong>运算符重载（算数、赋值）,特殊<a href></a>&gt;&gt;*不要求实现，要求阅读，lambda不考)</p>
<ul>
<li><p>赋值运算符的重载</p>
<p><strong>赋值运算符与复制构造函数不同</strong>，编译器会为类隐式重载一个赋值运算符。在多数情况下，隐式重载的赋值运算符函数工作得很好。但在某些特殊场合，例如需要深复制的场合，赋值操作可能会出现问题。所以，在这种情况下，显式地为类提供重载的赋值运算符是非常明智的选择。</p>
<p>赋值运算符是一个典型的双目运算符，它的左操作数是个左值，右操作数却是左右值不限。因此，赋值运算符函数最好（其实是只能）作为类的成员重载，其唯一的参数最好是右值对象的常量引用，而其返回值应该是左值对象的引用。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">complex</span>&amp; <span class="keyword">operator</span> = (<span class="keyword">const</span> <span class="built_in">complex</span>&amp; c)</span><br><span class="line">&#123;</span><br><span class="line">	real = c.real;</span><br><span class="line">	imag = c.imag;</span><br><span class="line">	<span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>算数运算符的重载</p>
<ul>
<li><p>单目运算符</p>
<p>产生临时变量，返回值为对象值</p>
<p>产生左值，返回值为操作数的引用</p>
</li>
<li><p>双目运算符</p>
<p>除了赋值（含复合赋值）运算符外，几乎所有的双目运算符都应该作为类的友元进行重载</p>
</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">friend</span> type <span class="keyword">operator</span> @ (<span class="keyword">const</span> &amp;, <span class="keyword">const</span> &amp;);</span><br></pre></td></tr></table></figure>
</li>
<li><p>重载++和—运算符</p>
<ul>
<li>前缀++应该以类的成员函数形式重载，其返回值是操作数对象本身的引用；</li>
<li>后缀++应该以类的成员函数形式重载，其返回值是操作数自加前的一个副本，是一个值结果。</li>
<li><strong>c++规定后缀++重载需要有一个整形占位参数</strong></li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">complex</span>&amp; <span class="keyword">operator</span>++()</span><br><span class="line">&#123;</span><br><span class="line">	++real;</span><br><span class="line">	++imag;</span><br><span class="line">	<span class="keyword">return</span> *<span class="keyword">this</span>;</span><br><span class="line">&#125;<span class="comment">//前缀++</span></span><br><span class="line"><span class="built_in">complex</span> <span class="keyword">operator</span>++(<span class="keyword">int</span>)</span><br><span class="line">&#123;</span><br><span class="line">	<span class="function"><span class="built_in">complex</span> <span class="title">temp</span><span class="params">(<span class="keyword">this</span>-&gt;real, <span class="keyword">this</span>-&gt;imag)</span></span>;</span><br><span class="line">	++real;++imag;</span><br><span class="line">	<span class="keyword">return</span> temp;</span><br><span class="line">&#125;<span class="comment">//后缀++</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>关系运算符重载</p>
</li>
<li><p>输入输出运算符重载</p>
</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">friend</span> ostream&amp; <span class="keyword">operator</span>&lt;&lt;(ostream&amp; os, <span class="keyword">const</span> <span class="built_in">complex</span> &amp;c);</span><br><span class="line">firend istream&amp; <span class="keyword">operator</span>&gt;&gt;(istream&amp; is, <span class="built_in">complex</span> &amp;c);</span><br></pre></td></tr></table></figure>
<ul>
<li>装箱和拆箱P177-P180</li>
<li>重载[] * ()</li>
</ul>
</li>
</ul>
<h4 id="第八章-继承和派生（全部重点）"><a href="#第八章-继承和派生（全部重点）" class="headerlink" title="第八章 继承和派生（全部重点）"></a>第八章 继承和派生（全部重点）</h4><ul>
<li><p><strong>继承：后代对祖先特征的全盘接受是继承的过程。</strong></p>
<ul>
<li><p><strong>基类和派生类：派生类（子类）继承基类（父类）</strong></p>
</li>
<li><p>继承关系确立</p>
<ul>
<li>继承基类的除（构造函数、析构函数、基类重载的赋值运算符）外的所有成员</li>
<li>改造基类成员，可以通过访问控制调用或直接<strong>使用同名成员覆盖基类成员</strong>。</li>
<li>增加新的成员。</li>
</ul>
</li>
<li><p>继承中的类等级</p>
<ul>
<li>直接基类、间接基类。<code>祖先类名::祖先类成员</code></li>
</ul>
</li>
<li><p>访问控制</p>
</li>
<li><p><img src="/2019/12/26/C++%E6%9C%9F%E6%9C%AB%E5%A4%8D%E4%B9%A0/Users\58341\AppData\Roaming\Typora\typora-user-images\1577778210569.png" alt="1577778210569" style="zoom:80%;"></p>
</li>
<li><p>基类的protected成员</p>
<p>​     基类的某些私有成员必须对派生类是可见的，或者可访问的，而在派生类外却又是不可见的，即是受保护的。  </p>
</li>
<li><p>访问声明</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">tiger</span> :</span> <span class="keyword">private</span> felid</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">	<span class="keyword">using</span> felid::prey;<span class="comment">//恢复成员的原有访问属性</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li><p>基类静态成员的派生</p>
<p>所有后代和基类共享唯一的静态成员</p>
<p>用<code>基类名::静态成员名</code>进行访问</p>
</li>
</ul>
</li>
<li><p>基类和派生类的关系</p>
<ul>
<li><p>派生类对象初始化必须调用基类的构造函数。</p>
</li>
<li><p><strong>派生类对象和基类对象的相互转换</strong></p>
<ul>
<li><p>派生类直接赋值给基类合法</p>
<ul>
<li><code>基类 = 派生类</code></li>
</ul>
</li>
<li><p>派生类直接赋给基类的引用、指针</p>
<ul>
<li><p><code>基类&amp; = 派生类</code>    不会引起对象转化</p>
</li>
<li><p><code>基类* = &amp;派生类</code></p>
</li>
<li><p><strong>如果要反过来则需要强制转换</strong></p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">felid &amp;fr = <span class="keyword">dynamic_cast</span>&lt;felid&amp;&gt;(c)<span class="comment">//强制转换基类为派生类</span></span><br><span class="line">q = <span class="keyword">dynamic_cast</span>&lt;felid *&gt;(&amp;c);</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>复制兼容性原则</strong></p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">子类对象可以直接赋值给父类对象</span><br><span class="line">父类指针可以直接指向子类对象</span><br><span class="line">父类引用可以直接引用子类对象</span><br></pre></td></tr></table></figure>
</li>
<li><p>派生类中重新定义基类的成员</p>
<ul>
<li><p>派生类中重新定义基类的数据成员（首先查找本类作用域中的数据成员）</p>
</li>
<li><p>派生类中重载基类的成员函数  </p>
<p>函数重载规则：</p>
<p>​    在相同的作用域中（例如同一个类中），重载的函数原型必须不同；</p>
<p>​    在不同的作用域中（例如不同的类中），重载的函数原型可以相同。</p>
<p>无论如何，派生类的函数名将屏蔽基类中重名的函数，即使它们的原型不一致。</p>
</li>
<li><p>```c++<br>class A {f();}<br>class B : A {f();}//可以原型相同(作用域不同)<br>//如果A中virtual f() 则B中为覆盖</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">      - 派生类继承基类重载的运算符函数  </span><br><span class="line"></span><br><span class="line">#### 第九章 虚函数和多态性</span><br><span class="line"></span><br><span class="line">- **多态性**：一个接口，多种实现</span><br><span class="line"></span><br><span class="line">  - 静态多态性：在编译时完成，普通的函数重载。</span><br><span class="line">  - 动态多态性：依赖**虚函数**来实现。虽然编译器仍然认为调用的是基类的成员，但由于派生类的成员覆盖了基类的同名成员，因此可以得到正确的结果。</span><br><span class="line"></span><br><span class="line">- **虚函数virtual关键字：**</span><br><span class="line"></span><br><span class="line">  - 关键字virtual明确地告诉编译器：该类派生类中的同名成员函数将**覆盖**基类已定义的函数。</span><br><span class="line"></span><br><span class="line">  - 包含虚函数的类被称为多态类。</span><br><span class="line"></span><br><span class="line">  - **特点：**</span><br><span class="line"></span><br><span class="line">    - ①虚特性必须赋予给类的**成员函数**；</span><br><span class="line"></span><br><span class="line">      ②虚函数不能是全局函数，也不能是类的静态成员函数；</span><br><span class="line"></span><br><span class="line">      ③不能将友元说明为虚函数，但虚函数可以是另一个类的友元；</span><br><span class="line"></span><br><span class="line">      ④**虚特性能够被继承**。如果派生类原型一致地重载了基类的某个虚函数，那么即使在派生类中没有将这个函数显式说明成是虚的，它也会被编译器认为是虚函数。</span><br><span class="line"></span><br><span class="line">  - 派生类覆盖之后，祖先的虚成员仍然存在。</span><br><span class="line"></span><br><span class="line">  - 一旦基类中的函数被声明为虚函数，后代中原型相同的函数都是虚的。</span><br><span class="line"></span><br><span class="line">  - 虚析构函数：</span><br><span class="line"></span><br><span class="line">    若析构函数不声明为虚函数，子类析构会出错。</span><br><span class="line"></span><br><span class="line">    - 通过强制类型转换将指针p转换为派生类指针，具体做法如下：</span><br><span class="line">    - delete (felid *)(p);</span><br><span class="line">    - 将felid类的析构函数说明成是虚的：</span><br><span class="line">    - virtual ~felid() &#123; … &#125;</span><br><span class="line"></span><br><span class="line">  - override和final描述符</span><br><span class="line"></span><br><span class="line">    - override表示覆盖基类中原型相同的成员</span><br><span class="line">    - final表示最终版本，派生类不能覆盖</span><br><span class="line"></span><br><span class="line">  - **&lt;font color&#x3D;red&gt;实现多态性的条件&lt;&#x2F;font&gt;**（要求阅读和编写）——程序阅读写结果&#x2F;程序补充</span><br><span class="line"></span><br><span class="line">    - 父类虚函数</span><br><span class="line">    - 子类覆盖</span><br><span class="line">    - 必须要父类指针、引用访问多态（虚）函数</span><br><span class="line"></span><br><span class="line">- **纯虚函数**</span><br><span class="line"></span><br><span class="line">  - 纯虚函数是一个在基类中说明的虚函数，它在该基类中没有定义，要求任何派生类都必须定义自己的版本。</span><br><span class="line"></span><br><span class="line">  &#96;&#96;&#96;c++</span><br><span class="line">  class felid</span><br><span class="line">  &#123;</span><br><span class="line">  public:</span><br><span class="line">  	virtual string what() &#x3D; 0;</span><br><span class="line">  &#125;;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
</li>
<li><p>包含纯虚函数的类是抽象类，<strong>不能直接对抽象类进行实例化</strong>。</p>
</li>
<li><p>在抽象类的派生类中，如果纯虚函数的最终覆盖函数仍是一个纯虚函数（即仍未提供一个函数体），那么该派生类仍是一个抽象类。</p>
</li>
<li><p>抽象类不能作为参数类型、返回类型，但指针、引用可</p>
</li>
</ul>
</li>
</ul>
<h4 id="第十章-模板和泛型编程"><a href="#第十章-模板和泛型编程" class="headerlink" title="第十章 模板和泛型编程"></a>第十章 模板和泛型编程</h4><ul>
<li><p><strong>模板</strong>（泛型编程）</p>
<ul>
<li><p>不依赖任何具体类型来编写通用代码。是某种形式上的<strong>静态多态</strong>。</p>
</li>
<li><p><strong>模板函数</strong></p>
<ul>
<li>函数模板需要实例化之后才能使用</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt; <span class="keyword">typename</span> T, </span><br><span class="line">                    [<span class="keyword">const</span>类 常量表达式, …] &gt;</span><br><span class="line">返回值类型 函数名(参数列表)</span><br><span class="line">&#123; </span><br><span class="line">	<span class="comment">//函数体</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">PS:</span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">Greater</span><span class="params">(<span class="keyword">const</span> T&amp; a, <span class="keyword">const</span> T&amp; b)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="keyword">return</span> a &gt; b;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, <span class="keyword">const</span> <span class="keyword">int</span> min&gt;</span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">Greater</span><span class="params">(<span class="keyword">const</span> T&amp; a, <span class="keyword">const</span> T&amp; b)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="keyword">return</span> a &gt; b &amp;&amp; b &gt; min;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//模板的非类型参数的类型不能是浮点型、类类型或void类型。它一般是整数类型、枚举类型。非类型参数如果不是引用，那么它不是左值，不能改变其值，也不能获取其地址。</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>模板特化</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">char</span> * cstring;</span><br><span class="line"><span class="keyword">template</span> &lt;&gt;<span class="comment">//特化的模板没有模板参数</span></span><br><span class="line"><span class="keyword">bool</span> Greater&lt;cstring&gt;(<span class="keyword">const</span> cstring&amp; s1, <span class="keyword">const</span> cstring&amp; s2)</span><br><span class="line">&#123;</span><br><span class="line">    out &lt;&lt; <span class="string">&quot;C-style string comparasion: &quot;</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">strcmp</span>(s1, s2) &gt; <span class="number">0</span> ? <span class="literal">true</span> : <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//特化后的模板仍然是模板</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>类模板</strong></p>
</li>
</ul>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, [<span class="keyword">const</span> 类型 常量表达式, …]&gt;</span><br><span class="line"><span class="class"><span class="keyword">class</span> 类名</span></span><br><span class="line"><span class="class">&#123;</span> </span><br><span class="line">	<span class="comment">//成员定义;</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">//类的所有成员函数都是函数模板。</span></span><br></pre></td></tr></table></figure>
<ul>
<li>类模板的使用<ul>
<li>模板名&lt;参数列表&gt; 对象名；        </li>
</ul>
</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>期末复习</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title>软件安全设计</title>
    <url>/2019/06/14/%E8%BD%AF%E4%BB%B6%E5%AE%89%E5%85%A8%E8%AE%BE%E8%AE%A1/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<h1 id="软件安全设计"><a href="#软件安全设计" class="headerlink" title="软件安全设计"></a>软件安全设计</h1><h2 id="CH01软件与软件安全"><a href="#CH01软件与软件安全" class="headerlink" title="CH01软件与软件安全"></a>CH01软件与软件安全</h2><h3 id="计算环境与软件"><a href="#计算环境与软件" class="headerlink" title="计算环境与软件"></a>计算环境与软件</h3><h4 id="二进制基础"><a href="#二进制基础" class="headerlink" title="二进制基础"></a>二进制基础</h4><h5 id="位运算"><a href="#位运算" class="headerlink" title="位运算"></a>位运算</h5><p><strong>所谓位运算是指进行二进制位的运算。在系统软件中，常要处理二进位的问题。</strong></p>
<font color="red">**不同长度的数据进行位运算**</font>

<p>如果两个数据长度不同(例如long型和int型)进行位运算时(如a &amp; b,而a为long型,b为int型),系统会将二者按右端对齐。如果b为正数,则左侧16位补满0。若b为负数,左端应补满1。如果b为无符号整数型,则左侧添满0。</p>
<h4 id="指令系统与指令集"><a href="#指令系统与指令集" class="headerlink" title="指令系统与指令集"></a>指令系统与指令集</h4><p><strong>指令系统：</strong>计算机的指令系统就是指该计算机能够执行的全部指令的集合。</p>
<p><strong>指令系统也称指令集</strong></p>
<h3 id="软件的形式与概念"><a href="#软件的形式与概念" class="headerlink" title="软件的形式与概念"></a>软件的形式与概念</h3><h4 id="软件"><a href="#软件" class="headerlink" title="软件"></a>软件</h4><p>与一个系统（尤指计算机系统）有关的<strong>程序、步骤和有关文件</strong>编制的完整集合。特指特定类型计算机所使用的程序的总称，连同与计算机或程序有关的资料，例如手册、图表和操作指令。</p>
<p><strong>程序</strong></p>
<p>根据一定的需要事先编写的一系列控制计算机工作的命令，就称为<strong>计算机程序。</strong></p>
<p><strong>计算机系统的组成</strong></p>
<p>完整的计算机系统包括计算机硬件系统和计算机软件系统。</p>
<p><strong>软件的主要内容</strong></p>
<p>程序、步骤及数据、信息手册等相关资料</p>
<p>功能：针对一个系统（计算机），合理组织工作。</p>
<p>两个层次：</p>
<p>–直接与硬件相关</p>
<p>–合理组织工作，完成特定任务。</p>
<p><strong>软件的形式</strong></p>
<p>软件分为<strong>系统软件</strong>和<strong>应用软件</strong>，<font color="red">应用软件以系统软件为基础。</font></p>
<h3 id="信息安全与软件安全"><a href="#信息安全与软件安全" class="headerlink" title="信息安全与软件安全"></a>信息安全与软件安全</h3><h4 id="信息与信息安全"><a href="#信息与信息安全" class="headerlink" title="信息与信息安全"></a>信息与信息安全</h4><p><strong>信息安全属性</strong></p>
<p><strong>安全性，可用性，保密性，可控性，可靠性</strong></p>
<h4 id="软件安全"><a href="#软件安全" class="headerlink" title="软件安全"></a>软件安全</h4><p><strong>软件安全：</strong>软件在恶意攻击下能够正确地完成其功能。</p>
<p><strong>软件安全性：</strong>软件安全性是指软件不被恶意使用或者攻击进而造成用户信息资产损失的属性。</p>
<p><strong>软件安全属性：</strong></p>
<ol>
<li>可信性：保护敏感信息不被未授权用户访问</li>
<li>完整性：保护数据不被更改或破坏</li>
<li>可用性：确保资源被授权用户的使用</li>
</ol>
<p><strong>软件安全保护：</strong></p>
<p>(1) 软件<strong>自身安全</strong>：防止软件丢失、被破坏、被篡改、被伪造</p>
<p>(2) 软件<strong>存储安全</strong>：可靠存储，保密存储，压缩存储，备份存储</p>
<p>(3) 软件<strong>通信安全</strong>：安全传输、加密传输、网络安全下载、完整下载</p>
<p>(4) 软件<strong>信用安全</strong>：合法用户与非法用户，授权访问，防止软件滥用，</p>
<p>  防止软件窃取，软件的非法复制</p>
<p>(5) 软件<strong>运行安全</strong> ：确保软件正常运行，功能正常</p>
<p><strong>软件安全研究：</strong>如何设计、构造、验证和维护软件以保证其是安全的。</p>
<p>包括改进和实现软件安全的<strong>架构或结构、工具、方法</strong></p>
<h4 id="ISO7498-2"><a href="#ISO7498-2" class="headerlink" title="ISO7498-2"></a><strong>ISO7498-2</strong></h4><h5 id="主要内容"><a href="#主要内容" class="headerlink" title="主要内容"></a>主要内容</h5><p>在ISO7498-2中描述开放系统互连安全的体系架构，提出设计安全的信息系统的基础架构应该包含的：5种安全服务，对5种安全服务提供支持的8类安全机制，需要进行的5种OSI安全管理方式</p>
<h5 id="5种安全服务"><a href="#5种安全服务" class="headerlink" title="5种安全服务"></a>5种安全服务</h5><ul>
<li>鉴别服务、访问控制、数据完整性、数据保密性、抗抵赖</li>
</ul>
<h5 id="8种安全机制"><a href="#8种安全机制" class="headerlink" title="8种安全机制"></a>8种安全机制</h5><ul>
<li>加密、数字签名、访问控制、数据完整性、数据交换、业务流填充、路由控制、公证</li>
</ul>
<h5 id="5种普遍性安全管理机制"><a href="#5种普遍性安全管理机制" class="headerlink" title="5种普遍性安全管理机制"></a>5种普遍性安全管理机制</h5><ul>
<li>可信功能度、安全标记、事件检测、安全审计跟踪、安全恢复</li>
</ul>
<h4 id="软件安全的概念"><a href="#软件安全的概念" class="headerlink" title="软件安全的概念"></a>软件安全的概念</h4><h5 id="漏洞"><a href="#漏洞" class="headerlink" title="漏洞"></a>漏洞</h5><p>计算机系统具有的某种可能被入侵者恶意利用的<font color="red">属性</font>。</p>
<p>有时安全漏洞也称为脆弱性（Vulnerability）。</p>
<p><strong>本质：</strong>漏洞是系统的一组特性，恶意的主体（攻击者或者攻击程序）能够利用这组特性，通过已授权的手段和方式获取对资源的未经授权访问，或者对系统造成损害。</p>
<h5 id="脆弱状态"><a href="#脆弱状态" class="headerlink" title="脆弱状态"></a>脆弱状态</h5><p>从已授权的状态变换到未授权状态。</p>
<h5 id="攻击"><a href="#攻击" class="headerlink" title="攻击"></a>攻击</h5><p>攻击是以授权状态或脆弱状态开始，以<strong>受损状态为目标</strong>的状态变换</p>
<h5 id="安全事件"><a href="#安全事件" class="headerlink" title="安全事件"></a>安全事件</h5><p>当系统的某个漏洞被入侵者渗透（exploit）而造成泄密</p>
<h4 id="ISO9126标准"><a href="#ISO9126标准" class="headerlink" title="ISO9126标准"></a>ISO9126标准</h4><p>ISO9126标准：软件产品评价－质量特性及其使用指南</p>
<h5 id="6个质量特性"><a href="#6个质量特性" class="headerlink" title="6个质量特性"></a>6个质量特性</h5><ul>
<li><strong>功能性</strong><ul>
<li>准确性：软件提供给用户功能的精确度是否符合目标。（例如：运算结果的准确，数字发生偏差，多个0或少个0）</li>
<li>互操作性：软件与其它系统进行交互的能力。（例如：PC机中WORD和打印机完成打印互通）</li>
<li>保密安全性：软件保护信息和数据的安全能力。（主要是权限和密码）</li>
<li>功能性的依从性：遵循相关标准（国际标准、国内标准、行业标准、企业内部规范）</li>
</ul>
</li>
<li><strong>可靠性</strong><ul>
<li>成熟性：软件产品为避免软件内部的错误扩散而导至系统失效的能力（主要是对内错误的隔离）</li>
<li>容错性：软件防止外部接口错误扩散而导致系统失效的能力（主要是对外错误的隔离）</li>
<li>易恢复性：系统失效后，重新恢复原有的功能和性能的能力。</li>
<li>可靠性的依从性：遵循相关标准</li>
</ul>
</li>
<li><strong>易用性</strong><ul>
<li>易理解性：软件交互给用户的信息时，要清晰，准确，且要易懂，使用户能够快速理解软件。</li>
<li>易学性：软件使用户能学习其应用的能力。</li>
<li>易操作性：软件产品使用户能易于操作和控制它的能力。</li>
<li>易用性的依从性：遵循一定的标准。</li>
</ul>
</li>
<li><strong>效率</strong><ul>
<li>时间特性：软件处理特定的业务请求所需要的响应时间。</li>
<li>资源利用性：软件处理特定的业务请求所消耗的系统资源。</li>
<li>效率依从性：遵循一定的标准。</li>
</ul>
</li>
<li><strong>维护性</strong><ul>
<li>易分析性：软件提供辅助手段帮助开发人员定位缺陷产生的原因，判断出修改的地方。</li>
<li>易改变性：软件产品使得指定的修改容易实现的能力。（降低修复问题的成本）</li>
<li>稳定性：软件产品避免由于软件修改而造成意外结果的能力。</li>
<li>易测试性：软件提供辅助性手段帮助测试人员实现其测试意图。</li>
<li>维护性的依从性：遵循相关标准。</li>
</ul>
</li>
<li><strong>可移植性</strong><ul>
<li>适应性：软件产品无需作相应变动就能适应不同环境的能力。</li>
<li>易安装性：尽可能少的提供选择，方便用户直接安装。</li>
<li>共存性：软件产品在公共环境中与其它软件分享公共资源共存的软件。</li>
<li>易替换性：软件产品在同样的环境下，替代另一个相同用途的软件产品的能力。</li>
<li>可移植性的依从性：遵循相关的标准。</li>
</ul>
</li>
</ul>
<h5 id="9126质量模型缺陷"><a href="#9126质量模型缺陷" class="headerlink" title="9126质量模型缺陷"></a>9126质量模型缺陷</h5><ul>
<li>安全性是软件功能性的子属性</li>
<li>充分体现了对安全的忽视。</li>
</ul>
<p><strong>安全的代码（secure code）</strong>：  能够抵抗恶意攻击的代码；安全的代码同时也是健壮的代码（robust code）</p>
<p><strong>安全性代码（security code）</strong>：   实现安全功能的代码。</p>
<p><strong>安全的程序：</strong>安全隐含某种程度的信任（trust），程序实现了期望的机密性、完整性、可用性及其功能。</p>
<h2 id="CH02典型软件安全问题"><a href="#CH02典型软件安全问题" class="headerlink" title="CH02典型软件安全问题"></a>CH02典型软件安全问题</h2><h3 id="安全问题的来源"><a href="#安全问题的来源" class="headerlink" title="安全问题的来源"></a>安全问题的来源</h3><p><strong>根本来源：</strong>漏洞(<font color="red">漏洞是软件的属性，是软件安全威胁的根源</font>)、攻击者、软件存在的攻击路径－攻击面问题。</p>
<h4 id="漏洞-1"><a href="#漏洞-1" class="headerlink" title="漏洞"></a>漏洞</h4><h5 id="产生漏洞的原因"><a href="#产生漏洞的原因" class="headerlink" title="产生漏洞的原因"></a>产生漏洞的原因</h5><ol>
<li>软件或协议<strong>设计</strong>时的瑕疵</li>
<li>软件或协议<strong>实现</strong>中的弱点</li>
<li>软件<strong>本身</strong>的瑕疵</li>
<li><strong>系统和网络</strong>的错误配置</li>
</ol>
<h5 id="漏洞的两种类型"><a href="#漏洞的两种类型" class="headerlink" title="漏洞的两种类型"></a>漏洞的两种类型</h5><ul>
<li>设计漏洞：<ul>
<li>设计错误，往往发现于软件的安全功能特性中。</li>
</ul>
</li>
<li>实现漏洞：<ul>
<li>来源于软件实际编码中的安全缺陷。</li>
</ul>
</li>
</ul>
<h4 id="意外行为和缺陷"><a href="#意外行为和缺陷" class="headerlink" title="意外行为和缺陷"></a>意外行为和缺陷</h4><p><strong>意外行为（Unexpected Behavior）</strong>：也称程序安全缺陷，是由于程序脆弱性引起的不适当的程序行为。</p>
<p><strong>缺陷（Flaw）</strong>：缺陷可以是故障（Fault），或者失效（Failure）</p>
<p>程序安全缺陷可能来源于任何种类的<strong>软件错误</strong>：</p>
<ul>
<li>无意或疏忽的</li>
<li>故意或有意的</li>
</ul>
<h5 id="缺陷的类型："><a href="#缺陷的类型：" class="headerlink" title="缺陷的类型："></a>缺陷的类型：</h5><ul>
<li>有意的缺陷<ul>
<li>恶意的</li>
<li>非恶意的</li>
</ul>
</li>
<li>无意的缺陷<ul>
<li><strong>确认</strong>错误</li>
<li><strong>域</strong>的错误</li>
<li><strong>顺序化和混淆</strong>现象</li>
<li>不完全的<strong>身份识别和认证</strong></li>
<li><strong>边界条件</strong>违反</li>
<li>其它可利用的<strong>逻辑</strong>错误</li>
</ul>
</li>
</ul>
<h5 id="APPLE-DEVELOPER常见软件缺陷"><a href="#APPLE-DEVELOPER常见软件缺陷" class="headerlink" title="APPLE DEVELOPER常见软件缺陷"></a><strong>APPLE DEVELOPER常见软件缺陷</strong></h5><ul>
<li>buffer overflows   缓冲区溢出</li>
<li>invalidated input 未校验输入</li>
<li>race conditions 资源竞争</li>
<li>access-control problems 访问控制问题</li>
<li>weaknesses in authentication, authorization, or cryptographic practices 认证、授权、加密缺陷</li>
</ul>
<h3 id="常见的安全设计问题"><a href="#常见的安全设计问题" class="headerlink" title="常见的安全设计问题"></a>常见的安全设计问题</h3><ol>
<li><strong>密码技术使用的败笔</strong><ul>
<li>创建自己的密码技术</li>
<li>选用了不当的密码技术</li>
<li>依赖隐蔽式安全</li>
<li>编写到程序中的密钥</li>
<li>错误地处理私密信息</li>
</ul>
</li>
<li><strong>对用户及其许可权限进行跟踪的薄弱或缺失</strong><ul>
<li>会话管理薄弱或者缺失</li>
<li>身份鉴别薄弱或缺失</li>
<li>授权薄弱或缺失</li>
</ul>
</li>
<li><strong>有缺陷的输入验证</strong><ul>
<li>没有在安全的上下文环境中执行验证，如在服务器验证而在客户端没有验证</li>
<li>验证例程不集中，验证应尽可能靠近用户输入，并应集中以便于核实</li>
<li>不安全的组件边界</li>
</ul>
</li>
<li><strong>薄弱的结构性安全</strong><ul>
<li>过大的攻击面</li>
<li>在过高权限级别上运行进程</li>
<li>没有纵深防御</li>
<li>失效时的处理不安全</li>
</ul>
</li>
<li><strong>其他设计缺陷</strong><ul>
<li>代码和数据混在一起</li>
<li>错将信任寄予外部系统</li>
<li>不安全的默认值</li>
<li>未做审计日志</li>
</ul>
</li>
</ol>
<h3 id="编程语言问题"><a href="#编程语言问题" class="headerlink" title="编程语言问题"></a>编程语言问题</h3><h4 id="C-C-的问题"><a href="#C-C-的问题" class="headerlink" title="C/C++的问题"></a>C/C++的问题</h4><ol>
<li><p><strong>没有安全的本地字符串类型，也没有安全而易用的字符串处理函数。</strong></p>
<p><strong>PS：</strong></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">//C中以NULL终止符表示一个字符串的末尾。</span></span><br><span class="line"><span class="comment">//如：</span></span><br><span class="line">Char buffer[]=“small <span class="built_in">string</span>”</span><br><span class="line"><span class="comment">//没有确切地存储字符串的长度，该字符串的长度要</span></span><br><span class="line"><span class="comment">//程序员管理。</span></span><br><span class="line"><span class="comment">//当程序员处理这个长度犯错时，就会导致超过缓冲</span></span><br><span class="line"><span class="comment">//区结尾部分的内存被覆盖。</span></span><br></pre></td></tr></table></figure>
<p><strong>缓冲区溢出（BufferOverflow）</strong><br><strong>——一个最典型的例子：</strong></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">char</span> sample[<span class="number">10</span>];</span><br><span class="line"><span class="keyword">for</span> (i=<span class="number">0</span>; i&lt;<span class="number">10</span>; i++) sample[i] = <span class="string">&#x27;A&#x27;</span>;</span><br><span class="line">	sample[<span class="number">10</span>] =<span class="string">&#x27;B&#x27;</span>;   <span class="comment">//</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>缓冲区超限覆盖栈中的函数返回地址</strong></p>
<ul>
<li>用于从被调用的函数返回到某个位置的返回地址驻留在栈中，紧接在本地变量之后；</li>
<li>返回地址是驻留在栈中的一段隐蔽的数据，栈中其余部分是传递给该函数的变量；</li>
<li>编译后的程序在调用这个函数之前会将这个地址数据放在栈中，以使程序获知当这个函数执行完后转到哪里；</li>
<li>通过把栈中某个变量产生缓冲区溢出，就可以覆盖栈中的这个返回地址。</li>
</ul>
<p><strong>PS:</strong></p>
<p><strong>典型例子－栈溢出（Stack Smashing）</strong></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function">Void <span class="title">createFullName</span> <span class="params">(<span class="keyword">char</span>* firstName, Char* lastName)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">Char fullName[<span class="number">1024</span>];</span><br><span class="line">Strcpy(fullName, firstName);</span><br><span class="line">Strcat(fullName, “ “)</span><br><span class="line">Strcat(fullName, lastName);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">接受参数名字和姓氏，放到一起，中间用空格分隔；</span></span><br><span class="line"><span class="comment">变量fullName的声明方式，使其在堆栈中驻留；</span></span><br><span class="line"><span class="comment">如果firstName和lastName太长，可能会使fullName超出1024；</span></span><br><span class="line"><span class="comment">调用strcpy 和strcat函数破坏内存栈，会导致程序崩溃；</span></span><br><span class="line"><span class="comment">如果控制参数使得fullName发生缓冲区溢出，就可以造成程序的恶意攻击。</span></span><br><span class="line"><span class="comment">*/</span></span><br></pre></td></tr></table></figure>
<p><strong>预防栈溢出的方法：</strong></p>
<ul>
<li>精确控制输入变量的长度（如上述firstName和lastName的长度限制为511个字节）；</li>
<li>建议使用strncpy和strncat替代strcpy和strcat；</li>
<li>避免使用无界字符串；</li>
<li>创建一个新的或使用已有的字符串缓冲区模块。</li>
</ul>
</li>
<li><p><strong>printf类型的格式化函数－格式化字符串攻击</strong></p>
<p>例子：</p>
<p>   sprintf(target, “Name:%s, count:%d”, person, num);</p>
<p>该例子获取字符串Name和整型数count，放入target（目标缓冲区）</p>
<p>如果：</p>
<p>  sprintf（target，“Name: %s%s%s%s, count:%d”,num）；</p>
<p>此时该函数将从栈中读取四个字符串，但事实上栈中不存在这四个字符串，程序读取栈中原本用于其他目的的值。</p>
</li>
<li><p>整数溢出</p>
<p>在C语言中，整数的正负标识是默认的；</p>
<p>当一个整数值增长从而超过了其最大可能的值并循环到成为一个负数的时候，将发生整数溢出；</p>
<p>C语言没有任何措施预防整数溢出。</p>
<p>如果攻击者通过用户输入操纵整数长度，就可以让这个值溢出，引起程序的处理发生错误。</p>
<p>例：整数2147483647加1，发生溢出，成为</p>
<p>​               -2147483648</p>
<p><strong>PS：</strong></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function">Int <span class="title">copy_something</span><span class="params">(<span class="keyword">char</span> *buf, <span class="keyword">int</span> len)</span></span></span><br><span class="line"><span class="function">  </span>&#123;</span><br><span class="line">    <span class="keyword">char</span> kbuf[<span class="number">800</span>];</span><br><span class="line">     <span class="keyword">if</span>(len&gt;<span class="keyword">sizeof</span>(kbuf)</span><br><span class="line">          &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">-1</span>;                      <span class="comment">/*1*/</span></span><br><span class="line">          &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">memcpy</span>(kbuf, buf, len);    <span class="comment">/*2*/</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在 1 利用符号整数进行了一次边界检查；</p>
<p>如果能够控制程序，传递一个负值给len，则可能通过1的检查；</p>
<p>在2中，memcpy接受无符号数作为长度，len被解释为一个大的无符号数，导致超越缓冲区kbuf的末尾；</p>
<p>具有讽刺意味的是：1所进行的边界检查是为了预防缓冲区溢出。</p>
</li>
</ol>
<h3 id="平台的实现问题"><a href="#平台的实现问题" class="headerlink" title="平台的实现问题"></a>平台的实现问题</h3><p><strong>平台：</strong>平台是指程序在其中所<strong>运行的环境</strong>，包括<strong>操作系统</strong>以及与之<strong>交互的组件</strong>。</p>
<p><strong>平台问题1：符号链接</strong></p>
<p>符号链接（Symbolic link, 简写为symlink）：文件系统中指向其他文件的文件。符号链接等效于其指向的文件。程序打开的是一个符号链接，实际打开的是该符号链接指向的文件。</p>
<p>符号链接问题</p>
<p>攻击者可以使用程序预计要操作的文件名创建一个符号链接，使该文件名指向希望的文件；利用符号链接，攻击者事实上可以启动系统中的任何程序。</p>
<p>解决</p>
<p>程序员或使用者创建、打开、删除文件，或更改文件权限，必须检查该文件的符号链接，不可以基于文件名做任何安全方面的判定。</p>
<p>权限攻击的例子：如果程序以攻击者没有的权限运行，比如作为SUID（系统用户身份），攻击者可以借此发动一次权限提升。</p>
<p><strong>平台问题2：目录遍历</strong></p>
<p>典型例子：</p>
<p>CIFS是WINDOWS的文件共享协议，允许计算机通过网络访问彼此的文件系统。</p>
<p>利用目录遍历，攻击者可通过使用“..”符号上升到文件系统的上一级目录，从而对文件共享程序进行欺骗，进而获得对不在共享目录下的目录进行访问。</p>
<p><strong>平台问题3：字符转换</strong></p>
<p>平台支持不同类型的字符编码，存在多种不同的表示某个字符的方式。</p>
<p>程序接受用户的输入，为了满足安全需求，通常会要求进行安全检查，以确保输入的字符串对该程序设计是有效的。</p>
<p>当平台进行升级的时候可能会引入新的字符编码。</p>
<h3 id="常见的应用程序安全问题"><a href="#常见的应用程序安全问题" class="headerlink" title="常见的应用程序安全问题"></a>常见的应用程序安全问题</h3><p><strong>引起原因：</strong></p>
<ul>
<li>应用程序的某个组件的恶意数据引起，这些恶意数据在其另一个组件中被当作了合法代码；</li>
<li>对涉密信息的不当处理</li>
</ul>
<p><strong>应用安全问题1：SQL注入</strong></p>
<p>攻击者通过操纵程序的某种输入，在连接到SQL数据库的应用程序上执行自己所构造的查询。</p>
<p>​    <strong>预防SQL攻击方法：</strong>    </p>
<ul>
<li>过滤所有输入，确保输入字段只包含所需要的字符；</li>
<li>尽量避免使用动态生成的SQL。</li>
</ul>
<p>　<strong>SQL注入典型例子：</strong></p>
<p>​    但如果我们刻意的去绕过登录认证呢？猜想下面这个sql语句，单说用户名，开发人员很可能会这样去<strong>数据库</strong>里对比：<br> 　　Select <em> from sys_user where username=‘XXX’<br> 　　当然可能更复杂，假如我们在输入框里输入下面一句特殊的字符会如何？’or‘1=1<br> 　　这是段神奇的字符，因为这样这个sql就变成：<br> 　　Select </em> from sys_user where username=‘’or‘1=1’ ‘<br> 　　这样我们就跳过了用户名的验证，实现了入侵。</p>
<p>这样的结果，导致无条件越过用户名验证。</p>
<p><strong>应用安全问题2：跨站点执行脚本</strong></p>
<p>利用Internet上某些环境（或WEB站点）的受信任级别高于其他环境。</p>
<p>来自非受信环境的攻击者可在受信的环境注入数据，使其在受信环境作为脚本予以执行。</p>
<p>跨站点执行脚本还可以用来访问数据，如用户cookies。</p>
<p> <strong>跨站点执行脚本的例子：</strong></p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">假如有下面一个textbox：　　</span><br><span class="line"><span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span> <span class="attr">name</span>=<span class="string">&quot;address1&quot;</span> <span class="attr">value</span>=<span class="string">&quot;value1from&quot;</span>&gt;</span></span><br><span class="line">value后面的值是来自用户的输入，如果用户输入　</span><br><span class="line">&quot;/&gt;<span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="javascript">alert(<span class="built_in">document</span>.cookie)</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span><span class="tag">&lt;<span class="name">!-</span></span></span><br><span class="line"><span class="tag">那么就会变成　</span></span><br><span class="line">&lt;input type=&quot;text&quot; name=&quot;address1&quot; value=&quot;&quot;/&gt;&lt;script&gt;alert(document.cookie)&lt;/script&gt;&lt;!- &quot;&gt;　</span><br><span class="line">嵌入的JavaScript代码将会被执行　</span><br><span class="line">或者用户输入的是：</span><br><span class="line">&quot;onfocus=&quot;alert(document.cookie)</span><br><span class="line">那么就会变成</span><br><span class="line"><span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">&quot;text&quot;</span> <span class="attr">name</span>=<span class="string">&quot;address1&quot;</span> <span class="attr">value</span>=<span class="string">&quot;&quot;</span><span class="attr">onfocus</span>=<span class="string">&quot;alert(document.cookie)&quot;</span>&gt;</span></span><br><span class="line">事件被触发的时候嵌入的JavaScript代码将会被执行</span><br></pre></td></tr></table></figure>
<h3 id="开发过程问题"><a href="#开发过程问题" class="headerlink" title="开发过程问题"></a>开发过程问题</h3><ul>
<li>安全需求和前提条件的文档记录缺乏</li>
<li>交流和文档匮乏</li>
<li>缺少安全过程</li>
</ul>
<h4 id="部署上的薄弱性"><a href="#部署上的薄弱性" class="headerlink" title="部署上的薄弱性"></a>部署上的薄弱性</h4><p>部署的执行者一般不属于开发团队</p>
<p>软件错误地设置文件或注册表的键值，使系统上的其他用户可以进行更改</p>
<p>使软件安装时具有不必要的权限。</p>
<h3 id="OWASP"><a href="#OWASP" class="headerlink" title="OWASP"></a>OWASP</h3><p><strong>The Open Web Application Security Project</strong></p>
<h4 id="OWASP-Top-10"><a href="#OWASP-Top-10" class="headerlink" title="OWASP Top 10"></a>OWASP Top 10</h4><p><strong>A1-注入：</strong>攻击者发送的恶意数据可以欺骗解释器，以执行计划外的命令或者在未被恰当授权时访问数据。</p>
<p><strong>A2-失效的身份认证</strong></p>
<p><strong>A3-跨站脚本：</strong>XSS允许攻击者在受害者的浏览器上执行脚本，从而劫持用户会话、危害网站、或者将用户转向至恶意网站。</p>
<p><strong>A4-不安全的直接对象引用</strong></p>
<p><strong>A5-安全配置错误</strong></p>
<p><strong>A6-敏感信息泄露</strong></p>
<p><strong>A7-功能及访问控制缺失</strong></p>
<p><strong>A8-跨站请求伪造（CSRF）</strong></p>
<p><strong>A9-使用含有已知漏洞的组件</strong></p>
<p><strong>A10-未验证的重定向和转发</strong></p>
<h2 id="CH03安全软件工程"><a href="#CH03安全软件工程" class="headerlink" title="CH03安全软件工程"></a>CH03安全软件工程</h2><h3 id="SSE-CMM"><a href="#SSE-CMM" class="headerlink" title="SSE-CMM"></a>SSE-CMM</h3><h4 id="开发SSE-CMM的目的"><a href="#开发SSE-CMM的目的" class="headerlink" title="开发SSE-CMM的目的"></a>开发SSE-CMM的目的</h4><p>降低开发和维护系统的花费；</p>
<p>提高工程进度和预算的一致性；</p>
<p>选择合适的承包者。</p>
<p><strong>发起者：</strong>国防部、国家安全局</p>
<h4 id="主要内容-1"><a href="#主要内容-1" class="headerlink" title="主要内容"></a>主要内容</h4><h5 id="能力方面"><a href="#能力方面" class="headerlink" title="能力方面"></a>能力方面</h5><h6 id="能力级别"><a href="#能力级别" class="headerlink" title="能力级别"></a>能力级别</h6><p><strong>能力级别1：非正式执行</strong></p>
<p><strong>公共特征</strong></p>
<p>执行基本实施</p>
<p><strong>能力级别2：计划与跟踪</strong></p>
<p><strong>公共特征</strong></p>
<p>计划执行</p>
<p>规范化执行</p>
<p>验证执行</p>
<p>跟踪执行</p>
<p><strong>能力级别3：充分定义</strong></p>
<p><strong>公共特征</strong></p>
<p>定义标准过程</p>
<p>执行已定义的过程</p>
<p>协调安全实施</p>
<p><strong>能力级别4：定量控制</strong></p>
<p><strong>公共特征</strong></p>
<p>建立可测的质量目标</p>
<p>客观地管理过程的执行</p>
<p><strong>能力级别５：连续改进</strong></p>
<p><strong>公共特征</strong></p>
<p>改进组织能力</p>
<p>改进过程的有效性</p>
<h5 id="域方面"><a href="#域方面" class="headerlink" title="域方面"></a>域方面</h5><p>工程和安全实施是安全工程过程中必须存在的性质，指出特殊过程区的目的并属于该过程区</p>
<p> 每个过程区（PA）是一组相关安全工程过程的性质，当这些性质全部实施后则能够达到过程区定义的目的。</p>
<p><strong>一组过程区指出活动的同一通用区</strong> </p>
<p><img src="/2019/06/14/%E8%BD%AF%E4%BB%B6%E5%AE%89%E5%85%A8%E8%AE%BE%E8%AE%A1/1.png" alt></p>
<h4 id="关于安全工程与评估"><a href="#关于安全工程与评估" class="headerlink" title="关于安全工程与评估"></a>关于安全工程与评估</h4><p><strong>安全工程分三个基本过程：风险、工程和保证</strong></p>
<p><strong>风险(风险信息)</strong></p>
<p><strong>风险过程是要<font color="red">确定</font>产品或者系统的危险性，并对这些危险性进行优先级排序</strong></p>
<p><strong>工程(解决方案)</strong></p>
<p><strong>工程过程是<font color="red">针对</font>面临的危险性，安全工程过程与相关工程过程一起来确定并实施解决方案</strong></p>
<p><strong>保证(保证论据)</strong></p>
<p><strong>保证过程是建立起对解决方案的<font color="red">信任</font>，并把这种信任传达给顾客</strong></p>
<h4 id="SSAM-SSE-CMM评定方法"><a href="#SSAM-SSE-CMM评定方法" class="headerlink" title="SSAM(SSE-CMM评定方法)"></a>SSAM(SSE-CMM评定方法)</h4><p>SSAM 为了进行评定，收集数据广泛、严格，每个数据有充分的证据。此方法在评定过程中最大程度地发挥了SSE-CMM模型的功效。</p>
<p>此方法：</p>
<ul>
<li>决定实施安全工程过程的能力</li>
<li>为了评定定义了安全工程环境</li>
<li>在评定时巧妙地使用了SSE-CMM体系结构中的两个方面。</li>
</ul>
<h3 id="SDL-安全开发生命周期模型"><a href="#SDL-安全开发生命周期模型" class="headerlink" title="SDL-安全开发生命周期模型"></a>SDL-安全开发生命周期模型</h3><p>Secure Development Lifecycle</p>
<p>微软可信计算(TrustWorthy Computing )努力的一个组成部分</p>
<ul>
<li>基于并行理念的标准软件开发过程</li>
<li>基于威胁建模和测试</li>
</ul>
<h4 id="SDL概览"><a href="#SDL概览" class="headerlink" title="SDL概览"></a>SDL概览</h4><p>SDL从三个方面考虑软件安全的保障。</p>
<h5 id="设计安全"><a href="#设计安全" class="headerlink" title="设计安全"></a>设计安全</h5><ul>
<li>为了保护软件自身以及软件处理的信息,并抵御攻击,软件应该从架构,设计和实现上进行考虑</li>
</ul>
<h5 id="缺省安全"><a href="#缺省安全" class="headerlink" title="缺省安全"></a>缺省安全</h5><ul>
<li><p>设计者应该假定安全缺陷将会出现。</p>
</li>
<li><p>为了当攻击者对软件存在的缺陷进行攻击时使损害降到最小, 软件的缺省状态应该保证安全。</p>
<p>比如 最小特权原则。</p>
</li>
</ul>
<h5 id="提交安全"><a href="#提交安全" class="headerlink" title="提交安全"></a>提交安全</h5><ul>
<li><p>工具和指南应该随着软件提供以帮助最终用户或管理员安全使用。</p>
</li>
<li><p>关于软件的更新应该容易提交。</p>
</li>
</ul>
<h4 id="SDL过程"><a href="#SDL过程" class="headerlink" title="SDL过程"></a>SDL过程</h4><p><strong>0：教育和意识</strong></p>
<p><strong>安全教育的内容</strong></p>
<p>安全设计基础：受攻击面分析、深度防御、最小特权、安全默认配置</p>
<p>威胁建模：设计威胁建模、编码威胁建模、测试威胁建模</p>
<p><strong>1：项目启动</strong></p>
<p>判断SDL是否覆盖应用、任命安全顾问、组建安全领导团队、确保在BUG追踪管理过程中包含安全、隐私类BUG、建立BUG标准</p>
<p><strong>2：定义并遵从设计最佳实践</strong></p>
<p><strong>常见安全设计原则</strong></p>
<p>经济机制、默认失效保护、安全中介、公开设计、权限分离、最小特权、最少公共机制、心里可接受程度</p>
<p><strong>受攻击面分析与降低</strong></p>
<p><strong>分析</strong></p>
<p>枚举所有接口、协议以及可执行代码的过程。</p>
<p><strong>软件的受攻击面</strong></p>
<p>代码、接口、服务、协议、其他</p>
<p><strong>降低</strong></p>
<p>核心观点：在所有代码中存在至少一个或多个漏洞的可能性一定不为零，一部分严重漏洞会导致用户不得不接受妥协。唯一解决上述问题的方法是将代码的利用率降至为零。</p>
<p><strong>受攻击面降低的方法：</strong></p>
<ul>
<li><p>降低默认执行的代码量</p>
</li>
<li><p>限制可访问到代码的人员范围</p>
</li>
<li><p>限定可访问到代码的人员身份</p>
</li>
<li><p>降低代码所需权限。</p>
</li>
</ul>
<p><strong>3：产品风险评估</strong></p>
<p><strong>安全风险评估</strong>、<strong>隐私影响分级</strong>、<strong>统一各种因素</strong></p>
<p><strong>4：风险分析</strong>/<strong>威胁建模</strong></p>
<p><strong>益处</strong></p>
<p>有助于整个风险管理过程</p>
<p>在系统进入编码阶段前发现系统威胁</p>
<p>开发团队通过威胁建模可以重新验证其架构与设计</p>
<p>有助于进一步明确针对应用以及环境采取相应的解决对策</p>
<p>有助于指导整个代码审核过程</p>
<p>指导整个渗透测试过程</p>
<p><strong>威胁建模过程</strong></p>
<ol>
<li><p>定义应用场景</p>
</li>
<li><p>收集外部依赖列表</p>
</li>
<li><p>定义安全假设</p>
</li>
<li><p>创建外部安全备注</p>
</li>
<li><p>绘制待建模应用的一个或多个数据流图</p>
</li>
<li><p>确定威胁类型</p>
</li>
<li><p>识别系统威胁</p>
</li>
<li><p>判断风险</p>
</li>
<li><p>规划消减措施</p>
</li>
</ol>
<p><strong>5：创建安全文档、工具以及客户最佳实践</strong></p>
<p><strong>6：安全编码策略</strong></p>
<p><strong>7：安全测试策略</strong></p>
<p>安全测试内容：模糊测试、渗透测试、运行时测试、重审威胁模型、重估受攻击模型</p>
<p><strong>8：安全推进过程</strong></p>
<p><strong>9：最终安全评审</strong></p>
<p><strong>10：安全响应规划</strong></p>
<p>使用SDL不能保证生产绝对安全的软件：</p>
<ul>
<li><p>开发团队一定会出错</p>
</li>
<li><p>新漏洞一定会变化</p>
</li>
<li><p>规则一定会变化</p>
</li>
</ul>
<p><strong>11：产品发布</strong></p>
<p><strong>12：遵从计划、尽可能补救、理解取舍之道</strong></p>
<h2 id="CH04软件安全测试"><a href="#CH04软件安全测试" class="headerlink" title="CH04软件安全测试"></a>CH04软件安全测试</h2><h3 id="软件安全测试"><a href="#软件安全测试" class="headerlink" title="软件安全测试"></a>软件安全测试</h3><p>安全性测试是指有关<strong>验证应用程序的安全等级和识别潜在安全性缺陷</strong>的过程。</p>
<p>应用程序级<strong>安全测试</strong>的主要目的是查找软件自身程序设计中存在的安全隐患，并检查应用程序对非法侵入的防范能力。</p>
<p>安全指标不同测试策略也不同。</p>
<h4 id="安全测试的法律问题"><a href="#安全测试的法律问题" class="headerlink" title="安全测试的法律问题"></a>安全测试的法律问题</h4><p>安全测试必须得到授权<br>安全测试工具的应用必须得到授权<br>穿透测试实验必须得到授权<br>在未得到明确授权的情况下，不允许针对第三方系统进行穿透测试的实验</p>
<h4 id="软件安全测试的方法"><a href="#软件安全测试的方法" class="headerlink" title="软件安全测试的方法"></a>软件安全测试的方法</h4><ul>
<li><strong>静态测试</strong></li>
</ul>
<p>主要通过对源代码进行安全扫描，根据程序中数据流、控制流、语义等信息与其特有软件安全规则库进行匹对，从中找出代码中潜在的安 全漏洞。</p>
<p>静态的源代码安全测试是非常有用的方法，可以在编码阶段找出所有可能存在安全风险的代码，这样开发人员可以在早期解决潜在的安全问题。</p>
<p>静态代码测试比较适用于早期的代码开发阶段，而不是测试阶段。</p>
<ul>
<li><strong>动态的测试</strong></li>
</ul>
<p>动态测试也称渗透测试，penetrate</p>
<p>渗透测试是常用的安全测试方法。是使用自动化工具或者人工的方法模拟黑客的输入，对应用系统进行攻击性测试，从中找出运行时刻所存在的安全漏洞。</p>
<p>渗透测试的特点就是真实有效，一般找出来的问题都是正确的，也是较为严重的。</p>
<p>渗透测试的缺点是模拟的测试数据只能到达有限的测试点，覆盖率很低。</p>
<ul>
<li><strong>程序数据扫描</strong></li>
</ul>
<p>一个有高安全性需求的软件， 在运行过程中数据是不能遭到破坏的，否则就会导致缓冲区溢出类型的攻击。</p>
<p>数据扫描的手段通常是进行内存测试，内存测试可以发现许多诸如缓冲区溢出之类的漏洞，而这类漏洞使用除此之外的测试手段都难以发现。</p>
<p>例如，利用专门的工具对软件运行时的内存信息进行扫描，检查是否存在导致隐患的信息。</p>
<h4 id="安全测试点"><a href="#安全测试点" class="headerlink" title="安全测试点"></a>安全测试点</h4><ul>
<li><p>程序安全性测试</p>
</li>
<li><p>数据安全性测试</p>
</li>
</ul>
<h4 id="典型问题"><a href="#典型问题" class="headerlink" title="典型问题"></a>典型问题</h4><h5 id="程序安全性测试典型问题参考"><a href="#程序安全性测试典型问题参考" class="headerlink" title="程序安全性测试典型问题参考"></a><strong>程序安全性测试典型问题参考</strong></h5><p>① 明确区分系统中不同用户权限;</p>
<p>② 系统中会不会出现用户冲突;</p>
<p>③ 系统会不会因用户的权限的改变造成混乱;</p>
<p>④ 用户登陆密码是否是可见、可复制;</p>
<p>⑤ 是否可以通过绝对途径登陆系统(拷贝用户登陆后的链接直接进入系统);</p>
<p>⑥ 用户推出系统后是否删除了所有鉴权标记，是否可以使用后退键而不通过输入口令进入系统。</p>
<h5 id="网络安全测试典型问题参考"><a href="#网络安全测试典型问题参考" class="headerlink" title="网络安全测试典型问题参考"></a><strong>网络安全测试典型问题参考</strong></h5><p>① 测试采取的防护措施是否正确装配好，有关系统的补丁是否打上;</p>
<p>② 模拟非授权攻击，看防护系统是否坚固;</p>
<p>③ 采用成熟的网络漏洞检查工具检查系统相关漏洞;</p>
<p>④ 采用各种木马检查工具检查系统木马情况;</p>
<p>⑤ 采用各种防外挂工具检查系统各组程序的客外挂漏洞。</p>
<h5 id="数据安全测试考虑问题参考："><a href="#数据安全测试考虑问题参考：" class="headerlink" title="数据安全测试考虑问题参考："></a><strong>数据安全测试考虑问题参考：</strong></h5><p>① 系统数据是否机密(比如对银行系统，这一点就特别重要，一般的网站就没有太高要求);</p>
<p>② 系统数据的完整性;</p>
<p>③ 系统数据可管理性;</p>
<p>④ 系统数据的独立性;</p>
<p>⑤ 系统数据可备份和恢复能力(数据备份是否完整，可否恢复，恢复是否可以完整)。</p>
<h3 id="安全漏洞分级"><a href="#安全漏洞分级" class="headerlink" title="安全漏洞分级"></a>安全漏洞分级</h3><h4 id="DREAD模型"><a href="#DREAD模型" class="headerlink" title="DREAD模型"></a>DREAD模型</h4><p><strong>DREAD模型</strong>：进行威胁程度级别分析的有效技术。</p>
<ul>
<li><p><strong>潜在的破坏（Damage potential）</strong></p>
<ul>
<li>如果该漏洞被利用，所产生的破坏程度</li>
</ul>
</li>
<li><p><strong>再现性（Reproducibility）</strong></p>
<ul>
<li>探测并利用该漏洞所需要的努力要多久</li>
</ul>
</li>
<li><p><strong>可利用性（Exploitability）</strong></p>
<ul>
<li>是否需要身份鉴别？</li>
</ul>
</li>
<li><p><strong>受影响用户（Affected users）</strong></p>
<ul>
<li>漏洞利用的影响面有多大</li>
</ul>
</li>
<li><p><strong>可发现性（Discoverability）</strong></p>
<ul>
<li>漏洞研究人员或黑客找出该漏洞的可能性</li>
</ul>
</li>
</ul>
<h4 id="TRAP模型"><a href="#TRAP模型" class="headerlink" title="TRAP模型"></a>TRAP模型</h4><p>基于可利用性提出。</p>
<p><strong>因素：</strong></p>
<p>时间（Time）</p>
<p>可靠性（Reliability）/再现性（Reproducibility）</p>
<p>访问（Access）</p>
<p>定位（Positioning）</p>
<h3 id="安全的常规测试方法"><a href="#安全的常规测试方法" class="headerlink" title="安全的常规测试方法"></a>安全的常规测试方法</h3><h4 id="基于风险的安全测试"><a href="#基于风险的安全测试" class="headerlink" title="基于风险的安全测试"></a>基于风险的安全测试</h4><p><strong>安全测试的目标</strong></p>
<p>在给定的时间和资源不变的情况下，尽可能多地找出最为严重的安全缺陷。</p>
<p><strong>威胁建模=风险建模</strong></p>
<p>基于风险的测试是软件测试的常规方法</p>
<h5 id="基于风险的测试的三个步骤"><a href="#基于风险的测试的三个步骤" class="headerlink" title="基于风险的测试的三个步骤"></a>基于风险的测试的三个步骤</h5><ol>
<li><p><strong>信息搜集</strong></p>
<p><strong>信息搜集的目的：</strong>熟悉程序的设计、了解程序访问入口点位置、了解程序所涉及的信息资产－需要保护的信息</p>
<p><strong>信息搜集的方法：</strong>程序设计文档的评审、与设计人员和架构师会谈、运行时分析－使用调试和诊断程序</p>
</li>
<li><p><strong>威胁（风险）建模</strong></p>
<p><strong>威胁建模的目的：</strong>排定测试优先级，找出测试区域，发现系统弱点</p>
<p><strong>威胁建模步骤：</strong></p>
<ol>
<li><p><strong>识别威胁路径</strong>：</p>
<p><strong>目的：</strong>识别应用程序级别最高的风险领域，确定相应的保护措施</p>
<p><strong>步骤：</strong></p>
<p>①了解应用程序平台和编程语言的整体强度</p>
<p>②确定用户的访问类别</p>
<p>③建立并分析数据流图</p>
</li>
<li><p><strong>识别威胁：</strong></p>
<p><strong>目的：</strong>深入识别沿威胁路径的处理，逐一理清与处理相关的每一种威胁。</p>
<p><strong>针对威胁路径的每一个处理组件的问题列表：</strong></p>
<p>–该组件执行什么样的处理</p>
<p>–该组件如何确定身份</p>
<p>–该组件信任数据或者其他组件吗</p>
<p>–该组件修改了什么数据</p>
<p>–该组件有何外部连接</p>
<p><strong>在一个威胁路径上的9个高风险活动：</strong></p>
<p>①数据解析 ②文件访问 ③数据库访问 ④生成子进程 ⑤身份鉴别    ⑥授权 ⑦同步或会话管理 ⑧处理私密数据 ⑨网络访问</p>
</li>
<li><p><strong>识别漏洞</strong></p>
<p><strong>目的：</strong>找出可能存在于组件中的实际漏洞。</p>
<p><strong>缓解措施：</strong></p>
<p>–数据验证测试</p>
<p>–资源监视</p>
<p>–关键功能的访问控制</p>
<p><strong>搜寻漏洞的方法及途径：</strong></p>
<p>–安全设计审查</p>
<p>–安全代码审查</p>
<p>–安全测试</p>
</li>
<li><p><strong>风险分级/排定优先级</strong></p>
</li>
</ol>
</li>
<li><p><strong>可用性分析</strong></p>
<p><strong>判定可利用性的目的：</strong>判断漏洞是否可被攻击者利用。</p>
<p><strong>原则：</strong>在开发中直接修补一个可能会被利用的问题比花时间判定其是否会被利用容易</p>
</li>
</ol>
<h4 id="白盒、黑盒和灰盒测试"><a href="#白盒、黑盒和灰盒测试" class="headerlink" title="白盒、黑盒和灰盒测试"></a>白盒、黑盒和灰盒测试</h4><h5 id="白盒测试"><a href="#白盒测试" class="headerlink" title="白盒测试"></a>白盒测试</h5><p>也称明盒测试、开盒测试或信息充分测试。</p>
<p>白盒测试可以看作是内部的攻击。</p>
<p>测试人员可以访问源代码和设计文档，可以进行威胁建模或逐行的代码检查。</p>
<p>白盒测试是找出漏洞最为有效的方法。</p>
<h5 id="黑盒测试"><a href="#黑盒测试" class="headerlink" title="黑盒测试"></a>黑盒测试</h5><p> 以局外人的身份对系统进行攻击，使用工具检查系统的攻击面，并探查系统的内部信息。</p>
<p>黑盒测试是白盒测试的补充。</p>
<p>方向工程团队利用黑盒测试验证隐蔽式安全方法的强度。</p>
<h5 id="灰盒测试"><a href="#灰盒测试" class="headerlink" title="灰盒测试"></a>灰盒测试</h5><p>组合使用白盒测和黑盒测试。</p>
<p>–白盒测试用于发现在设计和开发中详细说明的功能中的缺陷；</p>
<p>–黑盒测试在无法了解程序内部信息的时候找出缺陷。</p>
<p>程序开发中的调试运行是典型的灰盒测试方法。</p>
<h4 id="典型安全测试工具"><a href="#典型安全测试工具" class="headerlink" title="典型安全测试工具"></a>典型安全测试工具</h4><p><strong>JAVA代码安全分析工具：</strong></p>
<p>–IBM AppScan Source Edition</p>
<p>–Fotify  Static Code Analyzer</p>
<p>–Findbugs</p>
<p><strong>C++代码安全分析工具：</strong></p>
<p>–C++Test</p>
<p>–IBM AppScan Source Edition</p>
<p>–Fotify  Static Code Analyzer</p>
<p>Visual Studio（27.78%）</p>
<p><strong>JavaScript代码安全工具：</strong></p>
<p>–Google’s Closure Compiler</p>
<p>–JSHint</p>
<p><strong>Python代码安全工具：</strong></p>
<p>–Pychecker</p>
<p>–PyCharm</p>
<p>–Pylint</p>
<p>–PySEC，开源</p>
<p><strong>WEB应用安全测试工具：</strong></p>
<p>IBM AppScan</p>
<p>SoapUI</p>
<p>HP的WebInspect</p>
<p><strong>WEB应用的开源工具：</strong></p>
<p>Firebug</p>
<p>OWASP ZAP</p>
<p><strong>Android App安全测试工具：</strong></p>
<p>Android Tamer</p>
<p>AndroBugs</p>
<p>Mobisec</p>
<p><strong>SQL注入测试工具：</strong></p>
<p>SQLInjetor</p>
<p>SQL Power Injector</p>
<p>OWASP SQLiX</p>
<p><strong>网络状态监控与分析工具：</strong></p>
<p>Wireshark</p>
<h2 id="CH05编写安全的代码"><a href="#CH05编写安全的代码" class="headerlink" title="CH05编写安全的代码"></a>CH05编写安全的代码</h2><h3 id="SD3"><a href="#SD3" class="headerlink" title="SD3"></a>SD3</h3><h4 id="安全设计"><a href="#安全设计" class="headerlink" title="安全设计"></a>安全设计</h4><ul>
<li><p>安排具体的安全设计的人员；</p>
</li>
<li><p>进行安全教育；</p>
</li>
<li><p>确保威胁分析已经完成；</p>
</li>
<li><p>符合安全设计和编码的指导原则；</p>
</li>
<li><p>尽可能修补任何安全编程指南上的BUG;</p>
</li>
<li><p>确保安全指南是逐步改进的；</p>
</li>
<li><p>针对已经修复的缺陷开发回归测试；</p>
</li>
<li><p>简化代码和安全模型；</p>
</li>
<li><p>在打包以前完成穿透测试。</p>
</li>
</ul>
<h4 id="缺省安全-1"><a href="#缺省安全-1" class="headerlink" title="缺省安全"></a>缺省安全</h4><ul>
<li><p>缺省状态下，不要设置所有的特点和功能；</p>
</li>
<li><p>允许最小权限；</p>
</li>
<li><p>恰当的资源保护。</p>
</li>
</ul>
<h4 id="安全提交"><a href="#安全提交" class="headerlink" title="安全提交"></a>安全提交</h4><ul>
<li><p>确认程序给管理员提供了安全功能；</p>
</li>
<li><p>尽可能提供高质量的补丁；</p>
</li>
<li><p>提供足够的信息以使用户安全的使用软件。</p>
</li>
</ul>
<h3 id="安全规则"><a href="#安全规则" class="headerlink" title="安全规则"></a>安全规则</h3><ul>
<li><p>学习错误；</p>
</li>
<li><p>最小化攻击面；</p>
</li>
<li><p>使用深度防御；</p>
</li>
<li><p>使用最小权限；</p>
</li>
<li><p>应用缺省安全；</p>
</li>
<li><p>记住兼容性的倒退是痛苦的；</p>
</li>
<li><p>假定外部系统是不安全的；</p>
</li>
<li><p>基于错误计划；</p>
</li>
<li><p>切记安全的特性不等于安全特性；</p>
</li>
<li><p>Never depend on security through obscurity( 朦胧，晦涩，不分明) alone</p>
</li>
<li><p>不要混合编码和数据；</p>
</li>
<li><p>正确修复安全问题。</p>
</li>
</ul>
<h4 id="学习错误"><a href="#学习错误" class="headerlink" title="学习错误"></a>学习错误</h4><p>学习错误从填写一个文档开始，文档内容：<br>产品名称；产品版本；联系人；BUG数据库编号；<br>脆弱性描述；脆弱性的隐含意义；<br>在产品的缺省安装中，这个问题是否存在？<br>设计，开发和测试人员能够做什么来防止这个缺陷？<br>修复的细节，包括代码的区别，如果可以填写。</p>
<h4 id="最小化攻击面"><a href="#最小化攻击面" class="headerlink" title="最小化攻击面"></a>最小化攻击面</h4><p>需要计算下面的内容：<br>（1）打开socket、命名管道、RPC端点的数量；<br>（2）服务的数量；缺省运行服务的数量；服务以提高权限运行的数量；<br>（3）ISAPI过滤器和应用的数量；动态WEB页面数量；加入管理员组帐号的数量；<br>（4）文件，目录和注册键值的数量，带有弱访问控制列表。</p>
<h2 id="CH06信息系统的安全建模莫分析"><a href="#CH06信息系统的安全建模莫分析" class="headerlink" title="CH06信息系统的安全建模莫分析"></a>CH06信息系统的安全建模莫分析</h2><h3 id="信息系统及其特征"><a href="#信息系统及其特征" class="headerlink" title="信息系统及其特征"></a>信息系统及其特征</h3><h4 id="MIS"><a href="#MIS" class="headerlink" title="MIS"></a>MIS</h4><p>MIS是借助于自动化数据处理手段进行管理的系统，由计算机硬件、软件（包括：系统软件、应用软件和管理学软件包）、数据库各种规程和人共同组成。</p>
<p>是由人、计算机等组成的能进行管理信息的收集、传递、加工的信息系统。</p>
<h5 id="主要特征"><a href="#主要特征" class="headerlink" title="主要特征"></a>主要特征</h5><ul>
<li><p>依赖于计算机的；</p>
</li>
<li><p>涉及了计算机的软件和硬件；</p>
</li>
<li><p>实现数据的采集、传递、加工、处理功能。</p>
</li>
</ul>
<h5 id="系统主要特性"><a href="#系统主要特性" class="headerlink" title="系统主要特性"></a>系统主要特性</h5><p>1 整体性—系统的各个部分一定以整体目标为目标，追求全局最优；</p>
<p>2 目的性—一个系统一定是具有明确目标的，并完成一定的功能；</p>
<p>3 层次性—一个系统可以分为若干层次和子系统；</p>
<p>4 边界性—每一个系统都能够明显地区别于其他系统，系统之间有明确的界限；</p>
<p>5 关联性—系统包括若干元素，元素之间存在一定的关联性；</p>
<p>6 环境性—系统处于一定的环境之中并受环境影响。</p>
<h5 id="信息系统的类型"><a href="#信息系统的类型" class="headerlink" title="信息系统的类型"></a>信息系统的类型</h5><p>宏观的国家经济信息系统；</p>
<p>面向基层的企事业管理信息系统；</p>
<p>事务型管理信息系统；</p>
<p>办公型管理信息系统；</p>
<p>专业型管理信息系统等；</p>
<p>既有典型的MRP，ERP，SCM等通用的信息系统，也有针对特定业务的系统。</p>
<p>许许多多以计算机为核心的，实现数据的采集、存储、操作的系统都属于信息系统的范畴。</p>
<h5 id="运行环境要素"><a href="#运行环境要素" class="headerlink" title="运行环境要素"></a>运行环境要素</h5><ol>
<li><p>物理世界；</p>
</li>
<li><p>管理者实体—拥有授权管理、变更、修复和使用系统的人或者其他系统，其中一些被授权人可能缺乏有效管理系统的能力或具有恶意的目的；</p>
</li>
<li><p>使用者—在使用界面接受来自系统的服务的实体；</p>
</li>
<li>提供者—在系统的使用界面提供服务的实体；</li>
<li>基础组织—对系统提供信息源、通信链接、能源、冷气等特定服务的实体；</li>
<li>入侵者—企图超越所拥有的权限并且变更服务或阻止服务，变更系统的功能或性能或者存取秘密信息的实体。</li>
</ol>
<h3 id="信息系统的安全问题"><a href="#信息系统的安全问题" class="headerlink" title="信息系统的安全问题"></a>信息系统的安全问题</h3><p><strong>ISO7498-2标准中所定义的五种安全服务类型：</strong></p>
<ul>
<li><p>身份鉴别（Authentication）</p>
</li>
<li><p>访问控制（Access Control）</p>
</li>
<li><p>数据保密（Data Confidentiality）</p>
</li>
<li><p>数据完整性（ Data integrity）</p>
</li>
<li><p>抗抵赖（Non-reputation）</p>
</li>
</ul>
<h3 id="安全模型"><a href="#安全模型" class="headerlink" title="安全模型"></a>安全模型</h3><p><strong>系统使用者：</strong></p>
<p>用户    系统管理员    信息主管(企业主管)</p>
<p><strong>系统划分：</strong></p>
<p>用户界面逻辑    业务逻辑    异常检测机</p>
<p><strong>系统安全实现的主要功能：</strong></p>
<p>访问控制    抗抵赖    数据保密    身份鉴别    </p>
<p>授权机制    日志审计    系统异常探测</p>
<h4 id="用户界面逻辑"><a href="#用户界面逻辑" class="headerlink" title="用户界面逻辑"></a>用户界面逻辑</h4><p>用户界面逻辑部分：数据访问、登录控制。</p>
<p>在系统启动时，用户首先登录系统，通过系统验证后才可以完成数据访问功能。</p>
<h5 id="登录控制"><a href="#登录控制" class="headerlink" title="登录控制"></a>登录控制</h5><p><strong>主要功能：</strong>口令验证，口令修改，口令数据的加密，登录时间记录</p>
<p><strong>设计考虑：</strong></p>
<ol>
<li>用户ID：从权限数据中提取出相应的用户名。采用用户编号的原因是回避重名，简化输入，同时用户号本身也可以增加一定的安全性。</li>
<li>用户修改口令，而不是系统管理员：系统管理员<strong>对用户授权</strong>，但是口令由用户在用户界面输入，并加密存储至后台数据库中，以避免系统管理员获取用户口令造成泄密</li>
<li>初始口令的安全：系统的第一次运行关键是初始口令的赋予，由信息主管（或其他高层）完成用户身份的确认，同时要求用户第一次登录时必须更改初始口令。</li>
<li>口令安全：口令长度限制；口令字符集限制；口令有效期限制。</li>
<li>用户封锁：所谓的用户封锁是当出现用户多次登录系统失败的情况时，系统将锁定用户的操作并提示，解锁过程必须由系统管理员完成。</li>
</ol>
<h4 id="业务逻辑"><a href="#业务逻辑" class="headerlink" title="业务逻辑"></a>业务逻辑</h4><p>在系统的业务逻辑部分主要包括<strong>数据服务、权限管理、日志审计</strong>三个部分。</p>
<h5 id="数据服务"><a href="#数据服务" class="headerlink" title="数据服务"></a>数据服务</h5><p>主要安全任务是完成特定数据的加密、解密，日志数据的存储，权限及用户信息的存储。</p>
<h5 id="权限管理"><a href="#权限管理" class="headerlink" title="权限管理"></a>权限管理</h5><p>完成用户的授权，包括两个部分：系统管理员和信息主管。信息主管负责系统启动和初始授权，系统管理员负责日常权限管理、日志审计、系统状态监控、异常监测、用户锁定处理。</p>
<h5 id="日志审计"><a href="#日志审计" class="headerlink" title="日志审计"></a>日志审计</h5><p>对用户的操作行为进行跟踪，提供根据时间、用户、系统的检索手段。是保证安全，提高安全可信性的重要手段。</p>
<h4 id="异常探测机"><a href="#异常探测机" class="headerlink" title="异常探测机"></a>异常探测机</h4><p>异常探测机实现的主要功能：</p>
<p>–是日志的分析；</p>
<p>–网络状态的安全监测；</p>
<p>–提供一定的日志文件保护机制。</p>
<p><strong>异常检测独立于业务逻辑的目的</strong></p>
<p>1独立的程序，便于进一步发展，有较大的发展空间；</p>
<p>2位于业务和用户进程之外，能够对其进行监控；</p>
<p>3不对信息系统运行发生干扰；</p>
<p>4使该探测器成为系统的可选件。</p>
<h5 id="异常行为探测"><a href="#异常行为探测" class="headerlink" title="异常行为探测"></a>异常行为探测</h5><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">区别内容</th>
<th style="text-align:center">异常探测机</th>
<th style="text-align:center">IDS</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">检测范围</td>
<td style="text-align:center">网络内部行为</td>
<td style="text-align:center">网络外部行为</td>
</tr>
<tr>
<td style="text-align:center">实现方式</td>
<td style="text-align:center">软件</td>
<td style="text-align:center">硬件</td>
</tr>
<tr>
<td style="text-align:center">与系统关系</td>
<td style="text-align:center">可以存取系统数据</td>
<td style="text-align:center">不能存取系统数据</td>
</tr>
<tr>
<td style="text-align:center">保护目标</td>
<td style="text-align:center">信息系统</td>
<td style="text-align:center">网路</td>
</tr>
</tbody>
</table>
</div>
<h5 id="异常行为"><a href="#异常行为" class="headerlink" title="异常行为"></a>异常行为</h5><p><strong>用户身份的攻击：</strong>非法用户针对用户ID进行攻击，试图猜测用户身份。</p>
<p><strong>口令攻击：</strong>在已知用户身份的情况下，猜测口令，进行口令攻击。</p>
<p><strong>服务器的异常访问：</strong>这里是指服务器计算机和WEB<br>SERER等专用服务程序。类似DOS攻击的方式在局域网内也是有可能发生的。</p>
<p><strong>数据库异常连接：</strong>对数据库的访问主要是通过特定端口进行的，可能的威胁来自合法的客户端程序或者非法的客户端程序。</p>
<p><strong>数据库文件变动异常：</strong>系统中数据库文件的变动包括文件访问、拷贝、删除等操作。</p>
<p><strong>日志文件攻击：</strong>针对日志文件发起的包括文件删除、修改等非法操作。</p>
<h5 id="日志分析"><a href="#日志分析" class="headerlink" title="日志分析"></a>日志分析</h5><p><strong>针对日志文件自身的攻击主要有：</strong></p>
<ul>
<li>日志数据的删除<ul>
<li>系统本身不向用户提供日志数据的删除功能。</li>
<li>针对非法用户的攻击，如果是单独的日志文件，当系统启动后，该文件置于异常探测机的保护之下</li>
<li>如果是数据库数据，则依赖于操作系统和数据库本身的保护机制。</li>
<li>无论是系统操作员还是系统管理员的合法用户不具有日志文件删除的能力，而来自于客户端和服务器端的非法用户受到异常探测机、操作系统、数据库系统的安全机制约束。</li>
</ul>
</li>
<li>日志数据的修改<ul>
<li>系统不向用户提供日志修改功能。日志浏览也作为重要功能进行授权。</li>
<li>由于单独的日志文件置于了异常探测机的保护之下，所以可以避免合法用户的修改。非法用户试图对记录于数据库中的日志数据进行修改时，则受到操作系统和数据库系统的约束。</li>
</ul>
</li>
</ul>
<h6 id="日志数据审计和异常模式"><a href="#日志数据审计和异常模式" class="headerlink" title="日志数据审计和异常模式"></a><strong>日志数据审计和异常模式</strong></h6><ol>
<li>手动审计</li>
<li>自动审计和报警</li>
</ol>
<h5 id="网络异常探测机"><a href="#网络异常探测机" class="headerlink" title="网络异常探测机"></a>网络异常探测机</h5><p>网络异常探测机的主要功能是针对来自网络的信息进行分析，提供对信息系统的保护报警。</p>
<p>探测器并不是通用的系统异常探测器。</p>
<p><strong>功能</strong>：数据流量检测、服务端口连接数量检测、文件访问限制、日志文件保护</p>
<h2 id="CH07WEB应用安全"><a href="#CH07WEB应用安全" class="headerlink" title="CH07WEB应用安全"></a>CH07WEB应用安全</h2><h3 id="WEB应用"><a href="#WEB应用" class="headerlink" title="WEB应用"></a>WEB应用</h3><h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><ul>
<li>采用HTTP协议完成通信的应用程序</li>
<li><p>与后台WEB Server实现交互的程序</p>
</li>
<li><p>与互联网（Internet）服务器，包括Web Server，database server进行交互的程序</p>
</li>
<li><p>位于中间层，进行数据交互或者其他服务程序</p>
</li>
</ul>
<h4 id="安全现状"><a href="#安全现状" class="headerlink" title="安全现状"></a>安全现状</h4><ul>
<li><p>实现WEB应用安全非常困难</p>
<ul>
<li>WEB应用环境包括多个系统</li>
<li>WEB应用大部分运行于INTERNET，具有更广的攻击面</li>
</ul>
</li>
<li><p>在WEB应用的运行中，具有更多的临时决策，以支持系统的运行，系统状态具有更多的可变性</p>
</li>
<li><p>许多支持系统没有得到恰当的保护</p>
</li>
</ul>
<h4 id="微软WEB应用安全框架"><a href="#微软WEB应用安全框架" class="headerlink" title="微软WEB应用安全框架"></a>微软WEB应用安全框架</h4><h5 id="WEB应用安全建模"><a href="#WEB应用安全建模" class="headerlink" title="WEB应用安全建模"></a>WEB应用安全建模</h5><p><strong>活动：</strong>Web 应用程序的威胁建模</p>
<p><strong>目的：</strong>确定方案中的相关威胁和漏洞，以帮助您构建应用程序的安全设计。</p>
<p><strong>输入：</strong> </p>
<p>•主要用例和使用方案<br>•数据流<br>•数据架构<br>•部署关系图 </p>
<p><strong>输出：</strong> </p>
<p>•威胁列表<br>•漏洞列表 </p>
<p><strong>五个步骤：</strong></p>
<p><strong>步骤</strong> <strong>1</strong> <strong>：确定安全目标。</strong>目标清晰有助于将注意力集中在威胁建模活动上，以及确定后续步骤要做多少工作。<br><strong>步骤</strong> <strong>2</strong> <strong>：创建应用程序概述。</strong>逐条列出应用程序的重要特征和参与者有助于在步骤 4 中确定相关威胁。<br><strong>步骤</strong> <strong>3</strong> <strong>：分解应用程序。</strong>全面了解应用程序的结构可以更轻松地发现更相关、更具体的威胁。<br><strong>步骤</strong> <strong>4</strong> <strong>：确定威胁。</strong>使用步骤 2 和 3 中的详细信息来确定与应用程序方案和上下文相关的威胁。<br><strong>步骤</strong> <strong>5</strong> <strong>：确定漏洞。</strong>检查应用程序的各层以确定与威胁有关的弱点。使用漏洞类别来帮助关注最常出现错误的区域。 </p>
<h5 id="WEB应用安全框架"><a href="#WEB应用安全框架" class="headerlink" title="WEB应用安全框架"></a>WEB应用安全框架</h5><p>输入和数据验证<br>身份验证<br>授权<br>配置管理<br>敏感数据<br>会话管理<br>加密<br>参数操作<br>异常管理<br>审核与记录</p>
<h5 id="一个WEB应用安全模型"><a href="#一个WEB应用安全模型" class="headerlink" title="一个WEB应用安全模型"></a>一个WEB应用安全模型</h5><p>威胁建模：一种用于理解和消除系统安全威胁的形式化的方法</p>
<p><strong>方法：</strong></p>
<p><strong>信息收集</strong></p>
<p>•定位文档（Locate written document）<br>•访问相关人员（Interview stakeholders）<br>•探查系统（Inspect system）</p>
<p><strong>分析</strong></p>
<p>•用户Users<br>•构件，资产，动机 Components, assets, and motivation<br>•入口 Entry points<br>•弱点和威胁 Weaknesses and threats</p>
<p><strong>威胁消除</strong></p>
<p>•建立预算 Establish your budget.<br>•排序处理 Rank treats using a model that works for you.<br>•确立针对威胁的工作 Decide what to do with threats.</p>
<p><strong>消除选择：</strong></p>
<p>•忽略 Ignore risk. (<strong>Popular choice!</strong>)<br>•消除 Mitigate risk：入侵代价昂贵、安全代价昂贵、能够承受？<br>•接受 Accept risk.</p>
<p><strong>消除策略：</strong></p>
<p>•移除入口点.<br>•减少攻击面.<br>•区分.<br>•最小优先权原则</p>
<p><strong>消除技巧：</strong></p>
<p>•不要过度宽泛以避免不能自拔。建立子模型分支以处理复杂性。<br>•多数WEB APP具有共性-开发可重用的威胁模型库。<br>•由一个草稿开始（scratch），并且不要做任何假定。消除多数明显的（foolproof）威胁将导致简单的操作过程.</p>
<h2 id="CH08安全工程过程模型"><a href="#CH08安全工程过程模型" class="headerlink" title="CH08安全工程过程模型"></a>CH08安全工程过程模型</h2><h3 id="核心工作"><a href="#核心工作" class="headerlink" title="核心工作"></a>核心工作</h3><p>①安全目标定义<br>②敏感数据分析<br>③威胁分析<br>④安全设计<br>⑤受攻击面分析<br>⑥安全实现<br>⑦安全测试<br>⑧安全维护</p>
<h3 id="过程模型"><a href="#过程模型" class="headerlink" title="过程模型"></a>过程模型</h3><p><img src="/2019/06/14/%E8%BD%AF%E4%BB%B6%E5%AE%89%E5%85%A8%E8%AE%BE%E8%AE%A1/2.png" alt></p>
<h3 id="过程实施要点"><a href="#过程实施要点" class="headerlink" title="过程实施要点"></a>过程实施要点</h3><h4 id="安全实施能力培养"><a href="#安全实施能力培养" class="headerlink" title="安全实施能力培养"></a>安全实施能力培养</h4><p>团队安全能力范畴：<br>①软件安全的概念与意识；<br>②典型安全问题；<br>③开发语言的安全问题与工具；<br>④安全设计方法；<br>⑤数据及其敏感性；<br>⑥攻击面；<br>⑦威胁建模与分析；<br>⑧信息安全法律与政策；</p>
<h4 id="安全目标定义"><a href="#安全目标定义" class="headerlink" title="安全目标定义"></a>安全目标定义</h4><p>确定本项目需要达到的安全目标。形成规范的文档，作为工程过程中的指导原则。<br>安全目标定义应包括的内容：</p>
<p>①软件名称；<br>②软件开发目标及主要功能概述；<br>③软件主要用户及其分析；<br>④软件的关键信息与数据；<br>⑤软件各个部分及其总体需要达到的安全水平。</p>
<h4 id="资源及敏感数据分析"><a href="#资源及敏感数据分析" class="headerlink" title="资源及敏感数据分析"></a>资源及敏感数据分析</h4><p>确定本项目实施中所涉及的敏感数据，进行分类，给出明确的定义和敏感程度，以及保护措施。<br>软件操作的资源：网络端口，文件，服务器，URL，数据库…<br>软件操作的主要数据：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">数据名</th>
<th style="text-align:center">类型</th>
<th style="text-align:center">作用</th>
<th style="text-align:center">敏感程度</th>
<th style="text-align:center">安全要求</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
</div>
<h4 id="威胁分析"><a href="#威胁分析" class="headerlink" title="威胁分析"></a>威胁分析</h4><p>分析系统用户，部署，功能，确定系统威胁来源。<br>明确：系统关键工程，部署，各个部分及功能用户</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">威胁名称</th>
<th style="text-align:center">威胁来源</th>
<th style="text-align:center">说明</th>
<th style="text-align:center">重要程度</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
</div>
<h4 id="安全设计-1"><a href="#安全设计-1" class="headerlink" title="安全设计"></a>安全设计</h4><p>根据安全目标，敏感数据，威胁分析的内容，实现安全设计。包括架构，安全问题的应对措施等。<br>需明确：<br>①系统架构与安全性问题<br>②安全问题及其应对措施<br>③架构与安全目标的响应<br>④敏感数据的保护措施<br>⑤威胁的应对措施</p>
<h4 id="受攻击面分析"><a href="#受攻击面分析" class="headerlink" title="受攻击面分析"></a>受攻击面分析</h4><p>与安全设计对应，根据设计的架构，以及敏感信息，对受攻击面及攻击路径进行分析。<br>典型的受攻击面包括：端口，数据，文件…</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">攻击面</th>
<th style="text-align:center">类别</th>
<th style="text-align:center">威胁来源</th>
<th style="text-align:center">重要程度</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
</div>
<h4 id="安全实现"><a href="#安全实现" class="headerlink" title="安全实现"></a>安全实现</h4><h4 id="安全测试"><a href="#安全测试" class="headerlink" title="安全测试"></a>安全测试</h4><h4 id="安全维护"><a href="#安全维护" class="headerlink" title="安全维护"></a>安全维护</h4>]]></content>
      <categories>
        <category>大二</category>
      </categories>
      <tags>
        <tag>软件安全</tag>
      </tags>
  </entry>
</search>
